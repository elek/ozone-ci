2019-09-25 02:20:29,592 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:29,686 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:29,689 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:29,703 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @846ms
2019-09-25 02:20:29,782 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-25 02:20:29,782 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-25 02:20:29,782 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-25 02:20:29,783 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-25 02:20:29,783 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-25 02:20:29,783 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-25 02:20:29,792 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 02:20:29,792 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 02:20:29,793 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 02:20:30,195 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@411f53a0
2019-09-25 02:20:30,198 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-25 02:20:30,265 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 02:20:30,267 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 02:20:30,269 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-25 02:20:30,336 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-25 02:20:30,350 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:30,503 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-25 02:20:30,506 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:30,700 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-25 02:20:31,027 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:20:31,054 [Socket Reader #1 for port 44400] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44400
2019-09-25 02:20:31,189 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:20:31,190 [Socket Reader #1 for port 38175] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38175
2019-09-25 02:20:31,202 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:20:31,203 [Socket Reader #1 for port 45438] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45438
2019-09-25 02:20:31,232 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-25 02:20:31,351 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:31,367 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:31,376 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:31,379 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-25 02:20:31,379 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:31,379 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:31,406 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:45438
2019-09-25 02:20:31,456 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-25 02:20:31,469 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-25 02:20:31,470 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-25 02:20:31,683 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:45438
2019-09-25 02:20:31,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:20:31,684 [IPC Server listener on 45438] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45438: starting
2019-09-25 02:20:31,691 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38175
2019-09-25 02:20:31,693 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:38175
2019-09-25 02:20:31,693 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:20:31,693 [IPC Server listener on 38175] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38175: starting
2019-09-25 02:20:31,703 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44400
2019-09-25 02:20:31,704 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:44400
2019-09-25 02:20:31,705 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:20:31,706 [IPC Server listener on 44400] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44400: starting
2019-09-25 02:20:31,720 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35877
2019-09-25 02:20:31,723 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:31,771 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:31,772 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:31,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@544630b7{/,file:///tmp/jetty-0.0.0.0-35877-scm-_-any-4199535999834789007.dir/webapp/,AVAILABLE}{/scm}
2019-09-25 02:20:31,853 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:35877}
2019-09-25 02:20:31,853 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2996ms
2019-09-25 02:20:31,856 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-25 02:20:31,856 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-25 02:20:31,857 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:35877
2019-09-25 02:20:31,867 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@790174f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:31,872 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:32,007 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(181)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-25 02:20:32,008 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(211)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-25 02:20:32,009 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:32,010 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:32,698 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:20:32,706 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-25 02:20:32,706 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-25 02:20:32,707 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-25 02:20:32,707 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-25 02:20:32,707 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-25 02:20:32,707 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-25 02:20:32,708 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-25 02:20:32,708 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-25 02:20:32,708 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-25 02:20:32,708 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-25 02:20:32,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-25 02:20:32,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-25 02:20:32,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-25 02:20:32,709 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-25 02:20:32,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-25 02:20:32,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-25 02:20:32,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-25 02:20:32,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-25 02:20:32,710 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-25 02:20:32,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-25 02:20:32,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-25 02:20:32,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-25 02:20:32,711 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 02:20:32,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 02:20:32,712 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 02:20:33,536 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:20:33,538 [Socket Reader #1 for port 43017] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43017
2019-09-25 02:20:33,560 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:43017
2019-09-25 02:20:33,560 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-25 02:20:33,562 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:20:33,568 [IPC Server listener on 43017] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43017: starting
2019-09-25 02:20:33,580 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-25 02:20:33,583 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:33,584 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:33,587 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:33,588 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-25 02:20:33,588 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:33,589 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:33,592 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34419
2019-09-25 02:20:33,592 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:33,595 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:33,596 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:33,663 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27fde870{/,file:///tmp/jetty-0.0.0.0-34419-ozoneManager-_-any-8005986897521626494.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-25 02:20:33,663 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:34419}
2019-09-25 02:20:33,664 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4807ms
2019-09-25 02:20:33,665 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:33,666 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:34419
2019-09-25 02:20:33,991 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:20:34,064 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:20:34,104 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:20:34,106 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/containers/hdds to VolumeSet
2019-09-25 02:20:34,110 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-25 02:20:34,129 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-25 02:20:34,163 [main] WARN  impl.ChunkManagerFactory (ChunkManagerFactory.java:createChunkManager(83)) - hdds.container.chunk.persistdata is set to false. This should be used only for testing. All user data will be discarded.
2019-09-25 02:20:34,238 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:20:34,306 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:20:34,310 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:20:34,311 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:20:34,313 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:34,314 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:20:34,314 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:34,522 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis] (custom)
2019-09-25 02:20:34,591 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:20:34,595 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:34,597 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:34,600 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:34,602 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:20:34,602 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:34,602 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:34,605 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36776
2019-09-25 02:20:34,606 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:34,609 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6edcad64{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:34,610 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e33d73e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:34,655 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd64ee8{/,file:///tmp/jetty-0.0.0.0-36776-hddsDatanode-_-any-1290780990679577374.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:20:34,656 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@620c8641{HTTP/1.1,[http/1.1]}{0.0.0.0:36776}
2019-09-25 02:20:34,661 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5803ms
2019-09-25 02:20:34,661 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:34,662 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36776
2019-09-25 02:20:34,663 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:20:34,669 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:20:34,670 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2db5142c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:34,679 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:20:34,680 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/containers/hdds to VolumeSet
2019-09-25 02:20:34,681 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3c3a0032
2019-09-25 02:20:34,683 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3c3a0032
2019-09-25 02:20:34,702 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:20:34,703 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:20:34,703 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:20:34,703 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:20:34,704 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:34,704 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:20:34,704 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:34,705 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis] (custom)
2019-09-25 02:20:34,707 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:20:34,708 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:34,709 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:34,711 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:34,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:20:34,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:34,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:34,713 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38307
2019-09-25 02:20:34,713 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:34,720 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@524a076e{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:34,720 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62dbe64e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:34,757 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@726aa968{/,file:///tmp/jetty-0.0.0.0-38307-hddsDatanode-_-any-6289865532646420355.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:20:34,758 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7100dea{HTTP/1.1,[http/1.1]}{0.0.0.0:38307}
2019-09-25 02:20:34,758 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5901ms
2019-09-25 02:20:34,759 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:34,761 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38307
2019-09-25 02:20:34,761 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:20:34,765 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e240c5c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:34,767 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:20:34,776 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:20:34,777 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/containers/hdds to VolumeSet
2019-09-25 02:20:34,777 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@56da7487
2019-09-25 02:20:34,779 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@56da7487
2019-09-25 02:20:34,799 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:20:34,799 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:20:34,799 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:20:34,800 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:20:34,800 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:34,800 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:20:34,801 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:34,801 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis] (custom)
2019-09-25 02:20:34,803 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/meta/datanode.id
2019-09-25 02:20:34,805 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:20:34,807 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/meta/datanode.id
2019-09-25 02:20:34,808 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:34,809 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:34,812 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:34,813 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:20:34,813 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:34,813 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:34,814 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38301
2019-09-25 02:20:34,815 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:34,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74174a23{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:34,818 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@dc4a691{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:34,860 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1305c126{/,file:///tmp/jetty-0.0.0.0-38301-hddsDatanode-_-any-6189782033186026519.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:20:34,860 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72f9f27c{HTTP/1.1,[http/1.1]}{0.0.0.0:38301}
2019-09-25 02:20:34,861 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6004ms
2019-09-25 02:20:34,862 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:34,863 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38301
2019-09-25 02:20:34,864 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:20:34,867 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:20:34,867 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42673db6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:34,870 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/meta/datanode.id
2019-09-25 02:20:34,876 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:20:34,876 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/containers/hdds to VolumeSet
2019-09-25 02:20:34,876 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6caf7803
2019-09-25 02:20:34,877 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6caf7803
2019-09-25 02:20:34,893 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:20:34,894 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:20:34,894 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:20:34,894 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:20:34,894 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:34,895 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:20:34,895 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:34,896 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis] (custom)
2019-09-25 02:20:34,897 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:20:34,899 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:34,899 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:34,901 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:34,901 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:20:34,902 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:34,902 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:34,903 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37722
2019-09-25 02:20:34,903 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:34,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18b8d173{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:34,908 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44f24a20{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:34,937 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1457fde{/,file:///tmp/jetty-0.0.0.0-37722-hddsDatanode-_-any-7904124891268762751.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:20:34,937 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f94fb9d{HTTP/1.1,[http/1.1]}{0.0.0.0:37722}
2019-09-25 02:20:34,938 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6081ms
2019-09-25 02:20:34,938 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:34,939 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37722
2019-09-25 02:20:34,940 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:20:34,943 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:20:34,943 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b9091bd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:34,946 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/meta/datanode.id
2019-09-25 02:20:34,952 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:20:34,952 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/containers/hdds to VolumeSet
2019-09-25 02:20:34,952 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@16727bf0
2019-09-25 02:20:34,953 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@16727bf0
2019-09-25 02:20:34,968 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:20:34,968 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:20:34,968 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:20:34,968 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:20:34,968 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:34,969 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:20:34,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:34,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis] (custom)
2019-09-25 02:20:34,971 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:20:34,972 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:20:34,973 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:20:34,974 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:20:34,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:20:34,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:20:34,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:20:34,976 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35181
2019-09-25 02:20:34,976 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:20:34,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56637cff{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:20:34,979 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@127a7272{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:20:35,020 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12eedfee{/,file:///tmp/jetty-0.0.0.0-35181-hddsDatanode-_-any-3347642044896944044.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:20:35,021 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c3c4a71{HTTP/1.1,[http/1.1]}{0.0.0.0:35181}
2019-09-25 02:20:35,022 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6165ms
2019-09-25 02:20:35,022 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:20:35,023 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35181
2019-09-25 02:20:35,026 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:20:35,027 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26f6508e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:20:35,030 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/meta/datanode.id
2019-09-25 02:20:36,027 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:20:36,760 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:20:36,762 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:20:36,762 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 4c28c950-4d04-48e8-8fcc-397e6ff40a31 at port 0
2019-09-25 02:20:36,793 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start RPC server
2019-09-25 02:20:36,794 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:20:36,796 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:20:36,798 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis edc859c7-011f-4754-b289-08dca9617ef0 at port 0
2019-09-25 02:20:36,812 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - edc859c7-011f-4754-b289-08dca9617ef0: start RPC server
2019-09-25 02:20:36,891 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:20:36,893 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:20:36,894 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis de7fcbf2-7885-458b-afd3-c390059290a4 at port 0
2019-09-25 02:20:36,903 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - de7fcbf2-7885-458b-afd3-c390059290a4: start RPC server
2019-09-25 02:20:36,973 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:20:36,975 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:20:36,975 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 078a6b74-f6bd-4459-ac8a-c915d0e21e4a at port 0
2019-09-25 02:20:36,978 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - de7fcbf2-7885-458b-afd3-c390059290a4: GrpcService started, listening on 0.0.0.0/0.0.0.0:36095
2019-09-25 02:20:36,978 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: GrpcService started, listening on 0.0.0.0/0.0.0.0:38050
2019-09-25 02:20:36,978 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - edc859c7-011f-4754-b289-08dca9617ef0: GrpcService started, listening on 0.0.0.0/0.0.0.0:43388
2019-09-25 02:20:36,980 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 4c28c950-4d04-48e8-8fcc-397e6ff40a31 is started using port 38050
2019-09-25 02:20:36,980 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis de7fcbf2-7885-458b-afd3-c390059290a4 is started using port 36095
2019-09-25 02:20:36,980 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis edc859c7-011f-4754-b289-08dca9617ef0 is started using port 43388
2019-09-25 02:20:36,992 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc edc859c7-011f-4754-b289-08dca9617ef0 is started using port 39564
2019-09-25 02:20:36,992 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc de7fcbf2-7885-458b-afd3-c390059290a4 is started using port 40309
2019-09-25 02:20:36,992 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 4c28c950-4d04-48e8-8fcc-397e6ff40a31 is started using port 40529
2019-09-25 02:20:36,997 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: start RPC server
2019-09-25 02:20:37,001 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: GrpcService started, listening on 0.0.0.0/0.0.0.0:43991
2019-09-25 02:20:37,001 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 078a6b74-f6bd-4459-ac8a-c915d0e21e4a is started using port 43991
2019-09-25 02:20:37,009 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 078a6b74-f6bd-4459-ac8a-c915d0e21e4a is started using port 45281
2019-09-25 02:20:37,030 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:20:37,055 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:20:37,061 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:20:37,061 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0 at port 0
2019-09-25 02:20:37,072 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start RPC server
2019-09-25 02:20:37,076 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: GrpcService started, listening on 0.0.0.0/0.0.0.0:38655
2019-09-25 02:20:37,076 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0 is started using port 38655
2019-09-25 02:20:37,080 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0 is started using port 32814
2019-09-25 02:20:38,030 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:20:38,711 [IPC Server handler 15 on 44400] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:20:38,714 [IPC Server handler 15 on 44400] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 4c28c950-4d04-48e8-8fcc-397e6ff40a31{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:20:38,718 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-25 02:20:38,718 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-25 02:20:38,718 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-25 02:20:38,771 [IPC Server handler 13 on 44400] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:20:38,772 [IPC Server handler 13 on 44400] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : edc859c7-011f-4754-b289-08dca9617ef0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:20:38,870 [IPC Server handler 19 on 44400] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/de7fcbf2-7885-458b-afd3-c390059290a4
2019-09-25 02:20:38,870 [IPC Server handler 19 on 44400] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : de7fcbf2-7885-458b-afd3-c390059290a4{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:20:38,947 [IPC Server handler 18 on 44400] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/078a6b74-f6bd-4459-ac8a-c915d0e21e4a
2019-09-25 02:20:38,947 [IPC Server handler 18 on 44400] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 078a6b74-f6bd-4459-ac8a-c915d0e21e4a{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:20:39,030 [IPC Server handler 16 on 44400] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0
2019-09-25 02:20:39,031 [IPC Server handler 16 on 44400] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:20:39,031 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-25 02:20:39,037 [main] INFO  freon.TestDataValidate (TestDataValidateWithDummyContainers.java:validateWriteTest(64)) - Skipping validateWriteTest for non-persistent containers.
2019-09-25 02:20:39,045 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-25 02:20:39,300 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: addNew group-303FE9DC1D00:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050] returns group-303FE9DC1D00:java.util.concurrent.CompletableFuture@1007c462[Not completed]
2019-09-25 02:20:39,322 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: new RaftServerImpl for group-303FE9DC1D00:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050] with ContainerStateMachine:uninitialized
2019-09-25 02:20:39,324 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:39,325 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:39,325 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:39,326 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:39,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:39,340 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: ConfigurationManager, init=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:39,341 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis] (custom)
2019-09-25 02:20:39,348 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/7cfdb202-be64-4ad9-a4f8-303fe9dc1d00 does not exist. Creating ...
2019-09-25 02:20:39,376 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/7cfdb202-be64-4ad9-a4f8-303fe9dc1d00/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:39,402 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/7cfdb202-be64-4ad9-a4f8-303fe9dc1d00 has been successfully formatted.
2019-09-25 02:20:39,405 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-303FE9DC1D00: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:39,405 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:39,407 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:39,413 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:39,413 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:39,415 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,419 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:39,427 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/7cfdb202-be64-4ad9-a4f8-303fe9dc1d00
2019-09-25 02:20:39,428 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-25 02:20:39,434 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-25 02:20:39,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:39,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:39,466 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,467 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:39,467 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:39,468 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:39,468 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:39,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:39,469 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:39,478 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:39,482 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:39,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:39,489 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:39,490 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:39,490 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:39,516 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: start as a follower, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050], old=null
2019-09-25 02:20:39,518 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:39,519 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start FollowerState
2019-09-25 02:20:39,520 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-303FE9DC1D00,id=4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:20:39,584 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7cfdb202-be64-4ad9-a4f8-303fe9dc1d00, Nodes: 4c28c950-4d04-48e8-8fcc-397e6ff40a31{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:20:39,607 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - edc859c7-011f-4754-b289-08dca9617ef0: addNew group-716DF9FF857E:[edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] returns group-716DF9FF857E:java.util.concurrent.CompletableFuture@72cf142c[Not completed]
2019-09-25 02:20:39,651 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - edc859c7-011f-4754-b289-08dca9617ef0: new RaftServerImpl for group-716DF9FF857E:[edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] with ContainerStateMachine:uninitialized
2019-09-25 02:20:39,652 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:39,653 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:39,653 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:39,653 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:39,654 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:39,654 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: ConfigurationManager, init=-1: [edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:39,654 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis] (custom)
2019-09-25 02:20:39,655 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/26f96bc6-01fc-43a6-af4c-716df9ff857e does not exist. Creating ...
2019-09-25 02:20:39,681 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/26f96bc6-01fc-43a6-af4c-716df9ff857e/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:39,694 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/26f96bc6-01fc-43a6-af4c-716df9ff857e has been successfully formatted.
2019-09-25 02:20:39,696 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-716DF9FF857E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:39,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:39,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:39,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:39,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:39,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,699 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:39,699 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/26f96bc6-01fc-43a6-af4c-716df9ff857e
2019-09-25 02:20:39,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:39,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:39,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:39,708 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:39,708 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:39,709 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:39,709 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:39,709 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:39,709 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:39,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:39,715 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: start as a follower, conf=-1: [edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:39,715 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:39,715 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start FollowerState
2019-09-25 02:20:39,717 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-716DF9FF857E,id=edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:20:39,738 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 26f96bc6-01fc-43a6-af4c-716df9ff857e, Nodes: edc859c7-011f-4754-b289-08dca9617ef0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:20:39,759 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: addNew group-C85AAA813928:[b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655] returns group-C85AAA813928:java.util.concurrent.CompletableFuture@61230bd3[Not completed]
2019-09-25 02:20:39,779 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: new RaftServerImpl for group-C85AAA813928:[b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655] with ContainerStateMachine:uninitialized
2019-09-25 02:20:39,779 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:39,779 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:39,779 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:39,780 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:39,780 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:39,780 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: ConfigurationManager, init=-1: [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:39,780 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis] (custom)
2019-09-25 02:20:39,781 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/080d0f63-3706-46dc-8056-c85aaa813928 does not exist. Creating ...
2019-09-25 02:20:39,793 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/080d0f63-3706-46dc-8056-c85aaa813928/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:39,806 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/080d0f63-3706-46dc-8056-c85aaa813928 has been successfully formatted.
2019-09-25 02:20:39,806 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C85AAA813928: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:39,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:39,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:39,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:39,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:39,807 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,808 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:39,808 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/080d0f63-3706-46dc-8056-c85aaa813928
2019-09-25 02:20:39,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:39,845 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:39,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:39,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:39,846 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:39,847 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:39,847 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:39,847 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:39,847 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:39,848 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:39,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:39,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:39,848 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:39,849 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:39,854 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: start as a follower, conf=-1: [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655], old=null
2019-09-25 02:20:39,854 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:39,854 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start FollowerState
2019-09-25 02:20:39,855 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C85AAA813928,id=b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0
2019-09-25 02:20:39,865 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 080d0f63-3706-46dc-8056-c85aaa813928, Nodes: b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:20:39,886 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - de7fcbf2-7885-458b-afd3-c390059290a4: addNew group-33DE4CAFEC20:[de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095] returns group-33DE4CAFEC20:java.util.concurrent.CompletableFuture@2cf2b5a6[Not completed]
2019-09-25 02:20:39,888 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - de7fcbf2-7885-458b-afd3-c390059290a4: new RaftServerImpl for group-33DE4CAFEC20:[de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095] with ContainerStateMachine:uninitialized
2019-09-25 02:20:39,888 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:39,888 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:39,889 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:39,889 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:39,889 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:39,889 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: ConfigurationManager, init=-1: [de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:39,889 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis] (custom)
2019-09-25 02:20:39,890 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis/94b4fec8-7855-408e-bcd5-33de4cafec20 does not exist. Creating ...
2019-09-25 02:20:39,902 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis/94b4fec8-7855-408e-bcd5-33de4cafec20/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:39,915 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis/94b4fec8-7855-408e-bcd5-33de4cafec20 has been successfully formatted.
2019-09-25 02:20:39,915 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-33DE4CAFEC20: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:39,916 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis/94b4fec8-7855-408e-bcd5-33de4cafec20
2019-09-25 02:20:39,920 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:39,920 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:39,921 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:39,922 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:39,922 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:39,922 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:39,923 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:39,923 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:39,923 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:39,923 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:39,927 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: start as a follower, conf=-1: [de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095], old=null
2019-09-25 02:20:39,927 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:39,927 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de7fcbf2-7885-458b-afd3-c390059290a4: start FollowerState
2019-09-25 02:20:39,927 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-33DE4CAFEC20,id=de7fcbf2-7885-458b-afd3-c390059290a4
2019-09-25 02:20:39,938 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 94b4fec8-7855-408e-bcd5-33de4cafec20, Nodes: de7fcbf2-7885-458b-afd3-c390059290a4{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:20:39,964 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: addNew group-051D6C14F65E:[078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991] returns group-051D6C14F65E:java.util.concurrent.CompletableFuture@532d04d5[Not completed]
2019-09-25 02:20:39,966 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: new RaftServerImpl for group-051D6C14F65E:[078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991] with ContainerStateMachine:uninitialized
2019-09-25 02:20:39,966 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:39,966 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:39,967 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:39,967 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:39,967 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:39,967 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: ConfigurationManager, init=-1: [078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:39,967 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis] (custom)
2019-09-25 02:20:39,968 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis/99636279-33bf-43d6-a39d-051d6c14f65e does not exist. Creating ...
2019-09-25 02:20:39,992 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis/99636279-33bf-43d6-a39d-051d6c14f65e/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:40,005 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis/99636279-33bf-43d6-a39d-051d6c14f65e has been successfully formatted.
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-051D6C14F65E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,006 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:40,007 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis/99636279-33bf-43d6-a39d-051d6c14f65e
2019-09-25 02:20:40,009 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:40,009 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:40,009 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:40,010 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:40,011 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:40,011 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:40,011 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:40,011 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:40,011 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:40,015 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: start as a follower, conf=-1: [078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991], old=null
2019-09-25 02:20:40,015 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:40,016 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: start FollowerState
2019-09-25 02:20:40,016 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-051D6C14F65E,id=078a6b74-f6bd-4459-ac8a-c915d0e21e4a
2019-09-25 02:20:40,028 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 99636279-33bf-43d6-a39d-051d6c14f65e, Nodes: 078a6b74-f6bd-4459-ac8a-c915d0e21e4a{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:20:40,079 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: addNew group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] returns group-6665E224A542:java.util.concurrent.CompletableFuture@56cb7329[Not completed]
2019-09-25 02:20:40,082 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: addNew group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] returns group-6665E224A542:java.util.concurrent.CompletableFuture@77846f7e[Not completed]
2019-09-25 02:20:40,082 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - edc859c7-011f-4754-b289-08dca9617ef0: addNew group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] returns group-6665E224A542:java.util.concurrent.CompletableFuture@32390e19[Not completed]
2019-09-25 02:20:40,083 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: new RaftServerImpl for group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] with ContainerStateMachine:uninitialized
2019-09-25 02:20:40,083 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:40,083 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:40,083 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:40,084 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:40,084 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:40,084 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: ConfigurationManager, init=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:40,084 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis] (custom)
2019-09-25 02:20:40,084 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: new RaftServerImpl for group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] with ContainerStateMachine:uninitialized
2019-09-25 02:20:40,085 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 does not exist. Creating ...
2019-09-25 02:20:40,085 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:40,085 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:40,085 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:40,085 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:40,085 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:40,086 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - edc859c7-011f-4754-b289-08dca9617ef0: new RaftServerImpl for group-6665E224A542:[4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388] with ContainerStateMachine:uninitialized
2019-09-25 02:20:40,086 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: ConfigurationManager, init=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:40,086 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:20:40,086 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis] (custom)
2019-09-25 02:20:40,086 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:20:40,086 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:20:40,087 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 does not exist. Creating ...
2019-09-25 02:20:40,087 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:20:40,087 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:40,087 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: ConfigurationManager, init=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null, confs=<EMPTY_MAP>
2019-09-25 02:20:40,087 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis] (custom)
2019-09-25 02:20:40,088 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 does not exist. Creating ...
2019-09-25 02:20:40,101 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:40,101 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:40,101 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/in_use.lock acquired by nodename 17031@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:20:40,125 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 has been successfully formatted.
2019-09-25 02:20:40,125 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 has been successfully formatted.
2019-09-25 02:20:40,125 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542 has been successfully formatted.
2019-09-25 02:20:40,125 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6665E224A542: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:40,125 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6665E224A542: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:40,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:40,126 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6665E224A542: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:20:40,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:40,126 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:40,126 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:40,126 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:20:40,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:40,126 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:40,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,127 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:20:40,127 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:40,127 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:40,128 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542
2019-09-25 02:20:40,127 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:20:40,128 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:40,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:40,128 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:40,128 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:40,129 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,128 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,129 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:40,129 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,129 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:40,129 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:40,130 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:40,129 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:20:40,130 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:40,130 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542
2019-09-25 02:20:40,130 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:40,130 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542
2019-09-25 02:20:40,131 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:40,130 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:40,131 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:40,131 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:20:40,131 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:40,131 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:20:40,131 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:40,132 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,132 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:20:40,132 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:40,132 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:40,132 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:40,132 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:20:40,133 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:40,133 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:40,133 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:40,133 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:20:40,133 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:40,134 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:20:40,134 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:40,134 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:20:40,134 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:40,134 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:20:40,135 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:40,135 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:20:40,135 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:40,135 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:20:40,136 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:40,136 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:20:40,136 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:40,136 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:20:40,136 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:40,136 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:20:40,137 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:40,137 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:20:40,137 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:40,137 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:20:40,138 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: start as a follower, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:40,138 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:40,138 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start FollowerState
2019-09-25 02:20:40,139 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:20:40,146 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: start as a follower, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:40,146 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:40,146 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: start as a follower, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:40,147 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start FollowerState
2019-09-25 02:20:40,148 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:20:40,149 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start FollowerState
2019-09-25 02:20:40,149 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0
2019-09-25 02:20:40,150 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:20:40,173 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 539af5cf-a96c-467f-bc78-6665e224a542, Nodes: edc859c7-011f-4754-b289-08dca9617ef0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}4c28c950-4d04-48e8-8fcc-397e6ff40a31{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-25 02:20:40,287 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:41,288 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:41,725 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-25 02:20:41,730 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-25 02:20:42,290 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:43,291 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:44,293 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:44,523 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31:group-303FE9DC1D00 changes to CANDIDATE, lastRpcTime:5004, electionTimeout:5004ms
2019-09-25 02:20:44,528 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown FollowerState
2019-09-25 02:20:44,528 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:44,535 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start LeaderElection
2019-09-25 02:20:44,565 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1: begin an election at term 1 for -1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050], old=null
2019-09-25 02:20:44,567 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown LeaderElection
2019-09-25 02:20:44,568 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:44,568 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: change Leader from null to 4c28c950-4d04-48e8-8fcc-397e6ff40a31 at term 1 for becomeLeader, leader elected after 5163ms
2019-09-25 02:20:44,578 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:44,578 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:44,582 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:44,585 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:44,585 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:44,586 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:44,601 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start LeaderState
2019-09-25 02:20:44,628 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:44,637 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: set configuration 0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050], old=null at 0
2019-09-25 02:20:44,794 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - edc859c7-011f-4754-b289-08dca9617ef0:group-716DF9FF857E changes to CANDIDATE, lastRpcTime:5079, electionTimeout:5077ms
2019-09-25 02:20:44,796 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown FollowerState
2019-09-25 02:20:44,796 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:44,797 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start LeaderElection
2019-09-25 02:20:44,825 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2: begin an election at term 1 for -1: [edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:44,841 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown LeaderElection
2019-09-25 02:20:44,841 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:44,841 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: change Leader from null to edc859c7-011f-4754-b289-08dca9617ef0 at term 1 for becomeLeader, leader elected after 5143ms
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:44,844 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:44,848 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start LeaderState
2019-09-25 02:20:44,848 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:44,849 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: set configuration 0: [edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 0
2019-09-25 02:20:44,868 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/7cfdb202-be64-4ad9-a4f8-303fe9dc1d00/current/log_inprogress_0
2019-09-25 02:20:44,870 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/26f96bc6-01fc-43a6-af4c-716df9ff857e/current/log_inprogress_0
2019-09-25 02:20:44,954 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:group-C85AAA813928 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5099ms
2019-09-25 02:20:44,954 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown FollowerState
2019-09-25 02:20:44,954 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:44,954 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start LeaderElection
2019-09-25 02:20:44,981 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3: begin an election at term 1 for -1: [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655], old=null
2019-09-25 02:20:44,981 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown LeaderElection
2019-09-25 02:20:44,981 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:44,982 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: change Leader from null to b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0 at term 1 for becomeLeader, leader elected after 5174ms
2019-09-25 02:20:44,984 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:44,984 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:44,985 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:44,985 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:44,985 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:44,985 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:44,988 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start LeaderState
2019-09-25 02:20:44,988 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:44,989 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: set configuration 0: [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655], old=null at 0
2019-09-25 02:20:45,027 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/080d0f63-3706-46dc-8056-c85aaa813928/current/log_inprogress_0
2019-09-25 02:20:45,072 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - de7fcbf2-7885-458b-afd3-c390059290a4:group-33DE4CAFEC20 changes to CANDIDATE, lastRpcTime:5145, electionTimeout:5145ms
2019-09-25 02:20:45,073 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - de7fcbf2-7885-458b-afd3-c390059290a4: shutdown FollowerState
2019-09-25 02:20:45,073 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:45,073 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de7fcbf2-7885-458b-afd3-c390059290a4: start LeaderElection
2019-09-25 02:20:45,102 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4: begin an election at term 1 for -1: [de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095], old=null
2019-09-25 02:20:45,102 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - de7fcbf2-7885-458b-afd3-c390059290a4: shutdown LeaderElection
2019-09-25 02:20:45,102 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:45,102 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: change Leader from null to de7fcbf2-7885-458b-afd3-c390059290a4 at term 1 for becomeLeader, leader elected after 5186ms
2019-09-25 02:20:45,104 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:45,104 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:45,105 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:45,105 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:45,105 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:45,105 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:45,110 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - de7fcbf2-7885-458b-afd3-c390059290a4: start LeaderState
2019-09-25 02:20:45,110 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:45,111 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: set configuration 0: [de7fcbf2-7885-458b-afd3-c390059290a4:192.168.151.66:36095], old=null at 0
2019-09-25 02:20:45,140 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a:group-051D6C14F65E changes to CANDIDATE, lastRpcTime:5124, electionTimeout:5124ms
2019-09-25 02:20:45,140 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: shutdown FollowerState
2019-09-25 02:20:45,141 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:45,141 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: start LeaderElection
2019-09-25 02:20:45,158 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/ratis/94b4fec8-7855-408e-bcd5-33de4cafec20/current/log_inprogress_0
2019-09-25 02:20:45,159 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5: begin an election at term 1 for -1: [078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991], old=null
2019-09-25 02:20:45,159 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: shutdown LeaderElection
2019-09-25 02:20:45,159 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:45,159 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: change Leader from null to 078a6b74-f6bd-4459-ac8a-c915d0e21e4a at term 1 for becomeLeader, leader elected after 5153ms
2019-09-25 02:20:45,161 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:45,161 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:45,161 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:45,162 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:45,162 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:45,162 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:45,165 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: start LeaderState
2019-09-25 02:20:45,166 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:45,166 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: set configuration 0: [078a6b74-f6bd-4459-ac8a-c915d0e21e4a:192.168.151.66:43991], old=null at 0
2019-09-25 02:20:45,186 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(106)) - edc859c7-011f-4754-b289-08dca9617ef0:group-6665E224A542 changes to CANDIDATE, lastRpcTime:5037, electionTimeout:5026ms
2019-09-25 02:20:45,186 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown FollowerState
2019-09-25 02:20:45,186 [Thread-231] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:45,187 [Thread-231] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start LeaderElection
2019-09-25 02:20:45,209 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/ratis/99636279-33bf-43d6-a39d-051d6c14f65e/current/log_inprogress_0
2019-09-25 02:20:45,209 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6: begin an election at term 1 for -1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:45,231 [Thread-228] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31:group-6665E224A542 changes to CANDIDATE, lastRpcTime:5093, electionTimeout:5092ms
2019-09-25 02:20:45,232 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown FollowerState
2019-09-25 02:20:45,234 [Thread-228] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:20:45,234 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start LeaderElection
2019-09-25 02:20:45,250 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:20:45,250 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown FollowerState
2019-09-25 02:20:45,251 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start FollowerState
2019-09-25 02:20:45,251 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(115)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:20:45,263 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7: begin an election at term 1 for -1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:45,296 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:45,301 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6: Election PASSED; received 2 response(s) [edc859c7-011f-4754-b289-08dca9617ef0<-4c28c950-4d04-48e8-8fcc-397e6ff40a31#0:FAIL-t1, edc859c7-011f-4754-b289-08dca9617ef0<-b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0#0:OK-t1] and 0 exception(s); edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:t1, leader=null, voted=edc859c7-011f-4754-b289-08dca9617ef0, raftlog=edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:45,303 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7: Election REJECTED; received 2 response(s) [4c28c950-4d04-48e8-8fcc-397e6ff40a31<-b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0#0:FAIL-t1, 4c28c950-4d04-48e8-8fcc-397e6ff40a31<-edc859c7-011f-4754-b289-08dca9617ef0#0:FAIL-t1] and 0 exception(s); 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:t1, leader=null, voted=4c28c950-4d04-48e8-8fcc-397e6ff40a31, raftlog=4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:20:45,303 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown LeaderElection
2019-09-25 02:20:45,304 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-25 02:20:45,306 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:20:45,309 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown LeaderElection
2019-09-25 02:20:45,309 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: change Leader from null to edc859c7-011f-4754-b289-08dca9617ef0 at term 1 for becomeLeader, leader elected after 5183ms
2019-09-25 02:20:45,309 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start FollowerState
2019-09-25 02:20:45,309 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:20:45,310 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:20:45,311 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:20:45,311 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:20:45,311 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:20:45,312 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:20:45,318 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:20:45,319 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:45,319 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:20:45,323 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:20:45,329 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:45,329 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:45,330 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:20:45,331 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:20:45,331 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:20:45,331 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:20:45,331 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:20:45,332 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:20:45,335 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - edc859c7-011f-4754-b289-08dca9617ef0: start LeaderState
2019-09-25 02:20:45,336 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:45,337 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: set configuration 0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 0
2019-09-25 02:20:45,391 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_0
2019-09-25 02:20:45,393 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: change Leader from null to edc859c7-011f-4754-b289-08dca9617ef0 at term 1 for appendEntries, leader elected after 5265ms
2019-09-25 02:20:45,393 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: change Leader from null to edc859c7-011f-4754-b289-08dca9617ef0 at term 1 for appendEntries, leader elected after 5266ms
2019-09-25 02:20:45,436 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: set configuration 0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 0
2019-09-25 02:20:45,436 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: set configuration 0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 0
2019-09-25 02:20:45,436 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:45,436 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:20:45,469 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_0
2019-09-25 02:20:45,469 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_0
2019-09-25 02:20:46,301 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:47,303 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:48,304 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:49,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:50,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:51,315 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:52,317 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:53,318 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:54,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:55,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:56,322 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:57,323 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:58,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:59,325 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:20:59,327 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-25 02:21:00,329 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:01,330 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:02,332 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:03,334 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:04,335 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:05,336 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:06,338 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:07,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:08,341 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:09,342 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:09,344 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-25 02:21:10,345 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:11,347 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:12,348 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:13,350 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:14,351 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:15,352 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:16,354 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:17,355 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:18,357 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:19,358 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:19,360 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-25 02:21:20,361 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:21,362 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:22,364 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:23,366 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:24,367 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:25,368 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:26,370 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:27,371 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:28,372 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:29,374 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:29,376 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-25 02:21:30,378 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:31,379 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:32,380 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:33,382 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:34,383 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:35,385 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:36,386 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:37,387 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:38,389 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:39,390 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:39,392 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-25 02:21:40,393 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:41,394 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:42,397 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:43,398 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:44,399 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:45,401 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:46,402 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:47,403 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:48,404 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:49,406 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:49,408 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-25 02:21:50,410 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:51,411 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:52,412 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:53,414 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:54,415 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:55,416 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:56,418 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:57,419 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:58,420 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:59,422 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:21:59,423 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-25 02:22:00,425 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:01,426 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:02,428 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:03,429 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:04,431 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:05,432 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:06,434 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:07,435 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:08,437 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:09,438 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:09,440 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-25 02:22:10,441 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:11,442 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:12,444 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:13,446 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:14,447 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:15,449 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:16,450 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:17,451 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:18,452 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:19,454 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:19,455 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-25 02:22:20,457 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:21,458 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:22,459 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:23,461 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:24,463 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:25,464 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:26,466 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:27,469 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:28,470 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:29,471 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:29,474 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-25 02:22:29,478 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-25 02:22:29,500 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-25 02:22:30,504 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:31,506 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:32,507 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:33,509 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:34,510 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:35,512 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:36,513 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:37,514 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:38,516 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:39,517 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:40,520 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:41,522 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:42,523 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:43,524 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:44,525 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:45,527 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:46,528 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:47,529 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:48,531 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:49,532 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:49,534 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-25 02:22:50,535 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:51,537 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:52,538 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:53,539 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:54,540 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:55,542 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:56,543 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:57,544 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:58,545 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:59,546 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:22:59,548 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-25 02:23:00,549 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:01,550 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:02,552 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:03,554 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:04,555 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:05,556 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:06,558 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:07,559 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:08,560 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:09,561 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:09,563 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-25 02:23:10,564 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:11,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:12,567 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:13,569 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:14,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:15,571 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:16,573 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:17,574 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:18,575 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:19,576 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:19,579 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-25 02:23:20,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:21,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:22,583 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:23,584 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:24,586 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:25,587 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:26,588 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:27,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:28,591 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:29,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:29,595 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-25 02:23:30,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:31,598 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:32,599 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:33,601 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:34,602 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:35,603 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:36,605 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:37,606 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:38,607 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:39,608 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:39,610 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-25 02:23:40,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:41,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:42,628 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:43,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:44,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:45,632 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:46,633 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:47,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:48,636 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:49,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:49,640 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-25 02:23:50,641 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:51,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:52,644 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:53,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:54,647 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:55,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:56,652 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:57,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:58,655 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:59,656 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:23:59,658 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-25 02:24:00,660 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:01,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:02,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:03,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:04,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:05,667 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:06,669 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:07,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:08,674 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:09,676 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:09,677 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-25 02:24:10,679 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:11,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:12,682 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:13,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:14,684 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:15,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:16,687 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:17,689 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:18,691 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:19,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:24:19,694 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-25 02:24:19,695 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-25 02:24:19,699 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-25 02:24:19,699 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-25 02:24:19,700 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-25 02:24:19,700 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43017
2019-09-25 02:24:19,714 [IPC Server listener on 43017] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43017
2019-09-25 02:24:19,715 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-25 02:24:19,721 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:24:19,725 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-25 02:24:19,738 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-25 02:24:19,743 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27fde870{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-25 02:24:19,748 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:19,749 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:19,749 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:19,753 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-25 02:24:19,792 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:24:19,893 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:24:24,757 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:24:24,757 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:24:24,758 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - edc859c7-011f-4754-b289-08dca9617ef0: close
2019-09-25 02:24:24,758 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - de7fcbf2-7885-458b-afd3-c390059290a4: close
2019-09-25 02:24:24,761 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: shutdown
2019-09-25 02:24:24,761 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: shutdown
2019-09-25 02:24:24,762 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-716DF9FF857E,id=edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:24:24,762 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-33DE4CAFEC20,id=de7fcbf2-7885-458b-afd3-c390059290a4
2019-09-25 02:24:24,762 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown LeaderState
2019-09-25 02:24:24,763 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - de7fcbf2-7885-458b-afd3-c390059290a4: shutdown LeaderState
2019-09-25 02:24:24,764 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - edc859c7-011f-4754-b289-08dca9617ef0-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:24,764 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - de7fcbf2-7885-458b-afd3-c390059290a4-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:25,180 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:25,183 [Thread-249] WARN  util.JavaUtils (JavaUtils.java:sleep(250)) - Unexpected long sleep: sleep(5139ms) actually took 5499ms which is over the threshold 300ms
2019-09-25 02:24:25,180 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:25,187 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20: closes. applyIndex: 0
2019-09-25 02:24:25,186 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E: closes. applyIndex: 0
2019-09-25 02:24:25,189 [de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:25,189 [edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:25,193 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - de7fcbf2-7885-458b-afd3-c390059290a4@group-33DE4CAFEC20-SegmentedRaftLogWorker close()
2019-09-25 02:24:25,193 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - edc859c7-011f-4754-b289-08dca9617ef0@group-716DF9FF857E-SegmentedRaftLogWorker close()
2019-09-25 02:24:25,199 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: shutdown
2019-09-25 02:24:25,200 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=edc859c7-011f-4754-b289-08dca9617ef0
2019-09-25 02:24:25,200 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - de7fcbf2-7885-458b-afd3-c390059290a4: shutdown server with port 36095 now
2019-09-25 02:24:25,200 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown LeaderState
2019-09-25 02:24:25,203 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - edc859c7-011f-4754-b289-08dca9617ef0-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:25,203 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$397/1079994721@890edae] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:24:25,203 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$397/1079994721@53035ed5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542->4c28c950-4d04-48e8-8fcc-397e6ff40a31-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:24:25,206 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:25,209 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542: closes. applyIndex: 0
2019-09-25 02:24:25,213 [edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:25,213 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - de7fcbf2-7885-458b-afd3-c390059290a4: shutdown server with port 36095 successfully
2019-09-25 02:24:25,215 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542-SegmentedRaftLogWorker close()
2019-09-25 02:24:25,218 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown server with port 43388 now
2019-09-25 02:24:25,223 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:24:25,225 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - edc859c7-011f-4754-b289-08dca9617ef0: shutdown server with port 43388 successfully
2019-09-25 02:24:25,223 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: Completed APPEND_ENTRIES, lastRequest: edc859c7-011f-4754-b289-08dca9617ef0->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0#88-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-25 02:24:25,223 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: Completed APPEND_ENTRIES, lastRequest: edc859c7-011f-4754-b289-08dca9617ef0->4c28c950-4d04-48e8-8fcc-397e6ff40a31#88-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-25 02:24:25,227 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542->4c28c950-4d04-48e8-8fcc-397e6ff40a31-GrpcLogAppender is stopped
2019-09-25 02:24:25,227 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - edc859c7-011f-4754-b289-08dca9617ef0@group-6665E224A542->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0-GrpcLogAppender is stopped
2019-09-25 02:24:25,243 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:24:25,259 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:24:25,263 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:24:25,265 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1305c126{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:24:25,265 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72f9f27c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:25,266 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@dc4a691{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:25,266 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74174a23{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:25,272 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:24:25,276 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:24:25,279 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@726aa968{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:24:25,280 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7100dea{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:25,281 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62dbe64e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:25,283 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@524a076e{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:25,705 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:24:26,179 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:24:29,357 [Thread-252] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31:group-6665E224A542 changes to CANDIDATE, lastRpcTime:5898, electionTimeout:5022ms
2019-09-25 02:24:29,358 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown FollowerState
2019-09-25 02:24:29,358 [Thread-252] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-25 02:24:29,358 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start LeaderElection
2019-09-25 02:24:29,361 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: change Leader from edc859c7-011f-4754-b289-08dca9617ef0 to null at term 1 for initElection
2019-09-25 02:24:29,386 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8: begin an election at term 2 for 0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:24:29,398 [grpc-default-executor-4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: change Leader from edc859c7-011f-4754-b289-08dca9617ef0 to null at term 2 for updateCurrentTerm
2019-09-25 02:24:29,399 [grpc-default-executor-4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:24:29,399 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown FollowerState
2019-09-25 02:24:29,399 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: start FollowerState
2019-09-25 02:24:29,399 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(115)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:24:29,409 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8 got exception when requesting votes: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.66:43388
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-25 02:24:29,428 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8: Election PASSED; received 1 response(s) [4c28c950-4d04-48e8-8fcc-397e6ff40a31<-b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0#0:OK-t2] and 1 exception(s); 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:t2, leader=null, voted=4c28c950-4d04-48e8-8fcc-397e6ff40a31, raftlog=4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null
2019-09-25 02:24:29,429 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(149)) -   Exception 0: {}
java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.ratis.server.impl.LeaderElection.waitForResults(LeaderElection.java:263)
	at org.apache.ratis.server.impl.LeaderElection.askForVotes(LeaderElection.java:201)
	at org.apache.ratis.server.impl.LeaderElection.run(LeaderElection.java:133)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$RaftServerProtocolServiceBlockingStub.requestVote(RaftServerProtocolServiceGrpc.java:265)
	at org.apache.ratis.grpc.server.GrpcServerProtocolClient.requestVote(GrpcServerProtocolClient.java:90)
	at org.apache.ratis.grpc.server.GrpcService.requestVote(GrpcService.java:204)
	at org.apache.ratis.server.impl.LeaderElection.lambda$submitRequests$1(LeaderElection.java:238)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.151.66:43388
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.ratis.thirdparty.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496)
	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
2019-09-25 02:24:29,433 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown LeaderElection
2019-09-25 02:24:29,435 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-25 02:24:29,435 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: change Leader from null to 4c28c950-4d04-48e8-8fcc-397e6ff40a31 at term 2 for becomeLeader, leader elected after 74ms
2019-09-25 02:24:29,436 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:24:29,436 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:24:29,436 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:24:29,436 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:24:29,436 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:24:29,437 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:24:29,440 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:24:29,440 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:24:29,441 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:24:29,441 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:24:29,442 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:24:29,442 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:24:29,443 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:24:29,443 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:24:29,443 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:24:29,443 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:24:29,443 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:24:29,444 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:24:29,444 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: start LeaderState
2019-09-25 02:24:29,445 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2019-09-25 02:24:29,448 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_0 to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_0-0
2019-09-25 02:24:29,452 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: set configuration 1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 1
2019-09-25 02:24:29,470 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-25 02:24:29,476 [grpc-default-executor-5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: change Leader from null to 4c28c950-4d04-48e8-8fcc-397e6ff40a31 at term 2 for appendEntries, leader elected after 77ms
2019-09-25 02:24:29,476 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0: nextIndex: updateUnconditionally 1 -> 0
2019-09-25 02:24:29,482 [grpc-default-executor-5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: set configuration 1: [4c28c950-4d04-48e8-8fcc-397e6ff40a31:192.168.151.66:38050, b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0:192.168.151.66:38655, edc859c7-011f-4754-b289-08dca9617ef0:192.168.151.66:43388], old=null at 1
2019-09-25 02:24:29,482 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2019-09-25 02:24:29,491 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: Rolled log segment from /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_0 to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_0-0
2019-09-25 02:24:29,493 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_1
2019-09-25 02:24:29,529 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/ratis/539af5cf-a96c-467f-bc78-6665e224a542/current/log_inprogress_1
2019-09-25 02:24:29,557 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-25 02:24:29,560 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0: nextIndex: updateUnconditionally 1 -> 0
2019-09-25 02:24:29,566 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-25 02:24:29,568 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0: nextIndex: updateUnconditionally 1 -> 0
2019-09-25 02:24:30,268 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:24:30,269 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: close
2019-09-25 02:24:30,270 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: shutdown
2019-09-25 02:24:30,270 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C85AAA813928,id=b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0
2019-09-25 02:24:30,271 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown LeaderState
2019-09-25 02:24:30,271 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:30,272 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:30,272 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928: closes. applyIndex: 0
2019-09-25 02:24:30,273 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:30,275 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-C85AAA813928-SegmentedRaftLogWorker close()
2019-09-25 02:24:30,278 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: shutdown
2019-09-25 02:24:30,278 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0
2019-09-25 02:24:30,278 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown FollowerState
2019-09-25 02:24:30,279 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-StateMachineUpdater: set stopIndex = 1
2019-09-25 02:24:30,279 [Thread-476] INFO  impl.FollowerState (FollowerState.java:run(115)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:24:30,279 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542: closes. applyIndex: 1
2019-09-25 02:24:30,281 [b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:30,283 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0@group-6665E224A542-SegmentedRaftLogWorker close()
2019-09-25 02:24:30,285 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown server with port 38655 now
2019-09-25 02:24:30,286 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:24:30,286 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: close
2019-09-25 02:24:30,287 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: shutdown
2019-09-25 02:24:30,287 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-303FE9DC1D00,id=4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:24:30,287 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown LeaderState
2019-09-25 02:24:30,288 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:30,288 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:30,290 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00: closes. applyIndex: 0
2019-09-25 02:24:30,290 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: shutdown server with port 38655 successfully
2019-09-25 02:24:30,291 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:30,291 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-25 02:24:30,293 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-303FE9DC1D00-SegmentedRaftLogWorker close()
2019-09-25 02:24:30,295 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: nextIndex: updateUnconditionally 3 -> 2
2019-09-25 02:24:30,300 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0: installSnapshot onError, lastRequest: 4c28c950-4d04-48e8-8fcc-397e6ff40a31->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0#2-t2, previous=(t:2, i:1), leaderCommit=1, initializing? false, entries: size=1, first=(t:2, i:2), METADATAENTRY(c1): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-25 02:24:30,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: shutdown
2019-09-25 02:24:30,301 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6665E224A542,id=4c28c950-4d04-48e8-8fcc-397e6ff40a31
2019-09-25 02:24:30,301 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown LeaderState
2019-09-25 02:24:30,304 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$397/1079994721@b29957d] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->b3d2baab-7a4f-4d0e-8386-7aa2df9d70c0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:24:30,304 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:30,304 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$397/1079994721@4b34df10] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542->edc859c7-011f-4754-b289-08dca9617ef0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:24:30,309 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-StateMachineUpdater: set stopIndex = 2
2019-09-25 02:24:30,309 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542: closes. applyIndex: 2
2019-09-25 02:24:30,310 [4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:30,311 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31@group-6665E224A542-SegmentedRaftLogWorker close()
2019-09-25 02:24:30,314 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown server with port 38050 now
2019-09-25 02:24:30,314 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 4c28c950-4d04-48e8-8fcc-397e6ff40a31: shutdown server with port 38050 successfully
Sep 25, 2019 2:24:30 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@3f83fe5c
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-25 02:24:30,323 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:24:30,331 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:24:30,340 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:24:30,344 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:24:30,345 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12eedfee{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:24:30,346 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c3c4a71{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:30,346 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@127a7272{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:30,347 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56637cff{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:30,351 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:24:30,354 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:24:30,357 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cd64ee8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:24:30,357 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@620c8641{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:30,358 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e33d73e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:30,359 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6edcad64{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:31,183 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:24:35,349 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:24:35,350 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: close
2019-09-25 02:24:35,350 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: shutdown
2019-09-25 02:24:35,351 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-051D6C14F65E,id=078a6b74-f6bd-4459-ac8a-c915d0e21e4a
2019-09-25 02:24:35,351 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: shutdown LeaderState
2019-09-25 02:24:35,352 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a-PendingRequests: sendNotLeaderResponses
2019-09-25 02:24:35,352 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:24:35,353 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E: closes. applyIndex: 0
2019-09-25 02:24:35,354 [078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:24:35,355 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a@group-051D6C14F65E-SegmentedRaftLogWorker close()
2019-09-25 02:24:35,357 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: shutdown server with port 43991 now
2019-09-25 02:24:35,359 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 078a6b74-f6bd-4459-ac8a-c915d0e21e4a: shutdown server with port 43991 successfully
2019-09-25 02:24:35,373 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-dea72662-bd65-4e0e-813e-a5691711d509/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:24:35,390 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:24:35,394 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:24:35,395 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1457fde{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:24:35,396 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6f94fb9d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:35,396 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44f24a20{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:35,397 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18b8d173{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:35,398 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-25 02:24:35,398 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-25 02:24:35,398 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-25 02:24:35,398 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-25 02:24:35,399 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-25 02:24:35,399 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-25 02:24:35,399 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44400
2019-09-25 02:24:35,400 [IPC Server listener on 44400] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44400
2019-09-25 02:24:35,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:24:35,497 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-25 02:24:35,498 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-25 02:24:35,498 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-25 02:24:35,498 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38175
2019-09-25 02:24:35,501 [IPC Server listener on 38175] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38175
2019-09-25 02:24:35,501 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-25 02:24:35,501 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-25 02:24:35,502 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:24:35,502 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45438
2019-09-25 02:24:35,505 [IPC Server listener on 45438] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45438
2019-09-25 02:24:35,505 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:24:35,505 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-25 02:24:35,507 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@544630b7{/,null,UNAVAILABLE}{/scm}
2019-09-25 02:24:35,508 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:24:35,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:24:35,509 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:24:35,509 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-25 02:24:35,510 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 02:24:35,510 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 02:24:35,511 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-25 02:24:35,518 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-25 02:24:35,528 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-25 02:24:35,529 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

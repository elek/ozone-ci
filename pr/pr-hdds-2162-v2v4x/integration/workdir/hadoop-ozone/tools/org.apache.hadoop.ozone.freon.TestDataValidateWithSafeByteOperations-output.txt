2019-09-25 02:45:01,812 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:01,904 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:01,906 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:01,919 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @830ms
2019-09-25 02:45:01,995 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-25 02:45:01,995 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-25 02:45:01,995 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-25 02:45:01,995 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-25 02:45:01,996 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-25 02:45:01,996 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-25 02:45:02,005 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 02:45:02,005 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 02:45:02,006 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 02:45:02,383 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3e694b3f
2019-09-25 02:45:02,386 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-25 02:45:02,455 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 02:45:02,457 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-25 02:45:02,459 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-25 02:45:02,529 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-25 02:45:02,543 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:02,685 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-25 02:45:02,689 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:02,905 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-25 02:45:03,239 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:45:03,266 [Socket Reader #1 for port 35123] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35123
2019-09-25 02:45:03,395 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:45:03,396 [Socket Reader #1 for port 45293] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45293
2019-09-25 02:45:03,408 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:45:03,409 [Socket Reader #1 for port 45908] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45908
2019-09-25 02:45:03,439 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-25 02:45:03,591 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:03,606 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:03,615 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:03,618 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-25 02:45:03,618 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:03,618 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:03,646 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:45908
2019-09-25 02:45:03,696 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-25 02:45:03,709 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-25 02:45:03,709 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-25 02:45:03,921 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:45908
2019-09-25 02:45:03,921 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:45:03,921 [IPC Server listener on 45908] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45908: starting
2019-09-25 02:45:03,929 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45293
2019-09-25 02:45:03,931 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:45293
2019-09-25 02:45:03,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:45:03,931 [IPC Server listener on 45293] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45293: starting
2019-09-25 02:45:03,942 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:35123
2019-09-25 02:45:03,943 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:35123
2019-09-25 02:45:03,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:45:03,945 [IPC Server listener on 35123] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35123: starting
2019-09-25 02:45:03,959 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43483
2019-09-25 02:45:03,961 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:03,998 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:03,999 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:04,108 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-43483-scm-_-any-5964191907922652960.dir/webapp/,AVAILABLE}{/scm}
2019-09-25 02:45:04,114 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:43483}
2019-09-25 02:45:04,114 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3025ms
2019-09-25 02:45:04,116 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-25 02:45:04,117 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-25 02:45:04,119 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:43483
2019-09-25 02:45:04,129 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:04,133 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:04,255 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(181)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2019-09-25 02:45:04,255 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(211)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-25 02:45:04,257 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:04,257 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:04,937 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-25 02:45:04,945 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-25 02:45:04,945 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-25 02:45:04,946 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-25 02:45:04,946 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-25 02:45:04,946 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-25 02:45:04,946 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-25 02:45:04,947 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-25 02:45:04,947 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-25 02:45:04,947 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-25 02:45:04,947 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-25 02:45:04,948 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-25 02:45:04,948 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-25 02:45:04,948 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-25 02:45:04,948 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-25 02:45:04,948 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-25 02:45:04,949 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-25 02:45:04,949 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-25 02:45:04,949 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-25 02:45:04,949 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-25 02:45:04,950 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-25 02:45:04,950 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-25 02:45:04,950 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-25 02:45:04,950 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-25 02:45:04,951 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-25 02:45:04,951 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-25 02:45:05,754 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-25 02:45:05,755 [Socket Reader #1 for port 36283] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36283
2019-09-25 02:45:05,777 [main] INFO  om.OzoneManager (OzoneManager.java:start(1069)) - OzoneManager RPC server is listening at localhost/127.0.0.1:36283
2019-09-25 02:45:05,777 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-25 02:45:05,779 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-25 02:45:05,780 [IPC Server listener on 36283] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36283: starting
2019-09-25 02:45:05,797 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-25 02:45:05,800 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:05,801 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:05,804 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:05,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-25 02:45:05,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:05,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:05,809 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44219
2019-09-25 02:45:05,810 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:05,813 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:05,814 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:05,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-44219-ozoneManager-_-any-1771135018148388717.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-25 02:45:05,879 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:44219}
2019-09-25 02:45:05,879 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4790ms
2019-09-25 02:45:05,880 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:05,881 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:44219
2019-09-25 02:45:06,150 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:45:06,211 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:45:06,250 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:45:06,252 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/containers/hdds to VolumeSet
2019-09-25 02:45:06,256 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-25 02:45:06,275 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-25 02:45:06,381 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:45:06,445 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:45:06,449 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:45:06,450 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:45:06,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:06,452 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:45:06,453 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:06,643 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis] (custom)
2019-09-25 02:45:06,702 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:45:06,704 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:06,705 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:06,707 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:06,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:45:06,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:06,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:06,710 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37005
2019-09-25 02:45:06,710 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:06,712 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:06,713 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:06,743 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-37005-hddsDatanode-_-any-3762981670607980243.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:45:06,744 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:37005}
2019-09-25 02:45:06,745 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5656ms
2019-09-25 02:45:06,745 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:06,746 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37005
2019-09-25 02:45:06,748 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:45:06,753 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:45:06,755 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5be7461] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:06,762 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:45:06,763 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/containers/hdds to VolumeSet
2019-09-25 02:45:06,763 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-25 02:45:06,764 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-25 02:45:06,781 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:45:06,781 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:45:06,781 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:45:06,781 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:45:06,782 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:06,782 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:45:06,782 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:06,783 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis] (custom)
2019-09-25 02:45:06,785 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:45:06,786 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:06,787 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:06,789 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:06,789 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:45:06,789 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:06,790 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:06,791 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42187
2019-09-25 02:45:06,791 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:06,797 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:06,797 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:06,826 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-42187-hddsDatanode-_-any-276541466426658511.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:45:06,827 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:42187}
2019-09-25 02:45:06,829 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5739ms
2019-09-25 02:45:06,829 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:06,830 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42187
2019-09-25 02:45:06,831 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:45:06,834 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:45:06,834 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72efa55b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:06,844 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:45:06,844 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/containers/hdds to VolumeSet
2019-09-25 02:45:06,844 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-25 02:45:06,845 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@a098d76
2019-09-25 02:45:06,861 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:45:06,861 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:45:06,861 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:45:06,861 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:45:06,862 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:06,862 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:45:06,862 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:06,863 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis] (custom)
2019-09-25 02:45:06,865 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:45:06,866 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:06,866 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:06,868 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:06,869 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:45:06,869 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:06,870 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:06,870 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36777
2019-09-25 02:45:06,871 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:06,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:06,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:06,890 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/meta/datanode.id
2019-09-25 02:45:06,896 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/meta/datanode.id
2019-09-25 02:45:06,906 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f6917fb{/,file:///tmp/jetty-0.0.0.0-36777-hddsDatanode-_-any-7516531133071009611.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:45:06,907 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:36777}
2019-09-25 02:45:06,907 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5818ms
2019-09-25 02:45:06,908 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:06,909 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36777
2019-09-25 02:45:06,910 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:45:06,913 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:45:06,913 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63dc61a6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:06,916 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/meta/datanode.id
2019-09-25 02:45:06,922 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:45:06,923 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/containers/hdds to VolumeSet
2019-09-25 02:45:06,924 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-25 02:45:06,924 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@70972170
2019-09-25 02:45:06,939 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:45:06,939 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:45:06,939 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:45:06,939 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:45:06,940 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:06,940 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:45:06,940 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:06,941 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis] (custom)
2019-09-25 02:45:06,942 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:45:06,944 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:06,944 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:06,946 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:06,946 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:45:06,947 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:06,947 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:06,947 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41647
2019-09-25 02:45:06,948 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:06,951 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:06,952 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:06,980 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dc3502b{/,file:///tmp/jetty-0.0.0.0-41647-hddsDatanode-_-any-8707791724646518231.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:45:06,980 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:41647}
2019-09-25 02:45:06,981 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5892ms
2019-09-25 02:45:06,981 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:06,982 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41647
2019-09-25 02:45:06,982 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-25 02:45:06,986 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-v2v4x-1150571016 ip:192.168.151.66
2019-09-25 02:45:06,986 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71701771] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:06,988 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/meta/datanode.id
2019-09-25 02:45:06,992 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-25 02:45:06,993 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/containers/hdds to VolumeSet
2019-09-25 02:45:06,993 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@250a500b
2019-09-25 02:45:06,994 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@250a500b
2019-09-25 02:45:07,008 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-25 02:45:07,008 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-25 02:45:07,009 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-25 02:45:07,009 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-25 02:45:07,009 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:07,009 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-25 02:45:07,010 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:07,010 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis] (custom)
2019-09-25 02:45:07,012 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-25 02:45:07,013 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-25 02:45:07,014 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-25 02:45:07,015 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-25 02:45:07,016 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-25 02:45:07,016 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-25 02:45:07,016 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-25 02:45:07,017 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45722
2019-09-25 02:45:07,017 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-25 02:45:07,019 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2630dbc4{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-25 02:45:07,020 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a1c3cb4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-25 02:45:07,049 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@21505815{/,file:///tmp/jetty-0.0.0.0-45722-hddsDatanode-_-any-6457012894019763714.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-25 02:45:07,049 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e53339{HTTP/1.1,[http/1.1]}{0.0.0.0:45722}
2019-09-25 02:45:07,050 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5961ms
2019-09-25 02:45:07,050 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-25 02:45:07,051 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45722
2019-09-25 02:45:07,053 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:45:07,055 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46dffab] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-25 02:45:07,058 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/meta/datanode.id
2019-09-25 02:45:08,053 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:45:08,826 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:45:08,829 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:45:08,830 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e219f00c-70d9-4529-95db-0fe14364412e at port 0
2019-09-25 02:45:08,854 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:45:08,863 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:45:08,864 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 6e00097f-e359-4744-8673-96b234955a6b at port 0
2019-09-25 02:45:08,867 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e219f00c-70d9-4529-95db-0fe14364412e: start RPC server
2019-09-25 02:45:08,876 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6e00097f-e359-4744-8673-96b234955a6b: start RPC server
2019-09-25 02:45:08,940 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:45:08,943 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:45:08,943 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis ee927c45-5a52-4718-94ac-3cab6b482d7d at port 0
2019-09-25 02:45:08,952 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: start RPC server
2019-09-25 02:45:09,004 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:45:09,006 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:45:09,007 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0fb31bcd-734e-4bec-9c76-07f50ba1dba0 at port 0
2019-09-25 02:45:09,021 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: start RPC server
2019-09-25 02:45:09,041 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e219f00c-70d9-4529-95db-0fe14364412e: GrpcService started, listening on 0.0.0.0/0.0.0.0:37297
2019-09-25 02:45:09,041 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: GrpcService started, listening on 0.0.0.0/0.0.0.0:38390
2019-09-25 02:45:09,042 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e219f00c-70d9-4529-95db-0fe14364412e is started using port 37297
2019-09-25 02:45:09,041 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 6e00097f-e359-4744-8673-96b234955a6b: GrpcService started, listening on 0.0.0.0/0.0.0.0:38412
2019-09-25 02:45:09,042 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: GrpcService started, listening on 0.0.0.0/0.0.0.0:38582
2019-09-25 02:45:09,043 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 6e00097f-e359-4744-8673-96b234955a6b is started using port 38412
2019-09-25 02:45:09,042 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis ee927c45-5a52-4718-94ac-3cab6b482d7d is started using port 38390
2019-09-25 02:45:09,043 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0fb31bcd-734e-4bec-9c76-07f50ba1dba0 is started using port 38582
2019-09-25 02:45:09,048 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e219f00c-70d9-4529-95db-0fe14364412e is started using port 46534
2019-09-25 02:45:09,050 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 6e00097f-e359-4744-8673-96b234955a6b is started using port 38532
2019-09-25 02:45:09,051 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc ee927c45-5a52-4718-94ac-3cab6b482d7d is started using port 34535
2019-09-25 02:45:09,051 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0fb31bcd-734e-4bec-9c76-07f50ba1dba0 is started using port 39441
2019-09-25 02:45:09,054 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:45:09,080 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-25 02:45:09,084 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-25 02:45:09,084 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c87453c9-bc63-4e09-92ea-dddb813ed738 at port 0
2019-09-25 02:45:09,092 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start RPC server
2019-09-25 02:45:09,095 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c87453c9-bc63-4e09-92ea-dddb813ed738: GrpcService started, listening on 0.0.0.0/0.0.0.0:37219
2019-09-25 02:45:09,095 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c87453c9-bc63-4e09-92ea-dddb813ed738 is started using port 37219
2019-09-25 02:45:09,097 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c87453c9-bc63-4e09-92ea-dddb813ed738 is started using port 43097
2019-09-25 02:45:10,055 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-25 02:45:10,804 [IPC Server handler 18 on 35123] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e219f00c-70d9-4529-95db-0fe14364412e
2019-09-25 02:45:10,804 [IPC Server handler 18 on 35123] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e219f00c-70d9-4529-95db-0fe14364412e{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:45:10,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-25 02:45:10,810 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-25 02:45:10,810 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-25 02:45:10,838 [IPC Server handler 14 on 35123] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:45:10,838 [IPC Server handler 14 on 35123] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 6e00097f-e359-4744-8673-96b234955a6b{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:45:10,920 [IPC Server handler 15 on 35123] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/ee927c45-5a52-4718-94ac-3cab6b482d7d
2019-09-25 02:45:10,921 [IPC Server handler 15 on 35123] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : ee927c45-5a52-4718-94ac-3cab6b482d7d{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:45:10,989 [IPC Server handler 4 on 35123] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0fb31bcd-734e-4bec-9c76-07f50ba1dba0
2019-09-25 02:45:10,989 [IPC Server handler 4 on 35123] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0fb31bcd-734e-4bec-9c76-07f50ba1dba0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:45:11,055 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-25 02:45:11,059 [IPC Server handler 18 on 35123] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c87453c9-bc63-4e09-92ea-dddb813ed738
2019-09-25 02:45:11,059 [IPC Server handler 18 on 35123] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c87453c9-bc63-4e09-92ea-dddb813ed738{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}
2019-09-25 02:45:11,341 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e219f00c-70d9-4529-95db-0fe14364412e: addNew group-D5B3F1280498:[e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] returns group-D5B3F1280498:java.util.concurrent.CompletableFuture@10d57623[Not completed]
2019-09-25 02:45:11,364 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e219f00c-70d9-4529-95db-0fe14364412e: new RaftServerImpl for group-D5B3F1280498:[e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] with ContainerStateMachine:uninitialized
2019-09-25 02:45:11,366 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:11,367 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:11,367 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:11,368 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:11,369 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:11,377 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: ConfigurationManager, init=-1: [e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:11,377 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis] (custom)
2019-09-25 02:45:11,388 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/e9aa1a6e-648c-4b51-a976-d5b3f1280498 does not exist. Creating ...
2019-09-25 02:45:11,418 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/e9aa1a6e-648c-4b51-a976-d5b3f1280498/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:11,444 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/e9aa1a6e-648c-4b51-a976-d5b3f1280498 has been successfully formatted.
2019-09-25 02:45:11,447 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D5B3F1280498: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:11,448 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:11,451 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:11,460 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:11,460 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:11,463 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:11,478 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/e9aa1a6e-648c-4b51-a976-d5b3f1280498
2019-09-25 02:45:11,480 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-25 02:45:11,488 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-25 02:45:11,525 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:11,526 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:11,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:11,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:11,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:11,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:11,532 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:11,533 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:11,544 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:11,549 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:11,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:11,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:11,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:11,555 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:11,588 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: start as a follower, conf=-1: [e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:11,589 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:11,590 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start FollowerState
2019-09-25 02:45:11,592 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5B3F1280498,id=e219f00c-70d9-4529-95db-0fe14364412e
2019-09-25 02:45:11,666 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e9aa1a6e-648c-4b51-a976-d5b3f1280498, Nodes: e219f00c-70d9-4529-95db-0fe14364412e{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:45:11,695 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c87453c9-bc63-4e09-92ea-dddb813ed738: addNew group-61D6E0AE477A:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219] returns group-61D6E0AE477A:java.util.concurrent.CompletableFuture@65eea99[Not completed]
2019-09-25 02:45:11,746 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c87453c9-bc63-4e09-92ea-dddb813ed738: new RaftServerImpl for group-61D6E0AE477A:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219] with ContainerStateMachine:uninitialized
2019-09-25 02:45:11,747 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:11,747 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:11,747 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:11,747 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:11,748 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:11,748 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: ConfigurationManager, init=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:11,748 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis] (custom)
2019-09-25 02:45:11,749 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/5b3b5113-b029-4f70-9790-61d6e0ae477a does not exist. Creating ...
2019-09-25 02:45:11,765 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/5b3b5113-b029-4f70-9790-61d6e0ae477a/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:11,788 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/5b3b5113-b029-4f70-9790-61d6e0ae477a has been successfully formatted.
2019-09-25 02:45:11,789 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-61D6E0AE477A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:11,791 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:11,791 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:11,792 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:11,792 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:11,792 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,792 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:11,793 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/5b3b5113-b029-4f70-9790-61d6e0ae477a
2019-09-25 02:45:11,799 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:11,799 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:11,799 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:11,800 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:11,801 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:11,801 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:11,801 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:11,802 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:11,802 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:11,802 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:11,809 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: start as a follower, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219], old=null
2019-09-25 02:45:11,810 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:11,810 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start FollowerState
2019-09-25 02:45:11,812 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-61D6E0AE477A,id=c87453c9-bc63-4e09-92ea-dddb813ed738
2019-09-25 02:45:11,830 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5b3b5113-b029-4f70-9790-61d6e0ae477a, Nodes: c87453c9-bc63-4e09-92ea-dddb813ed738{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:45:11,853 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e00097f-e359-4744-8673-96b234955a6b: addNew group-BCC557643F44:[6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412] returns group-BCC557643F44:java.util.concurrent.CompletableFuture@2da6fca1[Not completed]
2019-09-25 02:45:11,875 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 6e00097f-e359-4744-8673-96b234955a6b: new RaftServerImpl for group-BCC557643F44:[6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412] with ContainerStateMachine:uninitialized
2019-09-25 02:45:11,875 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:11,875 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:11,875 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:11,876 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:11,876 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:11,876 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: ConfigurationManager, init=-1: [6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:11,876 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis] (custom)
2019-09-25 02:45:11,877 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/227b5f52-e15e-4fd0-8253-bcc557643f44 does not exist. Creating ...
2019-09-25 02:45:11,905 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/227b5f52-e15e-4fd0-8253-bcc557643f44/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:11,922 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/227b5f52-e15e-4fd0-8253-bcc557643f44 has been successfully formatted.
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-BCC557643F44: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:11,923 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,924 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:11,924 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/227b5f52-e15e-4fd0-8253-bcc557643f44
2019-09-25 02:45:11,959 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:11,960 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:11,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:11,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:11,961 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:11,961 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:11,962 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:11,962 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:11,962 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:11,962 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:11,966 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: start as a follower, conf=-1: [6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412], old=null
2019-09-25 02:45:11,966 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:11,966 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start FollowerState
2019-09-25 02:45:11,967 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCC557643F44,id=6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:45:11,978 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 227b5f52-e15e-4fd0-8253-bcc557643f44, Nodes: 6e00097f-e359-4744-8673-96b234955a6b{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:45:11,996 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: addNew group-5C4B36C32650:[0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582] returns group-5C4B36C32650:java.util.concurrent.CompletableFuture@7abe2883[Not completed]
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: new RaftServerImpl for group-5C4B36C32650:[0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582] with ContainerStateMachine:uninitialized
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:11,998 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: ConfigurationManager, init=-1: [0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:11,999 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis] (custom)
2019-09-25 02:45:11,999 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis/85b7addb-2203-48c6-910b-5c4b36c32650 does not exist. Creating ...
2019-09-25 02:45:12,023 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis/85b7addb-2203-48c6-910b-5c4b36c32650/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:12,048 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis/85b7addb-2203-48c6-910b-5c4b36c32650 has been successfully formatted.
2019-09-25 02:45:12,048 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-5C4B36C32650: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:12,048 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:12,049 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis/85b7addb-2203-48c6-910b-5c4b36c32650
2019-09-25 02:45:12,054 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:12,054 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:12,054 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,054 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:12,055 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:12,055 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:12,055 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:12,055 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:12,055 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:12,056 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:12,056 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:12,056 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-25 02:45:12,056 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:12,057 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:12,057 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:12,057 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:12,062 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: start as a follower, conf=-1: [0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582], old=null
2019-09-25 02:45:12,062 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:12,062 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: start FollowerState
2019-09-25 02:45:12,063 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5C4B36C32650,id=0fb31bcd-734e-4bec-9c76-07f50ba1dba0
2019-09-25 02:45:12,082 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 85b7addb-2203-48c6-910b-5c4b36c32650, Nodes: 0fb31bcd-734e-4bec-9c76-07f50ba1dba0{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:45:12,112 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: addNew group-05E2FFEACB96:[ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390] returns group-05E2FFEACB96:java.util.concurrent.CompletableFuture@302cf31f[Not completed]
2019-09-25 02:45:12,114 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: new RaftServerImpl for group-05E2FFEACB96:[ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390] with ContainerStateMachine:uninitialized
2019-09-25 02:45:12,114 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:12,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:12,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:12,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:12,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:12,116 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: ConfigurationManager, init=-1: [ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:12,116 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis] (custom)
2019-09-25 02:45:12,116 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis/572415a2-1d13-4e7b-8bca-05e2ffeacb96 does not exist. Creating ...
2019-09-25 02:45:12,140 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis/572415a2-1d13-4e7b-8bca-05e2ffeacb96/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:12,165 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis/572415a2-1d13-4e7b-8bca-05e2ffeacb96 has been successfully formatted.
2019-09-25 02:45:12,166 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-05E2FFEACB96: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:12,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:12,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:12,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:12,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:12,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,167 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:12,167 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis/572415a2-1d13-4e7b-8bca-05e2ffeacb96
2019-09-25 02:45:12,171 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:12,171 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:12,171 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:12,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:12,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:12,173 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:12,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:12,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:12,174 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:12,174 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:12,177 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: start as a follower, conf=-1: [ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390], old=null
2019-09-25 02:45:12,177 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:12,177 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: start FollowerState
2019-09-25 02:45:12,177 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-05E2FFEACB96,id=ee927c45-5a52-4718-94ac-3cab6b482d7d
2019-09-25 02:45:12,191 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 572415a2-1d13-4e7b-8bca-05e2ffeacb96, Nodes: ee927c45-5a52-4718-94ac-3cab6b482d7d{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-25 02:45:12,250 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e00097f-e359-4744-8673-96b234955a6b: addNew group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] returns group-4EAEDCD161B2:java.util.concurrent.CompletableFuture@4acfee62[Not completed]
2019-09-25 02:45:12,250 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e219f00c-70d9-4529-95db-0fe14364412e: addNew group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] returns group-4EAEDCD161B2:java.util.concurrent.CompletableFuture@14a592ef[Not completed]
2019-09-25 02:45:12,253 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c87453c9-bc63-4e09-92ea-dddb813ed738: addNew group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] returns group-4EAEDCD161B2:java.util.concurrent.CompletableFuture@51a70e1f[Not completed]
2019-09-25 02:45:12,253 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e219f00c-70d9-4529-95db-0fe14364412e: new RaftServerImpl for group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] with ContainerStateMachine:uninitialized
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: ConfigurationManager, init=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:12,254 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis] (custom)
2019-09-25 02:45:12,255 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 6e00097f-e359-4744-8673-96b234955a6b: new RaftServerImpl for group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] with ContainerStateMachine:uninitialized
2019-09-25 02:45:12,255 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 does not exist. Creating ...
2019-09-25 02:45:12,255 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:12,255 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:12,255 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:12,255 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:12,256 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:12,256 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c87453c9-bc63-4e09-92ea-dddb813ed738: new RaftServerImpl for group-4EAEDCD161B2:[c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297] with ContainerStateMachine:uninitialized
2019-09-25 02:45:12,256 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: ConfigurationManager, init=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:12,256 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-25 02:45:12,256 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis] (custom)
2019-09-25 02:45:12,256 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-25 02:45:12,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-25 02:45:12,257 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 does not exist. Creating ...
2019-09-25 02:45:12,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-25 02:45:12,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:12,257 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: ConfigurationManager, init=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null, confs=<EMPTY_MAP>
2019-09-25 02:45:12,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis] (custom)
2019-09-25 02:45:12,258 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 does not exist. Creating ...
2019-09-25 02:45:12,270 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:12,270 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:12,270 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/in_use.lock acquired by nodename 23892@pr-hdds-2162-v2v4x-1150571016
2019-09-25 02:45:12,293 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 has been successfully formatted.
2019-09-25 02:45:12,293 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 has been successfully formatted.
2019-09-25 02:45:12,294 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4EAEDCD161B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:12,293 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2 has been successfully formatted.
2019-09-25 02:45:12,294 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4EAEDCD161B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:12,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:12,294 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4EAEDCD161B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-25 02:45:12,294 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:12,295 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-25 02:45:12,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:12,295 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:12,295 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-25 02:45:12,297 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:12,297 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:12,298 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:12,297 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-25 02:45:12,298 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,298 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:12,298 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:12,298 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:12,298 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2
2019-09-25 02:45:12,298 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,299 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:12,299 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,299 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:12,299 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:12,299 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,299 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-25 02:45:12,300 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:12,299 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2
2019-09-25 02:45:12,300 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:12,300 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2
2019-09-25 02:45:12,300 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:12,300 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:12,300 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:12,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-25 02:45:12,301 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:12,300 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:12,301 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:12,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-25 02:45:12,301 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,301 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:12,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-25 02:45:12,301 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:12,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-25 02:45:12,302 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:12,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:12,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-25 02:45:12,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:12,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-25 02:45:12,302 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:12,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:12,302 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-25 02:45:12,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:12,303 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:12,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:12,303 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-25 02:45:12,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:12,303 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:12,303 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-25 02:45:12,305 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:12,305 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-25 02:45:12,305 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:12,306 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-25 02:45:12,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:12,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:12,306 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-25 02:45:12,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:12,306 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-25 02:45:12,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:12,306 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-25 02:45:12,307 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-25 02:45:12,311 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: start as a follower, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:12,311 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: start as a follower, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:12,311 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: start as a follower, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:12,311 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:12,311 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:12,311 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-25 02:45:12,311 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start FollowerState
2019-09-25 02:45:12,311 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start FollowerState
2019-09-25 02:45:12,311 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start FollowerState
2019-09-25 02:45:12,312 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=e219f00c-70d9-4529-95db-0fe14364412e
2019-09-25 02:45:12,312 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=c87453c9-bc63-4e09-92ea-dddb813ed738
2019-09-25 02:45:12,312 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:45:12,346 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d475a3c5-0258-40cd-8891-4eaedcd161b2, Nodes: c87453c9-bc63-4e09-92ea-dddb813ed738{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}e219f00c-70d9-4529-95db-0fe14364412e{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}6e00097f-e359-4744-8673-96b234955a6b{ip: 192.168.151.66, host: pr-hdds-2162-v2v4x-1150571016, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-25 02:45:13,421 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:13,892 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-25 02:45:13,895 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-25 02:45:14,422 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:15,424 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:16,425 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:16,725 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - e219f00c-70d9-4529-95db-0fe14364412e:group-D5B3F1280498 changes to CANDIDATE, lastRpcTime:5135, electionTimeout:5134ms
2019-09-25 02:45:16,728 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown FollowerState
2019-09-25 02:45:16,728 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:16,735 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start LeaderElection
2019-09-25 02:45:16,764 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1: begin an election at term 1 for -1: [e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:16,766 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown LeaderElection
2019-09-25 02:45:16,767 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:45:16,767 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: change Leader from null to e219f00c-70d9-4529-95db-0fe14364412e at term 1 for becomeLeader, leader elected after 5319ms
2019-09-25 02:45:16,777 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:16,777 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:16,781 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:16,784 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:16,784 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:16,785 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:16,801 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start LeaderState
2019-09-25 02:45:16,826 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:16,840 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: set configuration 0: [e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null at 0
2019-09-25 02:45:16,930 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - c87453c9-bc63-4e09-92ea-dddb813ed738:group-61D6E0AE477A changes to CANDIDATE, lastRpcTime:5120, electionTimeout:5118ms
2019-09-25 02:45:16,932 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown FollowerState
2019-09-25 02:45:16,932 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:16,932 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start LeaderElection
2019-09-25 02:45:16,959 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2: begin an election at term 1 for -1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219], old=null
2019-09-25 02:45:16,961 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown LeaderElection
2019-09-25 02:45:16,961 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:45:16,961 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: change Leader from null to c87453c9-bc63-4e09-92ea-dddb813ed738 at term 1 for becomeLeader, leader elected after 5169ms
2019-09-25 02:45:16,963 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:16,963 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:16,963 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:16,963 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:16,963 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:16,964 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:16,967 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start LeaderState
2019-09-25 02:45:16,967 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:16,967 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: set configuration 0: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219], old=null at 0
2019-09-25 02:45:17,022 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/e9aa1a6e-648c-4b51-a976-d5b3f1280498/current/log_inprogress_0
2019-09-25 02:45:17,022 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/5b3b5113-b029-4f70-9790-61d6e0ae477a/current/log_inprogress_0
2019-09-25 02:45:17,132 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e00097f-e359-4744-8673-96b234955a6b:group-BCC557643F44 changes to CANDIDATE, lastRpcTime:5165, electionTimeout:5165ms
2019-09-25 02:45:17,132 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown FollowerState
2019-09-25 02:45:17,132 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,132 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start LeaderElection
2019-09-25 02:45:17,160 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3: begin an election at term 1 for -1: [6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412], old=null
2019-09-25 02:45:17,160 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown LeaderElection
2019-09-25 02:45:17,161 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:45:17,161 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: change Leader from null to 6e00097f-e359-4744-8673-96b234955a6b at term 1 for becomeLeader, leader elected after 5238ms
2019-09-25 02:45:17,162 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:17,163 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:17,163 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:17,163 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:17,163 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:17,163 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:17,166 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start LeaderState
2019-09-25 02:45:17,167 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:17,167 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: set configuration 0: [6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412], old=null at 0
2019-09-25 02:45:17,208 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/227b5f52-e15e-4fd0-8253-bcc557643f44/current/log_inprogress_0
2019-09-25 02:45:17,248 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0:group-5C4B36C32650 changes to CANDIDATE, lastRpcTime:5186, electionTimeout:5185ms
2019-09-25 02:45:17,249 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: shutdown FollowerState
2019-09-25 02:45:17,249 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,249 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: start LeaderElection
2019-09-25 02:45:17,287 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4: begin an election at term 1 for -1: [0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582], old=null
2019-09-25 02:45:17,287 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: shutdown LeaderElection
2019-09-25 02:45:17,287 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:45:17,287 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: change Leader from null to 0fb31bcd-734e-4bec-9c76-07f50ba1dba0 at term 1 for becomeLeader, leader elected after 5238ms
2019-09-25 02:45:17,289 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:17,289 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:17,289 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:17,289 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:17,290 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:17,290 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:17,292 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: start LeaderState
2019-09-25 02:45:17,292 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:17,293 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: set configuration 0: [0fb31bcd-734e-4bec-9c76-07f50ba1dba0:192.168.151.66:38582], old=null at 0
2019-09-25 02:45:17,315 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - ee927c45-5a52-4718-94ac-3cab6b482d7d:group-05E2FFEACB96 changes to CANDIDATE, lastRpcTime:5137, electionTimeout:5137ms
2019-09-25 02:45:17,315 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: shutdown FollowerState
2019-09-25 02:45:17,315 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,315 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: start LeaderElection
2019-09-25 02:45:17,337 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/ratis/85b7addb-2203-48c6-910b-5c4b36c32650/current/log_inprogress_0
2019-09-25 02:45:17,361 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5: begin an election at term 1 for -1: [ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390], old=null
2019-09-25 02:45:17,361 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: shutdown LeaderElection
2019-09-25 02:45:17,361 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-25 02:45:17,361 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: change Leader from null to ee927c45-5a52-4718-94ac-3cab6b482d7d at term 1 for becomeLeader, leader elected after 5195ms
2019-09-25 02:45:17,363 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:17,363 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:17,364 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:17,364 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:17,364 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:17,364 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:17,368 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: start LeaderState
2019-09-25 02:45:17,368 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:17,369 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: set configuration 0: [ee927c45-5a52-4718-94ac-3cab6b482d7d:192.168.151.66:38390], old=null at 0
2019-09-25 02:45:17,386 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - c87453c9-bc63-4e09-92ea-dddb813ed738:group-4EAEDCD161B2 changes to CANDIDATE, lastRpcTime:5074, electionTimeout:5066ms
2019-09-25 02:45:17,386 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown FollowerState
2019-09-25 02:45:17,386 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,387 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start LeaderElection
2019-09-25 02:45:17,391 [Thread-228] INFO  impl.FollowerState (FollowerState.java:run(106)) - e219f00c-70d9-4529-95db-0fe14364412e:group-4EAEDCD161B2 changes to CANDIDATE, lastRpcTime:5079, electionTimeout:5079ms
2019-09-25 02:45:17,391 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown FollowerState
2019-09-25 02:45:17,391 [Thread-228] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,391 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start LeaderElection
2019-09-25 02:45:17,408 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/ratis/572415a2-1d13-4e7b-8bca-05e2ffeacb96/current/log_inprogress_0
2019-09-25 02:45:17,408 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7: begin an election at term 1 for -1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,408 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6: begin an election at term 1 for -1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,417 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e00097f-e359-4744-8673-96b234955a6b:group-4EAEDCD161B2 changes to CANDIDATE, lastRpcTime:5105, electionTimeout:5104ms
2019-09-25 02:45:17,417 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown FollowerState
2019-09-25 02:45:17,418 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-25 02:45:17,418 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start LeaderElection
2019-09-25 02:45:17,426 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:17,450 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8: begin an election at term 1 for -1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,486 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6: Election REJECTED; received 2 response(s) [c87453c9-bc63-4e09-92ea-dddb813ed738<-6e00097f-e359-4744-8673-96b234955a6b#0:FAIL-t1, c87453c9-bc63-4e09-92ea-dddb813ed738<-e219f00c-70d9-4529-95db-0fe14364412e#0:FAIL-t1] and 0 exception(s); c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:t1, leader=null, voted=c87453c9-bc63-4e09-92ea-dddb813ed738, raftlog=c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,486 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7: Election REJECTED; received 2 response(s) [e219f00c-70d9-4529-95db-0fe14364412e<-c87453c9-bc63-4e09-92ea-dddb813ed738#0:FAIL-t1, e219f00c-70d9-4529-95db-0fe14364412e<-6e00097f-e359-4744-8673-96b234955a6b#0:FAIL-t1] and 0 exception(s); e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:t1, leader=null, voted=e219f00c-70d9-4529-95db-0fe14364412e, raftlog=e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,499 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-25 02:45:17,499 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-25 02:45:17,499 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown LeaderElection
2019-09-25 02:45:17,501 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown LeaderElection
2019-09-25 02:45:17,501 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start FollowerState
2019-09-25 02:45:17,501 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start FollowerState
2019-09-25 02:45:17,517 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8: Election REJECTED; received 2 response(s) [6e00097f-e359-4744-8673-96b234955a6b<-c87453c9-bc63-4e09-92ea-dddb813ed738#0:FAIL-t1, 6e00097f-e359-4744-8673-96b234955a6b<-e219f00c-70d9-4529-95db-0fe14364412e#0:FAIL-t1] and 0 exception(s); 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:t1, leader=null, voted=6e00097f-e359-4744-8673-96b234955a6b, raftlog=6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:17,517 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-25 02:45:17,520 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown LeaderElection
2019-09-25 02:45:17,520 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start FollowerState
2019-09-25 02:45:18,431 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:19,434 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:20,436 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:21,437 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:22,438 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:22,531 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e00097f-e359-4744-8673-96b234955a6b:group-4EAEDCD161B2 changes to CANDIDATE, lastRpcTime:5010, electionTimeout:5009ms
2019-09-25 02:45:22,532 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown FollowerState
2019-09-25 02:45:22,532 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-25 02:45:22,532 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start LeaderElection
2019-09-25 02:45:22,560 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9: begin an election at term 2 for -1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:22,571 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:45:22,571 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:45:22,571 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown FollowerState
2019-09-25 02:45:22,571 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown FollowerState
2019-09-25 02:45:22,571 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c87453c9-bc63-4e09-92ea-dddb813ed738: start FollowerState
2019-09-25 02:45:22,572 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e219f00c-70d9-4529-95db-0fe14364412e: start FollowerState
2019-09-25 02:45:22,572 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(115)) - e219f00c-70d9-4529-95db-0fe14364412e: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:45:22,572 [Thread-255] INFO  impl.FollowerState (FollowerState.java:run(115)) - c87453c9-bc63-4e09-92ea-dddb813ed738: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:45:22,617 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9: Election PASSED; received 1 response(s) [6e00097f-e359-4744-8673-96b234955a6b<-e219f00c-70d9-4529-95db-0fe14364412e#0:OK-t2] and 0 exception(s); 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:t2, leader=null, voted=6e00097f-e359-4744-8673-96b234955a6b, raftlog=6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null
2019-09-25 02:45:22,617 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown LeaderElection
2019-09-25 02:45:22,619 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-25 02:45:22,624 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: change Leader from null to 6e00097f-e359-4744-8673-96b234955a6b at term 2 for becomeLeader, leader elected after 10328ms
2019-09-25 02:45:22,624 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-25 02:45:22,624 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-25 02:45:22,625 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-25 02:45:22,625 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-25 02:45:22,625 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-25 02:45:22,625 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-25 02:45:22,631 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:45:22,632 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:22,632 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:45:22,637 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:45:22,639 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:22,639 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:22,641 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-25 02:45:22,642 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-25 02:45:22,642 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-25 02:45:22,642 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-25 02:45:22,642 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-25 02:45:22,642 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-25 02:45:22,647 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e00097f-e359-4744-8673-96b234955a6b: start LeaderState
2019-09-25 02:45:22,647 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:22,648 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: set configuration 0: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null at 0
2019-09-25 02:45:22,689 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/current/log_inprogress_0
2019-09-25 02:45:22,698 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: change Leader from null to 6e00097f-e359-4744-8673-96b234955a6b at term 2 for appendEntries, leader elected after 10403ms
2019-09-25 02:45:22,698 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: change Leader from null to 6e00097f-e359-4744-8673-96b234955a6b at term 2 for appendEntries, leader elected after 10403ms
2019-09-25 02:45:22,738 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: set configuration 0: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null at 0
2019-09-25 02:45:22,738 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: set configuration 0: [c87453c9-bc63-4e09-92ea-dddb813ed738:192.168.151.66:37219, 6e00097f-e359-4744-8673-96b234955a6b:192.168.151.66:38412, e219f00c-70d9-4529-95db-0fe14364412e:192.168.151.66:37297], old=null at 0
2019-09-25 02:45:22,738 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:22,738 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-25 02:45:22,775 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/current/log_inprogress_0
2019-09-25 02:45:22,775 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/ratis/d475a3c5-0258-40cd-8891-4eaedcd161b2/current/log_inprogress_0
2019-09-25 02:45:23,445 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:24,446 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:25,448 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:26,449 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:27,450 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:28,451 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:29,453 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:30,454 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:31,456 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:32,457 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:32,460 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-25 02:45:33,462 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:34,463 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:35,465 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:36,466 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:37,467 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:38,468 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:39,470 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:40,471 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:41,472 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:42,474 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:42,475 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-25 02:45:43,476 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:44,478 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:45,479 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:46,481 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:47,482 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:48,483 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:49,484 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:50,486 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:51,487 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:52,489 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:52,491 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-25 02:45:53,492 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:54,493 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:55,495 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:56,496 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:57,498 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:58,500 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:45:59,501 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:00,503 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:01,504 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:02,505 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:02,507 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-25 02:46:03,508 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:04,509 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:05,511 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:06,512 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:07,514 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:08,515 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:09,517 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:10,518 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:11,519 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:12,521 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:12,522 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-25 02:46:13,524 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:14,525 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:15,526 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:16,527 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:17,528 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:18,529 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:19,531 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:20,532 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:21,534 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:22,535 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:22,537 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-25 02:46:23,538 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:24,539 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:25,540 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:26,542 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:27,543 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:28,544 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:29,545 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:30,547 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:31,549 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:32,552 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:32,554 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-25 02:46:33,555 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:34,556 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:35,558 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:36,559 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:37,561 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:38,562 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:39,563 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:40,565 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:41,566 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:42,567 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:42,569 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-25 02:46:43,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:44,572 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:45,573 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:46,574 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:47,575 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:48,577 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:49,578 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:50,579 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:51,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:52,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:52,584 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-25 02:46:53,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:54,586 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:55,587 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:56,589 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:57,590 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:58,591 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:46:59,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:00,594 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:01,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:02,596 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:02,598 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-25 02:47:02,601 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-25 02:47:03,625 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:04,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:05,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:06,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:07,630 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:08,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:09,633 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:10,634 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:11,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:12,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:13,640 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:14,641 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:15,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:16,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:17,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:18,646 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:19,647 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:20,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:21,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:22,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:22,655 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-25 02:47:23,656 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:24,657 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:25,659 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:26,660 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:27,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:28,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:29,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:30,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:31,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:32,667 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:32,669 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-25 02:47:33,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:34,672 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:35,673 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:36,674 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:37,676 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:38,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:39,678 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:40,679 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:41,682 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:42,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:42,685 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-25 02:47:43,687 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:44,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:45,689 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:46,691 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:47,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:48,693 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:49,694 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:50,695 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:51,697 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:52,698 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:52,700 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-25 02:47:53,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:54,702 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:55,704 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:56,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:57,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:58,707 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:47:59,708 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:00,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:01,711 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:02,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:02,714 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-25 02:48:03,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:04,716 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:05,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:06,719 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:07,720 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:08,722 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:09,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:10,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:11,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:12,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:12,729 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-25 02:48:13,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:14,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:15,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:16,744 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:17,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:18,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:19,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:20,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:21,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:22,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:22,754 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-25 02:48:23,755 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:24,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:25,758 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:26,759 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:27,761 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:28,762 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:29,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:30,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:31,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:32,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:32,770 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-25 02:48:33,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:34,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:35,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:36,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:37,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:38,777 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:39,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:40,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:41,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:42,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:42,785 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-25 02:48:43,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:44,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:45,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:46,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:47,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:48,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:49,793 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:50,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:51,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:52,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:52,798 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-25 02:48:52,799 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-25 02:48:53,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:54,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:55,809 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:56,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:57,811 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:58,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:48:59,813 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:00,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:01,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:02,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:03,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:04,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:05,823 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:06,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:07,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:08,827 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:09,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:10,829 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:11,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:12,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:12,833 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-25 02:49:13,834 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:14,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:15,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:16,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:17,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:18,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:19,840 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:21,233 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:22,234 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:23,235 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:23,237 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-25 02:49:24,238 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:25,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:26,248 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:27,250 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:28,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:29,253 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:30,254 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:31,256 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:32,257 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:33,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:33,259 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-25 02:49:34,260 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:35,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:36,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:37,264 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:38,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:39,266 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:40,268 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:41,269 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:42,271 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:43,271 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:43,273 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-25 02:49:44,274 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:45,275 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:46,276 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:47,278 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:48,279 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:49,280 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:50,281 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:51,282 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:52,283 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:53,284 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:53,286 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-25 02:49:54,287 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:55,288 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:56,289 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:57,290 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:58,291 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:49:59,292 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:00,294 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:01,295 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:02,296 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:03,297 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:03,298 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-25 02:50:04,299 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:05,300 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:06,301 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:07,302 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:08,304 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:09,305 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:10,306 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:11,307 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:12,308 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:13,309 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:13,310 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-25 02:50:13,896 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-25 02:50:14,311 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:15,313 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:16,314 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:17,315 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:18,316 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:19,317 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:20,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:21,319 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:22,321 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:23,322 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:23,323 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-25 02:50:24,324 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:25,325 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:26,327 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:27,328 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:28,329 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:29,331 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:30,332 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:31,333 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:32,334 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:33,335 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:33,337 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-25 02:50:34,338 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:35,339 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:36,340 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:37,341 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:38,342 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:39,343 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:40,344 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:41,346 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:42,347 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:43,347 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-25 02:50:43,349 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-25 02:50:43,349 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.validateWriteTest(TestDataValidate.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-25 02:50:43,353 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-25 02:50:43,354 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-25 02:50:43,354 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-25 02:50:43,355 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36283
2019-09-25 02:50:43,365 [IPC Server listener on 36283] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36283
2019-09-25 02:50:43,367 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-25 02:50:43,372 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:50:43,377 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-25 02:50:43,389 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-25 02:50:43,408 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-25 02:50:43,414 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:43,414 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:43,414 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:43,421 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-25 02:50:44,250 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:50:44,250 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:50:48,425 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:50:48,425 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:50:48,426 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: close
2019-09-25 02:50:48,426 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 6e00097f-e359-4744-8673-96b234955a6b: close
2019-09-25 02:50:48,430 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: shutdown
2019-09-25 02:50:48,430 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: shutdown
2019-09-25 02:50:48,430 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-05E2FFEACB96,id=ee927c45-5a52-4718-94ac-3cab6b482d7d
2019-09-25 02:50:48,431 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCC557643F44,id=6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:50:48,431 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: shutdown LeaderState
2019-09-25 02:50:48,431 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown LeaderState
2019-09-25 02:50:48,433 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e00097f-e359-4744-8673-96b234955a6b-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:48,433 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - ee927c45-5a52-4718-94ac-3cab6b482d7d-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:48,438 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:48,438 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:48,450 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96: closes. applyIndex: 0
2019-09-25 02:50:48,450 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44: closes. applyIndex: 0
2019-09-25 02:50:48,453 [6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:48,453 [ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:48,455 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e00097f-e359-4744-8673-96b234955a6b@group-BCC557643F44-SegmentedRaftLogWorker close()
2019-09-25 02:50:48,455 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - ee927c45-5a52-4718-94ac-3cab6b482d7d@group-05E2FFEACB96-SegmentedRaftLogWorker close()
2019-09-25 02:50:48,459 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: shutdown
2019-09-25 02:50:48,463 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=6e00097f-e359-4744-8673-96b234955a6b
2019-09-25 02:50:48,464 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown LeaderState
2019-09-25 02:50:48,464 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: shutdown server with port 38390 now
2019-09-25 02:50:48,467 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e00097f-e359-4744-8673-96b234955a6b-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:48,467 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$409/1049237930@5bea3ea] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2->c87453c9-bc63-4e09-92ea-dddb813ed738-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:50:48,467 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$409/1049237930@a4c3388] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2->e219f00c-70d9-4529-95db-0fe14364412e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-25 02:50:48,469 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:48,472 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2: closes. applyIndex: 0
2019-09-25 02:50:48,472 [6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:48,476 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2-SegmentedRaftLogWorker close()
2019-09-25 02:50:48,476 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - ee927c45-5a52-4718-94ac-3cab6b482d7d: shutdown server with port 38390 successfully
2019-09-25 02:50:48,480 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown server with port 38412 now
2019-09-25 02:50:48,482 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - c87453c9-bc63-4e09-92ea-dddb813ed738: Completed APPEND_ENTRIES, lastRequest: 6e00097f-e359-4744-8673-96b234955a6b->c87453c9-bc63-4e09-92ea-dddb813ed738#131-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-25 02:50:48,483 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - e219f00c-70d9-4529-95db-0fe14364412e: Completed APPEND_ENTRIES, lastRequest: 6e00097f-e359-4744-8673-96b234955a6b->e219f00c-70d9-4529-95db-0fe14364412e#131-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-25 02:50:48,488 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 6e00097f-e359-4744-8673-96b234955a6b: shutdown server with port 38412 successfully
2019-09-25 02:50:48,491 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:50:48,495 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2->e219f00c-70d9-4529-95db-0fe14364412e-GrpcLogAppender is stopped
2019-09-25 02:50:48,495 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - 6e00097f-e359-4744-8673-96b234955a6b@group-4EAEDCD161B2->c87453c9-bc63-4e09-92ea-dddb813ed738-GrpcLogAppender is stopped
2019-09-25 02:50:48,504 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:50:48,534 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:50:48,535 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:50:48,540 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:50:48,546 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:50:48,547 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:50:48,548 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:48,548 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f6917fb{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:50:48,549 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:48,551 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:48,551 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41eb94bc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:48,551 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a6fa56e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:48,552 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ecec90d{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:48,790 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:50:49,248 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:50:53,553 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:50:53,553 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:50:53,554 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e219f00c-70d9-4529-95db-0fe14364412e: close
2019-09-25 02:50:53,554 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c87453c9-bc63-4e09-92ea-dddb813ed738: close
2019-09-25 02:50:53,554 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: shutdown
2019-09-25 02:50:53,554 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: shutdown
2019-09-25 02:50:53,555 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=e219f00c-70d9-4529-95db-0fe14364412e
2019-09-25 02:50:53,555 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-61D6E0AE477A,id=c87453c9-bc63-4e09-92ea-dddb813ed738
2019-09-25 02:50:53,556 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown LeaderState
2019-09-25 02:50:53,555 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown FollowerState
2019-09-25 02:50:53,556 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c87453c9-bc63-4e09-92ea-dddb813ed738-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:53,556 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(115)) - e219f00c-70d9-4529-95db-0fe14364412e: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:50:53,556 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:53,559 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:53,559 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2: closes. applyIndex: 0
2019-09-25 02:50:53,559 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A: closes. applyIndex: 0
2019-09-25 02:50:53,560 [e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:53,560 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:53,561 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e219f00c-70d9-4529-95db-0fe14364412e@group-4EAEDCD161B2-SegmentedRaftLogWorker close()
2019-09-25 02:50:53,563 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-61D6E0AE477A-SegmentedRaftLogWorker close()
2019-09-25 02:50:53,565 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: shutdown
2019-09-25 02:50:53,567 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: shutdown
2019-09-25 02:50:53,567 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5B3F1280498,id=e219f00c-70d9-4529-95db-0fe14364412e
2019-09-25 02:50:53,567 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EAEDCD161B2,id=c87453c9-bc63-4e09-92ea-dddb813ed738
2019-09-25 02:50:53,568 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown FollowerState
2019-09-25 02:50:53,567 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown LeaderState
2019-09-25 02:50:53,568 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(115)) - c87453c9-bc63-4e09-92ea-dddb813ed738: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-25 02:50:53,568 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:53,570 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2: closes. applyIndex: 0
2019-09-25 02:50:53,569 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e219f00c-70d9-4529-95db-0fe14364412e-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:53,571 [c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:53,571 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:53,572 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c87453c9-bc63-4e09-92ea-dddb813ed738@group-4EAEDCD161B2-SegmentedRaftLogWorker close()
2019-09-25 02:50:53,572 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498: closes. applyIndex: 0
2019-09-25 02:50:53,574 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown server with port 37219 now
2019-09-25 02:50:53,575 [e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:53,578 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e219f00c-70d9-4529-95db-0fe14364412e@group-D5B3F1280498-SegmentedRaftLogWorker close()
2019-09-25 02:50:53,581 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown server with port 37297 now
2019-09-25 02:50:53,581 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c87453c9-bc63-4e09-92ea-dddb813ed738: shutdown server with port 37219 successfully
2019-09-25 02:50:53,584 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e219f00c-70d9-4529-95db-0fe14364412e: shutdown server with port 37297 successfully
2019-09-25 02:50:53,602 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:50:53,605 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:50:53,617 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:50:53,620 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:50:53,621 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@21505815{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:50:53,622 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:50:53,622 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e53339{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:53,622 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a1c3cb4{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:53,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2630dbc4{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:53,625 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:50:53,628 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:50:53,628 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:53,629 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:53,630 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:54,250 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-25 02:50:58,628 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-25 02:50:58,630 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: close
2019-09-25 02:50:58,630 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: shutdown
2019-09-25 02:50:58,630 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5C4B36C32650,id=0fb31bcd-734e-4bec-9c76-07f50ba1dba0
2019-09-25 02:50:58,631 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: shutdown LeaderState
2019-09-25 02:50:58,631 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0-PendingRequests: sendNotLeaderResponses
2019-09-25 02:50:58,632 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-StateMachineUpdater: set stopIndex = 0
2019-09-25 02:50:58,635 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650: closes. applyIndex: 0
2019-09-25 02:50:58,635 [0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-25 02:50:58,642 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0@group-5C4B36C32650-SegmentedRaftLogWorker close()
2019-09-25 02:50:58,644 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: shutdown server with port 38582 now
2019-09-25 02:50:58,646 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0fb31bcd-734e-4bec-9c76-07f50ba1dba0: shutdown server with port 38582 successfully
2019-09-25 02:50:58,651 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-7374fcdf-a2e8-4148-8a6e-7bdb5d58a711/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-25 02:50:58,669 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-25 02:50:58,673 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-25 02:50:58,674 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dc3502b{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-25 02:50:58,675 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a1d3225{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:58,675 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb29ca9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:58,676 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56dfab87{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:58,677 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-25 02:50:58,677 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-25 02:50:58,678 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-25 02:50:58,678 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-25 02:50:58,678 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-25 02:50:58,678 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-25 02:50:58,679 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35123
2019-09-25 02:50:58,680 [IPC Server listener on 35123] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35123
2019-09-25 02:50:58,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:50:58,765 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-25 02:50:58,766 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-25 02:50:58,766 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-25 02:50:58,766 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45293
2019-09-25 02:50:58,769 [IPC Server listener on 45293] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45293
2019-09-25 02:50:58,769 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-25 02:50:58,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:50:58,769 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-25 02:50:58,770 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45908
2019-09-25 02:50:58,770 [IPC Server listener on 45908] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45908
2019-09-25 02:50:58,770 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-25 02:50:58,774 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-25 02:50:58,774 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-25 02:50:58,776 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-25 02:50:58,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-25 02:50:58,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-25 02:50:58,780 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-25 02:50:58,781 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 02:50:58,782 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-25 02:50:58,783 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-25 02:50:58,791 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-25 02:50:58,800 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-25 02:50:58,800 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

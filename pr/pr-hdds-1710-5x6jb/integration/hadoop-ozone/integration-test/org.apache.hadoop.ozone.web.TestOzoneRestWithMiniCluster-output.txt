2019-07-14 16:14:03,500 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:03,599 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:03,602 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:03,619 INFO  util.log (Log.java:initialized(192)) - Logging initialized @877ms
2019-07-14 16:14:03,720 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-07-14 16:14:03,720 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-07-14 16:14:03,720 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-07-14 16:14:03,721 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-07-14 16:14:03,721 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-07-14 16:14:03,721 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-07-14 16:14:03,733 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-07-14 16:14:03,733 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-07-14 16:14:03,734 INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-07-14 16:14:03,979 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6eda5c9
2019-07-14 16:14:03,983 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-07-14 16:14:04,064 WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-07-14 16:14:04,066 WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-07-14 16:14:04,069 INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(119)) - Entering startup safe mode.
2019-07-14 16:14:04,152 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:04,238 INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-07-14 16:14:04,242 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:04,354 WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-07-14 16:14:04,689 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-14 16:14:04,717 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39618
2019-07-14 16:14:04,739 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-14 16:14:04,740 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38968
2019-07-14 16:14:04,746 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-14 16:14:04,748 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37828
2019-07-14 16:14:04,894 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-07-14 16:14:05,076 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-14 16:14:05,085 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-14 16:14:05,095 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-14 16:14:05,098 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-07-14 16:14:05,098 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-14 16:14:05,099 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-14 16:14:05,129 INFO  server.StorageContainerManager (StorageContainerManager.java:start(761)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37828
2019-07-14 16:14:05,186 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-07-14 16:14:05,199 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-07-14 16:14:05,199 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-07-14 16:14:05,420 INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(149)) - RPC server for Client  is listening at /0.0.0.0:37828
2019-07-14 16:14:05,421 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-14 16:14:05,421 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37828: starting
2019-07-14 16:14:05,426 INFO  server.StorageContainerManager (StorageContainerManager.java:start(771)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38968
2019-07-14 16:14:05,426 INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:38968
2019-07-14 16:14:05,426 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-14 16:14:05,426 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38968: starting
2019-07-14 16:14:05,434 INFO  server.StorageContainerManager (StorageContainerManager.java:start(775)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:39618
2019-07-14 16:14:05,435 INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:39618
2019-07-14 16:14:05,436 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39618: starting
2019-07-14 16:14:05,437 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-14 16:14:05,449 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35518
2019-07-14 16:14:05,452 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-14 16:14:05,503 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a1a3478{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-14 16:14:05,504 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55dfcc6{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-07-14 16:14:05,539 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71104a4{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-07-14 16:14:05,545 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bf9b098{HTTP/1.1,[http/1.1]}{0.0.0.0:35518}
2019-07-14 16:14:05,545 INFO  server.Server (Server.java:doStart(419)) - Started @2802ms
2019-07-14 16:14:05,547 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of SCM is listening at http://0.0.0.0:35518
2019-07-14 16:14:05,556 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-07-14 16:14:05,560 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:05,672 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:05,674 INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(632)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-07-14 16:14:05,674 INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(638)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 0a5826cb-aeb0-4a05-ab2a-612946d53c2c
2019-07-14 16:14:05,675 INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(589)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-07-14 16:14:05,936 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:05,945 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-07-14 16:14:05,945 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-07-14 16:14:05,946 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-07-14 16:14:05,946 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-07-14 16:14:05,946 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-07-14 16:14:05,946 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-07-14 16:14:05,947 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-07-14 16:14:05,947 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-07-14 16:14:05,947 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-07-14 16:14:05,948 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-07-14 16:14:05,948 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-07-14 16:14:05,948 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-07-14 16:14:05,948 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-07-14 16:14:05,949 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-07-14 16:14:05,949 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-07-14 16:14:05,949 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-07-14 16:14:05,950 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-07-14 16:14:05,950 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-07-14 16:14:05,950 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-07-14 16:14:05,950 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-07-14 16:14:05,951 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-07-14 16:14:05,951 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-07-14 16:14:05,951 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-07-14 16:14:05,951 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-07-14 16:14:05,952 INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-07-14 16:14:07,001 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-07-14 16:14:07,002 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40177
2019-07-14 16:14:07,032 WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-07-14 16:14:07,032 INFO  om.OzoneManager (OzoneManager.java:start(1230)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40177
2019-07-14 16:14:07,033 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-07-14 16:14:07,036 INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-07-14 16:14:07,037 INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40177: starting
2019-07-14 16:14:07,051 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-07-14 16:14:07,053 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-14 16:14:07,054 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-14 16:14:07,057 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-14 16:14:07,058 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-07-14 16:14:07,059 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-14 16:14:07,059 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-14 16:14:07,062 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45881
2019-07-14 16:14:07,062 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-14 16:14:07,065 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1eea9d2d{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-14 16:14:07,066 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bd2f5a9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-07-14 16:14:07,072 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f36b447{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-07-14 16:14:07,073 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6443b128{HTTP/1.1,[http/1.1]}{0.0.0.0:45881}
2019-07-14 16:14:07,074 INFO  server.Server (Server.java:doStart(419)) - Started @4331ms
2019-07-14 16:14:07,075 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45881
2019-07-14 16:14:07,410 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-07-14 16:14:07,497 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:pr-hdds-1710-5x6jb-1204890111 ip:192.168.69.77
2019-07-14 16:14:07,543 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 52710309888
2019-07-14 16:14:07,546 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/containers/hdds to VolumeSet
2019-07-14 16:14:07,550 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4a0df195
2019-07-14 16:14:07,574 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4a0df195
2019-07-14 16:14:07,694 INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-07-14 16:14:07,757 INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-07-14 16:14:07,762 INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-07-14 16:14:07,763 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-07-14 16:14:07,764 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-07-14 16:14:07,765 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-07-14 16:14:07,766 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-07-14 16:14:07,989 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis] (custom)
2019-07-14 16:14:08,035 INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-07-14 16:14:08,050 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-07-14 16:14:08,053 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-07-14 16:14:08,054 WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-07-14 16:14:08,056 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-07-14 16:14:08,057 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-07-14 16:14:08,057 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-07-14 16:14:08,057 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-07-14 16:14:08,058 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37474
2019-07-14 16:14:08,058 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-07-14 16:14:08,061 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@9b21bd3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-07-14 16:14:08,062 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7661b5a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-07-14 16:14:08,097 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@216e0771{/,file:///tmp/jetty-0.0.0.0-37474-hddsDatanode-_-any-3718107834588774696.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-07-14 16:14:08,099 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21079a12{HTTP/1.1,[http/1.1]}{0.0.0.0:37474}
2019-07-14 16:14:08,099 INFO  server.Server (Server.java:doStart(419)) - Started @5356ms
2019-07-14 16:14:08,101 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37474
Jul 14, 2019 4:14:08 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-07-14 16:14:09,224 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@392781e
2019-07-14 16:14:09,228 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-14 16:14:09,234 INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-07-14 16:14:09,362 INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/meta/datanode.id
2019-07-14 16:14:10,228 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-14 16:14:11,229 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-14 16:14:11,294 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-07-14 16:14:11,296 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-07-14 16:14:11,296 INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 09058f09-fa3c-49f6-af00-dcbaec476975 at port 0
2019-07-14 16:14:11,321 INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 09058f09-fa3c-49f6-af00-dcbaec476975: start RPC server
2019-07-14 16:14:11,471 INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 09058f09-fa3c-49f6-af00-dcbaec476975: GrpcService started, listening on 0.0.0.0/0.0.0.0:33762
2019-07-14 16:14:11,472 INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(428)) - XceiverServerRatis 09058f09-fa3c-49f6-af00-dcbaec476975 is started using port 33762
2019-07-14 16:14:11,474 INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(161)) - XceiverServerGrpc 09058f09-fa3c-49f6-af00-dcbaec476975 is started using port 39220
2019-07-14 16:14:12,230 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-14 16:14:13,231 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-07-14 16:14:13,280 INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/192.168.69.77
2019-07-14 16:14:13,281 INFO  node.SCMNodeManager (SCMNodeManager.java:register(269)) - Registered Data node : 09058f09-fa3c-49f6-af00-dcbaec476975{ip: 192.168.69.77, host: pr-hdds-1710-5x6jb-1204890111, networkLocation: /default-rack, certSerialId: null}
2019-07-14 16:14:13,287 INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-07-14 16:14:13,287 INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-07-14 16:14:13,288 INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-07-14 16:14:13,823 INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 09058f09-fa3c-49f6-af00-dcbaec476975: addNew group-E91AD8BAB61D:[09058f09-fa3c-49f6-af00-dcbaec476975:192.168.69.77:33762] returns group-E91AD8BAB61D:java.util.concurrent.CompletableFuture@364fa225[Not completed]
2019-07-14 16:14:13,839 INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 09058f09-fa3c-49f6-af00-dcbaec476975: new RaftServerImpl for group-E91AD8BAB61D:[09058f09-fa3c-49f6-af00-dcbaec476975:192.168.69.77:33762] with ContainerStateMachine:uninitialized
2019-07-14 16:14:13,842 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-07-14 16:14:13,843 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-07-14 16:14:13,843 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-07-14 16:14:13,845 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-07-14 16:14:13,846 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-07-14 16:14:13,855 INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D ConfigurationManager, init=-1: [09058f09-fa3c-49f6-af00-dcbaec476975:192.168.69.77:33762], old=null, confs=<EMPTY_MAP>
2019-07-14 16:14:13,855 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis] (custom)
2019-07-14 16:14:13,864 INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d does not exist. Creating ...
2019-07-14 16:14:13,881 INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d/in_use.lock acquired by nodename 31710@pr-hdds-1710-5x6jb-1204890111
2019-07-14 16:14:13,897 INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d has been successfully formatted.
2019-07-14 16:14:13,899 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(200)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-07-14 16:14:13,899 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-07-14 16:14:13,902 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-07-14 16:14:13,908 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000000 (custom)
2019-07-14 16:14:13,908 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-07-14 16:14:13,910 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-07-14 16:14:14,221 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-07-14 16:14:14,230 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d
2019-07-14 16:14:14,231 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-07-14 16:14:14,246 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-07-14 16:14:14,248 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-07-14 16:14:14,252 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-07-14 16:14:14,253 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-07-14 16:14:14,253 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-07-14 16:14:14,254 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-07-14 16:14:14,255 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-07-14 16:14:14,255 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-07-14 16:14:14,255 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-07-14 16:14:14,264 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-07-14 16:14:14,268 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d: flushIndex: setUnconditionally 0 -> -1
2019-07-14 16:14:14,272 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-07-14 16:14:14,273 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-07-14 16:14:14,273 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-07-14 16:14:14,294 INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 09058f09-fa3c-49f6-af00-dcbaec476975: start group-E91AD8BAB61D
2019-07-14 16:14:14,295 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-07-14 16:14:14,296 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09058f09-fa3c-49f6-af00-dcbaec476975: start FollowerState
2019-07-14 16:14:14,298 INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E91AD8BAB61D,id=09058f09-fa3c-49f6-af00-dcbaec476975
2019-07-14 16:14:14,360 INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bb86061c-f0f3-498c-a2ed-e91ad8bab61d, Nodes: 09058f09-fa3c-49f6-af00-dcbaec476975{ip: 192.168.69.77, host: pr-hdds-1710-5x6jb-1204890111, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-07-14 16:14:14,587 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumellnqf, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:14,646 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumellnqf/bucketfbm3p, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:14,970 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server 09058f09-fa3c-49f6-af00-dcbaec476975 is not the leader (null). Request must be sent to leader., logIndex=0, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c-1]
2019-07-14 16:14:16,290 INFO  container.ReplicationManager (ReplicationManager.java:start(155)) - Starting Replication Monitor Thread.
2019-07-14 16:14:16,298 INFO  container.ReplicationManager (ReplicationManager.java:run(207)) - Replication Monitor Thread took 6 milliseconds for processing 1 containers.
2019-07-14 16:14:17,024 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server 09058f09-fa3c-49f6-af00-dcbaec476975 is not the leader (null). Request must be sent to leader., logIndex=0, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c-1]
2019-07-14 16:14:19,067 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=1, FAILED org.apache.ratis.protocol.NotLeaderException: Server 09058f09-fa3c-49f6-af00-dcbaec476975 is not the leader (null). Request must be sent to leader., logIndex=0, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c-1]
2019-07-14 16:14:19,485 INFO  impl.FollowerState (FollowerState.java:run(106)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D changes to CANDIDATE, lastRpcTime:5188, electionTimeout:5188ms
2019-07-14 16:14:19,485 INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown FollowerState
2019-07-14 16:14:19,486 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-07-14 16:14:19,492 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09058f09-fa3c-49f6-af00-dcbaec476975: start LeaderElection
2019-07-14 16:14:19,499 INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D:LeaderElection1: begin an election at term 1 for -1: [09058f09-fa3c-49f6-af00-dcbaec476975:192.168.69.77:33762], old=null
2019-07-14 16:14:19,501 INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown LeaderElection
2019-07-14 16:14:19,502 INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-07-14 16:14:19,502 INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D change Leader from null to 09058f09-fa3c-49f6-af00-dcbaec476975 at term 1 for becomeLeader, leader elected after 5602ms
2019-07-14 16:14:19,511 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-07-14 16:14:19,511 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-07-14 16:14:19,515 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-07-14 16:14:19,518 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-07-14 16:14:19,519 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-07-14 16:14:19,520 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-07-14 16:14:19,531 INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 09058f09-fa3c-49f6-af00-dcbaec476975: start LeaderState
2019-07-14 16:14:19,555 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d: Starting segment from index:0
2019-07-14 16:14:19,565 INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D set configuration 0: [09058f09-fa3c-49f6-af00-dcbaec476975:192.168.69.77:33762], old=null at 0
2019-07-14 16:14:19,758 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d/current/log_inprogress_0
2019-07-14 16:14:21,289 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=1, SUCCESS, logIndex=1, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c1]
2019-07-14 16:14:21,493 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=2, SUCCESS, logIndex=3, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c7]
2019-07-14 16:14:21,498 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=3, SUCCESS, logIndex=5, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c7]
2019-07-14 16:14:21,499 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=4, SUCCESS, logIndex=6, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c7]
2019-07-14 16:14:21,541 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=5, SUCCESS, logIndex=8, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c9]
2019-07-14 16:14:21,543 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=6, SUCCESS, logIndex=9, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c9]
2019-07-14 16:14:21,608 INFO  pipeline.Pipeline (Pipeline.java:getProtobufMessage(195)) - Serialize pipeline PipelineID=bb86061c-f0f3-498c-a2ed-e91ad8bab61d with nodesInOrder{ }
2019-07-14 16:14:21,610 INFO  pipeline.Pipeline (Pipeline.java:build(342)) - Deserialize nodesInOrder [09058f09-fa3c-49f6-af00-dcbaec476975{ip: 192.168.69.77, host: pr-hdds-1710-5x6jb-1204890111, networkLocation: /default-rack, certSerialId: null}] in pipeline PipelineID=bb86061c-f0f3-498c-a2ed-e91ad8bab61d
2019-07-14 16:14:21,951 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: ae70cfe2752c5d6d:ae70cfe2752c5d6d:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
2019-07-14 16:14:21,956 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: c9529dad7ff67b4a:c9529dad7ff67b4a:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
16:14:21.957 [pool-26-thread-4] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688807444483 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
16:14:21.957 [pool-26-thread-5] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688807444483 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:21,971 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: ae70cfe2752c5d6d:ae70cfe2752c5d6d:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
2019-07-14 16:14:21,971 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: c9529dad7ff67b4a:c9529dad7ff67b4a:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
16:14:21.985 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688807444483 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:21,986 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: ae70cfe2752c5d6d:ae70cfe2752c5d6d:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
16:14:21.987 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102440688807444483 bcsId: 0,size=1048576]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:21,987 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: a34d9e7d5c239ed0:a34d9e7d5c239ed0:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:21,990 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=7, SUCCESS, logIndex=11, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c14]
16:14:21.989 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688807444483 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:21,990 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: c9529dad7ff67b4a:c9529dad7ff67b4a:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:21,991 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=8, SUCCESS, logIndex=12, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c14]
16:14:21.991 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102440688807444483 bcsId: 0,size=1572864]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:21,993 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: 9d8d80a0a27cf3e6:9d8d80a0a27cf3e6:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:21,993 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-14 16:14:21,993 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=9, SUCCESS, logIndex=13, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c14]
2019-07-14 16:14:21,996 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=10, SUCCESS, logIndex=14, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c14]
2019-07-14 16:14:22,010 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumepomqv, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,017 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumepomqv/bucketvu55p, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:22,033 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumecuosb, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,039 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumecuosb/bucket6ow8c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:22,061 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 84b88ae05e0af6d6:84b88ae05e0af6d6:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
16:14:22.062 [pool-26-thread-6] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102440688815636486 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,063 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 84b88ae05e0af6d6:84b88ae05e0af6d6:0:0 : Message: ContainerID 3 creation failed : Result: DISK_OUT_OF_SPACE
16:14:22.075 [pool-30-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102440688815636486 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,076 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 84b88ae05e0af6d6:84b88ae05e0af6d6:0:0 : Message: ContainerID 3 does not exist : Result: CONTAINER_NOT_FOUND
16:14:22.076 [pool-30-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102440688815636486 bcsId: 0,size=9]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,078 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: 6be19dcca41d7f9d:6be19dcca41d7f9d:0:0 : Message: ContainerID 3 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:22,078 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=11, SUCCESS, logIndex=16, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c17]
2019-07-14 16:14:22,080 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-14 16:14:22,081 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=12, SUCCESS, logIndex=17, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c17]
2019-07-14 16:14:22,084 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumem0jh8, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,088 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumem0jh8/bucketkzvhp, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:22,093 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumeofk50, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,138 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumemzxnk, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,142 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumemzxnk/bucketug1kz, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:22,200 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=13, SUCCESS, logIndex=19, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c20]
2019-07-14 16:14:22,202 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=14, SUCCESS, logIndex=20, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c20]
2019-07-14 16:14:22,211 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=15, SUCCESS, logIndex=21, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c23]
2019-07-14 16:14:22,212 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=16, SUCCESS, logIndex=22, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c24]
2019-07-14 16:14:22,245 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=17, SUCCESS, logIndex=25, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c26]
2019-07-14 16:14:22,247 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=18, SUCCESS, logIndex=26, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c26]
2019-07-14 16:14:22,266 INFO  pipeline.Pipeline (Pipeline.java:getProtobufMessage(195)) - Serialize pipeline PipelineID=bb86061c-f0f3-498c-a2ed-e91ad8bab61d with nodesInOrder{ }
2019-07-14 16:14:22,268 INFO  pipeline.Pipeline (Pipeline.java:build(342)) - Deserialize nodesInOrder [09058f09-fa3c-49f6-af00-dcbaec476975{ip: 192.168.69.77, host: pr-hdds-1710-5x6jb-1204890111, networkLocation: /default-rack, certSerialId: null}] in pipeline PipelineID=bb86061c-f0f3-498c-a2ed-e91ad8bab61d
2019-07-14 16:14:22,503 INFO  rpc.RpcClient (RpcClient.java:createVolume(289)) - Creating Volume: volumegjpaq, with bilbo as owner and quota set to 109951162777600 bytes.
2019-07-14 16:14:22,510 INFO  rpc.RpcClient (RpcClient.java:createBucket(424)) - Creating Bucket: volumegjpaq/bucketiwu5j, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-07-14 16:14:22,557 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 6bb4ff0c03259877:6bb4ff0c03259877:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
16:14:22.558 [pool-26-thread-10] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688846766090 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,559 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 6bb4ff0c03259877:6bb4ff0c03259877:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
2019-07-14 16:14:22,562 INFO  keyvalue.KeyValueHandler (ContainerUtils.java:logAndReturnError(146)) - Operation: CreateContainer : Trace ID: 47d838b0b8740383:47d838b0b8740383:0:0 : Message: Container creation failed, due to disk out of space : Result: DISK_OUT_OF_SPACE
16:14:22.563 [pool-26-thread-11] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688846766090 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:227) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$0(ContainerStateMachine.java:395) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,563 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 47d838b0b8740383:47d838b0b8740383:0:0 : Message: ContainerID 2 creation failed : Result: DISK_OUT_OF_SPACE
16:14:22.572 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688846766090 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,572 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 6bb4ff0c03259877:6bb4ff0c03259877:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
16:14:22.573 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102440688846766090 bcsId: 0,size=1048576]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,574 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: 4d9ba7caaab10efa:4d9ba7caaab10efa:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:22,575 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=19, SUCCESS, logIndex=28, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c29]
2019-07-14 16:14:22,576 ERROR storage.BlockOutputStream (BlockOutputStream.java:validateResponse(539)) - Unexpected Storage Container Exception: 
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.validateContainerResponse(ContainerProtocolCalls.java:536)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.validateResponse(BlockOutputStream.java:537)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.lambda$writeChunkToContainer$2(BlockOutputStream.java:615)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-14 16:14:22,577 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=20, SUCCESS, logIndex=29, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c29]
16:14:22.582 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102440688846766090 bcsId: 0} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,583 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: WriteChunk : Trace ID: 47d838b0b8740383:47d838b0b8740383:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
16:14:22.584 [pool-29-thread-1] ERROR DNAudit - user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102440688846766090 bcsId: 0,size=2097152]} | ret=FAILURE
org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 does not exist
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:242) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:148) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:357) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:364) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$applyTransaction$5(ContainerStateMachine.java:630) ~[hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_212]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_212]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]
2019-07-14 16:14:22,584 INFO  impl.HddsDispatcher (ContainerUtils.java:logAndReturnError(146)) - Operation: PutBlock : Trace ID: f5545efcedd4839e:f5545efcedd4839e:0:0 : Message: ContainerID 2 does not exist : Result: CONTAINER_NOT_FOUND
2019-07-14 16:14:22,585 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=21, SUCCESS, logIndex=30, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c32]
2019-07-14 16:14:22,586 INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975: receive RaftClientReply:client-005408C9E614->09058f09-fa3c-49f6-af00-dcbaec476975@group-E91AD8BAB61D, cid=22, SUCCESS, logIndex=31, commits[09058f09-fa3c-49f6-af00-dcbaec476975:c33]
2019-07-14 16:14:22,590 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-07-14 16:14:22,591 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-07-14 16:14:22,591 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-07-14 16:14:22,591 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40177
2019-07-14 16:14:22,599 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40177
2019-07-14 16:14:22,599 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-07-14 16:14:22,602 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-14 16:14:22,611 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f36b447{/,null,UNAVAILABLE}{/ozoneManager}
2019-07-14 16:14:22,616 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6443b128{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-14 16:14:22,617 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bd2f5a9{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-07-14 16:14:22,617 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1eea9d2d{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-14 16:14:22,633 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-07-14 16:14:22,633 INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-07-14 16:14:22,635 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@392781e
2019-07-14 16:14:23,239 INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-07-14 16:14:27,638 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-07-14 16:14:27,640 INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 09058f09-fa3c-49f6-af00-dcbaec476975: close
2019-07-14 16:14:27,643 INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown group-E91AD8BAB61D
2019-07-14 16:14:27,643 INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E91AD8BAB61D,id=09058f09-fa3c-49f6-af00-dcbaec476975
2019-07-14 16:14:27,644 INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown LeaderState
2019-07-14 16:14:27,645 INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 09058f09-fa3c-49f6-af00-dcbaec476975-PendingRequests: sendNotLeaderResponses
2019-07-14 16:14:27,654 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D: set stopIndex = 33
2019-07-14 16:14:27,654 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(246)) - Taking snapshot at termIndex:(t:1, i:33)
2019-07-14 16:14:27,656 INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(250)) - Taking a snapshot to file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d/sm/snapshot.1_33
2019-07-14 16:14:27,664 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D: Took a snapshot at index 33
2019-07-14 16:14:27,665 INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D: snapshotIndex: updateIncreasingly -1 -> 33
2019-07-14 16:14:27,670 INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 09058f09-fa3c-49f6-af00-dcbaec476975:group-E91AD8BAB61D closes. The last applied log index is 33
2019-07-14 16:14:27,673 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-07-14 16:14:27,675 INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 09058f09-fa3c-49f6-af00-dcbaec476975-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-860354f0-2eae-4104-aea3-8a9178af4ae2/datanode-0/data/ratis/bb86061c-f0f3-498c-a2ed-e91ad8bab61d close()
2019-07-14 16:14:27,678 INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown server with port 33762 now
2019-07-14 16:14:27,682 INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 09058f09-fa3c-49f6-af00-dcbaec476975: shutdown server with port 33762 successfully
2019-07-14 16:14:27,687 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-07-14 16:14:27,688 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-07-14 16:14:27,712 INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-07-14 16:14:27,714 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@216e0771{/,null,UNAVAILABLE}{/hddsDatanode}
2019-07-14 16:14:27,715 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21079a12{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-14 16:14:27,716 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7661b5a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-07-14 16:14:27,716 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@9b21bd3{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-14 16:14:27,717 INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-07-14 16:14:27,717 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(799)) - Stopping Replication Manager Service.
2019-07-14 16:14:27,717 INFO  container.ReplicationManager (ReplicationManager.java:stop(187)) - Stopping Replication Monitor Thread.
2019-07-14 16:14:27,718 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(806)) - Stopping Lease Manager of the command watchers
2019-07-14 16:14:27,718 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(813)) - Stopping datanode service RPC server
2019-07-14 16:14:27,718 INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(375)) - Stopping the RPC server for DataNodes
2019-07-14 16:14:27,718 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39618
2019-07-14 16:14:27,720 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39618
2019-07-14 16:14:27,722 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-14 16:14:27,745 WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(631)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-07-14 16:14:27,745 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(821)) - Stopping block service RPC server
2019-07-14 16:14:27,745 INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-07-14 16:14:27,745 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38968
2019-07-14 16:14:27,747 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(828)) - Stopping the StorageContainerLocationProtocol RPC server
2019-07-14 16:14:27,747 INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(157)) - Stopping the RPC server for Client Protocol
2019-07-14 16:14:27,747 INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37828
2019-07-14 16:14:27,749 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38968
2019-07-14 16:14:27,749 INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37828
2019-07-14 16:14:27,750 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(835)) - Stopping Storage Container Manager HTTP server.
2019-07-14 16:14:27,750 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-14 16:14:27,750 INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-07-14 16:14:27,751 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71104a4{/,null,UNAVAILABLE}{/scm}
2019-07-14 16:14:27,753 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bf9b098{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-07-14 16:14:27,754 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55dfcc6{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-07-14 16:14:27,754 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a1a3478{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-07-14 16:14:27,756 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping Block Manager Service.
2019-07-14 16:14:27,756 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-07-14 16:14:27,758 INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-07-14 16:14:27,759 INFO  server.StorageContainerManager (StorageContainerManager.java:stop(868)) - Stopping SCM Event Queue.
2019-07-14 16:14:27,789 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-07-14 16:14:27,791 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.

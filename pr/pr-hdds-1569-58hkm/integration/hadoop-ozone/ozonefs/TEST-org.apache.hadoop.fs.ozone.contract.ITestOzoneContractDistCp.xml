<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="125.001" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="java.vm.vendor" value="IcedTea"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://icedtea.classpath.org"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/workdir/hadoop-ozone/ozonefs/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64"/>
    <property name="sun.java.command" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter5196335599121807594.jar /workdir/hadoop-ozone/ozonefs/target/surefire 2019-09-12T10-07-27_366-jvmRun1 surefire2635329834572395655tmp surefire_1125556480946538985870tmp"/>
    <property name="test" value="!TestMiniChaosOzoneCluster"/>
    <property name="surefire.test.class.path" value="/workdir/hadoop-ozone/ozonefs/target/test-classes:/workdir/hadoop-ozone/ozonefs/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/tools.jar:/home/user/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.3.24.v20180605/jetty-server-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.3.24.v20180605/jetty-http-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.3.24.v20180605/jetty-io-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.24.v20180605/jetty-webapp-9.3.24.v20180605.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.24.v20180605/jetty-xml-9.3.24.v20180605.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.5/jackson-databind-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.5/jackson-annotations-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.5/jackson-core-2.9.5.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.3.24.v20180605/jetty-util-ajax-9.3.24.v20180605.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.5.0-SNAPSHOT/hadoop-hdds-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.5.0-SNAPSHOT/hadoop-hdds-config-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.4.0-2337318-SNAPSHOT/ratis-server-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.2.0/ratis-thirdparty-misc-0.2.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.4.0-2337318-SNAPSHOT/ratis-proto-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.4.0-2337318-SNAPSHOT/ratis-common-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.4.0-2337318-SNAPSHOT/ratis-client-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.4.0-2337318-SNAPSHOT/ratis-metrics-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.4.0-2337318-SNAPSHOT/ratis-netty-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.4.0-2337318-SNAPSHOT/ratis-grpc-0.4.0-2337318-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.0.1/rocksdbjni-6.0.1.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/0.33.1/jaeger-client-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/0.33.1/jaeger-thrift-0.33.1.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.11.0/libthrift-0.11.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/3.9.0/okhttp-3.9.0.jar:/home/user/.m2/repository/com/squareup/okio/okio/1.13.0/okio-1.13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/0.33.1/jaeger-core-0.33.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/0.33.1/jaeger-tracerresolver-0.33.1.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.5/opentracing-tracerresolver-0.1.5.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.31.0/opentracing-util-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.31.0/opentracing-api-0.31.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.31.0/opentracing-noop-0.31.0.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.5.0-SNAPSHOT/hadoop-hdds-docs-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-all/1.3/hamcrest-all-1.3.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.5.0-SNAPSHOT/hadoop-hdds-server-framework-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.5.0-SNAPSHOT/hadoop-hdds-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.5.0-SNAPSHOT/hadoop-ozone-common-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.5.0-SNAPSHOT/hadoop-hdds-tools-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-objectstore-service/0.5.0-SNAPSHOT/hadoop-ozone-objectstore-service-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/code/findbugs/findbugs/3.0.1/findbugs-3.0.1.jar:/home/user/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/home/user/.m2/repository/com/google/code/findbugs/bcel-findbugs/6.0/bcel-findbugs-6.0.jar:/home/user/.m2/repository/com/google/code/findbugs/jFormatString/2.0.1/jFormatString-2.0.1.jar:/home/user/.m2/repository/dom4j/dom4j/1.6.1/dom4j-1.6.1.jar:/home/user/.m2/repository/xml-apis/xml-apis/1.0.b2/xml-apis-1.0.b2.jar:/home/user/.m2/repository/org/ow2/asm/asm-debug-all/5.0.2/asm-debug-all-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-commons/5.0.2/asm-commons-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm-tree/5.0.2/asm-tree-5.0.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/user/.m2/repository/com/apple/AppleJavaExtensions/1.4/AppleJavaExtensions-1.4.jar:/home/user/.m2/repository/jaxen/jaxen/1.1.6/jaxen-1.1.6.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.5.0-SNAPSHOT/hadoop-ozone-client-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.0/hadoop-hdfs-3.2.0-tests.jar:/workdir/hadoop-ozone/integration-test/target/test-classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.5.0-SNAPSHOT/hadoop-ozone-s3gateway-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.9.0/jackson-dataformat-xml-2.9.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.5.0-SNAPSHOT/hadoop-ozone-csi-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.5.1/protobuf-java-util-3.5.1.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.17.1/grpc-netty-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.17.1/grpc-core-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.17.1/grpc-context-1.17.1.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/home/user/.m2/repository/io/opencensus/opencensus-api/0.17.0/opencensus-api-0.17.0.jar:/home/user/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.17.0/opencensus-contrib-grpc-metrics-0.17.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.30.Final/netty-codec-http2-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.30.Final/netty-codec-http-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.30.Final/netty-codec-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.30.Final/netty-handler-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.30.Final/netty-handler-proxy-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.30.Final/netty-codec-socks-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.30.Final/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.30.Final/netty-common-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.30.Final/netty-buffer-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.30.Final/netty-transport-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.30.Final/netty-resolver-4.1.30.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.30.Final/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.17.1/grpc-protobuf-1.17.1.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.0.0/proto-google-common-protos-1.0.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.17.1/grpc-protobuf-lite-1.17.1.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.17.1/grpc-stub-1.17.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.5.0-SNAPSHOT/hadoop-ozone-recon-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.5.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.5.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.1.3.RELEASE/spring-jdbc-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.1.3.RELEASE/spring-beans-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.1.3.RELEASE/spring-core-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.1.3.RELEASE/spring-jcl-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.1.3.RELEASE/spring-tx-5.1.3.RELEASE.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.10.19/mockito-all-1.10.19.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.0/hadoop-distcp-3.2.0-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4/1.6.5/powermock-module-junit4-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-module-junit4-common/1.6.5/powermock-module-junit4-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-core/1.6.5/powermock-core-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-reflect/1.6.5/powermock-reflect-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito/1.6.5/powermock-api-mockito-1.6.5.jar:/home/user/.m2/repository/org/mockito/mockito-core/1.10.19/mockito-core-1.10.19.jar:/home/user/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/user/.m2/repository/org/powermock/powermock-api-mockito-common/1.6.5/powermock-api-mockito-common-1.6.5.jar:/home/user/.m2/repository/org/powermock/powermock-api-support/1.6.5/powermock-api-support-1.6.5.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8-openjdk/jre"/>
    <property name="java.security.krb5.conf" value="/workdir/hadoop-ozone/ozonefs/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/workdir/hadoop-ozone/ozonefs/target/surefire/surefirebooter5196335599121807594.jar"/>
    <property name="hadoop.log.dir" value="/workdir/hadoop-ozone/ozonefs/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8-openjdk/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8-openjdk/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_212-b04"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1000"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="3.10.0-957.12.2.el7.x86_64"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://icedtea.classpath.org/bugzilla"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_212"/>
    <property name="user.dir" value="/workdir/hadoop-ozone/ozonefs"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/workdir/hadoop-ozone/ozonefs/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/workdir/hadoop-ozone/ozonefs/target/tmp"/>
    <property name="java.library.path" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/workdir/hadoop-ozone/ozonefs/target/native/target/usr/local/lib:/workdir/hadoop-ozone/ozonefs/../../hadoop-common-project/hadoop-common/target/native/target/usr/local/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="IcedTea"/>
    <property name="java.vm.version" value="25.212-b04"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8-openjdk/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testUpdateDeepDirectoryStructureNoChange" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="34.688">
    <error message="DistCp failure: Job job_local846992285_0001 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local846992285_0001 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureNoChange(AbstractContractDistCpTest.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:41:46,851 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:46,983 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:46,986 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:47,004 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @954ms
2019-09-12 11:41:47,115 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-12 11:41:47,115 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-12 11:41:47,116 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-12 11:41:47,116 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-12 11:41:47,116 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-12 11:41:47,117 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-12 11:41:47,129 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 11:41:47,129 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 11:41:47,131 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 11:41:47,392 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6b81ce95
2019-09-12 11:41:47,393 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-12 11:41:47,467 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 11:41:47,469 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 11:41:47,472 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-12 11:41:47,612 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-12 11:41:47,629 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:47,736 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-12 11:41:47,739 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:47,876 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-12 11:41:48,701 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:41:48,731 [Socket Reader #1 for port 35471] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35471
2019-09-12 11:41:48,756 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:41:48,757 [Socket Reader #1 for port 45617] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45617
2019-09-12 11:41:48,765 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:41:48,766 [Socket Reader #1 for port 40216] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40216
2019-09-12 11:41:48,787 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-12 11:41:48,907 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:48,922 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:48,932 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:48,934 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-12 11:41:48,934 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:48,934 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:48,959 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40216
2019-09-12 11:41:49,010 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-12 11:41:49,023 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-12 11:41:49,023 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-12 11:41:49,272 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:40216
2019-09-12 11:41:49,272 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:41:49,273 [IPC Server listener on 40216] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40216: starting
2019-09-12 11:41:49,276 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45617
2019-09-12 11:41:49,276 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:45617
2019-09-12 11:41:49,276 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:41:49,276 [IPC Server listener on 45617] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45617: starting
2019-09-12 11:41:49,279 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:35471
2019-09-12 11:41:49,279 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:35471
2019-09-12 11:41:49,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:41:49,279 [IPC Server listener on 35471] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35471: starting
2019-09-12 11:41:49,284 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39219
2019-09-12 11:41:49,286 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:49,335 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65b3a85a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:49,336 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53d1b9b3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:49,418 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@733037{/,file:///tmp/jetty-0.0.0.0-39219-scm-_-any-1432314801360743651.dir/webapp/,AVAILABLE}{/scm}
2019-09-12 11:41:49,422 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50b8ae8d{HTTP/1.1,[http/1.1]}{0.0.0.0:39219}
2019-09-12 11:41:49,423 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3372ms
2019-09-12 11:41:49,424 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:39219
2019-09-12 11:41:49,432 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7577b641] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:49,436 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:49,553 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:49,554 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:49,555 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-12 11:41:49,555 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 343d8de9-cd3e-46cf-a800-3e9ef38501a7
2019-09-12 11:41:49,557 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-12 11:41:49,842 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 11:41:50,307 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 11:41:50,318 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-12 11:41:50,318 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-12 11:41:50,319 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-12 11:41:50,319 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-12 11:41:50,319 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-12 11:41:50,320 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-12 11:41:50,320 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-12 11:41:50,320 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-12 11:41:50,321 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-12 11:41:50,321 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-12 11:41:50,321 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-12 11:41:50,322 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-12 11:41:50,322 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-12 11:41:50,322 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-12 11:41:50,323 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-12 11:41:50,323 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-12 11:41:50,323 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-12 11:41:50,324 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-12 11:41:50,324 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-12 11:41:50,324 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-12 11:41:50,325 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-12 11:41:50,325 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-12 11:41:50,325 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 11:41:50,326 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 11:41:50,326 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 11:41:51,121 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 11:41:51,123 [Socket Reader #1 for port 40313] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40313
2019-09-12 11:41:51,155 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40313
2019-09-12 11:41:51,155 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-12 11:41:51,157 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 11:41:51,157 [IPC Server listener on 40313] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40313: starting
2019-09-12 11:41:51,163 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-12 11:41:51,165 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:51,166 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:51,170 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:51,172 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-12 11:41:51,172 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:51,172 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:51,175 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34649
2019-09-12 11:41:51,175 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:51,178 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@749ab7b4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:51,179 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bf94401{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:51,236 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54562ea6{/,file:///tmp/jetty-0.0.0.0-34649-ozoneManager-_-any-8877889276046542398.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-12 11:41:51,237 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a35993f{HTTP/1.1,[http/1.1]}{0.0.0.0:34649}
2019-09-12 11:41:51,238 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5187ms
2019-09-12 11:41:51,239 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:34649
2019-09-12 11:41:51,412 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:41:51,506 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 11:41:51,544 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:41:51,548 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/containers/hdds to VolumeSet
2019-09-12 11:41:51,554 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-12 11:41:51,584 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-12 11:41:51,732 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:41:51,807 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:41:51,812 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:41:51,813 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:41:51,815 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:51,815 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:41:51,816 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:41:52,010 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:52,054 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:41:52,069 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:41:52,073 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:52,073 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:52,076 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:52,077 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:41:52,077 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:52,077 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:52,079 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41192
2019-09-12 11:41:52,079 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:52,081 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb66650{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:52,082 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a869a16{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:52,111 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6d5c2745{/,file:///tmp/jetty-0.0.0.0-41192-hddsDatanode-_-any-1063325172336038572.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:41:52,113 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44b29496{HTTP/1.1,[http/1.1]}{0.0.0.0:41192}
2019-09-12 11:41:52,113 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6063ms
2019-09-12 11:41:52,115 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41192
2019-09-12 11:41:53,192 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:38009 |  
2019-09-12 11:41:53,194 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@2eda2062
2019-09-12 11:41:53,196 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:41:53,199 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 11:41:53,202 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@284e7bcc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:53,208 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:41:53,208 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/containers/hdds to VolumeSet
2019-09-12 11:41:53,209 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-12 11:41:53,209 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@126f8f24
2019-09-12 11:41:53,235 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:41:53,235 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:41:53,236 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:41:53,236 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:41:53,237 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:53,237 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:41:53,237 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:41:53,238 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:53,239 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:41:53,240 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:41:53,243 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:53,250 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:53,253 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:53,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:41:53,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:53,254 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:53,255 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44799
2019-09-12 11:41:53,255 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:53,258 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57fdb8a4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:53,259 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2db15f70{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:53,287 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44b940a2{/,file:///tmp/jetty-0.0.0.0-44799-hddsDatanode-_-any-6679433780003353304.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:41:53,288 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@34c53688{HTTP/1.1,[http/1.1]}{0.0.0.0:44799}
2019-09-12 11:41:53,289 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7238ms
2019-09-12 11:41:53,290 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44799
2019-09-12 11:41:53,331 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/meta/datanode.id
2019-09-12 11:41:53,454 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:43717 |  
2019-09-12 11:41:53,455 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@284bdeed
2019-09-12 11:41:53,455 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:41:53,458 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 11:41:53,458 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6010811d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:53,464 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/meta/datanode.id
2019-09-12 11:41:53,469 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:41:53,470 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/containers/hdds to VolumeSet
2019-09-12 11:41:53,470 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-12 11:41:53,470 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-12 11:41:53,490 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:41:53,490 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:41:53,490 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:41:53,490 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:41:53,490 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:53,491 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:41:53,491 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:41:53,491 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:41:53,492 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:41:53,493 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:41:53,496 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:53,497 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:53,500 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:53,501 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:41:53,502 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:53,502 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:53,503 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42583
2019-09-12 11:41:53,503 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:53,506 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a0c5be{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:53,507 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14efa279{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:53,541 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24fba488{/,file:///tmp/jetty-0.0.0.0-42583-hddsDatanode-_-any-4771433902556697536.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:41:53,543 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73a6cc79{HTTP/1.1,[http/1.1]}{0.0.0.0:42583}
2019-09-12 11:41:53,543 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7492ms
2019-09-12 11:41:53,545 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42583
2019-09-12 11:41:53,751 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:43881 |  
2019-09-12 11:41:53,751 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3bbf1c0d
2019-09-12 11:41:53,752 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:41:53,755 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76c0b16e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:53,755 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 11:41:53,758 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/meta/datanode.id
2019-09-12 11:41:53,764 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:41:53,765 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/containers/hdds to VolumeSet
2019-09-12 11:41:53,765 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@18ffca6c
2019-09-12 11:41:53,766 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@18ffca6c
2019-09-12 11:41:53,791 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:41:53,791 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:41:53,792 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:41:53,792 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:41:53,792 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:53,792 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:41:53,793 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:41:53,793 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:53,794 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:41:53,795 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:41:53,797 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:53,798 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:53,800 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:53,802 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:41:53,802 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:53,802 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:53,803 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35923
2019-09-12 11:41:53,803 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:53,807 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72a8361b{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:53,808 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c48b543{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:53,838 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f5dfe69{/,file:///tmp/jetty-0.0.0.0-35923-hddsDatanode-_-any-1094298978550815492.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:41:53,839 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@571a663c{HTTP/1.1,[http/1.1]}{0.0.0.0:35923}
2019-09-12 11:41:53,839 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7789ms
2019-09-12 11:41:53,840 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35923
2019-09-12 11:41:54,022 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:34615 |  
2019-09-12 11:41:54,023 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@7ac5b4c
2019-09-12 11:41:54,023 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 11:41:54,026 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63e4a46a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:54,026 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 11:41:54,029 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/meta/datanode.id
2019-09-12 11:41:54,035 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 11:41:54,036 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/containers/hdds to VolumeSet
2019-09-12 11:41:54,036 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-12 11:41:54,036 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-12 11:41:54,059 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 11:41:54,060 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 11:41:54,060 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 11:41:54,060 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 11:41:54,060 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:54,061 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 11:41:54,061 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 11:41:54,061 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:41:54,062 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 11:41:54,063 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 11:41:54,066 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 11:41:54,066 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 11:41:54,069 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 11:41:54,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 11:41:54,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 11:41:54,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 11:41:54,071 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40220
2019-09-12 11:41:54,071 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 11:41:54,073 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cf01c2e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-12 11:41:54,074 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1eb9bf60{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 11:41:54,128 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68bd8ca7{/,file:///tmp/jetty-0.0.0.0-40220-hddsDatanode-_-any-9130298504714209339.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 11:41:54,130 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6744707b{HTTP/1.1,[http/1.1]}{0.0.0.0:40220}
2019-09-12 11:41:54,131 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8080ms
2019-09-12 11:41:54,132 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40220
2019-09-12 11:41:54,443 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:40360 |  
2019-09-12 11:41:54,443 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@5d66ae3a
2019-09-12 11:41:54,445 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:41:54,446 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c2db721] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 11:41:54,449 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/meta/datanode.id
2019-09-12 11:41:55,235 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:41:55,266 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:41:55,268 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:41:55,268 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at port 0
2019-09-12 11:41:55,290 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start RPC server
2019-09-12 11:41:55,425 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: GrpcService started, listening on 0.0.0.0/0.0.0.0:34630
2019-09-12 11:41:55,426 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d is started using port 34630
2019-09-12 11:41:55,428 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d is started using port 42969
2019-09-12 11:41:55,446 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:41:55,460 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:41:55,474 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:41:55,476 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:41:55,477 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at port 0
2019-09-12 11:41:55,486 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start RPC server
2019-09-12 11:41:55,490 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: GrpcService started, listening on 0.0.0.0/0.0.0.0:35241
2019-09-12 11:41:55,490 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 is started using port 35241
2019-09-12 11:41:55,497 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 is started using port 44093
2019-09-12 11:41:55,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:41:55,784 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:41:55,786 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:41:55,787 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at port 0
2019-09-12 11:41:55,795 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start RPC server
2019-09-12 11:41:55,798 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: GrpcService started, listening on 0.0.0.0/0.0.0.0:44890
2019-09-12 11:41:55,798 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis e16ea380-278b-4c57-9f7f-c0f6c0a358a5 is started using port 44890
2019-09-12 11:41:55,801 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc e16ea380-278b-4c57-9f7f-c0f6c0a358a5 is started using port 36022
2019-09-12 11:41:56,028 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:41:56,050 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:41:56,053 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:41:56,053 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis db5ea8ae-f1f9-4380-95d3-5f4efb341cff at port 0
2019-09-12 11:41:56,062 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start RPC server
2019-09-12 11:41:56,065 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: GrpcService started, listening on 0.0.0.0/0.0.0.0:42942
2019-09-12 11:41:56,065 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis db5ea8ae-f1f9-4380-95d3-5f4efb341cff is started using port 42942
2019-09-12 11:41:56,068 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc db5ea8ae-f1f9-4380-95d3-5f4efb341cff is started using port 38312
2019-09-12 11:41:56,446 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-12 11:41:56,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 11:41:56,465 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 11:41:56,471 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 11:41:56,472 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis c88806e9-8dfd-472a-ae12-1122c7897177 at port 0
2019-09-12 11:41:56,480 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c88806e9-8dfd-472a-ae12-1122c7897177: start RPC server
2019-09-12 11:41:56,484 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - c88806e9-8dfd-472a-ae12-1122c7897177: GrpcService started, listening on 0.0.0.0/0.0.0.0:42806
2019-09-12 11:41:56,484 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis c88806e9-8dfd-472a-ae12-1122c7897177 is started using port 42806
2019-09-12 11:41:56,487 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc c88806e9-8dfd-472a-ae12-1122c7897177 is started using port 38048
2019-09-12 11:41:57,241 [IPC Server handler 2 on 35471] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:57,241 [IPC Server handler 2 on 35471] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:41:57,247 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-12 11:41:57,247 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-12 11:41:57,247 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-12 11:41:57,254 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:41:57,449 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 5 DN Heartbeats.
2019-09-12 11:41:57,463 [IPC Server handler 3 on 35471] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:57,463 [IPC Server handler 3 on 35471] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:41:57,464 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:41:58,096 [IPC Server handler 2 on 35471] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:41:58,096 [IPC Server handler 1 on 35471] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:58,096 [IPC Server handler 2 on 35471] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:41:58,097 [IPC Server handler 1 on 35471] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:41:58,097 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:41:58,101 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:41:58,203 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-A18D15A2C329:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-A18D15A2C329:java.util.concurrent.CompletableFuture@4abff83[Not completed]
2019-09-12 11:41:58,226 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-A18D15A2C329:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,228 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,230 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,230 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,231 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,232 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,241 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,241 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:58,249 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329 does not exist. Creating ...
2019-09-12 11:41:58,267 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,282 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329 has been successfully formatted.
2019-09-12 11:41:58,285 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A18D15A2C329: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,285 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,288 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,293 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,293 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,294 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,299 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,305 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329
2019-09-12 11:41:58,318 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,319 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,325 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,326 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,327 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,329 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,330 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,345 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,355 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,361 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,362 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,362 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,393 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-A18D15A2C329
2019-09-12 11:41:58,394 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,396 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:58,398 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A18D15A2C329,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:58,449 [IPC Server handler 6 on 35471] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:41:58,450 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-12 11:41:58,450 [IPC Server handler 6 on 35471] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 11:41:58,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 11:41:58,462 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e604f847-a2c3-463d-b5a2-a18d15a2c329, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,481 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-893543292031:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-893543292031:java.util.concurrent.CompletableFuture@74c4c29b[Not completed]
2019-09-12 11:41:58,520 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-893543292031:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,522 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,522 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,522 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,522 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,523 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,523 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,523 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:41:58,523 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031 does not exist. Creating ...
2019-09-12 11:41:58,545 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,571 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031 has been successfully formatted.
2019-09-12 11:41:58,573 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-893543292031: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,576 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,577 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,578 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031
2019-09-12 11:41:58,579 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,579 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,580 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,580 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,580 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,581 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,581 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,581 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,581 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,581 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,582 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,582 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,582 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,582 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,583 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-893543292031
2019-09-12 11:41:58,583 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,583 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:41:58,585 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-893543292031,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:41:58,608 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4d9c219f-b32a-4b04-a37e-893543292031, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,628 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-6577BD925E4B:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-6577BD925E4B:java.util.concurrent.CompletableFuture@65bfbabb[Not completed]
2019-09-12 11:41:58,637 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-6577BD925E4B:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,637 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,637 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,638 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,638 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,638 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,638 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,638 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:58,639 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b does not exist. Creating ...
2019-09-12 11:41:58,651 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,664 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b has been successfully formatted.
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6577BD925E4B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,665 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,666 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,667 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,668 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,668 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,668 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,668 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,669 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-6577BD925E4B
2019-09-12 11:41:58,669 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,669 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:41:58,669 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6577BD925E4B,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:58,682 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 34d28b41-c5fe-43c6-be2d-6577bd925e4b, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,697 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-EF539133A2E4:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-EF539133A2E4:java.util.concurrent.CompletableFuture@34f89af7[Not completed]
2019-09-12 11:41:58,699 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-EF539133A2E4:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,699 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,699 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,699 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,699 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,700 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,700 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,700 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:58,700 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4 does not exist. Creating ...
2019-09-12 11:41:58,713 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,734 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4 has been successfully formatted.
2019-09-12 11:41:58,734 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-EF539133A2E4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,734 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,735 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4
2019-09-12 11:41:58,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,736 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,737 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,737 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,737 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,737 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,737 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,738 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,739 [Thread-217] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:41:58,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,741 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-EF539133A2E4
2019-09-12 11:41:58,741 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,741 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:41:58,741 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EF539133A2E4,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:58,750 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ebaa1135-e63d-453a-9fcd-ef539133a2e4, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,770 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-CA9FE7079F80:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-CA9FE7079F80:java.util.concurrent.CompletableFuture@708f4ca9[Not completed]
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-CA9FE7079F80:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,772 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,773 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,773 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:41:58,773 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80 does not exist. Creating ...
2019-09-12 11:41:58,786 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,807 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80 has been successfully formatted.
2019-09-12 11:41:58,808 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CA9FE7079F80: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,809 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,810 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,811 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,811 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,811 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,811 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,812 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,812 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-CA9FE7079F80
2019-09-12 11:41:58,812 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,812 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:41:58,813 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CA9FE7079F80,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:41:58,821 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2f5c6d80-8027-44ee-888e-ca9fe7079f80, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,835 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-244CDE579BAD:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-244CDE579BAD:java.util.concurrent.CompletableFuture@755d6675[Not completed]
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-244CDE579BAD:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,838 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,839 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,839 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:58,839 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad does not exist. Creating ...
2019-09-12 11:41:58,852 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,865 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad has been successfully formatted.
2019-09-12 11:41:58,865 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-244CDE579BAD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,865 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,866 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad
2019-09-12 11:41:58,867 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,867 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,867 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,867 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,867 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,868 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,868 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,868 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,868 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,868 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,869 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,869 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,869 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,870 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,870 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-244CDE579BAD
2019-09-12 11:41:58,870 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,870 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:41:58,871 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-244CDE579BAD,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:58,887 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 06bb5de5-9cb5-4a97-9d88-244cde579bad, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,899 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-F96247B24BCA:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-F96247B24BCA:java.util.concurrent.CompletableFuture@379b4fc5[Not completed]
2019-09-12 11:41:58,900 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-F96247B24BCA:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,900 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:58,901 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca does not exist. Creating ...
2019-09-12 11:41:58,915 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:58,928 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca has been successfully formatted.
2019-09-12 11:41:58,928 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F96247B24BCA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:58,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:58,928 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:58,929 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:58,930 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-F96247B24BCA
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:58,931 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:58,932 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F96247B24BCA,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:58,947 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 381e8535-e1e5-4930-b1ee-f96247b24bca, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:58,963 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-20999B7ABF81:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-20999B7ABF81:java.util.concurrent.CompletableFuture@3d6324b5[Not completed]
2019-09-12 11:41:58,964 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-20999B7ABF81:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:58,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:58,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:58,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:58,964 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:58,965 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:58,965 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:58,965 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:58,965 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81 does not exist. Creating ...
2019-09-12 11:41:58,978 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,023 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin71165, owner=user54546, volume=volume25800, creationTime=1568288519018, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:41:59,025 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81 has been successfully formatted.
2019-09-12 11:41:59,026 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-20999B7ABF81: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,026 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,027 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,029 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,030 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,031 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,032 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,032 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,032 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-20999B7ABF81
2019-09-12 11:41:59,033 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,033 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:59,033 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-20999B7ABF81,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:59,043 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume25800, bucket=bucket18840, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:41:59,064 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-F600077EEF08:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-F600077EEF08:java.util.concurrent.CompletableFuture@156920d3[Not completed]
2019-09-12 11:41:59,066 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-F600077EEF08:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,067 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,067 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,067 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,067 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,067 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,068 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,068 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:59,068 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08 does not exist. Creating ...
2019-09-12 11:41:59,094 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,121 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08 has been successfully formatted.
2019-09-12 11:41:59,122 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F600077EEF08: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,124 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,124 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,124 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,125 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08
2019-09-12 11:41:59,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,126 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,127 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,127 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,128 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,128 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,128 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,128 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,130 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,131 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,131 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,133 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,134 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,134 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,134 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-F600077EEF08
2019-09-12 11:41:59,135 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,136 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:41:59,136 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F600077EEF08,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:59,155 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 91739fc6-256b-4c8d-89a6-f600077eef08, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,167 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-E9374D494382:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-E9374D494382:java.util.concurrent.CompletableFuture@6d3180bc[Not completed]
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-E9374D494382:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,169 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,170 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:59,170 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382 does not exist. Creating ...
2019-09-12 11:41:59,182 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,195 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382 has been successfully formatted.
2019-09-12 11:41:59,195 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E9374D494382: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,195 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,195 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,195 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,196 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,197 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-E9374D494382
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,198 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:41:59,199 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E9374D494382,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:59,207 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4fb1a155-62b8-45ff-8e73-e9374d494382, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,221 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-CC3D74AE3758:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-CC3D74AE3758:java.util.concurrent.CompletableFuture@447d9650[Not completed]
2019-09-12 11:41:59,222 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-CC3D74AE3758:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,223 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:59,223 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:41:59,224 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758 does not exist. Creating ...
2019-09-12 11:41:59,236 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,266 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758 has been successfully formatted.
2019-09-12 11:41:59,266 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CC3D74AE3758: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,266 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,266 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,266 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,267 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,268 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-CC3D74AE3758
2019-09-12 11:41:59,269 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,270 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:59,270 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC3D74AE3758,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:59,281 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7b7a2f44-8a76-401f-84fd-cc3d74ae3758, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,306 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-F0E9DBD2C6E5:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-F0E9DBD2C6E5:java.util.concurrent.CompletableFuture@7635adeb[Not completed]
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-F0E9DBD2C6E5:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,308 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,309 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,309 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:59,309 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5 does not exist. Creating ...
2019-09-12 11:41:59,333 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,346 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5 has been successfully formatted.
2019-09-12 11:41:59,346 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F0E9DBD2C6E5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,346 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,347 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,348 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,349 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,349 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,349 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,349 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,349 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,350 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,350 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,350 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,350 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-F0E9DBD2C6E5
2019-09-12 11:41:59,351 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,351 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:41:59,351 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0E9DBD2C6E5,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:59,360 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 996ee4f3-91ca-414e-a441-f0e9dbd2c6e5, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,375 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-A78321F99418:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-A78321F99418:java.util.concurrent.CompletableFuture@3467f40b[Not completed]
2019-09-12 11:41:59,377 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-A78321F99418:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,377 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,377 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume25800} | ret=SUCCESS |  
2019-09-12 11:41:59,377 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,377 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,377 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,378 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,378 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,378 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:59,378 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418 does not exist. Creating ...
2019-09-12 11:41:59,386 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume25800, bucket=bucket18840} | ret=SUCCESS |  
2019-09-12 11:41:59,391 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,404 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418 has been successfully formatted.
2019-09-12 11:41:59,404 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A78321F99418: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,405 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,406 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,407 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,407 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,407 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,407 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,407 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,408 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,408 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,408 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,408 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,409 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-A78321F99418
2019-09-12 11:41:59,409 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,409 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:41:59,409 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A78321F99418,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:59,418 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 83c76a8d-9dd8-4a07-a5a8-a78321f99418, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,431 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-A62DF60811A1:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-A62DF60811A1:java.util.concurrent.CompletableFuture@7fc844e8[Not completed]
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-A62DF60811A1:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,433 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,434 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,434 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:59,435 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1 does not exist. Creating ...
2019-09-12 11:41:59,436 [Thread-217] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket18840.volume25800 implemented by OzoneFileSystem{URI=o3fs://bucket18840.volume25800, workingDir=o3fs://bucket18840.volume25800/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-12 11:41:59,448 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,469 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1 has been successfully formatted.
2019-09-12 11:41:59,469 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A62DF60811A1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,470 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,471 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,471 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,472 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,473 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,473 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,473 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,473 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,474 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,474 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,474 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-A62DF60811A1
2019-09-12 11:41:59,474 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,474 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:59,475 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A62DF60811A1,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:59,485 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d4110f41-5367-455a-a564-a62df60811a1, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,504 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-A6EED421E777:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-A6EED421E777:java.util.concurrent.CompletableFuture@696f9c79[Not completed]
2019-09-12 11:41:59,506 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-A6EED421E777:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,506 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,506 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,507 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,507 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,507 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,507 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,507 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:59,508 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777 does not exist. Creating ...
2019-09-12 11:41:59,513 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,555 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,573 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777 has been successfully formatted.
2019-09-12 11:41:59,573 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A6EED421E777: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,574 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,574 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,574 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,574 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,574 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,575 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,575 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,575 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777
2019-09-12 11:41:59,575 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,575 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,576 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,576 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,576 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,576 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,576 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,577 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,577 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,577 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,578 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,578 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,578 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,579 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,579 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-A6EED421E777
2019-09-12 11:41:59,579 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,579 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:41:59,580 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A6EED421E777,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:59,587 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f58f3cf1-ea8f-42eb-9add-a6eed421e777, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,594 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,601 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-6D1D3295C796:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-6D1D3295C796:java.util.concurrent.CompletableFuture@577fdcaa[Not completed]
2019-09-12 11:41:59,605 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-6D1D3295C796:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,605 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,605 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,606 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,606 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,606 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,606 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,606 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:41:59,607 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796 does not exist. Creating ...
2019-09-12 11:41:59,609 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume25800, bucket=bucket18840, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-12 11:41:59,620 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,624 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume25800, bucket=bucket18840, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-12 11:41:59,627 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:41:59,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:41:59,634 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796 has been successfully formatted.
2019-09-12 11:41:59,635 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6D1D3295C796: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,635 [Thread-217] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-12 11:41:59,635 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,635 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,635 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,636 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,637 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,638 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,638 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,638 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,638 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-6D1D3295C796
2019-09-12 11:41:59,638 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,639 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:41:59,639 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D1D3295C796,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:41:59,656 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,679 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-7F9BD8E856D2:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-7F9BD8E856D2:java.util.concurrent.CompletableFuture@7dda7e4f[Not completed]
2019-09-12 11:41:59,683 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-7F9BD8E856D2:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,683 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,683 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,683 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,683 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,684 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,684 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,684 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:59,684 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2 does not exist. Creating ...
2019-09-12 11:41:59,696 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,709 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2 has been successfully formatted.
2019-09-12 11:41:59,709 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7F9BD8E856D2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,713 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,715 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,716 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-7F9BD8E856D2
2019-09-12 11:41:59,717 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,718 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:41:59,727 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7F9BD8E856D2,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:41:59,735 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d12bd072-4b79-43cc-913f-7f9bd8e856d2, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,755 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: addNew group-A200423726CF:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] returns group-A200423726CF:java.util.concurrent.CompletableFuture@261b3238[Not completed]
2019-09-12 11:41:59,756 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: new RaftServerImpl for group-A200423726CF:[2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,756 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,756 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,767 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,767 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,767 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,767 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF ConfigurationManager, init=-1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,768 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis] (custom)
2019-09-12 11:41:59,768 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf does not exist. Creating ...
2019-09-12 11:41:59,781 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,812 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf has been successfully formatted.
2019-09-12 11:41:59,812 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A200423726CF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,812 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,812 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf
2019-09-12 11:41:59,813 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,814 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,815 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,815 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,815 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,815 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,816 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,816 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,816 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,816 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start group-A200423726CF
2019-09-12 11:41:59,816 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,817 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start FollowerState
2019-09-12 11:41:59,817 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A200423726CF,id=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d
2019-09-12 11:41:59,823 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 666817f5-d8a9-468b-b073-a200423726cf, Nodes: 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,825 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:41:59,834 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-2F513EEBB057:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-2F513EEBB057:java.util.concurrent.CompletableFuture@10d3b02c[Not completed]
2019-09-12 11:41:59,836 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-2F513EEBB057:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,837 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,838 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:41:59,838 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057 does not exist. Creating ...
2019-09-12 11:41:59,851 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:41:59,874 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057 has been successfully formatted.
2019-09-12 11:41:59,874 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-2F513EEBB057: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:41:59,874 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057
2019-09-12 11:41:59,875 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:41:59,876 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:41:59,877 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:41:59,877 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:41:59,877 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-2F513EEBB057
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:41:59,878 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:41:59,879 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2F513EEBB057,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:41:59,884 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2a346b72-387d-4f80-b538-2f513eebb057, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:41:59,886 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:41:59,903 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: addNew group-FA367BF0D9B0:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] returns group-FA367BF0D9B0:java.util.concurrent.CompletableFuture@216f3b29[Not completed]
2019-09-12 11:41:59,905 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: new RaftServerImpl for group-FA367BF0D9B0:[2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241] with ContainerStateMachine:uninitialized
2019-09-12 11:41:59,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:41:59,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:41:59,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:41:59,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:41:59,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:41:59,906 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 ConfigurationManager, init=-1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null, confs=<EMPTY_MAP>
2019-09-12 11:41:59,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis] (custom)
2019-09-12 11:41:59,906 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0 does not exist. Creating ...
2019-09-12 11:41:59,945 [Thread-217] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:41:59,952 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,006 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0 has been successfully formatted.
2019-09-12 11:42:00,006 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-FA367BF0D9B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,006 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,006 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,007 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,007 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,007 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,007 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,007 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,008 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,009 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,009 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,009 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,009 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,010 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,010 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,010 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,010 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,011 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start group-FA367BF0D9B0
2019-09-12 11:42:00,011 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,011 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start FollowerState
2019-09-12 11:42:00,016 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA367BF0D9B0,id=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9
2019-09-12 11:42:00,030 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c07ede72-4361-40d8-abf9-fa367bf0d9b0, Nodes: 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,038 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,038 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,052 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: addNew group-57AE31F8EC4D:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] returns group-57AE31F8EC4D:java.util.concurrent.CompletableFuture@3e3ad2da[Not completed]
2019-09-12 11:42:00,063 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: new RaftServerImpl for group-57AE31F8EC4D:[db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,063 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,064 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,064 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,064 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D ConfigurationManager, init=-1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,064 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis] (custom)
2019-09-12 11:42:00,065 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d does not exist. Creating ...
2019-09-12 11:42:00,072 [Thread-217] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:42:00,093 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:00,094 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:00,105 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,136 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d has been successfully formatted.
2019-09-12 11:42:00,136 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-57AE31F8EC4D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,137 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,138 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d
2019-09-12 11:42:00,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,138 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,139 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,140 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,140 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,140 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,141 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,141 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,141 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,141 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start group-57AE31F8EC4D
2019-09-12 11:42:00,142 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,142 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start FollowerState
2019-09-12 11:42:00,142 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-57AE31F8EC4D,id=db5ea8ae-f1f9-4380-95d3-5f4efb341cff
2019-09-12 11:42:00,148 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 428aea9d-e328-4946-8bea-57ae31f8ec4d, Nodes: db5ea8ae-f1f9-4380-95d3-5f4efb341cff{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,150 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,151 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,151 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,161 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-96CBEFFC64C0:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-96CBEFFC64C0:java.util.concurrent.CompletableFuture@6a0395e2[Not completed]
2019-09-12 11:42:00,164 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-96CBEFFC64C0:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,164 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,165 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,165 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,165 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,165 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,165 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,166 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:42:00,166 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0 does not exist. Creating ...
2019-09-12 11:42:00,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:00,226 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,239 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0 has been successfully formatted.
2019-09-12 11:42:00,239 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-96CBEFFC64C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,240 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,240 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,240 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,240 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,241 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,241 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,241 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0
2019-09-12 11:42:00,241 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,241 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,242 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,243 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,243 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,243 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,244 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,244 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,244 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,244 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-96CBEFFC64C0
2019-09-12 11:42:00,245 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,245 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:42:00,245 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-96CBEFFC64C0,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:42:00,253 [Thread-207] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-12 11:42:00,256 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-12 11:42:00,256 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6bd59abb-49ba-4ff0-b03e-96cbeffc64c0, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,257 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,257 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,257 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,268 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-D4672BC5757D:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-D4672BC5757D:java.util.concurrent.CompletableFuture@430bce35[Not completed]
2019-09-12 11:42:00,272 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-D4672BC5757D:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,272 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,273 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,273 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,274 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d does not exist. Creating ...
2019-09-12 11:42:00,279 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:00,331 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,403 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d has been successfully formatted.
2019-09-12 11:42:00,404 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D4672BC5757D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,404 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,405 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,405 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,405 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,405 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,406 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,406 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d
2019-09-12 11:42:00,406 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,406 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,407 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,407 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,407 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,408 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,411 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,412 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,412 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,413 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,413 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,413 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,413 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-D4672BC5757D
2019-09-12 11:42:00,413 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,414 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,414 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D4672BC5757D,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,423 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d67fd9ea-9ddd-4522-8e76-d4672bc5757d, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,424 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,425 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,425 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,436 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-061D57D4925F:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-061D57D4925F:java.util.concurrent.CompletableFuture@2ccad25e[Not completed]
2019-09-12 11:42:00,439 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-061D57D4925F:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,439 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,439 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,439 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,439 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,440 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,440 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,440 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:42:00,441 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f does not exist. Creating ...
2019-09-12 11:42:00,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:00,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:00,489 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,504 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f has been successfully formatted.
2019-09-12 11:42:00,505 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-061D57D4925F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,505 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,505 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,506 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,506 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,506 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,506 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,507 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f
2019-09-12 11:42:00,507 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,507 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,507 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,508 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,508 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,508 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,508 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,508 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,509 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,509 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,509 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,510 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,510 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,511 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,511 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-061D57D4925F
2019-09-12 11:42:00,511 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,511 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:42:00,520 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-061D57D4925F,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:42:00,525 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c6c83faf-75a4-4c9c-859b-061d57d4925f, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,532 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,532 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,532 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,542 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-50AC1863D020:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-50AC1863D020:java.util.concurrent.CompletableFuture@653a9641[Not completed]
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-50AC1863D020:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,546 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,547 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,547 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,547 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020 does not exist. Creating ...
2019-09-12 11:42:00,560 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,593 [Thread-217] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:42:00,593 [Thread-217] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:42:00,596 [Thread-217] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-12 11:42:00,596 [Thread-217] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-12 11:42:00,628 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020 has been successfully formatted.
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-50AC1863D020: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,629 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,630 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,631 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,631 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,631 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,631 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,631 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,632 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,632 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,632 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,632 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,632 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-50AC1863D020
2019-09-12 11:42:00,633 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,633 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,633 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-50AC1863D020,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,639 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a26d44b0-c109-4960-9398-50ac1863d020, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,641 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,641 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,641 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,651 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-7648080EC1CB:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-7648080EC1CB:java.util.concurrent.CompletableFuture@250ab43b[Not completed]
2019-09-12 11:42:00,653 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-7648080EC1CB:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,654 [Thread-217] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,654 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,655 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,655 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb does not exist. Creating ...
2019-09-12 11:42:00,666 [Thread-217] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:42:00,667 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,671 [Thread-217] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:42:00,680 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb has been successfully formatted.
2019-09-12 11:42:00,681 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7648080EC1CB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,681 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,681 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,681 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,682 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,683 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-7648080EC1CB
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,684 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7648080EC1CB,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,690 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 227b090a-592a-47c9-88b5-7648080ec1cb, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,691 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,691 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,692 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,701 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-8A5535E9F8BC:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-8A5535E9F8BC:java.util.concurrent.CompletableFuture@d2882c[Not completed]
2019-09-12 11:42:00,703 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-8A5535E9F8BC:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,703 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,703 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,704 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,704 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,704 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,704 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,704 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,705 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc does not exist. Creating ...
2019-09-12 11:42:00,717 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,743 [Thread-217] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:42:00,754 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc has been successfully formatted.
2019-09-12 11:42:00,754 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8A5535E9F8BC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,754 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,755 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc
2019-09-12 11:42:00,756 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,756 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,756 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,756 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,757 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,757 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,757 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,757 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,757 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,758 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,758 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,759 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,759 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,759 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,760 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-8A5535E9F8BC
2019-09-12 11:42:00,760 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,760 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,761 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8A5535E9F8BC,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,767 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 82713aa4-781f-4981-ae1b-8a5535e9f8bc, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,768 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,768 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,769 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,777 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: addNew group-0F53E9C04F25:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] returns group-0F53E9C04F25:java.util.concurrent.CompletableFuture@69159c2f[Not completed]
2019-09-12 11:42:00,778 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: new RaftServerImpl for group-0F53E9C04F25:[e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 ConfigurationManager, init=-1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,779 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis] (custom)
2019-09-12 11:42:00,780 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25 does not exist. Creating ...
2019-09-12 11:42:00,792 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,804 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25 has been successfully formatted.
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0F53E9C04F25: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,805 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,806 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,807 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,807 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,807 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,807 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,807 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start group-0F53E9C04F25
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,808 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start FollowerState
2019-09-12 11:42:00,809 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F53E9C04F25,id=e16ea380-278b-4c57-9f7f-c0f6c0a358a5
2019-09-12 11:42:00,813 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 40bca5da-f261-4d34-b781-0f53e9c04f25, Nodes: e16ea380-278b-4c57-9f7f-c0f6c0a358a5{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,814 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,815 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,815 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,815 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,823 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-3E6C4F7D8577:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-3E6C4F7D8577:java.util.concurrent.CompletableFuture@1052af75[Not completed]
2019-09-12 11:42:00,824 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-3E6C4F7D8577:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,825 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,826 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577 does not exist. Creating ...
2019-09-12 11:42:00,832 [Thread-217] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:11
2019-09-12 11:42:00,850 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,863 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577 has been successfully formatted.
2019-09-12 11:42:00,863 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-3E6C4F7D8577: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,863 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,863 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,864 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,865 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,866 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,866 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,866 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,866 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,867 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-3E6C4F7D8577
2019-09-12 11:42:00,867 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,867 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,867 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3E6C4F7D8577,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,871 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3196e589-f64c-411c-9172-3e6c4f7d8577, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,873 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,874 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,874 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,874 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,883 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c88806e9-8dfd-472a-ae12-1122c7897177: addNew group-004F80D1C824:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] returns group-004F80D1C824:java.util.concurrent.CompletableFuture@3e04eec3[Not completed]
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c88806e9-8dfd-472a-ae12-1122c7897177: new RaftServerImpl for group-004F80D1C824:[c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806] with ContainerStateMachine:uninitialized
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 11:42:00,885 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 ConfigurationManager, init=-1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null, confs=<EMPTY_MAP>
2019-09-12 11:42:00,886 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis] (custom)
2019-09-12 11:42:00,886 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824 does not exist. Creating ...
2019-09-12 11:42:00,900 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824/in_use.lock acquired by nodename 7042@pr-hdds-1569-58hkm-1881083799
2019-09-12 11:42:00,921 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824 has been successfully formatted.
2019-09-12 11:42:00,921 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-004F80D1C824: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 11:42:00,922 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 11:42:00,922 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 11:42:00,922 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 11:42:00,922 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 11:42:00,922 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 11:42:00,923 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 11:42:00,924 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 11:42:00,924 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 11:42:00,924 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 11:42:00,924 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 11:42:00,924 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824: flushIndex: setUnconditionally 0 -> -1
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c88806e9-8dfd-472a-ae12-1122c7897177: start group-004F80D1C824
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 11:42:00,925 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start FollowerState
2019-09-12 11:42:00,926 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-004F80D1C824,id=c88806e9-8dfd-472a-ae12-1122c7897177
2019-09-12 11:42:00,931 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3142eb33-529a-493b-bd59-004f80d1c824, Nodes: c88806e9-8dfd-472a-ae12-1122c7897177{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 11:42:00,933 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,933 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,933 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,933 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,933 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,934 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,935 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,936 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:00,937 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:01,003 [Thread-217] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local846992285_0001
2019-09-12 11:42:01,003 [Thread-217] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:42:01,101 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:01,101 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:01,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:01,242 [Thread-217] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:42:01,242 [Thread-217] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local846992285_0001
2019-09-12 11:42:01,243 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local846992285_0001
2019-09-12 11:42:01,251 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:42:01,270 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:01,270 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:01,273 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:42:01,390 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:42:01,393 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000000_0
2019-09-12 11:42:01,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:01,455 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:01,457 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:01,466 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:01,510 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:01,514 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:0+327
2019-09-12 11:42:01,526 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:01,526 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:01,579 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:01,580 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-12 11:42:01,598 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:01,608 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:01,620 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:01,632 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000000_0 is done. And is in the process of committing
2019-09-12 11:42:01,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:01,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000000_0 is allowed to commit now
2019-09-12 11:42:01,637 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:01,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-12 11:42:01,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000000_0' done.
2019-09-12 11:42:01,642 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=204463
		FILE: Number of bytes written=823933
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=6
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:01,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000000_0
2019-09-12 11:42:01,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:01,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:01,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:01,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:01,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:1150+293
2019-09-12 11:42:01,651 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:01,651 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:01,671 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:01,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-12 11:42:01,681 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:01,689 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:01,721 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:01,722 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:01,723 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:01,723 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:01,723 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:01,723 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:01,724 [IPC Server handler 0 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:01,725 [IPC Server handler 0 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:01,727 [IPC Server handler 0 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:01,727 [IPC Server handler 0 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:01,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:01,733 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:01,737 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:01,739 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:01,739 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:02,092 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:02,092 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:02,204 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:02,246 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local846992285_0001 running in uber mode : false
2019-09-12 11:42:02,249 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:42:02,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:02,465 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,092 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,093 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,448 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,465 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:03,484 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 changes to CANDIDATE, lastRpcTime:5089, electionTimeout:5088ms
2019-09-12 11:42:03,485 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:03,485 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,489 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:03,510 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:03,513 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:03,514 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:03,515 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5229ms
2019-09-12 11:42:03,525 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:03,526 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:03,530 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:03,534 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:03,534 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:03,535 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:03,545 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:03,572 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329: Starting segment from index:0
2019-09-12 11:42:03,587 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A18D15A2C329 set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:03,746 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 changes to CANDIDATE, lastRpcTime:5162, electionTimeout:5161ms
2019-09-12 11:42:03,771 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:03,771 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,772 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:03,789 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/e604f847-a2c3-463d-b5a2-a18d15a2c329/current/log_inprogress_0
2019-09-12 11:42:03,789 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:03,791 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B changes to CANDIDATE, lastRpcTime:5121, electionTimeout:5120ms
2019-09-12 11:42:03,792 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:03,792 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:03,792 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:03,792 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,793 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5216ms
2019-09-12 11:42:03,793 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:03,794 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:03,795 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:03,799 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:03,801 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:03,801 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:03,801 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:03,801 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:03,801 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031: Starting segment from index:0
2019-09-12 11:42:03,802 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-893543292031 set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:03,835 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 changes to CANDIDATE, lastRpcTime:5022, electionTimeout:5011ms
2019-09-12 11:42:03,835 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:03,835 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:03,835 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:03,835 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,835 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:03,835 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:03,835 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5170ms
2019-09-12 11:42:03,837 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:03,838 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:03,840 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:03,840 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:03,840 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:03,841 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:03,841 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:03,841 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b: Starting segment from index:0
2019-09-12 11:42:03,842 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-6577BD925E4B set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:03,873 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/4d9c219f-b32a-4b04-a37e-893543292031/current/log_inprogress_0
2019-09-12 11:42:03,873 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 changes to CANDIDATE, lastRpcTime:5131, electionTimeout:5102ms
2019-09-12 11:42:03,873 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:03,873 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:03,874 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:03,874 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,874 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:03,875 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5066ms
2019-09-12 11:42:03,875 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:03,875 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:03,876 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:03,878 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:03,878 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:03,878 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:03,878 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:03,879 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:03,879 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80: Starting segment from index:0
2019-09-12 11:42:03,879 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-CA9FE7079F80 set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:03,908 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/34d28b41-c5fe-43c6-be2d-6577bd925e4b/current/log_inprogress_0
2019-09-12 11:42:03,908 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:03,909 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:03,909 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:03,909 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5174ms
2019-09-12 11:42:03,910 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:03,911 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:03,911 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:03,911 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:03,911 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:03,911 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:03,912 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:03,912 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4: Starting segment from index:0
2019-09-12 11:42:03,913 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-EF539133A2E4 set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:03,943 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/2f5c6d80-8027-44ee-888e-ca9fe7079f80/current/log_inprogress_0
2019-09-12 11:42:03,967 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:03,968 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/ebaa1135-e63d-453a-9fcd-ef539133a2e4/current/log_inprogress_0
2019-09-12 11:42:03,975 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:03,975 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:03,975 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:03,975 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:03,975 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:03,976 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:03,976 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:03,976 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:03,976 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:03,977 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:03,977 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:03,979 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:03,981 [Thread-226] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD changes to CANDIDATE, lastRpcTime:5110, electionTimeout:5110ms
2019-09-12 11:42:03,982 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:03,982 [Thread-226] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,983 [Thread-226] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:03,983 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:03,990 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:03,990 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:03,995 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA changes to CANDIDATE, lastRpcTime:5063, electionTimeout:5063ms
2019-09-12 11:42:03,995 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:03,995 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:03,995 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:04,014 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:04,014 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:04,015 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:04,015 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:04,015 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,015 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,015 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5149ms
2019-09-12 11:42:04,015 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5086ms
2019-09-12 11:42:04,015 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,016 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,016 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,016 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,016 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,016 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,016 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,016 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,016 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,017 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,017 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,017 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,017 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:04,017 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:04,017 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad: Starting segment from index:0
2019-09-12 11:42:04,017 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca: Starting segment from index:0
2019-09-12 11:42:04,018 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-244CDE579BAD set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:04,057 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 changes to CANDIDATE, lastRpcTime:5024, electionTimeout:5019ms
2019-09-12 11:42:04,057 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-F96247B24BCA set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:04,057 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:04,059 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,059 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:04,071 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/381e8535-e1e5-4930-b1ee-f96247b24bca/current/log_inprogress_0
2019-09-12 11:42:04,071 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:04,071 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/06bb5de5-9cb5-4a97-9d88-244cde579bad/current/log_inprogress_0
2019-09-12 11:42:04,073 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:04,073 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,073 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5047ms
2019-09-12 11:42:04,074 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,074 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,074 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,074 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,074 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,075 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,075 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:04,075 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81: Starting segment from index:0
2019-09-12 11:42:04,076 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-20999B7ABF81 set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:04,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:04,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:04,124 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/fda9bdd0-ecb2-4bfe-a9eb-20999b7abf81/current/log_inprogress_0
2019-09-12 11:42:04,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:04,242 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 changes to CANDIDATE, lastRpcTime:5106, electionTimeout:5106ms
2019-09-12 11:42:04,243 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:04,243 [Thread-235] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,243 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 changes to CANDIDATE, lastRpcTime:5044, electionTimeout:5044ms
2019-09-12 11:42:04,243 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:04,243 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:04,243 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,248 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:04,267 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:04,267 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:04,267 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5146ms
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5072ms
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,268 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,269 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08: Starting segment from index:0
2019-09-12 11:42:04,270 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382: Starting segment from index:0
2019-09-12 11:42:04,271 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-F600077EEF08 set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:04,271 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-E9374D494382 set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:04,307 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 changes to CANDIDATE, lastRpcTime:5037, electionTimeout:5036ms
2019-09-12 11:42:04,308 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:04,308 [Thread-242] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,308 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:04,332 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/4fb1a155-62b8-45ff-8e73-e9374d494382/current/log_inprogress_0
2019-09-12 11:42:04,332 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/91739fc6-256b-4c8d-89a6-f600077eef08/current/log_inprogress_0
2019-09-12 11:42:04,332 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:04,333 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:04,333 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,333 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5066ms
2019-09-12 11:42:04,334 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,334 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,334 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,334 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,335 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,335 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,335 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:04,335 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758: Starting segment from index:0
2019-09-12 11:42:04,336 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-CC3D74AE3758 set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:04,385 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/7b7a2f44-8a76-401f-84fd-cc3d74ae3758/current/log_inprogress_0
2019-09-12 11:42:04,431 [Thread-246] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5080ms
2019-09-12 11:42:04,431 [Thread-246] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:04,432 [Thread-246] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,432 [Thread-246] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:04,449 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:04,450 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:04,450 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:04,450 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,450 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5103ms
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,451 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,452 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:04,452 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5: Starting segment from index:0
2019-09-12 11:42:04,453 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-F0E9DBD2C6E5 set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:04,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:04,494 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/996ee4f3-91ca-414e-a441-f0e9dbd2c6e5/current/log_inprogress_0
2019-09-12 11:42:04,595 [Thread-253] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 changes to CANDIDATE, lastRpcTime:5120, electionTimeout:5120ms
2019-09-12 11:42:04,595 [Thread-253] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:04,595 [Thread-253] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,595 [Thread-253] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:04,608 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 changes to CANDIDATE, lastRpcTime:5199, electionTimeout:5199ms
2019-09-12 11:42:04,609 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:04,609 [Thread-249] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,609 [Thread-249] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:04,614 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:04,614 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:04,614 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,614 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5144ms
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,615 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:04,616 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1: Starting segment from index:0
2019-09-12 11:42:04,616 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A62DF60811A1 set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:04,646 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:04,647 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:04,647 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,647 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5242ms
2019-09-12 11:42:04,647 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,647 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,648 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,648 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,648 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,648 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,648 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:04,649 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418: Starting segment from index:0
2019-09-12 11:42:04,649 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A78321F99418 set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:04,687 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/d4110f41-5367-455a-a564-a62df60811a1/current/log_inprogress_0
2019-09-12 11:42:04,687 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 changes to CANDIDATE, lastRpcTime:5107, electionTimeout:5086ms
2019-09-12 11:42:04,688 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:04,688 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,688 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:04,700 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/83c76a8d-9dd8-4a07-a5a8-a78321f99418/current/log_inprogress_0
2019-09-12 11:42:04,700 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:04,700 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:04,700 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,700 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5126ms
2019-09-12 11:42:04,701 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,701 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,701 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,701 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,702 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,702 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,702 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:04,703 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777: Starting segment from index:0
2019-09-12 11:42:04,703 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-A6EED421E777 set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:04,737 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5098ms
2019-09-12 11:42:04,737 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:04,737 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,738 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:04,759 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/f58f3cf1-ea8f-42eb-9add-a6eed421e777/current/log_inprogress_0
2019-09-12 11:42:04,759 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:04,759 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:04,759 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,759 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5124ms
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,760 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,761 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:04,761 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796: Starting segment from index:0
2019-09-12 11:42:04,762 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-6D1D3295C796 set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:04,804 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/7fbbb5fb-0bc2-40b6-92ed-6d1d3295c796/current/log_inprogress_0
2019-09-12 11:42:04,879 [Thread-272] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 changes to CANDIDATE, lastRpcTime:5161, electionTimeout:5152ms
2019-09-12 11:42:04,879 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:04,879 [Thread-272] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,880 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:04,891 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:04,892 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:04,892 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,892 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5180ms
2019-09-12 11:42:04,892 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,893 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,893 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,893 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,893 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,893 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,894 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:04,894 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2: Starting segment from index:0
2019-09-12 11:42:04,895 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-7F9BD8E856D2 set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:04,928 [Thread-285] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF changes to CANDIDATE, lastRpcTime:5111, electionTimeout:5111ms
2019-09-12 11:42:04,928 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown FollowerState
2019-09-12 11:42:04,928 [Thread-285] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:04,929 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderElection
2019-09-12 11:42:04,942 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/d12bd072-4b79-43cc-913f-7f9bd8e856d2/current/log_inprogress_0
2019-09-12 11:42:04,953 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18: begin an election at term 1 for -1: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null
2019-09-12 11:42:04,954 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: shutdown LeaderElection
2019-09-12 11:42:04,954 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:04,954 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF change Leader from null to 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d at term 1 for becomeLeader, leader elected after 5141ms
2019-09-12 11:42:04,954 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:04,954 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:04,955 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:04,955 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:04,955 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:04,955 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:04,956 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d: start LeaderState
2019-09-12 11:42:04,956 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf: Starting segment from index:0
2019-09-12 11:42:04,957 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:group-A200423726CF set configuration 0: [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d:192.168.36.114:34630], old=null at 0
2019-09-12 11:42:05,000 [Thread-288] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 changes to CANDIDATE, lastRpcTime:5121, electionTimeout:5121ms
2019-09-12 11:42:05,000 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:05,001 [Thread-288] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,001 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:05,007 [2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2909770e-87e5-4d6e-b81e-a1ae67fa8b8d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-0/data/ratis/666817f5-d8a9-468b-b073-a200423726cf/current/log_inprogress_0
2019-09-12 11:42:05,009 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:05,009 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:05,009 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5135ms
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,010 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,011 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,011 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:05,011 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057: Starting segment from index:0
2019-09-12 11:42:05,012 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-2F513EEBB057 set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:05,044 [Thread-292] INFO  impl.FollowerState (FollowerState.java:run(106)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 changes to CANDIDATE, lastRpcTime:5032, electionTimeout:5016ms
2019-09-12 11:42:05,044 [Thread-292] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown FollowerState
2019-09-12 11:42:05,044 [Thread-292] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,044 [Thread-292] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderElection
2019-09-12 11:42:05,061 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/2a346b72-387d-4f80-b538-2f513eebb057/current/log_inprogress_0
2019-09-12 11:42:05,075 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20: begin an election at term 1 for -1: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null
2019-09-12 11:42:05,075 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: shutdown LeaderElection
2019-09-12 11:42:05,075 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,075 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 change Leader from null to 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9 at term 1 for becomeLeader, leader elected after 5069ms
2019-09-12 11:42:05,076 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,076 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,076 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,076 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,076 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,077 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,077 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9: start LeaderState
2019-09-12 11:42:05,077 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0: Starting segment from index:0
2019-09-12 11:42:05,078 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:group-FA367BF0D9B0 set configuration 0: [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9:192.168.36.114:35241], old=null at 0
2019-09-12 11:42:05,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:05,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:05,114 [2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-1/data/ratis/c07ede72-4361-40d8-abf9-fa367bf0d9b0/current/log_inprogress_0
2019-09-12 11:42:05,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:05,220 [Thread-301] INFO  impl.FollowerState (FollowerState.java:run(106)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D changes to CANDIDATE, lastRpcTime:5078, electionTimeout:5078ms
2019-09-12 11:42:05,221 [Thread-301] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown FollowerState
2019-09-12 11:42:05,221 [Thread-301] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,221 [Thread-301] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderElection
2019-09-12 11:42:05,237 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21: begin an election at term 1 for -1: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: shutdown LeaderElection
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D change Leader from null to db5ea8ae-f1f9-4380-95d3-5f4efb341cff at term 1 for becomeLeader, leader elected after 5101ms
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,238 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,239 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,239 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff: start LeaderState
2019-09-12 11:42:05,239 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d: Starting segment from index:0
2019-09-12 11:42:05,240 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff:group-57AE31F8EC4D set configuration 0: [db5ea8ae-f1f9-4380-95d3-5f4efb341cff:192.168.36.114:42942], old=null at 0
2019-09-12 11:42:05,298 [db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - db5ea8ae-f1f9-4380-95d3-5f4efb341cff-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-3/data/ratis/428aea9d-e328-4946-8bea-57ae31f8ec4d/current/log_inprogress_0
2019-09-12 11:42:05,412 [Thread-304] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 changes to CANDIDATE, lastRpcTime:5167, electionTimeout:5167ms
2019-09-12 11:42:05,413 [Thread-304] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:05,413 [Thread-304] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,413 [Thread-304] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:05,425 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:05,426 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:05,426 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,426 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5186ms
2019-09-12 11:42:05,426 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,426 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,427 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,427 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,427 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,427 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,428 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:05,428 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0: Starting segment from index:0
2019-09-12 11:42:05,429 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-96CBEFFC64C0 set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:05,466 [Thread-310] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D changes to CANDIDATE, lastRpcTime:5051, electionTimeout:5020ms
2019-09-12 11:42:05,466 [Thread-310] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:05,466 [Thread-310] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,466 [Thread-310] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:05,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:05,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:05,490 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/6bd59abb-49ba-4ff0-b03e-96cbeffc64c0/current/log_inprogress_0
2019-09-12 11:42:05,490 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:05,490 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:05,491 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,491 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5086ms
2019-09-12 11:42:05,492 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,492 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,493 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,493 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,493 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,493 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,494 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:05,494 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d: Starting segment from index:0
2019-09-12 11:42:05,494 [c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-D4672BC5757D set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:05,551 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/d67fd9ea-9ddd-4522-8e76-d4672bc5757d/current/log_inprogress_0
2019-09-12 11:42:05,555 [Thread-317] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F changes to CANDIDATE, lastRpcTime:5043, electionTimeout:5035ms
2019-09-12 11:42:05,555 [Thread-317] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:05,555 [Thread-317] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,555 [Thread-317] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:05,564 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:05,565 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:05,565 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,565 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5059ms
2019-09-12 11:42:05,565 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,566 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,566 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,566 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,566 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,567 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,567 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:05,567 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f: Starting segment from index:0
2019-09-12 11:42:05,568 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-061D57D4925F set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:05,635 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/c6c83faf-75a4-4c9c-859b-061d57d4925f/current/log_inprogress_0
2019-09-12 11:42:05,794 [Thread-328] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 changes to CANDIDATE, lastRpcTime:5161, electionTimeout:5161ms
2019-09-12 11:42:05,795 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:05,795 [Thread-328] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,795 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:05,811 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:05,812 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:05,812 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,812 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5183ms
2019-09-12 11:42:05,812 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,812 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,813 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,813 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,813 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,813 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,814 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:05,814 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020: Starting segment from index:0
2019-09-12 11:42:05,815 [c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-50AC1863D020 set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:05,854 [Thread-336] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB changes to CANDIDATE, lastRpcTime:5169, electionTimeout:5131ms
2019-09-12 11:42:05,854 [Thread-336] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:05,854 [Thread-336] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,854 [Thread-336] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:05,877 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/a26d44b0-c109-4960-9398-50ac1863d020/current/log_inprogress_0
2019-09-12 11:42:05,877 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:05,877 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:05,878 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,878 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5196ms
2019-09-12 11:42:05,878 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,878 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,878 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,879 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,879 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,879 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,879 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:05,880 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb: Starting segment from index:0
2019-09-12 11:42:05,880 [c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-7648080EC1CB set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:05,920 [Thread-364] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 changes to CANDIDATE, lastRpcTime:5052, electionTimeout:5044ms
2019-09-12 11:42:05,920 [Thread-364] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:05,920 [Thread-364] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,920 [Thread-364] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:05,933 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/227b090a-592a-47c9-88b5-7648080ec1cb/current/log_inprogress_0
2019-09-12 11:42:05,933 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:05,933 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:05,933 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,934 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5070ms
2019-09-12 11:42:05,934 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,934 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,934 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,935 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,935 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,935 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,935 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:05,936 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577: Starting segment from index:0
2019-09-12 11:42:05,936 [c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-3E6C4F7D8577 set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:05,975 [Thread-343] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC changes to CANDIDATE, lastRpcTime:5215, electionTimeout:5197ms
2019-09-12 11:42:05,976 [Thread-352] INFO  impl.FollowerState (FollowerState.java:run(106)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 changes to CANDIDATE, lastRpcTime:5167, electionTimeout:5142ms
2019-09-12 11:42:05,976 [Thread-343] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:05,976 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown FollowerState
2019-09-12 11:42:05,976 [Thread-343] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,976 [Thread-352] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:05,977 [Thread-343] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:05,977 [Thread-352] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderElection
2019-09-12 11:42:05,990 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3196e589-f64c-411c-9172-3e6c4f7d8577/current/log_inprogress_0
2019-09-12 11:42:05,990 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:05,990 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29: begin an election at term 1 for -1: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null
2019-09-12 11:42:05,991 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:05,991 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: shutdown LeaderElection
2019-09-12 11:42:05,991 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,991 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:05,991 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5236ms
2019-09-12 11:42:05,991 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 change Leader from null to e16ea380-278b-4c57-9f7f-c0f6c0a358a5 at term 1 for becomeLeader, leader elected after 5186ms
2019-09-12 11:42:05,991 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,992 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:05,992 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,992 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:05,992 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,992 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:05,992 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,993 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:05,993 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,993 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:05,993 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,993 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:05,993 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:05,994 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5: start LeaderState
2019-09-12 11:42:05,994 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc: Starting segment from index:0
2019-09-12 11:42:05,994 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25: Starting segment from index:0
2019-09-12 11:42:05,995 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5:group-0F53E9C04F25 set configuration 0: [e16ea380-278b-4c57-9f7f-c0f6c0a358a5:192.168.36.114:44890], old=null at 0
2019-09-12 11:42:05,995 [c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-8A5535E9F8BC set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:06,038 [Thread-367] INFO  impl.FollowerState (FollowerState.java:run(106)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 changes to CANDIDATE, lastRpcTime:5112, electionTimeout:5073ms
2019-09-12 11:42:06,043 [Thread-367] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown FollowerState
2019-09-12 11:42:06,044 [Thread-367] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 11:42:06,044 [Thread-367] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderElection
2019-09-12 11:42:06,072 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/82713aa4-781f-4981-ae1b-8a5535e9f8bc/current/log_inprogress_0
2019-09-12 11:42:06,072 [e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e16ea380-278b-4c57-9f7f-c0f6c0a358a5-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-2/data/ratis/40bca5da-f261-4d34-b781-0f53e9c04f25/current/log_inprogress_0
2019-09-12 11:42:06,072 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30: begin an election at term 1 for -1: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null
2019-09-12 11:42:06,072 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c88806e9-8dfd-472a-ae12-1122c7897177: shutdown LeaderElection
2019-09-12 11:42:06,073 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 11:42:06,073 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 change Leader from null to c88806e9-8dfd-472a-ae12-1122c7897177 at term 1 for becomeLeader, leader elected after 5151ms
2019-09-12 11:42:06,073 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 11:42:06,073 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 11:42:06,073 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 11:42:06,074 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 11:42:06,074 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 11:42:06,074 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 11:42:06,074 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c88806e9-8dfd-472a-ae12-1122c7897177: start LeaderState
2019-09-12 11:42:06,075 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824: Starting segment from index:0
2019-09-12 11:42:06,075 [c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c88806e9-8dfd-472a-ae12-1122c7897177:group-004F80D1C824 set configuration 0: [c88806e9-8dfd-472a-ae12-1122c7897177:192.168.36.114:42806], old=null at 0
2019-09-12 11:42:06,115 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:06,115 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:06,127 [c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c88806e9-8dfd-472a-ae12-1122c7897177-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-9de70e87-d22a-48ac-932c-4e9546c2fc12/datanode-4/data/ratis/3142eb33-529a-493b-bd59-004f80d1c824/current/log_inprogress_0
2019-09-12 11:42:06,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:06,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:06,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:07,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:07,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:07,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:07,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:07,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:08,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:08,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:08,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:08,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:08,484 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:09,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:09,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:09,181 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:09,188 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,188 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,188 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,188 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,189 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,189 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:09,189 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:09,189 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:09,193 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:09,193 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:09,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:09,195 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:09,199 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:09,202 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000001_0
2019-09-12 11:42:09,202 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:09,203 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:09,205 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:09,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:09,209 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:09,209 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:09,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:09,211 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:2250+293
2019-09-12 11:42:09,212 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:09,212 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:09,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:09,252 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-12 11:42:09,259 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:09,270 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:09,274 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,274 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,274 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,275 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,275 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:09,275 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:09,275 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:09,275 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:09,276 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:09,276 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:09,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:09,277 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:09,281 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:09,281 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:09,282 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:09,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:09,485 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:10,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:10,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:10,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:10,379 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:10,384 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:10,384 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:10,385 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:10,385 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:10,385 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:10,386 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:10,386 [IPC Server handler 0 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:10,386 [IPC Server handler 0 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:10,387 [IPC Server handler 0 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:10,387 [IPC Server handler 0 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:10,387 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:10,388 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:10,394 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:10,396 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:10,397 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:10,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:10,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:11,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:11,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:11,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:11,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:11,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:12,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:12,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:12,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:12,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:12,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:13,670 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:42:14,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:14,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:14,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:14,284 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 18% reduce 0%
2019-09-12 11:42:14,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:14,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:15,108 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,113 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:15,114 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:15,114 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:15,114 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:15,114 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:15,114 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:15,115 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:15,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:15,116 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:15,118 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:15,122 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000002_0
2019-09-12 11:42:15,122 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:15,123 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:15,124 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:15,133 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:15,133 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:15,134 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:15,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:2808+293
2019-09-12 11:42:15,137 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:15,137 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:15,155 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:15,156 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-12 11:42:15,162 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:15,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:15,168 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:15,169 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:15,170 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:15,170 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:15,170 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:15,170 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:15,172 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:15,173 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:15,173 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:15,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:15,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:15,487 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,487 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:16,980 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:16,986 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:16,986 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:16,987 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:16,987 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:16,987 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:16,987 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:16,988 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:16,988 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:16,988 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:16,988 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:16,989 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:16,990 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:16,996 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:16,999 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:17,000 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:17,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:17,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:17,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:17,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:17,488 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:18,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:18,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:18,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:18,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:18,488 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,488 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:19,673 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:42:20,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:20,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:20,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:20,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:20,488 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:20,889 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:20,895 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:20,895 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:20,895 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:20,895 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:20,896 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:20,896 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:20,896 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:20,896 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:20,909 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:20,909 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:20,909 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:20,910 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:20,913 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:20,914 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000003_0
2019-09-12 11:42:20,914 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:20,915 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:20,916 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000004_0
2019-09-12 11:42:20,917 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:20,917 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:20,918 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:20,919 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:588+281
2019-09-12 11:42:20,920 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:20,920 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:20,941 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:20,943 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:42:20,950 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:20,954 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:20,955 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:20,956 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000004_0 is done. And is in the process of committing
2019-09-12 11:42:20,957 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:20,957 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000004_0 is allowed to commit now
2019-09-12 11:42:20,959 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:20,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:42:20,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000004_0' done.
2019-09-12 11:42:20,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=223655
		FILE: Number of bytes written=823965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=23
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:20,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000004_0
2019-09-12 11:42:20,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000005_0
2019-09-12 11:42:20,961 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:20,962 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:20,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:20,963 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:869+281
2019-09-12 11:42:20,964 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:20,964 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:20,983 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:20,984 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:42:20,992 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:20,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:20,995 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:20,996 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000005_0 is done. And is in the process of committing
2019-09-12 11:42:20,997 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:20,997 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000005_0 is allowed to commit now
2019-09-12 11:42:20,998 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:20,999 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:42:20,999 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000005_0' done.
2019-09-12 11:42:21,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=228069
		FILE: Number of bytes written=823973
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=25
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:21,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000005_0
2019-09-12 11:42:21,000 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:21,001 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:21,001 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:21,001 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:21,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:1708+277
2019-09-12 11:42:21,003 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:21,003 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:21,033 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:21,034 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-09-12 11:42:21,042 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:21,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:21,057 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:21,058 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:21,058 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:21,058 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:21,059 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:21,059 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:21,059 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:21,059 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:21,060 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:21,060 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:21,060 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:21,062 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:21,067 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:21,068 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:21,069 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:21,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:21,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:21,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:21,229 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-12 11:42:21,289 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-12 11:42:21,469 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:21,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:22,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:22,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:22,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:22,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:22,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:23,765 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:23,770 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:23,770 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:23,770 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:23,771 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:23,771 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:23,771 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:23,771 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:23,771 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:23,772 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:23,772 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:23,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:23,773 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:23,779 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:23,780 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:23,780 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:24,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:24,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:24,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:24,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:24,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:25,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:25,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:25,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:25,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:25,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:26,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:26,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:26,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:26,173 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,174 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,174 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,174 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,175 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,175 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:26,175 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:26,175 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:26,176 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:26,176 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:26,176 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:26,177 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:26,183 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:26,184 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000006_0
2019-09-12 11:42:26,184 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:26,185 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:26,186 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000007_0
2019-09-12 11:42:26,187 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,187 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:26,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:1443+265
2019-09-12 11:42:26,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:26,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,214 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-12 11:42:26,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,226 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,227 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000007_0 is done. And is in the process of committing
2019-09-12 11:42:26,228 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,228 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000007_0 is allowed to commit now
2019-09-12 11:42:26,230 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:26,231 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-12 11:42:26,231 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000007_0' done.
2019-09-12 11:42:26,232 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=236385
		FILE: Number of bytes written=823989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=32
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:26,232 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000007_0
2019-09-12 11:42:26,232 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000008_0
2019-09-12 11:42:26,233 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,233 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,233 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:26,235 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:1985+265
2019-09-12 11:42:26,235 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,235 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,255 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,256 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-12 11:42:26,263 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,265 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,267 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,267 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000008_0 is done. And is in the process of committing
2019-09-12 11:42:26,268 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,268 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000008_0 is allowed to commit now
2019-09-12 11:42:26,270 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:26,271 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-12 11:42:26,271 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000008_0' done.
2019-09-12 11:42:26,272 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=240287
		FILE: Number of bytes written=823997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=34
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:26,272 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000008_0
2019-09-12 11:42:26,272 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000009_0
2019-09-12 11:42:26,273 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,273 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:26,274 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:2543+265
2019-09-12 11:42:26,275 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,275 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,293 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:42:26,294 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,295 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-12 11:42:26,303 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:26,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,307 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,308 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local846992285_0001_m_000009_0 is done. And is in the process of committing
2019-09-12 11:42:26,309 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:26,309 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local846992285_0001_m_000009_0 is allowed to commit now
2019-09-12 11:42:26,311 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local846992285_0001_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/_logs
2019-09-12 11:42:26,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-12 11:42:26,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local846992285_0001_m_000009_0' done.
2019-09-12 11:42:26,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local846992285_0001_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=244189
		FILE: Number of bytes written=824005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=36
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:26,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local846992285_0001_m_000009_0
2019-09-12 11:42:26,313 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:26,313 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,314 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:26,315 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995/fileList.seq:327+261
2019-09-12 11:42:26,316 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:26,316 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:26,345 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:26,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
2019-09-12 11:42:26,353 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:26,355 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:26,359 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,360 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,360 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,360 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,360 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:26,360 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:26,361 [IPC Server handler 0 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:26,361 [IPC Server handler 0 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:26,362 [IPC Server handler 0 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:26,362 [IPC Server handler 0 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:26,362 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:26,363 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:26,365 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:26,366 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:26,366 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:26,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:26,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:27,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:27,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:27,151 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:42:27,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:27,293 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 82% reduce 0%
2019-09-12 11:42:27,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:27,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:28,114 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:28,117 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:28,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:28,118 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:28,119 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:28,119 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:28,119 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:28,119 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:28,120 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:28,120 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:28,120 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:28,121 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:28,121 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:28,121 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:28,122 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:28,124 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:28,124 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:28,125 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:28,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:28,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:28,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:29,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:29,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:29,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:29,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:29,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:30,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:30,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:30,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:30,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:30,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:31,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:31,118 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:31,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:31,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:31,490 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,488 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:32,744 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:32,749 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:32,749 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:32,750 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:32,750 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:32,750 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:32,750 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:32,750 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:32,751 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:32,751 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:32,751 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:32,752 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:32,752 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:32,758 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25800 bucket: bucket18840 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:32,758 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local846992285_0001_m_000010_0
2019-09-12 11:42:32,759 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:32,759 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:32,760 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:42:32,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:32,786 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:32,795 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:32,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:32,798 [Thread-369] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10002010039681/.staging/_distcp2070320995
2019-09-12 11:42:32,801 [Thread-369] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local846992285_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket18840.volume25800/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:33,021 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-12 11:42:33,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:33,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:33,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:33,297 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 91% reduce 0%
2019-09-12 11:42:33,298 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local846992285_0001 failed with state FAILED due to: NA
2019-09-12 11:42:33,355 [Thread-217] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=2323930
		FILE: Number of bytes written=8239826
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=288
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=210
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Input split bytes=1580
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=20583546880
	File Input Format Counters 
		Bytes Read=31570
	File Output Format Counters 
		Bytes Written=80
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:42:33,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,365 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25800, bucket=bucket18840, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,371 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume25800, bucket=bucket18840, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:42:33,375 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,378 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,380 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,381 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,383 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,385 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume25800, bucket=bucket18840, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,386 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume25800, bucket=bucket18840, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
    <system-err><![CDATA[Sep 12, 2019 11:41:52 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:41:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:41:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:41:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:41:54 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Sep 12, 2019 11:41:58 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
]]></system-err>
  </testcase>
  <testcase name="testTrackDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="32.729">
    <error message="DistCp failure: Job job_local38041492_0002 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local38041492_0002 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testTrackDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:42:33,430 [Thread-489] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:42:33,434 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin20733, owner=user32680, volume=volume85016, creationTime=1568288553433, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:42:33,436 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume85016, bucket=bucket52313, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:42:33,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:33,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:33,515 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume85016} | ret=SUCCESS |  
2019-09-12 11:42:33,517 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume85016, bucket=bucket52313} | ret=SUCCESS |  
2019-09-12 11:42:33,518 [Thread-489] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket52313.volume85016 implemented by OzoneFileSystem{URI=o3fs://bucket52313.volume85016, workingDir=o3fs://bucket52313.volume85016/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 48 read ops, 0 large read ops, 32 write ops}
2019-09-12 11:42:33,520 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,533 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,535 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,537 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume85016, bucket=bucket52313, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:42:33,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,542 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume85016, bucket=bucket52313, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:42:33,544 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:33,547 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:33,548 [Thread-489] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-12 11:42:33,663 [Thread-489] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:42:33,687 [Thread-489] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:42:33,703 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:33,775 [Thread-489] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:42:33,778 [Thread-489] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:42:33,788 [Thread-489] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:42:33,806 [Thread-489] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:42:33,807 [Thread-489] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:42:33,823 [Thread-489] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:42:33,878 [Thread-489] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:11
2019-09-12 11:42:33,917 [Thread-489] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local38041492_0002
2019-09-12 11:42:33,917 [Thread-489] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:42:34,022 [Thread-489] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:42:34,025 [Thread-489] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local38041492_0002
2019-09-12 11:42:34,025 [Thread-552] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:42:34,025 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local38041492_0002
2019-09-12 11:42:34,025 [Thread-552] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:34,025 [Thread-552] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:34,026 [Thread-552] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:42:34,050 [Thread-552] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:42:34,051 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000000_0
2019-09-12 11:42:34,052 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:34,053 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:34,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:34,054 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:0+326
2019-09-12 11:42:34,055 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:34,055 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:34,079 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:34,080 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:42:34,088 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:34,091 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:34,092 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:34,092 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000000_0 is done. And is in the process of committing
2019-09-12 11:42:34,093 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:34,093 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000000_0 is allowed to commit now
2019-09-12 11:42:34,095 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000000_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:34,098 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:42:34,098 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000000_0' done.
2019-09-12 11:42:34,098 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=451965
		FILE: Number of bytes written=1644860
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:34,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000000_0
2019-09-12 11:42:34,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:34,099 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:34,100 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:34,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:34,101 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:882+292
2019-09-12 11:42:34,101 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:34,101 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:34,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:34,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-12 11:42:34,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:34,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:34,122 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:34,123 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:34,127 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:34,128 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:34,128 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:34,128 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:34,128 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:34,129 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:34,129 [IPC Server handler 13 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:34,129 [IPC Server handler 13 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:34,130 [IPC Server handler 13 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:34,130 [IPC Server handler 13 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:34,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:34,131 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:34,139 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:34,140 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:34,140 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:34,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:34,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:34,495 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:35,026 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local38041492_0002 running in uber mode : false
2019-09-12 11:42:35,026 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:42:35,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:35,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:35,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:35,450 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:35,455 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:35,455 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:35,456 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:35,456 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:35,456 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:35,456 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:35,456 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:35,457 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:35,457 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:35,457 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:35,458 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:35,459 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:35,462 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:35,463 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:35,463 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:35,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:35,495 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:36,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:36,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:36,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:36,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:36,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:37,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:37,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:37,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:37,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:37,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:38,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:38,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:38,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:38,320 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-12 11:42:38,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:38,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,119 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:39,903 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:39,909 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,909 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,910 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,910 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,910 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,911 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:39,911 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:39,911 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:39,912 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:39,912 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:39,912 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:39,913 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:39,916 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:39,918 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000001_0
2019-09-12 11:42:39,918 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:39,918 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:39,919 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:39,920 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:39,920 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:39,921 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:39,922 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:1438+292
2019-09-12 11:42:39,923 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:39,923 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:39,944 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:39,945 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-12 11:42:39,954 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:39,955 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:39,959 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,959 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,960 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,960 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,960 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:39,960 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:39,960 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:39,961 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:39,961 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:39,961 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:39,962 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:39,962 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:39,965 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:39,966 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:39,966 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:40,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:40,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:40,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:40,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:40,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:41,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:41,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:41,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:41,434 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:41,439 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:41,439 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:41,439 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:41,440 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:41,440 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:41,440 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:41,440 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:41,440 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:41,441 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:41,441 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:41,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:41,442 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:41,445 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:41,446 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:41,447 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:41,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:41,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:42,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:42,121 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:42,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:42,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:42,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:43,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:43,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:43,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:43,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:43,498 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:44,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:44,121 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:44,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:44,321 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 > map
2019-09-12 11:42:44,470 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:44,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:45,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:45,121 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:45,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:45,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:45,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:46,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:46,017 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,017 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,018 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,018 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,018 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,018 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:46,018 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:46,019 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:46,019 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:46,019 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:46,020 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:46,020 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:46,023 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:46,024 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000002_0
2019-09-12 11:42:46,024 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:46,025 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:46,026 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:46,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:46,027 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:46,028 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:46,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:1994+292
2019-09-12 11:42:46,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:46,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:46,059 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:46,060 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-12 11:42:46,068 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:46,069 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:46,073 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,073 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,074 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,074 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,074 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:46,074 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:46,074 [IPC Server handler 13 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:46,075 [IPC Server handler 13 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:46,075 [IPC Server handler 13 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:46,075 [IPC Server handler 13 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:46,076 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:46,076 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:46,079 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:46,079 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:46,080 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:46,115 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-12 11:42:46,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:46,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:46,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:46,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:46,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:47,033 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 18% reduce 0%
2019-09-12 11:42:47,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:47,121 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:47,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:47,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:47,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,122 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,122 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:48,695 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:48,701 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:48,701 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:48,701 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:48,701 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:48,702 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:48,702 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:48,702 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:48,702 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:48,703 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:48,703 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:48,703 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:48,704 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:48,707 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:48,708 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:48,708 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:49,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:49,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:49,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:49,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:49,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:50,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:50,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:50,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:50,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:50,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:51,938 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:42:52,037 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 27% reduce 0%
2019-09-12 11:42:52,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:52,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:52,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:52,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:52,498 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:53,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:53,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:53,193 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,193 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,193 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,193 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,193 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,194 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:53,194 [IPC Server handler 10 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:53,194 [IPC Server handler 10 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:53,195 [IPC Server handler 10 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:53,195 [IPC Server handler 10 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:53,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:53,196 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:53,201 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:53,202 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000003_0
2019-09-12 11:42:53,202 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:53,203 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:53,204 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000004_0
2019-09-12 11:42:53,205 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,205 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,206 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:53,207 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:602+280
2019-09-12 11:42:53,208 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,208 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:53,227 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:53,229 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:42:53,236 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:53,239 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:53,240 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:53,241 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000004_0 is done. And is in the process of committing
2019-09-12 11:42:53,242 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:53,242 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000004_0 is allowed to commit now
2019-09-12 11:42:53,244 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:53,244 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:42:53,244 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000004_0' done.
2019-09-12 11:42:53,245 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=471069
		FILE: Number of bytes written=1644892
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=71
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:53,245 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000004_0
2019-09-12 11:42:53,245 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000005_0
2019-09-12 11:42:53,246 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,246 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,247 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:53,248 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:2286+280
2019-09-12 11:42:53,249 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,249 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:53,268 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:42:53,275 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:53,278 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:53,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:53,279 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000005_0 is done. And is in the process of committing
2019-09-12 11:42:53,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:53,280 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000005_0 is allowed to commit now
2019-09-12 11:42:53,282 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:53,282 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:42:53,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000005_0' done.
2019-09-12 11:42:53,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=475461
		FILE: Number of bytes written=1644900
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=73
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:53,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000005_0
2019-09-12 11:42:53,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:53,284 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,284 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,285 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:53,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:326+276
2019-09-12 11:42:53,286 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:53,286 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:53,315 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:53,316 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-12 11:42:53,328 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:53,329 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:53,333 [IPC Server handler 0 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:53,334 [IPC Server handler 0 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:53,334 [IPC Server handler 0 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:53,334 [IPC Server handler 0 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:53,334 [IPC Server handler 0 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:53,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:53,335 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:53,337 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:53,337 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:53,338 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:53,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:53,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:54,038 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:42:54,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:54,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:54,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:54,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:54,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:55,869 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:55,874 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:55,875 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:55,875 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:55,875 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:55,875 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:55,876 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:55,876 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:55,876 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:55,877 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:55,877 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:55,877 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:55,878 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:55,880 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:55,881 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:55,881 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:56,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:56,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:56,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:56,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:56,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:57,939 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:42:58,046 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:42:58,046 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-12 11:42:58,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:58,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:58,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:58,472 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:58,498 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,047 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 55% reduce 0%
2019-09-12 11:42:59,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,396 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:59,401 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,401 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:59,402 [IPC Server handler 1 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:59,403 [IPC Server handler 1 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:59,403 [IPC Server handler 1 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:59,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:59,404 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:59,407 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:59,408 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000006_0
2019-09-12 11:42:59,408 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:42:59,409 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:42:59,410 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000007_0
2019-09-12 11:42:59,411 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,411 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:59,413 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:1174+264
2019-09-12 11:42:59,414 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,414 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,439 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:42:59,448 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:59,452 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,453 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,454 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000007_0 is done. And is in the process of committing
2019-09-12 11:42:59,455 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,455 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000007_0 is allowed to commit now
2019-09-12 11:42:59,457 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:59,457 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:42:59,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000007_0' done.
2019-09-12 11:42:59,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=483733
		FILE: Number of bytes written=1644916
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=80
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:59,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000007_0
2019-09-12 11:42:59,458 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000008_0
2019-09-12 11:42:59,459 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,460 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,460 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:59,461 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:1730+264
2019-09-12 11:42:59,462 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,462 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,473 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:42:59,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,512 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:42:59,525 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,529 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,530 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000008_0 is done. And is in the process of committing
2019-09-12 11:42:59,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,532 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000008_0 is allowed to commit now
2019-09-12 11:42:59,533 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:59,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:42:59,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000008_0' done.
2019-09-12 11:42:59,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=487613
		FILE: Number of bytes written=1644924
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=82
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:59,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000008_0
2019-09-12 11:42:59,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000009_0
2019-09-12 11:42:59,536 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,536 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,536 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:59,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:2566+264
2019-09-12 11:42:59,538 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,538 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,557 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:42:59,566 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,570 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,570 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local38041492_0002_m_000009_0 is done. And is in the process of committing
2019-09-12 11:42:59,571 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:42:59,571 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local38041492_0002_m_000009_0 is allowed to commit now
2019-09-12 11:42:59,572 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local38041492_0002_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/_logs
2019-09-12 11:42:59,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:42:59,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local38041492_0002_m_000009_0' done.
2019-09-12 11:42:59,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local38041492_0002_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=491493
		FILE: Number of bytes written=1644932
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=84
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=57
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:42:59,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local38041492_0002_m_000009_0
2019-09-12 11:42:59,574 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local38041492_0002_m_000010_0
2019-09-12 11:42:59,574 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,574 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:42:59,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077/fileList.seq:2830+260
2019-09-12 11:42:59,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:42:59,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:42:59,617 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:42:59,618 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-12 11:42:59,626 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:59,627 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:42:59,631 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,631 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,631 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,631 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,632 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:42:59,632 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:59,632 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:42:59,632 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:42:59,633 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:42:59,633 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:42:59,633 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:42:59,634 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:42:59,636 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:42:59,637 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:42:59,637 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:00,054 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:43:00,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:00,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:00,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:00,473 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:00,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,474 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:01,945 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:43:01,951 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:01,951 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:01,952 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:01,952 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:01,952 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:01,952 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:01,952 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:01,953 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:01,953 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:01,953 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:01,954 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:01,954 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:01,957 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:01,958 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:43:01,958 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:02,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:02,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:02,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:02,474 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:02,500 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:03,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:03,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:03,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:03,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:03,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:04,047 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-12 11:43:04,064 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 82% reduce 0%
2019-09-12 11:43:04,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:04,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:04,207 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:04,475 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:04,500 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,300 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-12 11:43:05,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,500 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:05,508 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:43:05,513 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:05,513 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:05,513 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:05,514 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:05,514 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:05,514 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:05,514 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:05,515 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:05,515 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:05,515 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:05,516 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:05,516 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:05,519 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume85016 bucket: bucket52313 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:05,520 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local38041492_0002_m_000010_0
2019-09-12 11:43:05,520 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:05,521 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:05,535 [Thread-552] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:43:05,542 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:05,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:05,547 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:05,550 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:05,550 [Thread-552] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000208987639/.staging/_distcp1073854077
2019-09-12 11:43:05,552 [Thread-552] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local38041492_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket52313.volume85016/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:06,065 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 91% reduce 0%
2019-09-12 11:43:06,066 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local38041492_0002 failed with state FAILED due to: NA
2019-09-12 11:43:06,113 [Thread-489] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=4797586
		FILE: Number of bytes written=16449096
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=764
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=530
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Input split bytes=1570
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=20583546880
	File Input Format Counters 
		Bytes Read=31460
	File Output Format Counters 
		Bytes Written=80
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:43:06,115 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,117 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,118 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume85016, bucket=bucket52313, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,120 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume85016, bucket=bucket52313, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:43:06,122 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:06,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:06,124 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,126 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,127 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,128 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,130 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume85016, bucket=bucket52313, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,131 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume85016, bucket=bucket52313, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="largeFilesToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="13.828">
    <error message="DistCp failure: Job job_local169774015_0003 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local169774015_0003 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:534)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFilesToRemote(AbstractContractDistCpTest.java:452)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:43:06,159 [Thread-610] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:43:06,161 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin43472, owner=user01358, volume=volume95900, creationTime=1568288586161, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:43:06,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume95900, bucket=bucket10547, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:43:06,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:06,216 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume95900} | ret=SUCCESS |  
2019-09-12 11:43:06,217 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume95900, bucket=bucket10547} | ret=SUCCESS |  
2019-09-12 11:43:06,218 [Thread-610] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket10547.volume95900 implemented by OzoneFileSystem{URI=o3fs://bucket10547.volume95900, workingDir=o3fs://bucket10547.volume95900/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 96 read ops, 0 large read ops, 64 write ops}
2019-09-12 11:43:06,219 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume95900, bucket=bucket10547, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,232 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,233 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,236 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume95900, bucket=bucket10547, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:06,237 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,238 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume95900, bucket=bucket10547, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:06,239 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,242 [Thread-610] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-12 11:43:06,251 [Thread-610] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-12 11:43:06,408 [Thread-610] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:06,421 [Thread-610] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:06,436 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:06,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:06,583 [Thread-610] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-12 11:43:06,584 [Thread-610] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:43:06,623 [Thread-610] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-12 11:43:06,635 [Thread-610] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-12 11:43:06,636 [Thread-610] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:06,646 [Thread-610] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:43:06,709 [Thread-610] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-12 11:43:06,762 [Thread-610] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local169774015_0003
2019-09-12 11:43:06,762 [Thread-610] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:43:06,914 [Thread-610] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:43:06,915 [Thread-610] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local169774015_0003
2019-09-12 11:43:06,917 [Thread-657] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:43:06,917 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local169774015_0003
2019-09-12 11:43:06,917 [Thread-657] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:06,918 [Thread-657] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:06,918 [Thread-657] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:43:06,938 [Thread-657] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:43:06,938 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:06,939 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:06,939 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:06,940 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:06,942 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000609584353/.staging/_distcp-2108271984/fileList.seq:0+780
2019-09-12 11:43:06,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:06,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:06,966 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,967 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
2019-09-12 11:43:06,976 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,979 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:06,980 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
2019-09-12 11:43:06,987 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,988 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:06,993 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:06,993 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:06,993 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:06,993 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:06,994 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:06,994 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:06,994 [IPC Server handler 13 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:06,994 [IPC Server handler 13 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:06,995 [IPC Server handler 13 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:06,995 [IPC Server handler 13 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:06,995 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:06,996 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:06,998 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:06,998 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:07,000 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:07,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:07,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:07,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:07,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:07,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:07,918 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local169774015_0003 running in uber mode : false
2019-09-12 11:43:07,919 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:43:08,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:08,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:08,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:08,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:08,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:08,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:08,905 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:08,906 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:08,906 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:08,906 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:08,906 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:08,907 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:08,907 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:08,907 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:08,907 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:08,908 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:08,908 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:08,908 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:08,911 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:08,912 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:08,912 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:09,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:09,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:09,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:09,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:09,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:10,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:10,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:10,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:10,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:10,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:11,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:11,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:11,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:11,301 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-12 11:43:11,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:11,591 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-12 11:43:11,592 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:12,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:12,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:12,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:12,477 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:12,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,124 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,477 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:13,696 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:13,700 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,700 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,700 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,701 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,701 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,701 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:13,701 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:13,701 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:13,702 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:13,702 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:13,702 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:13,703 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:13,705 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:13,705 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000000_0
2019-09-12 11:43:13,705 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:13,706 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:13,707 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:13,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:13,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:13,707 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:13,708 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000609584353/.staging/_distcp-2108271984/fileList.seq:780+238
2019-09-12 11:43:13,708 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:13,709 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:13,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:13,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
2019-09-12 11:43:13,728 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:13,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:13,732 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,732 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,732 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,732 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,732 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:13,733 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:13,733 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:13,733 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:13,733 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:13,733 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:13,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:13,734 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:13,736 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:13,736 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:13,736 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:14,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:14,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:14,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:14,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:14,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:15,926 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:15,930 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:15,931 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:15,931 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:15,931 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:15,931 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:15,931 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:15,932 [IPC Server handler 13 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:15,932 [IPC Server handler 13 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:15,932 [IPC Server handler 13 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:15,932 [IPC Server handler 13 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:15,933 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:15,933 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:15,935 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:15,936 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:15,936 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:16,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:16,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:16,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:16,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:16,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:17,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:17,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:17,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:17,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:17,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,125 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:18,958 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-12 11:43:19,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:19,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:19,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:19,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:19,511 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:19,517 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:19,517 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:19,517 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:19,517 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:19,518 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:19,518 [IPC Server handler 16 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:19,518 [IPC Server handler 16 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:19,518 [IPC Server handler 16 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:19,519 [IPC Server handler 16 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:19,519 [IPC Server handler 16 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:19,519 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:19,520 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:19,522 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95900 bucket: bucket10547 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:19,523 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local169774015_0003_m_000001_0
2019-09-12 11:43:19,523 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:19,524 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:19,525 [Thread-657] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:43:19,532 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,533 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,536 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,538 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,539 [Thread-657] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000609584353/.staging/_distcp-2108271984
2019-09-12 11:43:19,543 [Thread-657] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local169774015_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket10547.volume95900/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:19,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:19,928 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 33% reduce 0%
2019-09-12 11:43:19,929 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local169774015_0003 failed with state FAILED due to: NA
2019-09-12 11:43:19,944 [Thread-610] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=686905
		FILE: Number of bytes written=11970656
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=110
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=75
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=1058
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:19,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,948 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,949 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95900, bucket=bucket10547, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,952 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume95900, bucket=bucket10547, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:43:19,954 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume95900, bucket=bucket10547, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume95900, bucket=bucket10547, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:19,958 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume95900, bucket=bucket10547, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testLargeFilesFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.131">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.largeFiles(AbstractContractDistCpTest.java:528)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testLargeFilesFromRemote(AbstractContractDistCpTest.java:464)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:43:19,985 [Thread-674] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:43:19,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin80385, owner=user04355, volume=volume96741, creationTime=1568288599987, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:43:19,989 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume96741, bucket=bucket55720, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:43:20,040 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume96741} | ret=SUCCESS |  
2019-09-12 11:43:20,041 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume96741, bucket=bucket55720} | ret=SUCCESS |  
2019-09-12 11:43:20,042 [Thread-674] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket55720.volume96741 implemented by OzoneFileSystem{URI=o3fs://bucket55720.volume96741, workingDir=o3fs://bucket55720.volume96741/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 118 read ops, 0 large read ops, 78 write ops}
2019-09-12 11:43:20,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume96741, bucket=bucket55720, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,056 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,058 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,059 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume96741, bucket=bucket55720, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:20,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,063 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume96741, bucket=bucket55720, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:20,064 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume96741 bucket: bucket55720 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,065 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,066 [Thread-674] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-12 11:43:20,068 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,068 [Thread-674] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-12 11:43:20,080 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,080 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,080 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,081 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,081 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,081 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:20,081 [IPC Server handler 10 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:20,081 [IPC Server handler 10 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:20,082 [IPC Server handler 10 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:20,082 [IPC Server handler 10 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:20,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:20,083 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:20,084 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,085 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume96741, bucket=bucket55720, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,088 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume96741, bucket=bucket55720, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:43:20,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume96741, bucket=bucket55720, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,091 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume96741, bucket=bucket55720, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,092 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume96741, bucket=bucket55720, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testUpdateDeepDirectoryStructureToRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="15.678">
    <error message="DistCp failure: Job job_local2114300185_0004 has failed: NA" type="java.io.IOException">java.io.IOException: DistCp failure: Job job_local2114300185_0004 has failed: NA
	at org.apache.hadoop.tools.DistCp.waitForJobCompletion(DistCp.java:230)
	at org.apache.hadoop.tools.DistCp.execute(DistCp.java:185)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:560)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.runDistCp(AbstractContractDistCpTest.java:549)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:496)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testUpdateDeepDirectoryStructureToRemote(AbstractContractDistCpTest.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:43:20,118 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin88967, owner=user05534, volume=volume74305, creationTime=1568288600117, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:43:20,119 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume74305, bucket=bucket81637, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:43:20,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:20,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:20,171 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume74305} | ret=SUCCESS |  
2019-09-12 11:43:20,172 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume74305, bucket=bucket81637} | ret=SUCCESS |  
2019-09-12 11:43:20,173 [Thread-678] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket81637.volume74305 implemented by OzoneFileSystem{URI=o3fs://bucket81637.volume74305, workingDir=o3fs://bucket81637.volume74305/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 124 read ops, 0 large read ops, 81 write ops}
2019-09-12 11:43:20,174 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,186 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,186 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,188 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,189 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume74305, bucket=bucket81637, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:20,191 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume74305, bucket=bucket81637, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:20,193 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,195 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:20,195 [Thread-678] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-12 11:43:20,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:20,303 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:20,319 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:20,336 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,423 [Thread-678] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-12 11:43:20,424 [Thread-678] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-12 11:43:20,437 [Thread-678] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:43:20,452 [Thread-678] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-12 11:43:20,454 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-12 11:43:20,463 [Thread-678] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-12 11:43:20,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:20,529 [Thread-678] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-12 11:43:20,567 [Thread-678] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local2114300185_0004
2019-09-12 11:43:20,567 [Thread-678] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-12 11:43:20,585 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:20,671 [Thread-678] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-12 11:43:20,675 [Thread-740] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-12 11:43:20,675 [Thread-678] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local2114300185_0004
2019-09-12 11:43:20,676 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local2114300185_0004
2019-09-12 11:43:20,676 [Thread-740] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:20,676 [Thread-740] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:20,676 [Thread-740] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-12 11:43:20,699 [Thread-740] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-12 11:43:20,699 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:20,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:20,700 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:20,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:20,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:1134+586
2019-09-12 11:43:20,702 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:20,702 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:20,726 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-12 11:43:20,736 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,737 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:20,743 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,743 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,743 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,743 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,743 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:20,744 [IPC Server handler 13 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:20,744 [IPC Server handler 13 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:20,744 [IPC Server handler 13 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:20,745 [IPC Server handler 13 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:20,745 [IPC Server handler 13 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:20,745 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:20,746 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:20,748 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:20,748 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:20,749 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:21,126 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:21,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:21,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:21,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:21,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:21,676 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local2114300185_0004 running in uber mode : false
2019-09-12 11:43:21,677 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-12 11:43:22,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:22,122 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:22,123 [IPC Server handler 18 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:22,123 [IPC Server handler 18 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:22,123 [IPC Server handler 18 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:22,123 [IPC Server handler 18 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:22,123 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:22,124 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:22,126 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:22,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:22,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:22,127 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:22,127 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:22,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:22,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:22,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:23,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:23,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:23,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:23,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:23,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:24,655 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:24,660 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,660 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,660 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,661 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,661 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,661 [IPC Server handler 11 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:24,661 [IPC Server handler 11 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:24,662 [IPC Server handler 11 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:24,662 [IPC Server handler 11 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:24,662 [IPC Server handler 11 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:24,663 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:24,663 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:24,665 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:24,666 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000000_0
2019-09-12 11:43:24,666 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:24,667 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:24,668 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:24,669 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:24,669 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:24,669 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:24,671 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:2001+554
2019-09-12 11:43:24,671 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:24,671 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:24,693 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:24,694 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-12 11:43:24,702 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:24,703 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:24,706 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,707 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,707 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,707 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,707 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:24,707 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:24,708 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:24,708 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:24,708 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:24,708 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:24,709 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:24,709 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:24,711 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:24,712 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:24,712 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:24,961 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-12 11:43:25,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:25,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:25,212 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:25,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:25,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:25,725 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
2019-09-12 11:43:26,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:26,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:26,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:26,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:26,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:27,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:27,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:27,155 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:27,160 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:27,160 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:27,160 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:27,160 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:27,161 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:27,161 [IPC Server handler 2 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:27,161 [IPC Server handler 2 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:27,161 [IPC Server handler 2 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:27,162 [IPC Server handler 2 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:27,162 [IPC Server handler 2 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:27,162 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:27,163 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:27,165 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:27,165 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:27,165 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:27,212 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:27,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:27,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:28,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:28,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:28,212 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:28,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:28,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:29,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:29,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:29,212 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:29,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:29,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,032 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:30,036 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,037 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,037 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,037 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,037 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,037 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:30,038 [IPC Server handler 10 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:30,038 [IPC Server handler 10 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:30,038 [IPC Server handler 10 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:30,038 [IPC Server handler 10 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:30,039 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:30,039 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:30,041 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,042 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000001_0
2019-09-12 11:43:30,042 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:30,043 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:30,044 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000002_0
2019-09-12 11:43:30,045 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,045 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,045 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:30,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:0+327
2019-09-12 11:43:30,047 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,047 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,066 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,067 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:43:30,074 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,077 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,078 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,079 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000002_0 is done. And is in the process of committing
2019-09-12 11:43:30,079 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,079 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000002_0 is allowed to commit now
2019-09-12 11:43:30,081 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:30,081 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-12 11:43:30,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000002_0' done.
2019-09-12 11:43:30,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=900219
		FILE: Number of bytes written=12797286
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=140
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:30,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000002_0
2019-09-12 11:43:30,082 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000003_0
2019-09-12 11:43:30,083 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,083 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,084 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:30,084 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:1720+281
2019-09-12 11:43:30,085 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,085 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,101 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,102 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:43:30,109 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,111 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000003_0 is done. And is in the process of committing
2019-09-12 11:43:30,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000003_0 is allowed to commit now
2019-09-12 11:43:30,115 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:30,115 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-12 11:43:30,115 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000003_0' done.
2019-09-12 11:43:30,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=904816
		FILE: Number of bytes written=12797294
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=142
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:30,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000003_0
2019-09-12 11:43:30,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000004_0
2019-09-12 11:43:30,117 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,117 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:30,118 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:2555+281
2019-09-12 11:43:30,118 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,119 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:43:30,164 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,167 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,168 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000004_0 is done. And is in the process of committing
2019-09-12 11:43:30,169 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:30,169 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000004_0 is allowed to commit now
2019-09-12 11:43:30,171 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:30,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-12 11:43:30,171 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000004_0' done.
2019-09-12 11:43:30,172 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=908901
		FILE: Number of bytes written=12797302
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=144
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=94
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:30,172 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000004_0
2019-09-12 11:43:30,172 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:30,173 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,173 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,173 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:30,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:592+277
2019-09-12 11:43:30,174 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:30,175 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:30,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:30,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-12 11:43:30,199 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,200 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:30,202 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,202 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,202 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,203 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,203 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:30,203 [IPC Server handler 12 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:30,203 [IPC Server handler 12 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:30,203 [IPC Server handler 12 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:30,204 [IPC Server handler 12 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:30,204 [IPC Server handler 12 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:30,204 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:30,205 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:30,206 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:30,207 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:30,207 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:30,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:30,681 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:43:31,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:31,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:31,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:31,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:31,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:32,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:32,689 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:32,690 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:32,690 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:32,690 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:32,690 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:32,690 [IPC Server handler 4 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:32,691 [IPC Server handler 4 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:32,691 [IPC Server handler 4 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:32,691 [IPC Server handler 4 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:32,691 [IPC Server handler 4 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:32,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:32,692 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:32,694 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:32,695 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:32,695 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:32,717 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-12 11:43:33,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:33,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:33,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:33,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:33,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:33,683 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 39% reduce 0%
2019-09-12 11:43:34,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:34,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:34,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:34,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:34,585 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,049 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:35,053 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,053 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,053 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,054 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,054 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,054 [IPC Server handler 18 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:35,054 [IPC Server handler 18 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:35,054 [IPC Server handler 18 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:35,055 [IPC Server handler 18 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:35,055 [IPC Server handler 18 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:35,055 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:35,055 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:35,057 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:35,058 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local2114300185_0004_m_000005_0
2019-09-12 11:43:35,058 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 11:43:35,059 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:35,059 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000006_0
2019-09-12 11:43:35,060 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,060 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,061 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:35,062 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:327+265
2019-09-12 11:43:35,062 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,062 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,113 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,114 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:43:35,121 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,123 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,123 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,124 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000006_0 is done. And is in the process of committing
2019-09-12 11:43:35,125 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,125 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000006_0 is allowed to commit now
2019-09-12 11:43:35,126 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-12 11:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000006_0' done.
2019-09-12 11:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=917071
		FILE: Number of bytes written=12797318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=151
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=100
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000006_0
2019-09-12 11:43:35,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000007_0
2019-09-12 11:43:35,128 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,128 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,128 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:35,129 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:869+265
2019-09-12 11:43:35,130 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,130 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=e16ea380-278b-4c57-9f7f-c0f6c0a358a5, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,130 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=db5ea8ae-f1f9-4380-95d3-5f4efb341cff, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,148 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:43:35,155 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume74305 bucket: bucket81637 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:35,158 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,158 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000007_0 is done. And is in the process of committing
2019-09-12 11:43:35,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,160 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000007_0 is allowed to commit now
2019-09-12 11:43:35,161 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:35,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-12 11:43:35,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000007_0' done.
2019-09-12 11:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=920644
		FILE: Number of bytes written=12797326
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=153
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=100
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000007_0
2019-09-12 11:43:35,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2114300185_0004_m_000008_0
2019-09-12 11:43:35,163 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,163 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-12 11:43:35,164 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/fileList.seq:2836+265
2019-09-12 11:43:35,164 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-12 11:43:35,164 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-12 11:43:35,189 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,190 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:43:35,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,199 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2114300185_0004_m_000008_0 is done. And is in the process of committing
2019-09-12 11:43:35,199 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-12 11:43:35,199 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2114300185_0004_m_000008_0 is allowed to commit now
2019-09-12 11:43:35,200 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2114300185_0004_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745/_logs
2019-09-12 11:43:35,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-12 11:43:35,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2114300185_0004_m_000008_0' done.
2019-09-12 11:43:35,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2114300185_0004_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=924217
		FILE: Number of bytes written=12797334
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=155
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=100
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-12 11:43:35,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2114300185_0004_m_000008_0
2019-09-12 11:43:35,201 [Thread-740] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-12 11:43:35,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,208 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,210 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,212 [Thread-740] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001114528835/.staging/_distcp305692745
2019-09-12 11:43:35,214 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2909770e-87e5-4d6e-b81e-a1ae67fa8b8d, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,214 [Thread-740] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local2114300185_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket81637.volume74305/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-12 11:43:35,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=c88806e9-8dfd-472a-ae12-1122c7897177, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=2a8b7a9f-6887-4eab-b6d8-f6032b4ad6a9, command=[]} | ret=SUCCESS |  
2019-09-12 11:43:35,684 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-12 11:43:35,685 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local2114300185_0004 failed with state FAILED due to: NA
2019-09-12 11:43:35,750 [Thread-678] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=6388854
		FILE: Number of bytes written=89581170
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1033
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=680
	Map-Reduce Framework
		Map input records=7
		Map output records=0
		Input split bytes=1099
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=14048821248
	File Input Format Counters 
		Bytes Read=22099
	File Output Format Counters 
		Bytes Written=56
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-12 11:43:35,752 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,754 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,756 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume74305, bucket=bucket81637, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,758 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume74305, bucket=bucket81637, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:43:35,760 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume74305, bucket=bucket81637, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume74305, bucket=bucket81637, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
  <testcase name="testDeepDirectoryStructureFromRemote" classname="org.apache.hadoop.fs.ozone.contract.ITestOzoneContractDistCp" time="0.141">
    <error message="Allocated 0 blocks. Requested 1 blocks" type="INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException">INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:633)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.distCpDeepDirectoryStructure(AbstractContractDistCpTest.java:488)
	at org.apache.hadoop.tools.contract.AbstractContractDistCpTest.testDeepDirectoryStructureFromRemote(AbstractContractDistCpTest.java:458)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2019-09-12 11:43:35,800 [Thread-784] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-12 11:43:35,802 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin63358, owner=user03118, volume=volume27134, creationTime=1568288615802, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 11:43:35,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume27134, bucket=bucket51838, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-12 11:43:35,862 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume27134} | ret=SUCCESS |  
2019-09-12 11:43:35,863 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume27134, bucket=bucket51838} | ret=SUCCESS |  
2019-09-12 11:43:35,864 [Thread-784] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket51838.volume27134 implemented by OzoneFileSystem{URI=o3fs://bucket51838.volume27134, workingDir=o3fs://bucket51838.volume27134/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 162 read ops, 0 large read ops, 101 write ops}
2019-09-12 11:43:35,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume27134, bucket=bucket51838, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,880 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,881 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,883 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,884 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume27134, bucket=bucket51838, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:35,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,887 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume27134, bucket=bucket51838, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-12 11:43:35,888 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume27134 bucket: bucket51838 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-12 11:43:35,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,891 [Thread-784] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-12 11:43:35,892 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,897 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,897 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,897 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,898 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,898 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 11:43:35,898 [IPC Server handler 10 on 45617] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:35,898 [IPC Server handler 10 on 45617] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-12 11:43:35,898 [IPC Server handler 10 on 45617] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 11:43:35,899 [IPC Server handler 10 on 45617] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 11:43:35,899 [IPC Server handler 10 on 45617] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 11:43:35,899 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=343d8de9-cd3e-46cf-a800-3e9ef38501a7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 11:43:35,899 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-12 11:43:35,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,902 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,903 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume27134, bucket=bucket51838, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,905 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume27134, bucket=bucket51838, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-12 11:43:35,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume27134, bucket=bucket51838, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,910 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume27134, bucket=bucket51838, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 11:43:35,911 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume27134, bucket=bucket51838, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
]]></system-out>
  </testcase>
</testsuite>
2019-09-12 10:44:03,688 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:03,806 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:03,810 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:03,829 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @939ms
2019-09-12 10:44:03,965 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-12 10:44:03,965 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-12 10:44:03,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-12 10:44:03,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-12 10:44:03,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-12 10:44:03,966 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-12 10:44:03,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 10:44:03,979 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 10:44:03,981 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 10:44:04,178 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5ffead27
2019-09-12 10:44:04,180 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-12 10:44:04,268 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 10:44:04,271 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-12 10:44:04,274 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-12 10:44:04,362 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-12 10:44:04,378 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:04,496 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-12 10:44:04,499 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:04,633 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-12 10:44:05,442 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:44:05,475 [Socket Reader #1 for port 43971] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43971
2019-09-12 10:44:05,499 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:44:05,500 [Socket Reader #1 for port 45226] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45226
2019-09-12 10:44:05,507 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:44:05,507 [Socket Reader #1 for port 43713] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43713
2019-09-12 10:44:05,527 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-12 10:44:05,713 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:44:05,726 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:44:05,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:44:05,741 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-12 10:44:05,741 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:44:05,741 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:44:05,778 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43713
2019-09-12 10:44:05,853 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-12 10:44:05,867 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-12 10:44:05,867 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-12 10:44:06,118 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:43713
2019-09-12 10:44:06,118 [IPC Server listener on 43713] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43713: starting
2019-09-12 10:44:06,118 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:44:06,121 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45226
2019-09-12 10:44:06,122 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:45226
2019-09-12 10:44:06,122 [IPC Server listener on 45226] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45226: starting
2019-09-12 10:44:06,122 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:44:06,124 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:43971
2019-09-12 10:44:06,125 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:43971
2019-09-12 10:44:06,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:44:06,125 [IPC Server listener on 43971] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43971: starting
2019-09-12 10:44:06,129 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34857
2019-09-12 10:44:06,131 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:44:06,171 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:44:06,171 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-12 10:44:06,223 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43c67247{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-12 10:44:06,232 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:34857}
2019-09-12 10:44:06,232 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3342ms
2019-09-12 10:44:06,233 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:34857
2019-09-12 10:44:06,240 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24f43aa3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:44:06,243 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:06,378 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:06,378 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:06,379 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-12 10:44:06,380 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63
2019-09-12 10:44:06,381 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-12 10:44:06,627 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 10:44:07,127 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-12 10:44:07,135 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-12 10:44:07,135 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-12 10:44:07,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-12 10:44:07,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-12 10:44:07,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-12 10:44:07,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-12 10:44:07,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-12 10:44:07,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-12 10:44:07,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-12 10:44:07,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-12 10:44:07,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-12 10:44:07,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-12 10:44:07,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-12 10:44:07,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-12 10:44:07,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-12 10:44:07,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-12 10:44:07,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-12 10:44:07,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-12 10:44:07,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-12 10:44:07,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-12 10:44:07,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-12 10:44:07,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-12 10:44:07,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-12 10:44:07,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-12 10:44:07,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-12 10:44:07,578 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3406)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-12 10:44:07,775 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:44:07,807 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: localhost:9872
2019-09-12 10:44:07,836 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:44:07,904 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:44:07,909 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9872 (custom)
2019-09-12 10:44:07,910 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-12 10:44:07,912 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:07,912 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:44:07,913 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:44:08,147 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis] (custom)
2019-09-12 10:44:08,155 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: addNew group-C5BA1605619E:[05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:localhost:9872] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@5496c165[Not completed]
2019-09-12 10:44:08,158 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1398)) - OzoneManager Ratis server initialized at port 9872
2019-09-12 10:44:08,161 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:44:08,161 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-12 10:44:08,172 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: new RaftServerImpl for group-C5BA1605619E:[05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:localhost:9872] with OzoneManagerStateMachine:uninitialized
2019-09-12 10:44:08,175 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-12 10:44:08,176 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-12 10:44:08,176 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:08,177 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:08,178 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:08,180 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-12 10:44:08,182 [Socket Reader #1 for port 38955] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38955
2019-09-12 10:44:08,186 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E ConfigurationManager, init=-1: [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:localhost:9872], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:08,186 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis] (custom)
2019-09-12 10:44:08,198 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2019-09-12 10:44:08,206 [main] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38955
2019-09-12 10:44:08,207 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-12 10:44:08,207 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63 at port 9872
2019-09-12 10:44:08,216 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:08,231 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2019-09-12 10:44:08,236 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:08,239 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:08,244 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:08,244 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:08,246 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-12 10:44:08,250 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:08,255 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2019-09-12 10:44:08,271 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-12 10:44:08,272 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-12 10:44:08,279 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-12 10:44:08,280 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:08,281 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-12 10:44:08,281 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:08,283 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:08,284 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:08,284 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:08,297 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-12 10:44:08,304 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:08,311 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:08,313 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-12 10:44:08,313 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:08,338 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: start group-C5BA1605619E
2019-09-12 10:44:08,341 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:08,342 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: start FollowerState
2019-09-12 10:44:08,345 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63
2019-09-12 10:44:08,346 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: start RPC server
2019-09-12 10:44:08,455 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
2019-09-12 10:44:08,470 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-12 10:44:08,470 [IPC Server listener on 38955] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38955: starting
2019-09-12 10:44:08,476 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-12 10:44:08,479 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:44:08,480 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:44:08,483 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:44:08,483 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-12 10:44:08,484 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:44:08,484 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:44:08,486 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45560
2019-09-12 10:44:08,486 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:44:08,488 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:44:08,489 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-12 10:44:08,494 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1debc91c{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-12 10:44:08,495 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:45560}
2019-09-12 10:44:08,496 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5606ms
2019-09-12 10:44:08,497 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45560
2019-09-12 10:44:08,655 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:44:08,745 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 10:44:08,778 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:44:08,780 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/containers/hdds to VolumeSet
2019-09-12 10:44:08,783 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-12 10:44:08,802 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-12 10:44:08,856 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:44:08,856 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:44:08,857 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:44:08,857 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:44:08,857 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:08,857 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:44:08,858 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:44:08,858 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:08,894 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:44:08,908 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:44:08,911 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:44:08,912 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:44:08,916 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:44:08,917 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:44:08,917 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:44:08,918 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:44:08,919 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41959
2019-09-12 10:44:08,919 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:44:08,923 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:44:08,924 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:44:08,973 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a87026{/,file:///tmp/jetty-0.0.0.0-41959-hddsDatanode-_-any-2292596337608798067.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:44:08,974 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:41959}
2019-09-12 10:44:08,976 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6086ms
2019-09-12 10:44:08,977 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41959
Sep 12, 2019 10:44:09 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:44:09,440 [Thread-94] INFO  impl.FollowerState (FollowerState.java:run(106)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E changes to CANDIDATE, lastRpcTime:1098, electionTimeout:1096ms
2019-09-12 10:44:09,441 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown FollowerState
2019-09-12 10:44:09,444 [Thread-94] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:09,447 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: start LeaderElection
2019-09-12 10:44:09,478 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1: begin an election at term 1 for -1: [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:localhost:9872], old=null
2019-09-12 10:44:09,480 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown LeaderElection
2019-09-12 10:44:09,481 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:09,481 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E change Leader from null to 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63 at term 1 for becomeLeader, leader elected after 1245ms
2019-09-12 10:44:09,490 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:09,490 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:09,494 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:09,497 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:09,497 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:09,498 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:09,512 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: start LeaderState
2019-09-12 10:44:09,550 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Starting segment from index:0
2019-09-12 10:44:09,569 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E set configuration 0: [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:localhost:9872], old=null at 0
2019-09-12 10:44:09,735 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2019-09-12 10:44:10,222 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:40472 |  
2019-09-12 10:44:10,223 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-12 10:44:10,224 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:44:10,228 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 10:44:10,230 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71e42f92] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:44:10,238 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:44:10,239 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/containers/hdds to VolumeSet
2019-09-12 10:44:10,239 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26c77f54
2019-09-12 10:44:10,239 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26c77f54
2019-09-12 10:44:10,259 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:44:10,259 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:44:10,259 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:44:10,260 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:44:10,260 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:10,260 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:44:10,260 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:44:10,261 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:10,262 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:44:10,263 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:44:10,266 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:44:10,267 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:44:10,270 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:44:10,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:44:10,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:44:10,271 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:44:10,272 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40311
2019-09-12 10:44:10,273 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:44:10,277 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4be490da{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:44:10,278 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@353e6389{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:44:10,317 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73f6e07{/,file:///tmp/jetty-0.0.0.0-40311-hddsDatanode-_-any-3640344131312855571.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:44:10,318 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c9d90fc{HTTP/1.1,[http/1.1]}{0.0.0.0:40311}
2019-09-12 10:44:10,319 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7429ms
2019-09-12 10:44:10,320 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:40311
Sep 12, 2019 10:44:10 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:44:10,346 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/meta/datanode.id
2019-09-12 10:44:10,496 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:44998 |  
2019-09-12 10:44:10,496 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@747f6c5a
2019-09-12 10:44:10,497 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-12 10:44:10,500 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d091bc9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:44:10,501 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-58hkm-1881083799 ip:192.168.36.114
2019-09-12 10:44:10,507 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/meta/datanode.id
2019-09-12 10:44:10,511 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-12 10:44:10,512 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/containers/hdds to VolumeSet
2019-09-12 10:44:10,512 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5939e24
2019-09-12 10:44:10,512 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5939e24
2019-09-12 10:44:10,532 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-12 10:44:10,532 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-12 10:44:10,532 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-12 10:44:10,532 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-12 10:44:10,533 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:10,533 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-12 10:44:10,533 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-12 10:44:10,534 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:10,535 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-12 10:44:10,536 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-12 10:44:10,537 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-12 10:44:10,537 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-12 10:44:10,539 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-12 10:44:10,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-12 10:44:10,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-12 10:44:10,540 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-12 10:44:10,541 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38520
2019-09-12 10:44:10,541 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-12 10:44:10,543 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63d677f5{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-12 10:44:10,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2997ddfc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-12 10:44:10,574 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@743c3520{/,file:///tmp/jetty-0.0.0.0-38520-hddsDatanode-_-any-2706104264709929742.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-12 10:44:10,574 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6842c101{HTTP/1.1,[http/1.1]}{0.0.0.0:38520}
2019-09-12 10:44:10,575 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7685ms
2019-09-12 10:44:10,575 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38520
Sep 12, 2019 10:44:10 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-12 10:44:10,715 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:39190 |  
2019-09-12 10:44:10,715 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3be3e76c
2019-09-12 10:44:10,717 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:44:10,718 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d779e7e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-12 10:44:10,720 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/meta/datanode.id
2019-09-12 10:44:11,717 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:44:12,264 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:44:12,296 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:44:12,298 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:44:12,298 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 364f652f-ef6f-448e-9b53-5fc05d785e98 at port 0
2019-09-12 10:44:12,308 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start RPC server
2019-09-12 10:44:12,314 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: GrpcService started, listening on 0.0.0.0/0.0.0.0:45119
2019-09-12 10:44:12,314 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 364f652f-ef6f-448e-9b53-5fc05d785e98 is started using port 45119
2019-09-12 10:44:12,317 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 364f652f-ef6f-448e-9b53-5fc05d785e98 is started using port 44454
2019-09-12 10:44:12,502 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:44:12,517 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:44:12,519 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:44:12,520 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 25a00999-72ce-4fe5-a995-b18dc52f570d at port 0
2019-09-12 10:44:12,531 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start RPC server
2019-09-12 10:44:12,534 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: GrpcService started, listening on 0.0.0.0/0.0.0.0:35072
2019-09-12 10:44:12,535 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 25a00999-72ce-4fe5-a995-b18dc52f570d is started using port 35072
2019-09-12 10:44:12,537 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 25a00999-72ce-4fe5-a995-b18dc52f570d is started using port 42799
2019-09-12 10:44:12,718 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:44:12,723 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-12 10:44:12,749 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-12 10:44:12,751 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-12 10:44:12,751 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at port 0
2019-09-12 10:44:12,822 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start RPC server
2019-09-12 10:44:12,825 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: GrpcService started, listening on 0.0.0.0/0.0.0.0:34849
2019-09-12 10:44:12,826 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 is started using port 34849
2019-09-12 10:44:12,829 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 is started using port 41370
2019-09-12 10:44:13,719 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-12 10:44:14,274 [IPC Server handler 4 on 43971] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:14,275 [IPC Server handler 4 on 43971] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:44:14,280 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-12 10:44:14,280 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-12 10:44:14,281 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-12 10:44:14,287 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:44:14,724 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 3 DN Heartbeats.
2019-09-12 10:44:14,731 [IPC Server handler 10 on 43971] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:14,731 [IPC Server handler 1 on 43971] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:14,733 [IPC Server handler 10 on 43971] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:44:14,736 [IPC Server handler 1 on 43971] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}
2019-09-12 10:44:14,737 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:44:14,737 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=REGISTER {datanodeDetails=8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-12 10:44:15,088 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-D221872E0F1A:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-D221872E0F1A:java.util.concurrent.CompletableFuture@315d8ab6[Not completed]
2019-09-12 10:44:15,094 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-D221872E0F1A:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,095 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,096 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:15,096 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a does not exist. Creating ...
2019-09-12 10:44:15,121 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,134 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a has been successfully formatted.
2019-09-12 10:44:15,136 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D221872E0F1A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,137 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,137 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,137 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,137 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,137 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,138 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,138 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a
2019-09-12 10:44:15,138 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,138 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,139 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,140 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,140 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,140 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,141 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,141 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,141 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-D221872E0F1A
2019-09-12 10:44:15,141 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,141 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:15,142 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D221872E0F1A,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:15,190 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bdd0a805-d738-4d5d-9c75-d221872e0f1a, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,210 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-DC8781F1BE95:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-DC8781F1BE95:java.util.concurrent.CompletableFuture@288f5bcd[Not completed]
2019-09-12 10:44:15,241 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-DC8781F1BE95:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,242 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,243 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,244 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95 does not exist. Creating ...
2019-09-12 10:44:15,256 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,269 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95 has been successfully formatted.
2019-09-12 10:44:15,269 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DC8781F1BE95: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,271 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,271 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,271 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,272 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,272 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,272 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,272 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95
2019-09-12 10:44:15,272 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,273 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,273 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,273 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,273 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,274 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,274 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,274 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,274 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,275 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,275 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,276 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,276 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,276 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,276 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-DC8781F1BE95
2019-09-12 10:44:15,277 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,277 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,277 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC8781F1BE95,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,290 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0edccb19-c6d4-4022-8d9f-dc8781f1be95, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,310 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-D5A0C6A0C92A:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-D5A0C6A0C92A:java.util.concurrent.CompletableFuture@6f562789[Not completed]
2019-09-12 10:44:15,312 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-D5A0C6A0C92A:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,314 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,314 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,314 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a does not exist. Creating ...
2019-09-12 10:44:15,327 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,331 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a has been successfully formatted.
2019-09-12 10:44:15,331 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D5A0C6A0C92A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,331 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,332 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,332 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,332 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,332 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,332 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,333 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,334 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,334 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,334 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,334 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,334 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,335 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,335 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,335 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,336 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,336 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-D5A0C6A0C92A
2019-09-12 10:44:15,336 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,336 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,337 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5A0C6A0C92A,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,363 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-5A02E043B186:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-5A02E043B186:java.util.concurrent.CompletableFuture@2095ccb3[Not completed]
2019-09-12 10:44:15,372 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-5A02E043B186:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,372 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,373 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:15,374 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186 does not exist. Creating ...
2019-09-12 10:44:15,386 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,405 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186 has been successfully formatted.
2019-09-12 10:44:15,406 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5A02E043B186: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,406 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,406 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,407 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,407 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,407 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,407 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,407 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,408 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,409 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,409 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,409 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,409 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,410 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,410 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,410 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,411 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,411 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-5A02E043B186
2019-09-12 10:44:15,411 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,411 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:15,412 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5A02E043B186,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:15,423 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 80c267d5-f3cd-41d0-b18e-5a02e043b186, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,437 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-49B6BB0610D6:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-49B6BB0610D6:java.util.concurrent.CompletableFuture@1cd07cd7[Not completed]
2019-09-12 10:44:15,439 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-49B6BB0610D6:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,440 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,441 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:15,441 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6 does not exist. Creating ...
2019-09-12 10:44:15,454 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,467 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6 has been successfully formatted.
2019-09-12 10:44:15,467 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-49B6BB0610D6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,467 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,467 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,468 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,468 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,468 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,468 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,468 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,469 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,470 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,470 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,470 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,470 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,471 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,471 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,471 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,472 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-49B6BB0610D6
2019-09-12 10:44:15,472 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,472 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:15,472 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-49B6BB0610D6,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:15,484 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 66489fb9-4e62-4794-9107-49b6bb0610d6, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,500 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-A3D78199B64D:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-A3D78199B64D:java.util.concurrent.CompletableFuture@557f8e0d[Not completed]
2019-09-12 10:44:15,501 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-A3D78199B64D:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,501 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,502 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,503 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d does not exist. Creating ...
2019-09-12 10:44:15,532 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,543 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d has been successfully formatted.
2019-09-12 10:44:15,544 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A3D78199B64D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,544 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,544 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,544 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,545 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,546 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,547 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,547 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,547 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,548 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,548 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,548 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,548 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-A3D78199B64D
2019-09-12 10:44:15,548 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,549 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,549 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A3D78199B64D,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,558 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 9851042b-e963-4fcc-a135-a3d78199b64d, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,578 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-D24E31EA21A7:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-D24E31EA21A7:java.util.concurrent.CompletableFuture@2bd8064b[Not completed]
2019-09-12 10:44:15,579 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-D24E31EA21A7:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,580 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,581 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,581 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7 does not exist. Creating ...
2019-09-12 10:44:15,592 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,603 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7 has been successfully formatted.
2019-09-12 10:44:15,604 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D24E31EA21A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,606 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,607 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,607 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,607 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,607 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,608 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-D24E31EA21A7
2019-09-12 10:44:15,608 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,608 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,608 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D24E31EA21A7,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,619 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 35c1c3a7-11fc-4d93-80f8-d24e31ea21a7, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,631 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-ACA02D7F7103:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-ACA02D7F7103:java.util.concurrent.CompletableFuture@50a19910[Not completed]
2019-09-12 10:44:15,633 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-ACA02D7F7103:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,633 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,633 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,633 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,633 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,634 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,634 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,634 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:15,634 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103 does not exist. Creating ...
2019-09-12 10:44:15,646 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,688 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103 has been successfully formatted.
2019-09-12 10:44:15,688 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-ACA02D7F7103: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,688 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,689 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,689 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,689 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,689 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,689 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,690 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,691 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,691 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,691 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,691 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,691 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,692 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,692 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,692 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,693 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,693 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-ACA02D7F7103
2019-09-12 10:44:15,693 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,693 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:15,694 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ACA02D7F7103,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:15,706 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b0720546-750f-4111-baef-aca02d7f7103, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,721 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-37E11E9E741C:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-37E11E9E741C:java.util.concurrent.CompletableFuture@42c75119[Not completed]
2019-09-12 10:44:15,723 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-37E11E9E741C:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,724 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,725 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,725 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-12 10:44:15,725 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:15,726 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c does not exist. Creating ...
2019-09-12 10:44:15,749 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,766 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c has been successfully formatted.
2019-09-12 10:44:15,766 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-37E11E9E741C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,767 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c
2019-09-12 10:44:15,768 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,768 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,768 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,769 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,769 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,769 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,769 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,769 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,770 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,770 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,771 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,771 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,771 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,771 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,772 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-37E11E9E741C
2019-09-12 10:44:15,772 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,772 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:15,773 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-37E11E9E741C,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:15,787 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ec9c4673-de8a-495f-8890-37e11e9e741c, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,798 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-74B5B0006083:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-74B5B0006083:java.util.concurrent.CompletableFuture@18bd45b0[Not completed]
2019-09-12 10:44:15,800 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-74B5B0006083:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,800 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,800 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,800 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,800 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,801 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,801 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,801 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,801 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083 does not exist. Creating ...
2019-09-12 10:44:15,814 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,827 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083 has been successfully formatted.
2019-09-12 10:44:15,827 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-74B5B0006083: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,827 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,827 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,827 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,828 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,828 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,828 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,828 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083
2019-09-12 10:44:15,828 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,829 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,830 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,830 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,830 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,831 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,831 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,831 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-74B5B0006083
2019-09-12 10:44:15,831 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,831 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,832 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-74B5B0006083,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,839 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bb56150b-c101-494c-856d-74b5b0006083, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,850 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-C445A466EBC6:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-C445A466EBC6:java.util.concurrent.CompletableFuture@69d399[Not completed]
2019-09-12 10:44:15,851 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-C445A466EBC6:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,851 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:15,852 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6 does not exist. Creating ...
2019-09-12 10:44:15,865 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,878 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6 has been successfully formatted.
2019-09-12 10:44:15,879 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C445A466EBC6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,879 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,879 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,879 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,879 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,880 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,880 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,880 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6
2019-09-12 10:44:15,880 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,880 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,881 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,882 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,882 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,882 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,883 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,883 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,883 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,883 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-C445A466EBC6
2019-09-12 10:44:15,883 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,884 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:15,884 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C445A466EBC6,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:15,892 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bdca2718-fb76-4226-b53d-c445a466ebc6, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,904 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: addNew group-ECAF23504DB6:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] returns group-ECAF23504DB6:java.util.concurrent.CompletableFuture@7d3cc63b[Not completed]
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: new RaftServerImpl for group-ECAF23504DB6:[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 ConfigurationManager, init=-1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,906 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis] (custom)
2019-09-12 10:44:15,907 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6 does not exist. Creating ...
2019-09-12 10:44:15,933 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:15,947 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6 has been successfully formatted.
2019-09-12 10:44:15,947 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-ECAF23504DB6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:15,947 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:15,948 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6
2019-09-12 10:44:15,949 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:15,949 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:15,949 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:15,949 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:15,949 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:15,950 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:15,950 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:15,950 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:15,950 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:15,950 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:15,951 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:15,951 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:15,951 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:15,951 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:15,952 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start group-ECAF23504DB6
2019-09-12 10:44:15,952 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:15,952 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start FollowerState
2019-09-12 10:44:15,953 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ECAF23504DB6,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:15,961 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 548ae151-a0b6-464f-bf17-ecaf23504db6, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:15,963 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:15,975 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-7EA02E577151:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-7EA02E577151:java.util.concurrent.CompletableFuture@3b01ada1[Not completed]
2019-09-12 10:44:15,976 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-7EA02E577151:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:15,977 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:15,978 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151 does not exist. Creating ...
2019-09-12 10:44:15,992 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,004 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151 has been successfully formatted.
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7EA02E577151: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,005 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,006 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,007 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,007 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,007 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,007 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,007 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-7EA02E577151
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,008 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:16,009 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7EA02E577151,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:16,016 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 19d901b2-fa62-4606-bfe1-7ea02e577151, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,018 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,028 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-17F9D13D9533:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-17F9D13D9533:java.util.concurrent.CompletableFuture@5ba750ed[Not completed]
2019-09-12 10:44:16,031 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-17F9D13D9533:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:16,031 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:16,031 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:16,031 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:16,032 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:16,032 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:16,032 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:16,032 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:16,033 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533 does not exist. Creating ...
2019-09-12 10:44:16,045 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,049 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:getStorageContainerLocationClient(241)) - Creating StorageContainerLocationProtocol RPC client with address /0.0.0.0:43713
2019-09-12 10:44:16,058 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533 has been successfully formatted.
2019-09-12 10:44:16,059 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-17F9D13D9533: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,059 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,060 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533
2019-09-12 10:44:16,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,060 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,061 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,062 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,062 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,062 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,063 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,063 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,063 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,063 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-17F9D13D9533
2019-09-12 10:44:16,064 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,064 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:16,064 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-17F9D13D9533,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:16,082 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c12f5bcd-1b43-4936-85ae-17f9d13d9533, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,083 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,089 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c2a808f7-e04e-478b-b11a-2a851bb0436d, with jenkins1000 as owner.
2019-09-12 10:44:16,098 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-C2DE7A059854:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-C2DE7A059854:java.util.concurrent.CompletableFuture@4a0c36ee[Not completed]
2019-09-12 10:44:16,101 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-C2DE7A059854:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:16,101 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:16,102 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:16,103 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854 does not exist. Creating ...
2019-09-12 10:44:16,115 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,128 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854 has been successfully formatted.
2019-09-12 10:44:16,129 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C2DE7A059854: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,129 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,129 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,129 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,129 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,130 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,130 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,130 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854
2019-09-12 10:44:16,130 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,130 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,131 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,131 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,131 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,131 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,131 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,132 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,132 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,132 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,132 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,133 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,133 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,133 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,134 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-C2DE7A059854
2019-09-12 10:44:16,134 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,134 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:16,135 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2DE7A059854,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:16,140 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a50e3c16-bd20-4e78-9704-c2de7a059854, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,142 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,153 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: addNew group-D94854D67773:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] returns group-D94854D67773:java.util.concurrent.CompletableFuture@16622d1[Not completed]
2019-09-12 10:44:16,155 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: new RaftServerImpl for group-D94854D67773:[364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119] with ContainerStateMachine:uninitialized
2019-09-12 10:44:16,155 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:16,155 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:16,155 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:16,155 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:16,156 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:16,156 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 ConfigurationManager, init=-1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:16,156 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis] (custom)
2019-09-12 10:44:16,156 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773 does not exist. Creating ...
2019-09-12 10:44:16,170 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,185 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c2a808f7-e04e-478b-b11a-2a851bb0436d, creationTime=1568285056142, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773 has been successfully formatted.
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D94854D67773: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,190 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,191 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,192 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773
2019-09-12 10:44:16,193 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,193 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,194 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,195 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start group-D94854D67773
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,197 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start FollowerState
2019-09-12 10:44:16,202 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D94854D67773,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:16,202 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c2a808f7-e04e-478b-b11a-2a851bb0436d} | ret=SUCCESS |  
2019-09-12 10:44:16,206 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ac34390b-6158-449b-8b4f-d94854d67773, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,207 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,207 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,216 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c2a808f7-e04e-478b-b11a-2a851bb0436d/0da1041f-477a-4eb5-a728-d4de196e6375, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:16,220 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-12F00208A22D:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-12F00208A22D:java.util.concurrent.CompletableFuture@6888346e[Not completed]
2019-09-12 10:44:16,221 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-12F00208A22D:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:16,222 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:16,223 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:16,223 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d does not exist. Creating ...
2019-09-12 10:44:16,237 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c2a808f7-e04e-478b-b11a-2a851bb0436d, bucket=0da1041f-477a-4eb5-a728-d4de196e6375, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285056231} | ret=SUCCESS |  
2019-09-12 10:44:16,248 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,250 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c2a808f7-e04e-478b-b11a-2a851bb0436d, bucket=0da1041f-477a-4eb5-a728-d4de196e6375} | ret=SUCCESS |  
2019-09-12 10:44:16,258 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d has been successfully formatted.
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-12F00208A22D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,259 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,260 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,261 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,261 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,261 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,261 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,261 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,262 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,262 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,262 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,262 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,263 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-12F00208A22D
2019-09-12 10:44:16,263 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,263 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:16,264 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12F00208A22D,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:16,269 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1389de10-6395-4041-b6ad-12f00208a22d, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,271 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,271 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,280 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: addNew group-423FAB19B7B8:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] returns group-423FAB19B7B8:java.util.concurrent.CompletableFuture@44f3b8d7[Not completed]
2019-09-12 10:44:16,282 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: new RaftServerImpl for group-423FAB19B7B8:[25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072] with ContainerStateMachine:uninitialized
2019-09-12 10:44:16,282 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 ConfigurationManager, init=-1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null, confs=<EMPTY_MAP>
2019-09-12 10:44:16,283 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis] (custom)
2019-09-12 10:44:16,284 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8 does not exist. Creating ...
2019-09-12 10:44:16,297 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8/in_use.lock acquired by nodename 28295@pr-hdds-1569-58hkm-1881083799
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8 has been successfully formatted.
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-423FAB19B7B8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-12 10:44:16,310 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-12 10:44:16,311 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8: flushIndex: setUnconditionally 0 -> -1
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-12 10:44:16,312 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-12 10:44:16,313 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-12 10:44:16,313 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start group-423FAB19B7B8
2019-09-12 10:44:16,313 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-12 10:44:16,313 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start FollowerState
2019-09-12 10:44:16,313 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-423FAB19B7B8,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:16,317 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2874368b-e696-4f38-9193-423fab19b7b8, Nodes: 25a00999-72ce-4fe5-a995-b18dc52f570d{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,322 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,322 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,323 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,323 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,324 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,325 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,325 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,325 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,325 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,325 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,327 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,327 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,327 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,327 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,328 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,328 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,328 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,328 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,329 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,329 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,329 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,330 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,330 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,331 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,331 [IPC Server handler 1 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,331 [IPC Server handler 1 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,332 [IPC Server handler 1 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,332 [IPC Server handler 1 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,338 [IPC Server handler 16 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38955, call Call#14 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,343 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:16,347 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,347 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,347 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,348 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,348 [IPC Server handler 0 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,348 [IPC Server handler 0 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,349 [IPC Server handler 0 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,349 [IPC Server handler 0 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,350 [IPC Server handler 14 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38955, call Call#14 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,353 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,357 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,357 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,357 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,358 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,358 [IPC Server handler 9 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,358 [IPC Server handler 9 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,358 [IPC Server handler 9 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,359 [IPC Server handler 9 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,359 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,360 [IPC Server handler 10 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38955, call Call#14 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,363 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,372 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,373 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,373 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,373 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,373 [IPC Server handler 16 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,373 [IPC Server handler 16 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,374 [IPC Server handler 16 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,374 [IPC Server handler 16 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,374 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,375 [IPC Server handler 12 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38955, call Call#14 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,378 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,381 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,382 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,382 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,382 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,382 [IPC Server handler 12 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,383 [IPC Server handler 12 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,383 [IPC Server handler 12 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,383 [IPC Server handler 12 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,383 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,384 [IPC Server handler 11 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38955, call Call#14 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,386 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,390 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,390 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,391 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,391 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,391 [IPC Server handler 19 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,391 [IPC Server handler 19 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,392 [IPC Server handler 19 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,392 [IPC Server handler 19 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,392 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,393 [IPC Server handler 9 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38955, call Call#14 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,397 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,400 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,401 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,401 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,401 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,401 [IPC Server handler 2 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,401 [IPC Server handler 2 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,402 [IPC Server handler 2 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,402 [IPC Server handler 2 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,403 [IPC Server handler 8 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38955, call Call#14 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,406 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,410 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,410 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,410 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,410 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,410 [IPC Server handler 5 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,411 [IPC Server handler 5 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,411 [IPC Server handler 5 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,411 [IPC Server handler 5 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,412 [IPC Server handler 7 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38955, call Call#14 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,415 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,418 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,418 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,418 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,419 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,419 [IPC Server handler 14 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,419 [IPC Server handler 14 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,420 [IPC Server handler 14 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,420 [IPC Server handler 14 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,420 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,421 [IPC Server handler 6 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38955, call Call#14 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,423 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,427 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,427 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,427 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,427 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,427 [IPC Server handler 6 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,428 [IPC Server handler 6 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,428 [IPC Server handler 6 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,428 [IPC Server handler 6 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,428 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,429 [IPC Server handler 5 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38955, call Call#14 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,432 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,435 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,435 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,436 [IPC Server handler 3 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,437 [IPC Server handler 4 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38955, call Call#14 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,439 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:16,456 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, with jenkins1000 as owner.
2019-09-12 10:44:16,466 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, creationTime=1568285056458, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:16,469 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd} | ret=SUCCESS |  
2019-09-12 10:44:16,470 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd/fc9c6034-561f-42f1-9581-6ac8645e36a0, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:16,479 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, bucket=fc9c6034-561f-42f1-9581-6ac8645e36a0, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285056472} | ret=SUCCESS |  
2019-09-12 10:44:16,481 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, bucket=fc9c6034-561f-42f1-9581-6ac8645e36a0} | ret=SUCCESS |  
2019-09-12 10:44:16,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, bucket=fc9c6034-561f-42f1-9581-6ac8645e36a0, key=78b8e990-9a12-48b5-b4a9-17a0485a10a8, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,536 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=c0a19c69-5b21-4fe6-a278-2bae6b8e3bcd, bucket=fc9c6034-561f-42f1-9581-6ac8645e36a0, key=78b8e990-9a12-48b5-b4a9-17a0485a10a8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,549 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,550 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,550 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,550 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,551 [IPC Server handler 7 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,551 [IPC Server handler 7 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,551 [IPC Server handler 7 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,552 [IPC Server handler 7 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,553 [IPC Server handler 15 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 38955, call Call#32 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,554 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:16,556 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,557 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,557 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,557 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,557 [IPC Server handler 13 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,557 [IPC Server handler 13 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,558 [IPC Server handler 13 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,558 [IPC Server handler 13 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,558 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,559 [IPC Server handler 17 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 38955, call Call#32 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,561 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,563 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,564 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,564 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,564 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,564 [IPC Server handler 15 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,564 [IPC Server handler 15 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,565 [IPC Server handler 15 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,565 [IPC Server handler 15 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,565 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,566 [IPC Server handler 13 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 38955, call Call#32 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,569 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,570 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,571 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,571 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,571 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,571 [IPC Server handler 8 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,571 [IPC Server handler 8 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,572 [IPC Server handler 8 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,572 [IPC Server handler 8 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,573 [IPC Server handler 16 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38955, call Call#32 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,575 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,578 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,578 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,579 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,579 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,579 [IPC Server handler 4 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,579 [IPC Server handler 4 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,580 [IPC Server handler 4 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,580 [IPC Server handler 4 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,580 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,581 [IPC Server handler 14 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38955, call Call#32 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,584 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,585 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,586 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,586 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,586 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,586 [IPC Server handler 17 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,586 [IPC Server handler 17 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,587 [IPC Server handler 17 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,587 [IPC Server handler 17 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,587 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,588 [IPC Server handler 10 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38955, call Call#32 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,591 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,593 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,593 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,594 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,594 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,594 [IPC Server handler 11 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,594 [IPC Server handler 11 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,595 [IPC Server handler 11 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,595 [IPC Server handler 11 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,595 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,596 [IPC Server handler 12 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38955, call Call#32 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,599 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,600 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,601 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,601 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,601 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,601 [IPC Server handler 10 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,601 [IPC Server handler 10 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,602 [IPC Server handler 10 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,602 [IPC Server handler 10 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,603 [IPC Server handler 11 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38955, call Call#32 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,609 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,611 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,611 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,611 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,611 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,612 [IPC Server handler 18 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,612 [IPC Server handler 18 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,615 [IPC Server handler 18 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,615 [IPC Server handler 18 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,615 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,616 [IPC Server handler 9 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38955, call Call#32 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,620 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,622 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,622 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,622 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,622 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,622 [IPC Server handler 1 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,623 [IPC Server handler 1 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,623 [IPC Server handler 1 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,623 [IPC Server handler 1 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,623 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,624 [IPC Server handler 8 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38955, call Call#32 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,629 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:16,630 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,631 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,631 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:16,631 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,631 [IPC Server handler 0 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:16,632 [IPC Server handler 0 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,632 [IPC Server handler 0 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:16,632 [IPC Server handler 0 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:16,632 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:16,633 [IPC Server handler 7 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38955, call Call#32 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:16,635 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:16,635 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUpload(TestOzoneRpcClientAbstract.java:1833)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:44:16,637 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 35b88310-552f-4986-a852-b4a10e53fee6, with jenkins1000 as owner.
2019-09-12 10:44:16,652 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=35b88310-552f-4986-a852-b4a10e53fee6, creationTime=1568285056639, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:16,654 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=35b88310-552f-4986-a852-b4a10e53fee6} | ret=SUCCESS |  
2019-09-12 10:44:16,655 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 35b88310-552f-4986-a852-b4a10e53fee6/16f97bee-c8aa-478b-bb7d-d68e12c2adc4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:16,665 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=35b88310-552f-4986-a852-b4a10e53fee6, bucket=16f97bee-c8aa-478b-bb7d-d68e12c2adc4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285056656} | ret=SUCCESS |  
2019-09-12 10:44:16,667 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=35b88310-552f-4986-a852-b4a10e53fee6, bucket=16f97bee-c8aa-478b-bb7d-d68e12c2adc4} | ret=SUCCESS |  
2019-09-12 10:44:16,677 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=35b88310-552f-4986-a852-b4a10e53fee6, bucket=16f97bee-c8aa-478b-bb7d-d68e12c2adc4, key=7252caba-8803-47ec-845e-06e732e1c02f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,690 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=35b88310-552f-4986-a852-b4a10e53fee6, bucket=16f97bee-c8aa-478b-bb7d-d68e12c2adc4, key=7252caba-8803-47ec-845e-06e732e1c02f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,691 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 25f5b709-a771-497d-9410-615b853ebc92, with jenkins1000 as owner.
2019-09-12 10:44:16,700 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=25f5b709-a771-497d-9410-615b853ebc92, creationTime=1568285056693, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:16,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=25f5b709-a771-497d-9410-615b853ebc92} | ret=SUCCESS |  
2019-09-12 10:44:16,703 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 25f5b709-a771-497d-9410-615b853ebc92/72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:16,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285056705} | ret=SUCCESS |  
2019-09-12 10:44:16,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4} | ret=SUCCESS |  
2019-09-12 10:44:16,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:16,727 [IPC Server handler 9 on 45226] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
2019-09-12 10:44:16,745 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:16,792 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129478709252
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:16,829 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-09-12 10:44:17,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,102 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129478709252 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,236 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129478709252 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:17,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129478709252
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,282 [Thread-182] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-12 10:44:17,285 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2019-09-12 10:44:17,289 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:17,307 [IPC Server handler 16 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:17,308 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:17,310 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:17,330 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | INVALID_KEY_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Key name is empty
	at org.apache.hadoop.ozone.om.request.key.OMKeyRenameRequest.validateAndUpdateCache(OMKeyRenameRequest.java:117)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:17,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRenameRequest (OMKeyRenameRequest.java:validateAndUpdateCache(194)) - Rename key failed for volume:25f5b709-a771-497d-9410-615b853ebc92 bucket:72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4 fromKey:42d22cfd-0760-4926-b1e7-b53211b17cf6 toKey:. Key: 42d22cfd-0760-4926-b1e7-b53211b17cf6 not found.
2019-09-12 10:44:17,342 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,344 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=42d22cfd-0760-4926-b1e7-b53211b17cf6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-12 10:44:17,347 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:17,349 [IPC Server handler 12 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:17,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:17,350 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=25f5b709-a771-497d-9410-615b853ebc92, bucket=72be8d5d-4eb3-4f94-a96a-aa7fb3789eb4, key=f6a9fbda-793b-49e6-bb9a-b77b94795f9a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:17,352 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 60495828-2156-4b7f-a6cd-456c4ef93c0b, with jenkins1000 as owner.
2019-09-12 10:44:17,366 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=60495828-2156-4b7f-a6cd-456c4ef93c0b, creationTime=1568285057353, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:17,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=60495828-2156-4b7f-a6cd-456c4ef93c0b} | ret=SUCCESS |  
2019-09-12 10:44:17,369 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 60495828-2156-4b7f-a6cd-456c4ef93c0b/0ace3fc8-d299-4ad6-8019-ac74255dc3e3, with Versioning true and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:17,378 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=60495828-2156-4b7f-a6cd-456c4ef93c0b, bucket=0ace3fc8-d299-4ad6-8019-ac74255dc3e3, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=true, storageType=DISK, creationTime=1568285057370} | ret=SUCCESS |  
2019-09-12 10:44:17,380 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=60495828-2156-4b7f-a6cd-456c4ef93c0b, bucket=0ace3fc8-d299-4ad6-8019-ac74255dc3e3} | ret=SUCCESS |  
2019-09-12 10:44:17,403 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {jenkins1000=username, ce98b970-2900-4e93-bf44-862ee2a77bb4=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:44:17,411 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3jenkins1000} | ret=SUCCESS |  
2019-09-12 10:44:17,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3jenkins1000, bucket=ce98b970-2900-4e93-bf44-862ee2a77bb4} | ret=SUCCESS |  
2019-09-12 10:44:17,414 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f71b44d7-6352-466d-bc91-0ba8f136eca6, with jenkins1000 as owner.
2019-09-12 10:44:17,428 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, creationTime=1568285057415, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:17,430 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6} | ret=SUCCESS |  
2019-09-12 10:44:17,431 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: f71b44d7-6352-466d-bc91-0ba8f136eca6/094be10b-1ba3-4923-a907-6172591b2cda, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:17,439 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285057432} | ret=SUCCESS |  
2019-09-12 10:44:17,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda} | ret=SUCCESS |  
2019-09-12 10:44:17,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,466 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,474 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:17,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129524846599} | ret=SUCCESS |  
2019-09-12 10:44:17,487 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129526550536 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,492 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129526550536 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:17,523 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129526550536
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,538 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=19, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,541 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:17,549 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=19, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129529958409} | ret=SUCCESS |  
2019-09-12 10:44:17,555 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129531006986 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,560 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129531006986 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:17,578 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=f71b44d7-6352-466d-bc91-0ba8f136eca6, bucket=094be10b-1ba3-4923-a907-6172591b2cda, key=c7354270-7509-4e1e-9c6a-2a31ed1816ad, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129531006986
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,579 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ed9f3ad5-3719-407a-904a-6f2e5940cd87, with jenkins1000 as owner.
2019-09-12 10:44:17,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, creationTime=1568285057581, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:17,589 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87} | ret=SUCCESS |  
2019-09-12 10:44:17,590 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ed9f3ad5-3719-407a-904a-6f2e5940cd87/b0c88712-2264-4928-8f6f-b009dd0dff36, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:17,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285057591} | ret=SUCCESS |  
2019-09-12 10:44:17,604 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36} | ret=SUCCESS |  
2019-09-12 10:44:17,607 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:17,621 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129535266827
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,634 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129535266827 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,638 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129535266827 bcsId: 0,size=2354]} | ret=SUCCESS |  
2019-09-12 10:44:17,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=2354, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129535266827
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2354
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,659 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:17,665 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2c86e9714-2308-498b-844e-d7cf0aaddb8f, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129538674701
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,671 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129538674701 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,676 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129538674701 bcsId: 0,size=2385]} | ret=SUCCESS |  
2019-09-12 10:44:17,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2c86e9714-2308-498b-844e-d7cf0aaddb8f, dataSize=2385, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129538674701
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2385
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,744 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,750 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,774 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,778 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,809 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,818 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,820 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,839 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,885 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:17,888 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:17,902 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129553747983
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,909 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129553747983 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:17,913 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129553747983 bcsId: 0,size=2344]} | ret=SUCCESS |  
2019-09-12 10:44:17,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=2344, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129553747983
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2344
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:17,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=null} | ret=SUCCESS |  
2019-09-12 10:44:17,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:17,968 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/} | ret=SUCCESS |  
2019-09-12 10:44:17,983 [IPC Server handler 13 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-0_96 to index:96
2019-09-12 10:44:17,991 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_0-96
2019-09-12 10:44:18,032 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97
2019-09-12 10:44:18,065 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:18,085 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:18,088 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:18,099 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129566789649
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:18,108 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129566789649 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:18,116 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129566789649 bcsId: 0,size=2409]} | ret=SUCCESS |  
2019-09-12 10:44:18,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd, dataSize=2409, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129566789649
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2409
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:18,137 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/} | ret=SUCCESS |  
2019-09-12 10:44:18,139 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=ed9f3ad5-3719-407a-904a-6f2e5940cd87, bucket=b0c88712-2264-4928-8f6f-b009dd0dff36, key=dir1/dir2af212e65-7501-4893-96a5-67559d40d6bd} | ret=SUCCESS |  
2019-09-12 10:44:18,141 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e1ea9289-5546-415f-8df2-f13ea72fe541, with jenkins1000 as owner.
2019-09-12 10:44:18,145 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e1ea9289-5546-415f-8df2-f13ea72fe541, creationTime=1568285058142, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:18,147 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e1ea9289-5546-415f-8df2-f13ea72fe541} | ret=SUCCESS |  
2019-09-12 10:44:18,147 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e1ea9289-5546-415f-8df2-f13ea72fe541/8aa46495-a634-4d1a-ae27-d6a1af5c8ef4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:18,160 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e1ea9289-5546-415f-8df2-f13ea72fe541, bucket=8aa46495-a634-4d1a-ae27-d6a1af5c8ef4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285058148} | ret=SUCCESS |  
2019-09-12 10:44:18,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e1ea9289-5546-415f-8df2-f13ea72fe541, bucket=8aa46495-a634-4d1a-ae27-d6a1af5c8ef4} | ret=SUCCESS |  
2019-09-12 10:44:18,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e1ea9289-5546-415f-8df2-f13ea72fe541, bucket=8aa46495-a634-4d1a-ae27-d6a1af5c8ef4} | ret=SUCCESS |  
2019-09-12 10:44:18,177 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=e1ea9289-5546-415f-8df2-f13ea72fe541, bucket=8aa46495-a634-4d1a-ae27-d6a1af5c8ef4, key=null} | ret=SUCCESS |  
2019-09-12 10:44:18,178 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, with jenkins1000 as owner.
2019-09-12 10:44:18,191 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, creationTime=1568285058179, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:18,193 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9} | ret=SUCCESS |  
2019-09-12 10:44:18,193 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 93d50e1a-518c-4f47-9cb4-26fe4d1d00f9/c1bd95db-d04f-4780-8205-33c2e57486d6, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:18,211 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285058194} | ret=SUCCESS |  
2019-09-12 10:44:18,213 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6} | ret=SUCCESS |  
2019-09-12 10:44:18,215 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:18,230 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6, key=b77fd7a8-b6b1-42c1-80a4-b48653d86c89, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779129575178259
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:18,276 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 is not the leader (null). Request must be sent to leader., logIndex=0, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c-1]
2019-09-12 10:44:18,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:18,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:19,066 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:19,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:19,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:20,066 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:20,183 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A changes to CANDIDATE, lastRpcTime:5041, electionTimeout:5041ms
2019-09-12 10:44:20,185 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:20,185 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,185 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:20,201 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:20,202 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:20,202 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,202 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5065ms
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,203 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,204 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:20,204 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a: Starting segment from index:0
2019-09-12 10:44:20,205 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:20,263 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a/current/log_inprogress_0
2019-09-12 10:44:20,304 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 is not the leader (null). Request must be sent to leader., logIndex=0, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c-1]
2019-09-12 10:44:20,355 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 changes to CANDIDATE, lastRpcTime:5078, electionTimeout:5078ms
2019-09-12 10:44:20,356 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:20,356 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,356 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5101ms
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,372 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,373 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,373 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,373 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,373 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,373 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:20,374 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95: Starting segment from index:0
2019-09-12 10:44:20,374 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:20,426 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95/current/log_inprogress_0
2019-09-12 10:44:20,501 [Thread-190] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A changes to CANDIDATE, lastRpcTime:5164, electionTimeout:5164ms
2019-09-12 10:44:20,501 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:20,501 [Thread-190] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,501 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:20,517 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:20,517 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:20,517 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,517 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5185ms
2019-09-12 10:44:20,518 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,518 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,518 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,518 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,518 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,519 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,519 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:20,519 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a: Starting segment from index:0
2019-09-12 10:44:20,520 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:20,555 [Thread-196] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 changes to CANDIDATE, lastRpcTime:5083, electionTimeout:5081ms
2019-09-12 10:44:20,555 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:20,555 [Thread-196] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,556 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:20,568 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a/current/log_inprogress_0
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5101ms
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,569 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,570 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,570 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,570 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,570 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,570 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:20,571 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6: Starting segment from index:0
2019-09-12 10:44:20,571 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:20,595 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D changes to CANDIDATE, lastRpcTime:5046, electionTimeout:5040ms
2019-09-12 10:44:20,595 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:20,596 [Thread-199] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,596 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:20,610 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6/current/log_inprogress_0
2019-09-12 10:44:20,610 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:20,610 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:20,610 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,610 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5066ms
2019-09-12 10:44:20,611 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,611 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,611 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,611 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,611 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,612 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,612 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 changes to CANDIDATE, lastRpcTime:5200, electionTimeout:5200ms
2019-09-12 10:44:20,612 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:20,612 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:20,612 [Thread-193] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,612 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d: Starting segment from index:0
2019-09-12 10:44:20,612 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:20,613 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:20,662 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d/current/log_inprogress_0
2019-09-12 10:44:20,662 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:20,663 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:20,663 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,663 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5256ms
2019-09-12 10:44:20,663 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,663 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,664 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,664 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,664 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,664 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,664 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:20,665 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186: Starting segment from index:0
2019-09-12 10:44:20,665 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:20,703 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 changes to CANDIDATE, lastRpcTime:5095, electionTimeout:5068ms
2019-09-12 10:44:20,704 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:20,704 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,704 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:20,716 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186/current/log_inprogress_0
2019-09-12 10:44:20,716 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:20,717 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:20,717 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,717 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5113ms
2019-09-12 10:44:20,717 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,717 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,718 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,718 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,718 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,718 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,718 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:20,719 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7: Starting segment from index:0
2019-09-12 10:44:20,719 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:20,759 [Thread-205] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 changes to CANDIDATE, lastRpcTime:5065, electionTimeout:5048ms
2019-09-12 10:44:20,759 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:20,759 [Thread-205] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,759 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:20,764 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:20,764 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:20,773 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7/current/log_inprogress_0
2019-09-12 10:44:20,773 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:20,774 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:20,774 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,774 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5085ms
2019-09-12 10:44:20,774 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,775 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,775 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,775 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,776 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,776 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,776 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:20,777 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103: Starting segment from index:0
2019-09-12 10:44:20,778 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:20,829 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103/current/log_inprogress_0
2019-09-12 10:44:20,838 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C changes to CANDIDATE, lastRpcTime:5065, electionTimeout:5064ms
2019-09-12 10:44:20,839 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:20,839 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,839 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:20,857 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:20,857 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:20,858 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,858 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5091ms
2019-09-12 10:44:20,858 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,858 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,858 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,859 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,859 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,859 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 changes to CANDIDATE, lastRpcTime:5027, electionTimeout:5027ms
2019-09-12 10:44:20,859 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,859 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:20,859 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:20,859 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:20,860 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c: Starting segment from index:0
2019-09-12 10:44:20,860 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:20,897 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:20,909 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c/current/log_inprogress_0
2019-09-12 10:44:20,909 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:20,909 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:20,910 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:20,910 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5082ms
2019-09-12 10:44:20,910 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:20,910 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:20,910 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:20,911 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:20,911 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:20,911 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:20,911 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:20,912 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083: Starting segment from index:0
2019-09-12 10:44:20,912 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:20,964 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083/current/log_inprogress_0
2019-09-12 10:44:21,044 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5035ms
2019-09-12 10:44:21,044 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:21,045 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,045 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:21,048 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 changes to CANDIDATE, lastRpcTime:5163, electionTimeout:5162ms
2019-09-12 10:44:21,049 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:21,050 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,050 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:21,065 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:21,065 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:21,065 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:21,065 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5187ms
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5061ms
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,066 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,067 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6: Starting segment from index:0
2019-09-12 10:44:21,068 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151: Starting segment from index:0
2019-09-12 10:44:21,069 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:21,069 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:21,147 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 changes to CANDIDATE, lastRpcTime:5195, electionTimeout:5178ms
2019-09-12 10:44:21,148 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown FollowerState
2019-09-12 10:44:21,148 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,148 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6/current/log_inprogress_0
2019-09-12 10:44:21,148 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderElection
2019-09-12 10:44:21,159 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151/current/log_inprogress_0
2019-09-12 10:44:21,159 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14: begin an election at term 1 for -1: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null
2019-09-12 10:44:21,160 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderElection
2019-09-12 10:44:21,160 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,160 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 change Leader from null to 8b56acbb-8697-4c0e-bb7c-14cea5d20b49 at term 1 for becomeLeader, leader elected after 5212ms
2019-09-12 10:44:21,160 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,160 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,161 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,161 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,161 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,161 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,161 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: start LeaderState
2019-09-12 10:44:21,162 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6: Starting segment from index:0
2019-09-12 10:44:21,162 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 set configuration 0: [8b56acbb-8697-4c0e-bb7c-14cea5d20b49:192.168.36.114:34849], old=null at 0
2019-09-12 10:44:21,205 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 changes to CANDIDATE, lastRpcTime:5141, electionTimeout:5141ms
2019-09-12 10:44:21,206 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:21,206 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,206 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:21,211 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6/current/log_inprogress_0
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5165ms
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,224 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,225 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,225 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,225 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,225 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,225 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:21,226 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533: Starting segment from index:0
2019-09-12 10:44:21,226 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:21,291 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533/current/log_inprogress_0
2019-09-12 10:44:21,313 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 changes to CANDIDATE, lastRpcTime:5115, electionTimeout:5112ms
2019-09-12 10:44:21,313 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown FollowerState
2019-09-12 10:44:21,318 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,321 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderElection
2019-09-12 10:44:21,332 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 changes to CANDIDATE, lastRpcTime:5198, electionTimeout:5198ms
2019-09-12 10:44:21,333 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:21,333 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,333 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:21,338 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16: begin an election at term 1 for -1: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null
2019-09-12 10:44:21,338 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderElection
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 change Leader from null to 364f652f-ef6f-448e-9b53-5fc05d785e98 at term 1 for becomeLeader, leader elected after 5148ms
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,339 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,340 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,340 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: start LeaderState
2019-09-12 10:44:21,340 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773: Starting segment from index:0
2019-09-12 10:44:21,341 [364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 set configuration 0: [364f652f-ef6f-448e-9b53-5fc05d785e98:192.168.36.114:45119], old=null at 0
2019-09-12 10:44:21,341 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:21,379 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D changes to CANDIDATE, lastRpcTime:5116, electionTimeout:5109ms
2019-09-12 10:44:21,379 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 changes to CANDIDATE, lastRpcTime:5066, electionTimeout:5037ms
2019-09-12 10:44:21,380 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:21,380 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:21,380 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,380 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown FollowerState
2019-09-12 10:44:21,380 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:21,380 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,380 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-12 10:44:21,380 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5251ms
2019-09-12 10:44:21,382 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderElection
2019-09-12 10:44:21,384 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,386 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,388 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,388 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,388 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,389 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,389 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:21,389 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854: Starting segment from index:0
2019-09-12 10:44:21,390 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:21,425 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773/current/log_inprogress_0
2019-09-12 10:44:21,425 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:21,425 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19: begin an election at term 1 for -1: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderElection
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5167ms
2019-09-12 10:44:21,426 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 change Leader from null to 25a00999-72ce-4fe5-a995-b18dc52f570d at term 1 for becomeLeader, leader elected after 5116ms
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,427 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,428 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-12 10:44:21,429 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:21,429 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: start LeaderState
2019-09-12 10:44:21,429 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d: Starting segment from index:0
2019-09-12 10:44:21,429 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8: Starting segment from index:0
2019-09-12 10:44:21,430 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:21,430 [25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 set configuration 0: [25a00999-72ce-4fe5-a995-b18dc52f570d:192.168.36.114:35072], old=null at 0
2019-09-12 10:44:21,472 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854/current/log_inprogress_0
2019-09-12 10:44:21,486 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8/current/log_inprogress_0
2019-09-12 10:44:21,486 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d/current/log_inprogress_0
2019-09-12 10:44:21,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:21,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,413 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779129575178259 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,414 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,452 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779129575178259 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,462 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=18, SUCCESS, logIndex=1, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c1]
2019-09-12 10:44:22,542 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779129575178259 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:22,549 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-0582C3A0D525->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=19, SUCCESS, logIndex=3, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c4]
2019-09-12 10:44:22,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6, key=b77fd7a8-b6b1-42c1-80a4-b48653d86c89, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779129575178259
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:22,573 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:22,575 [IPC Server handler 17 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:22,575 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:22,576 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6, key=b77fd7a8-b6b1-42c1-80a4-b48653d86c89, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:22,647 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:22,648 [IPC Server handler 0 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:22,649 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:22,650 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=93d50e1a-518c-4f47-9cb4-26fe4d1d00f9, bucket=c1bd95db-d04f-4780-8205-33c2e57486d6, key=b77fd7a8-b6b1-42c1-80a4-b48653d86c89, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:22,699 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779129575178259 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:22,721 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779129575178259 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:22,724 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 05bcd811-859c-4cad-8a84-d5d551f9300f, with jenkins1000 as owner.
2019-09-12 10:44:22,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=05bcd811-859c-4cad-8a84-d5d551f9300f, creationTime=1568285062726, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:22,741 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=05bcd811-859c-4cad-8a84-d5d551f9300f} | ret=SUCCESS |  
2019-09-12 10:44:22,742 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 05bcd811-859c-4cad-8a84-d5d551f9300f/1700b7f7-b62d-46db-8730-10c7629a1e4a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:22,750 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285062743} | ret=SUCCESS |  
2019-09-12 10:44:22,752 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a} | ret=SUCCESS |  
2019-09-12 10:44:22,753 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a, key=null} | ret=SUCCESS |  
2019-09-12 10:44:22,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-12 10:44:22,778 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a} | ret=SUCCESS |  
2019-09-12 10:44:22,781 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=05bcd811-859c-4cad-8a84-d5d551f9300f, bucket=1700b7f7-b62d-46db-8730-10c7629a1e4a, key=null} | ret=SUCCESS |  
2019-09-12 10:44:22,782 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 73141506-a580-43e2-8f3b-68d3b4f0d30b, with jenkins1000 as owner.
2019-09-12 10:44:22,786 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, creationTime=1568285062783, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:22,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b} | ret=SUCCESS |  
2019-09-12 10:44:22,789 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 73141506-a580-43e2-8f3b-68d3b4f0d30b/c475a06d-be8d-4686-865f-37c42c20ce6c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:22,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285062790} | ret=SUCCESS |  
2019-09-12 10:44:22,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c} | ret=SUCCESS |  
2019-09-12 10:44:22,814 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:22,844 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:22,851 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129877364758} | ret=SUCCESS |  
2019-09-12 10:44:22,891 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129878544407 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,895 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129878544407 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:22,905 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129878544407 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,912 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129878544407 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:22,923 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129878544407 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,929 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129878544407 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:22,940 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129878544407 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,943 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129878544407 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:22,947 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:22,960 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129877364758} | ret=SUCCESS |  
2019-09-12 10:44:22,973 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129885294616 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:22,977 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129885294616 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:23,006 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129878544407
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129885294616
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:23,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,019 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:23,032 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129889357849} | ret=SUCCESS |  
2019-09-12 10:44:23,045 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129890013210 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,049 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129890013210 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:23,060 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129890013210 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,066 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129890013210 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:23,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,078 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129890013210 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,084 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129890013210 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:23,095 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129890013210 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,106 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129890013210 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:23,110 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:23,124 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129889357849} | ret=SUCCESS |  
2019-09-12 10:44:23,135 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129895976987 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,139 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129895976987 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:23,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129890013210
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129895976987
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:23,166 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,169 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:23,182 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129899188252} | ret=SUCCESS |  
2019-09-12 10:44:23,194 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129899843613 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,199 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129899843613 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:23,209 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129899843613 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,212 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129899843613 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:23,222 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129899843613 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,229 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129899843613 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:23,239 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129899843613 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,244 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129899843613 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:23,248 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:23,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779129899188252} | ret=SUCCESS |  
2019-09-12 10:44:23,277 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129905020958 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:23,282 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129905020958 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:23,299 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, key=2c104e3f-731a-4a50-b474-93ae8ee8d982, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129899843613
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129905020958
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:23,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=73141506-a580-43e2-8f3b-68d3b4f0d30b, bucket=c475a06d-be8d-4686-865f-37c42c20ce6c, uploadID=80761066-d839-46d1-bd0e-111c1df4ae22-102779129875791893, partNumberMarker=0, maxParts=3, key=2c104e3f-731a-4a50-b474-93ae8ee8d982} | ret=SUCCESS |  
2019-09-12 10:44:23,312 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 38cb393a-1fa4-4923-b8f8-aaa98d0044e4, with jenkins1000 as owner.
2019-09-12 10:44:23,326 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, creationTime=1568285063314, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:23,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4} | ret=SUCCESS |  
2019-09-12 10:44:23,329 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 38cb393a-1fa4-4923-b8f8-aaa98d0044e4/a965230d-4e2a-43f2-9c06-17891fe5b8a9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,338 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063330} | ret=SUCCESS |  
2019-09-12 10:44:23,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9} | ret=SUCCESS |  
2019-09-12 10:44:23,366 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,385 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,386 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,447 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,454 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,489 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9} | ret=SUCCESS |  
2019-09-12 10:44:23,490 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 38cb393a-1fa4-4923-b8f8-aaa98d0044e4/a965230d-4e2a-43f2-9c06-17891fe5b8a9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,496 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:remoteUser:r[ACCESS], group:remoteGroup:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063492} | ret=SUCCESS |  
2019-09-12 10:44:23,500 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,502 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38cb393a-1fa4-4923-b8f8-aaa98d0044e4, bucket=a965230d-4e2a-43f2-9c06-17891fe5b8a9, key=null} | ret=SUCCESS |  
2019-09-12 10:44:23,522 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {7e8ec7b4-ef04-4c51-a5b4-883b4aa2b35d=s3Bucket} | ret=FAILURE | S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 7e8ec7b4-ef04-4c51-a5b4-883b4aa2b35d not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:23,523 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.S3BucketDeleteRequest (S3BucketDeleteRequest.java:validateAndUpdateCache(175)) - S3Bucket Deletion failed for S3Bucket:7e8ec7b4-ef04-4c51-a5b4-883b4aa2b35d
S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 7e8ec7b4-ef04-4c51-a5b4-883b4aa2b35d not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:23,528 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 002fff59-90df-4879-9d51-9681b23de532, with jenkins1000 as owner.
2019-09-12 10:44:23,535 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=002fff59-90df-4879-9d51-9681b23de532, creationTime=1568285063529, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:23,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=002fff59-90df-4879-9d51-9681b23de532} | ret=SUCCESS |  
2019-09-12 10:44:23,541 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 002fff59-90df-4879-9d51-9681b23de532/98bc3563-5c56-468a-be8c-e87b48cd3a2c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=002fff59-90df-4879-9d51-9681b23de532, bucket=98bc3563-5c56-468a-be8c-e87b48cd3a2c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063542} | ret=SUCCESS |  
2019-09-12 10:44:23,572 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=002fff59-90df-4879-9d51-9681b23de532, bucket=98bc3563-5c56-468a-be8c-e87b48cd3a2c} | ret=SUCCESS |  
2019-09-12 10:44:23,574 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=002fff59-90df-4879-9d51-9681b23de532, bucket=98bc3563-5c56-468a-be8c-e87b48cd3a2c, uploadID=random, partNumberMarker=100, maxParts=2, key=f8726ed0-0de2-4dbb-8059-c088e196c7b4} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No Such Multipart upload exists for this key.
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listParts(KeyManagerImpl.java:1294)
	at org.apache.hadoop.ozone.om.OzoneManager.listParts(OzoneManager.java:2846) 
2019-09-12 10:44:23,576 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: bb30922e-9b24-4c7d-a8a2-f928c9491527, with jenkins1000 as owner.
2019-09-12 10:44:23,578 [IPC Server handler 10 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-97_190 to index:190
2019-09-12 10:44:23,580 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_97-190
2019-09-12 10:44:23,604 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191
2019-09-12 10:44:23,606 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=bb30922e-9b24-4c7d-a8a2-f928c9491527, creationTime=1568285063578, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:23,609 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=bb30922e-9b24-4c7d-a8a2-f928c9491527} | ret=SUCCESS |  
2019-09-12 10:44:23,610 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bb30922e-9b24-4c7d-a8a2-f928c9491527/b8e40ddd-3c00-4e8a-a04d-8538e9c73382, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,623 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bb30922e-9b24-4c7d-a8a2-f928c9491527, bucket=b8e40ddd-3c00-4e8a-a04d-8538e9c73382, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063611} | ret=SUCCESS |  
2019-09-12 10:44:23,626 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=bb30922e-9b24-4c7d-a8a2-f928c9491527, bucket=b8e40ddd-3c00-4e8a-a04d-8538e9c73382} | ret=SUCCESS |  
2019-09-12 10:44:23,640 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=bb30922e-9b24-4c7d-a8a2-f928c9491527, bucket=b8e40ddd-3c00-4e8a-a04d-8538e9c73382, key=a1853299-4e2f-42e6-890a-38466be8d80c, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,654 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=bb30922e-9b24-4c7d-a8a2-f928c9491527, bucket=b8e40ddd-3c00-4e8a-a04d-8538e9c73382, key=a1853299-4e2f-42e6-890a-38466be8d80c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,658 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,658 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,658 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,659 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,659 [IPC Server handler 9 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,659 [IPC Server handler 9 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,660 [IPC Server handler 9 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,660 [IPC Server handler 9 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,660 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,661 [IPC Server handler 6 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38955, call Call#249 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,664 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:23,666 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,666 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,667 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,667 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,667 [IPC Server handler 16 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,667 [IPC Server handler 16 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,668 [IPC Server handler 16 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,668 [IPC Server handler 16 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,668 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,669 [IPC Server handler 5 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38955, call Call#249 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,670 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,672 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,672 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,673 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,673 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,673 [IPC Server handler 12 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,673 [IPC Server handler 12 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,674 [IPC Server handler 12 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,674 [IPC Server handler 12 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,674 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,674 [IPC Server handler 4 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38955, call Call#249 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,676 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,678 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,678 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,679 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,679 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,679 [IPC Server handler 19 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,679 [IPC Server handler 19 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,680 [IPC Server handler 19 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,680 [IPC Server handler 19 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,680 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,681 [IPC Server handler 19 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 38955, call Call#249 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,683 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,685 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,685 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,686 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,686 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,686 [IPC Server handler 14 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,686 [IPC Server handler 14 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,687 [IPC Server handler 14 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,687 [IPC Server handler 14 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,687 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,688 [IPC Server handler 0 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38955, call Call#249 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,690 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,691 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,692 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,692 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,692 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,692 [IPC Server handler 5 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,692 [IPC Server handler 5 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,693 [IPC Server handler 5 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,693 [IPC Server handler 5 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,694 [IPC Server handler 2 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38955, call Call#249 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,695 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,697 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,697 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,697 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,698 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,698 [IPC Server handler 2 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,698 [IPC Server handler 2 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,698 [IPC Server handler 2 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,699 [IPC Server handler 2 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,699 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,699 [IPC Server handler 1 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38955, call Call#249 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,701 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,703 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,703 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,703 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,703 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,704 [IPC Server handler 6 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,704 [IPC Server handler 6 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,704 [IPC Server handler 6 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,704 [IPC Server handler 6 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,705 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,705 [IPC Server handler 3 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38955, call Call#249 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,707 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,709 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,709 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,709 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,709 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,709 [IPC Server handler 3 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,710 [IPC Server handler 3 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,710 [IPC Server handler 3 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,710 [IPC Server handler 3 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,710 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,711 [IPC Server handler 18 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 38955, call Call#249 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,712 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,714 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,714 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,714 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,714 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,715 [IPC Server handler 7 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,715 [IPC Server handler 7 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,715 [IPC Server handler 7 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,715 [IPC Server handler 7 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,715 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,716 [IPC Server handler 15 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 38955, call Call#249 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,718 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:23,719 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:23,719 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:23,720 [IPC Server handler 13 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:23,721 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:23,721 [IPC Server handler 17 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 38955, call Call#249 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:23,723 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:23,723 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testUploadPartOverrideWithRatis(TestOzoneRpcClientAbstract.java:1773)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:44:23,725 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-42952, with jenkins1000 as owner.
2019-09-12 10:44:23,738 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-42952, creationTime=1568285063726, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:23,740 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-19782, with jenkins1000 as owner.
2019-09-12 10:44:23,753 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-19782, creationTime=1568285063741, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:23,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-42952} | ret=SUCCESS |  
2019-09-12 10:44:23,757 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-19782} | ret=SUCCESS |  
2019-09-12 10:44:23,758 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-0-50552, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:23,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-0-50552, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063759} | ret=SUCCESS |  
2019-09-12 10:44:23,766 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-0-27863, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-0-27863, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063767} | ret=SUCCESS |  
2019-09-12 10:44:23,789 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-1-05018, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-1-05018, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063790} | ret=SUCCESS |  
2019-09-12 10:44:23,801 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-1-44254, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,815 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-1-44254, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063802} | ret=SUCCESS |  
2019-09-12 10:44:23,815 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-2-28391, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,827 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-2-28391, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063816} | ret=SUCCESS |  
2019-09-12 10:44:23,828 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-2-78130, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,842 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-2-78130, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063829} | ret=SUCCESS |  
2019-09-12 10:44:23,842 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-3-44791, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,854 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-3-44791, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063843} | ret=SUCCESS |  
2019-09-12 10:44:23,854 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-3-25490, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,868 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-3-25490, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063855} | ret=SUCCESS |  
2019-09-12 10:44:23,869 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-4-74112, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,883 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-4-74112, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063870} | ret=SUCCESS |  
2019-09-12 10:44:23,884 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-4-99312, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-4-99312, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063885} | ret=SUCCESS |  
2019-09-12 10:44:23,895 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-5-77941, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-5-77941, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063896} | ret=SUCCESS |  
2019-09-12 10:44:23,909 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-5-50650, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-5-50650, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063910} | ret=SUCCESS |  
2019-09-12 10:44:23,921 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-6-07881, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-6-07881, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063922} | ret=SUCCESS |  
2019-09-12 10:44:23,935 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-6-29978, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,949 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-6-29978, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063936} | ret=SUCCESS |  
2019-09-12 10:44:23,950 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-7-82550, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,960 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-7-82550, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063951} | ret=SUCCESS |  
2019-09-12 10:44:23,962 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-7-53744, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,965 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-7-53744, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063963} | ret=SUCCESS |  
2019-09-12 10:44:23,966 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-8-25285, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,978 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-8-25285, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063967} | ret=SUCCESS |  
2019-09-12 10:44:23,979 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-8-94053, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-8-94053, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063980} | ret=SUCCESS |  
2019-09-12 10:44:23,989 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-a-9-61927, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:23,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-a-9-61927, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063991} | ret=SUCCESS |  
2019-09-12 10:44:23,995 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-a-9-32929, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,007 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-a-9-32929, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285063996} | ret=SUCCESS |  
2019-09-12 10:44:24,008 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-0-67878, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-0-67878, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064009} | ret=SUCCESS |  
2019-09-12 10:44:24,032 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-0-18521, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,043 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-0-18521, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064034} | ret=SUCCESS |  
2019-09-12 10:44:24,044 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-1-27286, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:24,068 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-1-27286, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064045} | ret=SUCCESS |  
2019-09-12 10:44:24,069 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-1-02476, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,079 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-1-02476, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064070} | ret=SUCCESS |  
2019-09-12 10:44:24,080 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-2-58271, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,093 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-2-58271, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064081} | ret=SUCCESS |  
2019-09-12 10:44:24,094 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-2-70869, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,105 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-2-70869, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064095} | ret=SUCCESS |  
2019-09-12 10:44:24,107 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-3-57025, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,120 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-3-57025, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064108} | ret=SUCCESS |  
2019-09-12 10:44:24,121 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-3-66236, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-3-66236, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064122} | ret=SUCCESS |  
2019-09-12 10:44:24,136 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-4-47798, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,147 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-4-47798, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064137} | ret=SUCCESS |  
2019-09-12 10:44:24,148 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-4-78698, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,160 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-4-78698, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064149} | ret=SUCCESS |  
2019-09-12 10:44:24,161 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-5-51798, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,177 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-5-51798, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064162} | ret=SUCCESS |  
2019-09-12 10:44:24,179 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-5-01867, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,189 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-5-01867, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064181} | ret=SUCCESS |  
2019-09-12 10:44:24,191 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-6-04947, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,204 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-6-04947, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064192} | ret=SUCCESS |  
2019-09-12 10:44:24,205 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-6-99507, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,216 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-6-99507, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064205} | ret=SUCCESS |  
2019-09-12 10:44:24,216 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-7-49700, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-7-49700, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064217} | ret=SUCCESS |  
2019-09-12 10:44:24,228 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-7-21884, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,239 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-7-21884, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064229} | ret=SUCCESS |  
2019-09-12 10:44:24,240 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-8-60075, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-8-60075, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064240} | ret=SUCCESS |  
2019-09-12 10:44:24,243 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-8-72255, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,245 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-8-72255, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064244} | ret=SUCCESS |  
2019-09-12 10:44:24,246 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-42952/bucket-b-9-39024, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-42952, bucket=bucket-b-9-39024, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064247} | ret=SUCCESS |  
2019-09-12 10:44:24,250 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-19782/bucket-b-9-18807, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,261 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-19782, bucket=bucket-b-9-18807, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064250} | ret=SUCCESS |  
2019-09-12 10:44:24,270 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=bucket-b-9-39024, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,277 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,279 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=bucket-b-9-39024, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,280 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,282 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=bucket-a-9-61927, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,283 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=bucket-b-9-39024, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,286 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,288 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-42952, startKey=bucket-b-9-39024, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,289 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-19782, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,291 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-19782, startKey=bucket-a-9-32929, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:24,292 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, with jenkins1000 as owner.
2019-09-12 10:44:24,305 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, creationTime=1568285064293, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d} | ret=SUCCESS |  
2019-09-12 10:44:24,307 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d/fc2813a3-13b2-4553-b492-fa01b0809fd3, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, bucket=fc2813a3-13b2-4553-b492-fa01b0809fd3, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064308} | ret=SUCCESS |  
2019-09-12 10:44:24,318 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, bucket=fc2813a3-13b2-4553-b492-fa01b0809fd3} | ret=SUCCESS |  
2019-09-12 10:44:24,327 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, bucket=fc2813a3-13b2-4553-b492-fa01b0809fd3, isVersionEnabled=null, storageType=SSD} | ret=SUCCESS |  
2019-09-12 10:44:24,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=7f0a39d3-dca5-4ea7-8fce-e0b0be1c7e5d, bucket=fc2813a3-13b2-4553-b492-fa01b0809fd3} | ret=SUCCESS |  
2019-09-12 10:44:24,329 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 29b4a51e-b78c-40ba-a8e4-04c81f187bb1, with jenkins1000 as owner.
2019-09-12 10:44:24,341 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, creationTime=1568285064330, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,343 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1} | ret=SUCCESS |  
2019-09-12 10:44:24,343 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 29b4a51e-b78c-40ba-a8e4-04c81f187bb1/c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,355 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064344} | ret=SUCCESS |  
2019-09-12 10:44:24,357 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d} | ret=SUCCESS |  
2019-09-12 10:44:24,359 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:24,373 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, key=4265992a-0671-435f-aaec-552b31ab004a, dataSize=294, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129977831457
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,377 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129977831457 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,380 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129977831457 bcsId: 0,size=294]} | ret=SUCCESS |  
2019-09-12 10:44:24,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, key=4265992a-0671-435f-aaec-552b31ab004a, dataSize=294, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129977831457
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 294
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,398 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:24,399 [IPC Server handler 17 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:24,399 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:24,400 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, key=4265992a-0671-435f-aaec-552b31ab004a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:24,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:24,413 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779129977831457 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,419 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779129977831457 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,421 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:24,422 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, key=4265992a-0671-435f-aaec-552b31ab004a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:24,423 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:24,425 [IPC Server handler 4 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:24,425 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:24,426 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=29b4a51e-b78c-40ba-a8e4-04c81f187bb1, bucket=c9c1bd15-35ae-4e7c-a0d8-a0ad86ecc50d, key=4265992a-0671-435f-aaec-552b31ab004a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:24,436 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, with jenkins1000 as owner.
2019-09-12 10:44:24,449 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, creationTime=1568285064437, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,451 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf} | ret=SUCCESS |  
2019-09-12 10:44:24,452 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: aa8896b1-09f0-462d-9d4d-c2eb5f5facdf/ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,461 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064453} | ret=SUCCESS |  
2019-09-12 10:44:24,462 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf} | ret=SUCCESS |  
2019-09-12 10:44:24,464 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:24,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129984712739
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,484 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129984712739 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,487 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129984712739 bcsId: 0,size=2376]} | ret=SUCCESS |  
2019-09-12 10:44:24,502 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=2376, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129984712739
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2376
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,504 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:24,508 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PF7c2da3bb-8a3a-4ab4-a263-29cba84ed6a9/KEYc6d2372f-03c0-4204-99a2-fe42b6e41128, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129987334181
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,512 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129987334181 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,515 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129987334181 bcsId: 0,size=2356]} | ret=SUCCESS |  
2019-09-12 10:44:24,528 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PF7c2da3bb-8a3a-4ab4-a263-29cba84ed6a9/KEYc6d2372f-03c0-4204-99a2-fe42b6e41128, dataSize=2356, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129987334181
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2356
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/} | ret=SUCCESS |  
2019-09-12 10:44:24,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/} | ret=SUCCESS |  
2019-09-12 10:44:24,574 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/} | ret=SUCCESS |  
2019-09-12 10:44:24,612 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:24,615 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:24,617 [IPC Server handler 9 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-191_320 to index:320
2019-09-12 10:44:24,623 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_191-320
2019-09-12 10:44:24,637 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321
2019-09-12 10:44:24,639 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129994608679
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,647 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779129994608679 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,651 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779129994608679 bcsId: 0,size=2361]} | ret=SUCCESS |  
2019-09-12 10:44:24,671 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=2361, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779129994608679
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2361
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,673 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/} | ret=SUCCESS |  
2019-09-12 10:44:24,676 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb} | ret=SUCCESS |  
2019-09-12 10:44:24,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:24,709 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:24,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130000769065
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,729 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130000769065 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:24,732 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130000769065 bcsId: 0,size=2386]} | ret=SUCCESS |  
2019-09-12 10:44:24,747 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb, dataSize=2386, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130000769065
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2386
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:24,749 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PF7c2da3bb-8a3a-4ab4-a263-29cba84ed6a9/} | ret=SUCCESS |  
2019-09-12 10:44:24,750 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=aa8896b1-09f0-462d-9d4d-c2eb5f5facdf, bucket=ad06b386-26a4-4cbc-a29e-7dcfc4e0d7bf, key=PFfb4c6c49-4a11-46fd-b82f-f25cfc9a9a8d/KEYba2bf59b-1501-4df1-93f2-a5c2e5681cdb} | ret=SUCCESS |  
2019-09-12 10:44:24,752 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 9cd002b4-4639-4f12-8e70-3e97873c99f5, with jenkins1000 as owner.
2019-09-12 10:44:24,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=9cd002b4-4639-4f12-8e70-3e97873c99f5, creationTime=1568285064753, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,756 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9cd002b4-4639-4f12-8e70-3e97873c99f5} | ret=SUCCESS |  
2019-09-12 10:44:24,757 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 9cd002b4-4639-4f12-8e70-3e97873c99f5/5e7a8dad-9007-40f4-b68d-40dc2f61a75f, with Versioning true and Storage Type set to SSD and Encryption set to false 
2019-09-12 10:44:24,759 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=9cd002b4-4639-4f12-8e70-3e97873c99f5, bucket=5e7a8dad-9007-40f4-b68d-40dc2f61a75f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=true, storageType=SSD, creationTime=1568285064757} | ret=SUCCESS |  
2019-09-12 10:44:24,759 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:24,760 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=9cd002b4-4639-4f12-8e70-3e97873c99f5, bucket=5e7a8dad-9007-40f4-b68d-40dc2f61a75f} | ret=SUCCESS |  
2019-09-12 10:44:24,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=9cd002b4-4639-4f12-8e70-3e97873c99f5, bucket=5e7a8dad-9007-40f4-b68d-40dc2f61a75f, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,763 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 32a1c9c1-aeda-41b5-b0e7-83769ec95249, with jenkins1000 as owner.
2019-09-12 10:44:24,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249, creationTime=1568285064763, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249} | ret=SUCCESS |  
2019-09-12 10:44:24,767 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 32a1c9c1-aeda-41b5-b0e7-83769ec95249/9b5fd664-5825-4b77-8cd1-be9619cb3468, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:24,770 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249, bucket=9b5fd664-5825-4b77-8cd1-be9619cb3468, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285064768} | ret=SUCCESS |  
2019-09-12 10:44:24,771 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249, bucket=9b5fd664-5825-4b77-8cd1-be9619cb3468} | ret=SUCCESS |  
2019-09-12 10:44:24,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249, bucket=9b5fd664-5825-4b77-8cd1-be9619cb3468} | ret=SUCCESS |  
2019-09-12 10:44:24,790 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=32a1c9c1-aeda-41b5-b0e7-83769ec95249, bucket=9b5fd664-5825-4b77-8cd1-be9619cb3468, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,792 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 755929b1-c72a-4d22-b731-0c0c4f4520a9, with jenkins1000 as owner.
2019-09-12 10:44:24,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, creationTime=1568285064793, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:24,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,848 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,868 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,923 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,924 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,941 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=755929b1-c72a-4d22-b731-0c0c4f4520a9, bucket=null, key=null} | ret=SUCCESS |  
2019-09-12 10:44:24,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ae5c35ba-ad2c-4651-86f7-acf9c4fbc612=s3Bucket, ozone1=username} | ret=SUCCESS |  
2019-09-12 10:44:24,960 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone1} | ret=SUCCESS |  
2019-09-12 10:44:24,961 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone1, bucket=ae5c35ba-ad2c-4651-86f7-acf9c4fbc612} | ret=SUCCESS |  
2019-09-12 10:44:24,969 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {ae5c35ba-ad2c-4651-86f7-acf9c4fbc612=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:44:24,990 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {fe8b8094-ad80-4f64-a405-fefd374524c7=s3Bucket, 6e1f1f2b8cdde9c11717322d7e158a89=username} | ret=SUCCESS |  
2019-09-12 10:44:24,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s36e1f1f2b8cdde9c11717322d7e158a89} | ret=SUCCESS |  
2019-09-12 10:44:24,995 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s36e1f1f2b8cdde9c11717322d7e158a89, bucket=fe8b8094-ad80-4f64-a405-fefd374524c7} | ret=SUCCESS |  
2019-09-12 10:44:24,997 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, with jenkins1000 as owner.
2019-09-12 10:44:25,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, creationTime=1568285064998, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:25,003 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e} | ret=SUCCESS |  
2019-09-12 10:44:25,004 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: cfb6df4e-d812-4c61-bbe0-b324e4d01d2e/62a01804-6ced-456a-bc8d-1786a69e720b, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,008 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065005} | ret=SUCCESS |  
2019-09-12 10:44:25,010 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b} | ret=SUCCESS |  
2019-09-12 10:44:25,019 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, key=631f8f44-ee29-471b-9bac-c81e42032efc, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:25,024 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, key=631f8f44-ee29-471b-9bac-c81e42032efc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:25,027 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, key=631f8f44-ee29-471b-9bac-c81e42032efc, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130021216300} | ret=SUCCESS |  
2019-09-12 10:44:25,036 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130021609517 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,040 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130021609517 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:25,046 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, key=631f8f44-ee29-471b-9bac-c81e42032efc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130021609517
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,061 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=cfb6df4e-d812-4c61-bbe0-b324e4d01d2e, bucket=62a01804-6ced-456a-bc8d-1786a69e720b, key=631f8f44-ee29-471b-9bac-c81e42032efc, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={3=random}} | ret=FAILURE | MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: cfb6df4e-d812-4c61-bbe0-b324e4d01d2ebucket: 62a01804-6ced-456a-bc8d-1786a69e720bkey: 631f8f44-ee29-471b-9bac-c81e42032efc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:25,064 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 631f8f44-ee29-471b-9bac-c81e42032efc in Volume/Bucket cfb6df4e-d812-4c61-bbe0-b324e4d01d2e/62a01804-6ced-456a-bc8d-1786a69e720b
MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: cfb6df4e-d812-4c61-bbe0-b324e4d01d2ebucket: 62a01804-6ced-456a-bc8d-1786a69e720bkey: 631f8f44-ee29-471b-9bac-c81e42032efc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:25,065 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f7eee3fd-9b73-4505-91ba-375023897120, with jenkins1000 as owner.
2019-09-12 10:44:25,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:25,069 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f7eee3fd-9b73-4505-91ba-375023897120, creationTime=1568285065067, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:25,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f7eee3fd-9b73-4505-91ba-375023897120} | ret=SUCCESS |  
2019-09-12 10:44:25,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=SET_QUOTA {volume=f7eee3fd-9b73-4505-91ba-375023897120, quota=100000000} | ret=SUCCESS |  
2019-09-12 10:44:25,109 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f7eee3fd-9b73-4505-91ba-375023897120} | ret=SUCCESS |  
2019-09-12 10:44:25,110 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ab96261a-7b37-4f85-be25-300d787fd3ac, with jenkins1000 as owner.
2019-09-12 10:44:25,117 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ab96261a-7b37-4f85-be25-300d787fd3ac, creationTime=1568285065112, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:25,119 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ab96261a-7b37-4f85-be25-300d787fd3ac} | ret=SUCCESS |  
2019-09-12 10:44:25,120 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ab96261a-7b37-4f85-be25-300d787fd3ac/4cd8a82e-b6f0-4d10-a53c-995b8587388f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,133 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ab96261a-7b37-4f85-be25-300d787fd3ac, bucket=4cd8a82e-b6f0-4d10-a53c-995b8587388f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065121} | ret=SUCCESS |  
2019-09-12 10:44:25,134 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ab96261a-7b37-4f85-be25-300d787fd3ac, bucket=4cd8a82e-b6f0-4d10-a53c-995b8587388f} | ret=SUCCESS |  
2019-09-12 10:44:25,144 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=ab96261a-7b37-4f85-be25-300d787fd3ac, bucket=4cd8a82e-b6f0-4d10-a53c-995b8587388f} | ret=SUCCESS |  
2019-09-12 10:44:25,147 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ab96261a-7b37-4f85-be25-300d787fd3ac, bucket=4cd8a82e-b6f0-4d10-a53c-995b8587388f} | ret=FAILURE | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
	at org.apache.hadoop.ozone.om.BucketManagerImpl.getBucketInfo(BucketManagerImpl.java:229)
	at org.apache.hadoop.ozone.om.OzoneManager.getBucketInfo(OzoneManager.java:2147) 
2019-09-12 10:44:25,150 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-41358, with jenkins1000 as owner.
2019-09-12 10:44:25,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-41358, creationTime=1568285065151, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:25,157 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-63560, with jenkins1000 as owner.
2019-09-12 10:44:25,171 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-63560, creationTime=1568285065158, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:25,173 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-41358} | ret=SUCCESS |  
2019-09-12 10:44:25,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-63560} | ret=SUCCESS |  
2019-09-12 10:44:25,175 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-41358/buc-a-08893, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,182 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-41358, bucket=buc-a-08893, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065176} | ret=SUCCESS |  
2019-09-12 10:44:25,183 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-41358/buc-b-64859, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-41358, bucket=buc-b-64859, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065184} | ret=SUCCESS |  
2019-09-12 10:44:25,197 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-63560/buc-a-08893, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,208 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-63560, bucket=buc-a-08893, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065197} | ret=SUCCESS |  
2019-09-12 10:44:25,209 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-63560/buc-b-64859, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:25,221 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-63560, bucket=buc-b-64859, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285065209} | ret=SUCCESS |  
2019-09-12 10:44:25,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-41358, bucket=buc-a-08893} | ret=SUCCESS |  
2019-09-12 10:44:25,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-41358, bucket=buc-b-64859} | ret=SUCCESS |  
2019-09-12 10:44:25,224 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-63560, bucket=buc-a-08893} | ret=SUCCESS |  
2019-09-12 10:44:25,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-63560, bucket=buc-b-64859} | ret=SUCCESS |  
2019-09-12 10:44:25,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-0-09665, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130034847790
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,247 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130034847790 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,250 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130034847790 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,263 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-0-09665, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130034847790
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,265 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,268 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-0-01460, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130037207088
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,271 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130037207088 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,274 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130037207088 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,287 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-0-01460, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130037207088
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,289 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,293 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-0-14006, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130038779954
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,297 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130038779954 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,299 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130038779954 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-0-14006, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130038779954
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,306 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,310 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-0-37144, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130039894068
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,313 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130039894068 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,316 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130039894068 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-0-37144, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130039894068
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-1-65135, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130041204790
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,334 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130041204790 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,337 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130041204790 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,349 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-1-65135, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130041204790
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,353 [IPC Server handler 17 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-321_422 to index:422
2019-09-12 10:44:25,354 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_321-422
2019-09-12 10:44:25,358 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423
2019-09-12 10:44:25,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-1-45182, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130042843192
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,365 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130042843192 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,368 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130042843192 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-1-45182, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130042843192
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,403 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-1-62167, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130045399098
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,408 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130045399098 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,411 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130045399098 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:25,426 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-1-62167, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130045399098
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,428 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,442 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-1-09265, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130047889468
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,446 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130047889468 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,449 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130047889468 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-1-09265, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130047889468
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,457 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,470 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-2-14711, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130049724478
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,474 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130049724478 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,477 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130049724478 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,492 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-2-14711, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130049724478
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-2-63553, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130052214848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,507 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130052214848 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,510 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130052214848 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-2-63553, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130052214848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,527 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,537 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-2-64092, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130054377538
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,541 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130054377538 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,544 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130054377538 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,548 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-2-64092, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130054377538
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,563 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-2-07158, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130055950404
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,569 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130055950404 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,572 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130055950404 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,585 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-2-07158, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130055950404
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,589 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,600 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-3-32965, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130058440774
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,605 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130058440774 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,609 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130058440774 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,621 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-3-32965, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130058440774
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-3-34545, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130060734536
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,662 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130060734536 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,667 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130060734536 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,682 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-3-34545, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130060734536
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,699 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-3-98012, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130064732234
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,704 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130064732234 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,709 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130064732234 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-3-98012, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130064732234
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,740 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-3-10038, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130067484748
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,745 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130067484748 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,749 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130067484748 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:25,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-3-10038, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130067484748
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,768 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-4-96579, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130070106190
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,781 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130070106190 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,784 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130070106190 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-4-96579, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130070106190
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,802 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-4-78250, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130072399952
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,815 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130072399952 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,818 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130072399952 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,834 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-4-78250, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130072399952
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,836 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-4-73206, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130074628178
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,850 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130074628178 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,853 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130074628178 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,858 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-4-73206, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130074628178
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,860 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-4-50643, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130076201044
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,869 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130076201044 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,872 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130076201044 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-4-50643, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130076201044
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,889 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,905 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-5-45594, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130078101590
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,911 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130078101590 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,915 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130078101590 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-5-45594, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130078101590
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,939 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,949 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-5-00086, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130081378392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,953 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130081378392 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,956 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130081378392 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,961 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-5-00086, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130081378392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,963 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:25,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-5-43834, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130082951258
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,976 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130082951258 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:25,978 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130082951258 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:25,980 [IPC Server handler 2 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-423_492 to index:492
2019-09-12 10:44:25,981 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_423-492
2019-09-12 10:44:25,993 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493
2019-09-12 10:44:25,995 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-5-43834, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130082951258
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:25,998 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-5-46886, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130085245020
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,016 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130085245020 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,019 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130085245020 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,033 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-5-46886, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130085245020
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,037 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,050 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-6-14072, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130087800926
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,053 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130087800926 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,056 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130087800926 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,066 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:26,081 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-6-14072, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130087800926
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,083 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,093 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-6-73546, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130090815584
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,097 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130090815584 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,100 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130090815584 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-6-73546, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130090815584
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,109 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,119 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-6-92121, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130092519522
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,123 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130092519522 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,126 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130092519522 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-6-92121, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130092519522
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,164 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,209 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-6-82328, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130096124004
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,214 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130096124004 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,218 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130096124004 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,259 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-6-82328, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130096124004
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,262 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:26,578 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-7-02179, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130102546534
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,584 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130102546534 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,587 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130102546534 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,598 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-7-02179, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130102546534
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,601 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,617 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-7-04786, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130124697704
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,620 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130124697704 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,624 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130124697704 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,643 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-7-04786, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130124697704
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,645 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,653 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-7-71623, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130127646826
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,657 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130127646826 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,660 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130127646826 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,674 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-7-71623, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130127646826
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,677 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,685 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-7-91894, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130129743980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,689 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130129743980 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,692 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130129743980 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,699 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-7-91894, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130129743980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,702 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-8-15346, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130131382382
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,710 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130131382382 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,717 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130131382382 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-8-15346, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130131382382
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,728 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,734 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-8-10934, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130133086320
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,739 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130133086320 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,742 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130133086320 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,749 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-8-10934, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130133086320
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,751 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:26,762 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-8-32132, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130134593650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,765 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130134593650 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,768 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130134593650 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,776 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-8-32132, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130134593650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-8-29505, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130136363124
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,788 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130136363124 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,791 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130136363124 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-8-29505, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130136363124
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,802 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-9-20315, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130137935990
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,815 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130137935990 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,817 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130137935990 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,831 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-a-9-20315, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130137935990
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,833 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-9-07886, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130139902072
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,855 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130139902072 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,858 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130139902072 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,870 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-a-9-07886, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130139902072
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,872 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,878 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-9-34192, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130142523514
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,882 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130142523514 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,885 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130142523514 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-a-9-34192, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130142523514
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,907 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-9-15963, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130144751740
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,924 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130144751740 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,927 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130144751740 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,941 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-a-9-15963, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130144751740
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,944 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:26,945 [IPC Server handler 6 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-493_562 to index:562
2019-09-12 10:44:26,946 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_493-562
2019-09-12 10:44:26,970 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563
2019-09-12 10:44:26,972 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-0-49983, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130147242110
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,978 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130147242110 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:26,981 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130147242110 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:26,996 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-0-49983, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130147242110
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:26,998 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-0-24335, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130150781056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,017 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130150781056 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,020 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130150781056 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-0-24335, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130150781056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,039 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,053 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-0-69706, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130153468034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,058 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130153468034 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,061 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130153468034 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:27,078 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-0-69706, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130153468034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,086 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-0-03281, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130156220548
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,093 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130156220548 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,098 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130156220548 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-0-03281, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130156220548
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,109 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,121 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-1-78459, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130158055558
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,127 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130158055558 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,129 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130158055558 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,147 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-1-78459, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130158055558
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,152 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,157 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-1-41507, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130160808072
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,166 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130160808072 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,170 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130160808072 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-1-41507, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130160808072
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,200 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-1-24006, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130163167370
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,206 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130163167370 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,209 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130163167370 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,224 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-1-24006, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130163167370
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-1-97295, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130165723276
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,243 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130165723276 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,251 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130165723276 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,266 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-1-97295, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130165723276
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,279 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-2-11146, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130168541326
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,283 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130168541326 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,288 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130168541326 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,302 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-2-11146, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130168541326
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,305 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,308 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-2-72392, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130170835088
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,311 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130170835088 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,313 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130170835088 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,326 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-2-72392, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130170835088
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,327 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-2-99428, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130172342418
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,335 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130172342418 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,337 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130172342418 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-2-99428, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130172342418
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,363 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,373 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-2-38152, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130174701716
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,377 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130174701716 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,380 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130174701716 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,392 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-2-38152, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130174701716
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,395 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,409 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-3-53546, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130176798870
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:27,414 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130176798870 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,417 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130176798870 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-3-53546, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130176798870
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,435 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,449 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-3-13440, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130179420312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,454 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130179420312 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,458 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130179420312 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,472 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-3-13440, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130179420312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,475 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,490 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-3-66810, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130182041754
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,494 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130182041754 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,498 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130182041754 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,513 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-3-66810, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130182041754
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,515 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,529 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-3-95645, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130184663196
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,534 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130184663196 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,538 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130184663196 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,553 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-3-95645, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130184663196
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-4-97969, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130187284638
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,576 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130187284638 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,580 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130187284638 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-4-97969, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130187284638
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,599 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-4-45986, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130190168224
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,628 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130190168224 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,632 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130190168224 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,634 [IPC Server handler 14 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-563_632 to index:632
2019-09-12 10:44:27,635 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_563-632
2019-09-12 10:44:27,662 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633
2019-09-12 10:44:27,675 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-4-45986, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130190168224
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,677 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,689 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-4-95868, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130195280034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,695 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130195280034 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,699 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130195280034 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,716 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-4-95868, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130195280034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,718 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,731 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-4-46114, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130197967012
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,735 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130197967012 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,738 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130197967012 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,752 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-4-46114, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130197967012
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,754 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:27,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-5-08796, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130200326310
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,772 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130200326310 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,774 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130200326310 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-5-08796, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130200326310
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,791 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-5-97877, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130202751144
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,810 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130202751144 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,813 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130202751144 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,826 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-5-97877, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130202751144
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,828 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,831 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-5-56450, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130205175978
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,835 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130205175978 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,837 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130205175978 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-5-56450, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130205175978
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,842 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,853 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-5-25128, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130206093484
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,858 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130206093484 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,860 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130206093484 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-5-25128, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130206093484
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,881 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,889 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-6-86163, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130208649390
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,895 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130208649390 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,897 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130208649390 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,911 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-6-86163, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130208649390
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,924 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-6-23432, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130211467440
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,943 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130211467440 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,946 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130211467440 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,959 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-6-23432, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130211467440
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,961 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:27,974 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-6-89700, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130213892274
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,980 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130213892274 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:27,983 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130213892274 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:27,997 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-6-89700, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130213892274
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:27,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-6-86871, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130216382644
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,017 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130216382644 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,020 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130216382644 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,035 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-6-86871, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130216382644
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,038 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,050 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-7-60848, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130218873014
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,056 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130218873014 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,058 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130218873014 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,067 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,072 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-7-60848, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130218873014
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,074 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-7-64464, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130221297848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,093 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130221297848 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,095 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130221297848 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,113 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-7-64464, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130221297848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,115 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-7-35413, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130223984826
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,141 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130223984826 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,144 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130223984826 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,158 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-7-35413, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130223984826
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,160 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,173 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-7-76315, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130226933948
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,176 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130226933948 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,179 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130226933948 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,193 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-7-76315, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130226933948
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,217 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-8-47946, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130229227710
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,221 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130229227710 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,226 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130229227710 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,240 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-8-47946, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130229227710
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,242 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,255 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-8-03643, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130232307904
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,260 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130232307904 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,264 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130232307904 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,279 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-8-03643, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130232307904
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,281 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,290 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-8-06477, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130234863810
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,295 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130234863810 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,297 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130234863810 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,311 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-8-06477, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130234863810
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,315 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,316 [IPC Server handler 17 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-633_702 to index:702
2019-09-12 10:44:28,317 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_633-702
2019-09-12 10:44:28,332 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703
2019-09-12 10:44:28,344 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-8-88347, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130237092036
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,351 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130237092036 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,354 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130237092036 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,366 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-8-88347, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130237092036
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,369 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-9-68736, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130240630982
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,395 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130240630982 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,397 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130240630982 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,405 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-a-08893, key=key-b-9-68736, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130240630982
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-9-26940, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130243055816
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,423 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130243055816 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,425 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130243055816 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-41358, bucket=buc-b-64859, key=key-b-9-26940, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130243055816
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,440 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-9-16836, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130245284042
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,456 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130245284042 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,459 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130245284042 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,473 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-a-08893, key=key-b-9-16836, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130245284042
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,475 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,487 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-9-25729, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130247577804
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,491 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130247577804 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,497 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130247577804 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-12 10:44:28,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-63560, bucket=buc-b-64859, key=key-b-9-25729, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130247577804
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-a-08893, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,527 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-a-08893, startKey=key-b-9-68736, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-b-64859, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,534 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-b-64859, startKey=key-b-9-26940, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,537 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-63560, bucket=buc-a-08893, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-63560, bucket=buc-a-08893, startKey=key-b-9-16836, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-63560, bucket=buc-b-64859, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,548 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-63560, bucket=buc-b-64859, startKey=key-b-9-25729, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,550 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-a-08893, startKey=, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-12 10:44:28,552 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-a-08893, startKey=key-a-9-20315, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-12 10:44:28,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-a-08893, startKey=, maxKeys=1000, keyPrefix=key-b-} | ret=SUCCESS |  
2019-09-12 10:44:28,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-41358, bucket=buc-b-64859, startKey=key-b-9-26940, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-12 10:44:28,557 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1a2a3cc4-7956-42bf-b44f-a31423ee0eb6, with jenkins1000 as owner.
2019-09-12 10:44:28,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1a2a3cc4-7956-42bf-b44f-a31423ee0eb6, creationTime=1568285068558, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:28,572 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1a2a3cc4-7956-42bf-b44f-a31423ee0eb6} | ret=SUCCESS |  
2019-09-12 10:44:28,573 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1a2a3cc4-7956-42bf-b44f-a31423ee0eb6/1c38b267-6f5a-4765-8099-a56426da40bb, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:28,583 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1a2a3cc4-7956-42bf-b44f-a31423ee0eb6, bucket=1c38b267-6f5a-4765-8099-a56426da40bb, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285068573} | ret=SUCCESS |  
2019-09-12 10:44:28,584 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1a2a3cc4-7956-42bf-b44f-a31423ee0eb6, bucket=1c38b267-6f5a-4765-8099-a56426da40bb} | ret=SUCCESS |  
2019-09-12 10:44:28,585 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 254dd326-a17d-4061-94db-208d9d05ec82, with jenkins1000 as owner.
2019-09-12 10:44:28,598 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=254dd326-a17d-4061-94db-208d9d05ec82, creationTime=1568285068586, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:28,599 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=254dd326-a17d-4061-94db-208d9d05ec82} | ret=SUCCESS |  
2019-09-12 10:44:28,599 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 254dd326-a17d-4061-94db-208d9d05ec82/830224fb-021d-4753-b6dc-d575562e1ef7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:28,612 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285068600} | ret=SUCCESS |  
2019-09-12 10:44:28,613 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7} | ret=SUCCESS |  
2019-09-12 10:44:28,625 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,648 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,650 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,666 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130257473743} | ret=SUCCESS |  
2019-09-12 10:44:28,670 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130259046608 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,672 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130259046608 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:28,686 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130259046608
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,699 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,701 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,713 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130261471441} | ret=SUCCESS |  
2019-09-12 10:44:28,717 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130262388946 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,719 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130262388946 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:28,735 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130262388946
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,749 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(212)) - MultipartUpload: /254dd326-a17d-4061-94db-208d9d05ec82/830224fb-021d-4753-b6dc-d575562e1ef7/31ffa973-d36c-4197-ae0d-01960be5cca9Part number: 1size 4 is less than minimum part size 5242880
2019-09-12 10:44:28,749 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=254dd326-a17d-4061-94db-208d9d05ec82, bucket=830224fb-021d-4753-b6dc-d575562e1ef7, key=31ffa973-d36c-4197-ae0d-01960be5cca9, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=/254dd326-a17d-4061-94db-208d9d05ec82/830224fb-021d-4753-b6dc-d575562e1ef7/31ffa973-d36c-4197-ae0d-01960be5cca9102779130257473743, 2=/254dd326-a17d-4061-94db-208d9d05ec82/830224fb-021d-4753-b6dc-d575562e1ef7/31ffa973-d36c-4197-ae0d-01960be5cca9102779130261471441}} | ret=FAILURE | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 254dd326-a17d-4061-94db-208d9d05ec82bucket: 830224fb-021d-4753-b6dc-d575562e1ef7key: 31ffa973-d36c-4197-ae0d-01960be5cca9
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:28,752 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 31ffa973-d36c-4197-ae0d-01960be5cca9 in Volume/Bucket 254dd326-a17d-4061-94db-208d9d05ec82/830224fb-021d-4753-b6dc-d575562e1ef7
ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 254dd326-a17d-4061-94db-208d9d05ec82bucket: 830224fb-021d-4753-b6dc-d575562e1ef7key: 31ffa973-d36c-4197-ae0d-01960be5cca9
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:28,753 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: dc234e73-6bf4-452f-b008-9246bb1aead6, with jenkins1000 as owner.
2019-09-12 10:44:28,760 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,766 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=dc234e73-6bf4-452f-b008-9246bb1aead6, creationTime=1568285068754, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:28,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=dc234e73-6bf4-452f-b008-9246bb1aead6} | ret=SUCCESS |  
2019-09-12 10:44:28,768 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: dc234e73-6bf4-452f-b008-9246bb1aead6/939abfd7-7c8d-454a-a278-e09d96d17219, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:28,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285068769} | ret=SUCCESS |  
2019-09-12 10:44:28,780 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219} | ret=SUCCESS |  
2019-09-12 10:44:28,782 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:28,792 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=2e2d53f6-f8c5-44cd-8976-943ebf37f9cf, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779130267697363
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "66489fb9-4e62-4794-9107-49b6bb0610d6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,871 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779130267697363 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,872 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:28,874 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779130267697363 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:28,882 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98@group-49B6BB0610D6, cid=20, SUCCESS, logIndex=1, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c1]
2019-09-12 10:44:28,950 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102779130267697363 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:28,961 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98@group-49B6BB0610D6, cid=21, SUCCESS, logIndex=3, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c4]
2019-09-12 10:44:28,975 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=2e2d53f6-f8c5-44cd-8976-943ebf37f9cf, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779130267697363
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "66489fb9-4e62-4794-9107-49b6bb0610d6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:28,978 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:28,979 [IPC Server handler 2 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:28,979 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:28,980 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=2e2d53f6-f8c5-44cd-8976-943ebf37f9cf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:28,983 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:28,984 [IPC Server handler 6 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:28,984 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:28,984 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=2e2d53f6-f8c5-44cd-8976-943ebf37f9cf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:28,992 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 3 locID: 102779130267697363 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,004 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 3 locID: 102779130267697363 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,007 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:29,008 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=2e2d53f6-f8c5-44cd-8976-943ebf37f9cf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=3} | ret=SUCCESS |  
2019-09-12 10:44:29,017 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=d77e2f6c-b4cd-4109-8044-8c32c85f3013, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779130283098325
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b0720546-750f-4111-baef-aca02d7f7103"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,103 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779130283098325 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,103 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,116 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102779130283098325 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,122 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-95DF75788D64->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-95DF75788D64->364f652f-ef6f-448e-9b53-5fc05d785e98@group-ACA02D7F7103, cid=22, SUCCESS, logIndex=1, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c1]
2019-09-12 10:44:29,181 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102779130283098325 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:29,186 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-95DF75788D64->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-95DF75788D64->364f652f-ef6f-448e-9b53-5fc05d785e98@group-ACA02D7F7103, cid=23, SUCCESS, logIndex=3, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c4]
2019-09-12 10:44:29,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=d77e2f6c-b4cd-4109-8044-8c32c85f3013, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102779130283098325
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b0720546-750f-4111-baef-aca02d7f7103"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,200 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:44:29,201 [IPC Server handler 17 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,201 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,202 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=d77e2f6c-b4cd-4109-8044-8c32c85f3013, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,204 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:44:29,205 [IPC Server handler 4 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=d77e2f6c-b4cd-4109-8044-8c32c85f3013, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,214 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102779130283098325 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,218 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102779130283098325 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,219 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-12 10:44:29,220 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=d77e2f6c-b4cd-4109-8044-8c32c85f3013, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,220 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-12 10:44:29,223 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,237 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=85d1b3ee-7dea-4b24-a6ae-77911cb62e10, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779130296598743
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,247 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779130296598743 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,262 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779130296598743 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,270 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=24, SUCCESS, logIndex=5, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c5]
2019-09-12 10:44:29,288 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779130296598743 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:29,294 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=25, SUCCESS, logIndex=7, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c7]
2019-09-12 10:44:29,300 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=85d1b3ee-7dea-4b24-a6ae-77911cb62e10, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779130296598743
  }
  blockCommitSequenceId: 7
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,302 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:29,303 [IPC Server handler 11 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,303 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,303 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=85d1b3ee-7dea-4b24-a6ae-77911cb62e10, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,305 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:29,306 [IPC Server handler 10 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,306 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=85d1b3ee-7dea-4b24-a6ae-77911cb62e10, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,315 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779130296598743 bcsId: 7} | ret=SUCCESS |  
2019-09-12 10:44:29,318 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779130296598743 bcsId: 7} | ret=SUCCESS |  
2019-09-12 10:44:29,319 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:29,320 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=85d1b3ee-7dea-4b24-a6ae-77911cb62e10, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,320 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=2} | ret=SUCCESS |  
2019-09-12 10:44:29,322 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,334 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1bc785bc-9e03-4e6f-a024-0558fb24784d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779130303086809
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "548ae151-a0b6-464f-bf17-ecaf23504db6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,443 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779130303086809 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,443 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,456 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779130303086809 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,461 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-ECAF23504DB6, cid=26, SUCCESS, logIndex=1, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c1]
2019-09-12 10:44:29,539 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 5 locID: 102779130303086809 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:29,542 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-ECAF23504DB6, cid=27, SUCCESS, logIndex=3, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c4]
2019-09-12 10:44:29,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1bc785bc-9e03-4e6f-a024-0558fb24784d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779130303086809
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "548ae151-a0b6-464f-bf17-ecaf23504db6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,558 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,559 [IPC Server handler 1 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,559 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,560 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1bc785bc-9e03-4e6f-a024-0558fb24784d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,562 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,563 [IPC Server handler 9 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,564 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1bc785bc-9e03-4e6f-a024-0558fb24784d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,573 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 5 locID: 102779130303086809 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,578 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 5 locID: 102779130303086809 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,580 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,581 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1bc785bc-9e03-4e6f-a024-0558fb24784d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=5} | ret=SUCCESS |  
2019-09-12 10:44:29,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,597 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=f88da0de-cab4-479e-937b-f858791d448c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779130320257243
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "548ae151-a0b6-464f-bf17-ecaf23504db6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,602 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779130320257243 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,614 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102779130320257243 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,615 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 5 locID: 102779130320257243 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:29,616 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-ECAF23504DB6, cid=28, SUCCESS, logIndex=5, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c6]
2019-09-12 10:44:29,617 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-13C2E96E15DC->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-ECAF23504DB6, cid=29, SUCCESS, logIndex=6, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c6]
2019-09-12 10:44:29,629 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=f88da0de-cab4-479e-937b-f858791d448c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102779130320257243
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "548ae151-a0b6-464f-bf17-ecaf23504db6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,631 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,632 [IPC Server handler 12 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,632 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=f88da0de-cab4-479e-937b-f858791d448c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,635 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,636 [IPC Server handler 19 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,637 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,637 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=f88da0de-cab4-479e-937b-f858791d448c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,641 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 5 locID: 102779130320257243 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:29,643 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 5 locID: 102779130320257243 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:29,646 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-12 10:44:29,647 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=f88da0de-cab4-479e-937b-f858791d448c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,648 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=5} | ret=SUCCESS |  
2019-09-12 10:44:29,649 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,670 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=dca801b4-53f5-4499-8509-aa89f42c6f71, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779130324517085
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "bdca2718-fb76-4226-b53d-c445a466ebc6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,759 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,777 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779130324517085 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,791 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779130324517085 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,796 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d@group-C445A466EBC6, cid=30, SUCCESS, logIndex=1, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c1]
2019-09-12 10:44:29,850 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102779130324517085 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:29,853 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d@group-C445A466EBC6, cid=31, SUCCESS, logIndex=3, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c4]
2019-09-12 10:44:29,859 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=dca801b4-53f5-4499-8509-aa89f42c6f71, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779130324517085
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "bdca2718-fb76-4226-b53d-c445a466ebc6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,860 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:29,861 [IPC Server handler 5 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,862 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,862 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=dca801b4-53f5-4499-8509-aa89f42c6f71, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,864 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:29,865 [IPC Server handler 2 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:29,865 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:29,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=dca801b4-53f5-4499-8509-aa89f42c6f71, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,873 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102779130324517085 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,884 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102779130324517085 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:29,886 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:29,886 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=dca801b4-53f5-4499-8509-aa89f42c6f71, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:29,887 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-12 10:44:29,889 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:29,890 [IPC Server handler 7 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-703_774 to index:774
2019-09-12 10:44:29,890 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_703-774
2019-09-12 10:44:29,895 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775
2019-09-12 10:44:29,897 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1d1449a1-a546-4693-b689-0120c30593b2, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102779130340245727
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1389de10-6395-4041-b6ad-12f00208a22d"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:29,984 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102779130340245727 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:29,985 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:29,997 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102779130340245727 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,002 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-7D48332B5717->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-7D48332B5717->25a00999-72ce-4fe5-a995-b18dc52f570d@group-12F00208A22D, cid=32, SUCCESS, logIndex=1, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c1]
2019-09-12 10:44:30,080 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102779130340245727 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:30,083 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-7D48332B5717->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-7D48332B5717->25a00999-72ce-4fe5-a995-b18dc52f570d@group-12F00208A22D, cid=33, SUCCESS, logIndex=3, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c4]
2019-09-12 10:44:30,099 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1d1449a1-a546-4693-b689-0120c30593b2, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102779130340245727
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1389de10-6395-4041-b6ad-12f00208a22d"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,101 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:44:30,103 [IPC Server handler 7 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,103 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,103 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,104 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1d1449a1-a546-4693-b689-0120c30593b2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,106 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:44:30,107 [IPC Server handler 13 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,107 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,108 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1d1449a1-a546-4693-b689-0120c30593b2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,119 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102779130340245727 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:30,126 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102779130340245727 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:30,127 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-12 10:44:30,128 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=1d1449a1-a546-4693-b689-0120c30593b2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-12 10:44:30,131 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,143 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=80a0132f-cd2b-4875-88c8-a41438dde5c3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779130356105441
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,150 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779130356105441 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,160 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102779130356105441 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,162 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102779130356105441 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:30,162 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=34, SUCCESS, logIndex=9, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c11]
2019-09-12 10:44:30,163 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-68E5408904EB->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-DC8781F1BE95, cid=35, SUCCESS, logIndex=10, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c11]
2019-09-12 10:44:30,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=80a0132f-cd2b-4875-88c8-a41438dde5c3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102779130356105441
  }
  blockCommitSequenceId: 10
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "0edccb19-c6d4-4022-8d9f-dc8781f1be95"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,178 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:30,179 [IPC Server handler 17 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,179 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,180 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=80a0132f-cd2b-4875-88c8-a41438dde5c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,183 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:30,184 [IPC Server handler 4 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,184 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,185 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=80a0132f-cd2b-4875-88c8-a41438dde5c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,188 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102779130356105441 bcsId: 10} | ret=SUCCESS |  
2019-09-12 10:44:30,191 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102779130356105441 bcsId: 10} | ret=SUCCESS |  
2019-09-12 10:44:30,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-12 10:44:30,194 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=80a0132f-cd2b-4875-88c8-a41438dde5c3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=2} | ret=SUCCESS |  
2019-09-12 10:44:30,199 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=11b228fa-d094-433c-88d8-9c78e4deface, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779130360561891
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "bdca2718-fb76-4226-b53d-c445a466ebc6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,218 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779130360561891 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,231 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102779130360561891 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,232 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d@group-C445A466EBC6, cid=36, SUCCESS, logIndex=5, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c7]
2019-09-12 10:44:30,241 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102779130360561891 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:30,243 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d: receive RaftClientReply:client-AC76762619D3->25a00999-72ce-4fe5-a995-b18dc52f570d@group-C445A466EBC6, cid=37, SUCCESS, logIndex=6, commits[25a00999-72ce-4fe5-a995-b18dc52f570d:c7]
2019-09-12 10:44:30,257 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=11b228fa-d094-433c-88d8-9c78e4deface, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102779130360561891
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 44998
    }
    ports {
      name: "RATIS"
      value: 35072
    }
    ports {
      name: "STANDALONE"
      value: 42799
    }
    networkName: "25a00999-72ce-4fe5-a995-b18dc52f570d"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "bdca2718-fb76-4226-b53d-c445a466ebc6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,259 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:30,260 [IPC Server handler 11 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,261 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,261 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=11b228fa-d094-433c-88d8-9c78e4deface, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,263 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:30,265 [IPC Server handler 10 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,265 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,266 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=11b228fa-d094-433c-88d8-9c78e4deface, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,272 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102779130360561891 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:30,275 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102779130360561891 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:30,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-12 10:44:30,277 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=11b228fa-d094-433c-88d8-9c78e4deface, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,278 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-12 10:44:30,282 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,295 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=def24754-f969-405c-ba42-784fcf8d5222, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779130366001381
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "66489fb9-4e62-4794-9107-49b6bb0610d6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,301 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779130366001381 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,313 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102779130366001381 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,314 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102779130366001381 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:30,315 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98@group-49B6BB0610D6, cid=38, SUCCESS, logIndex=5, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c7]
2019-09-12 10:44:30,316 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-19A221192E3F->364f652f-ef6f-448e-9b53-5fc05d785e98@group-49B6BB0610D6, cid=39, SUCCESS, logIndex=6, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c7]
2019-09-12 10:44:30,329 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=def24754-f969-405c-ba42-784fcf8d5222, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102779130366001381
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "66489fb9-4e62-4794-9107-49b6bb0610d6"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:30,333 [IPC Server handler 0 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,333 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,334 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=def24754-f969-405c-ba42-784fcf8d5222, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:30,337 [IPC Server handler 1 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:30,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:30,338 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=def24754-f969-405c-ba42-784fcf8d5222, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,341 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 3 locID: 102779130366001381 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:30,345 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 3 locID: 102779130366001381 bcsId: 6} | ret=SUCCESS |  
2019-09-12 10:44:30,346 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-12 10:44:30,347 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=dc234e73-6bf4-452f-b008-9246bb1aead6, bucket=939abfd7-7c8d-454a-a278-e09d96d17219, key=def24754-f969-405c-ba42-784fcf8d5222, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:30,348 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=3} | ret=SUCCESS |  
2019-09-12 10:44:30,362 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {cd85ad82-2faf-4b45-a42a-63af40bd1969=s3Bucket, ozone100=username} | ret=SUCCESS |  
2019-09-12 10:44:30,374 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone100=username, 19047e93-292f-413e-afd5-b11aec36deaa=s3Bucket} | ret=SUCCESS |  
2019-09-12 10:44:30,383 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:30,397 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=cd85ad82-2faf-4b45-a42a-63af40bd1969, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:30,398 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0bd37973-86d4-45de-9796-9098685fde3c, with jenkins1000 as owner.
2019-09-12 10:44:30,411 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0bd37973-86d4-45de-9796-9098685fde3c, creationTime=1568285070399, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:30,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0bd37973-86d4-45de-9796-9098685fde3c} | ret=SUCCESS |  
2019-09-12 10:44:30,412 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0bd37973-86d4-45de-9796-9098685fde3c/325f74ce-3d94-4ff0-86be-2417c035e943, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:30,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285070413} | ret=SUCCESS |  
2019-09-12 10:44:30,431 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943} | ret=SUCCESS |  
2019-09-12 10:44:30,444 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, key=186881ef-f6b2-4586-8079-81202497f2ee, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,458 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, key=186881ef-f6b2-4586-8079-81202497f2ee, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,461 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,475 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, key=186881ef-f6b2-4586-8079-81202497f2ee, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130376749288} | ret=SUCCESS |  
2019-09-12 10:44:30,480 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130377732329 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,483 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130377732329 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:30,498 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, key=186881ef-f6b2-4586-8079-81202497f2ee, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130377732329
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,517 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=0bd37973-86d4-45de-9796-9098685fde3c, bucket=325f74ce-3d94-4ff0-86be-2417c035e943, key=186881ef-f6b2-4586-8079-81202497f2ee, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,519 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-12 10:44:30,524 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-12 10:44:30,527 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ac2c2a75-1299-4abe-9366-a209a7595427, with jenkins1000 as owner.
2019-09-12 10:44:30,540 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ac2c2a75-1299-4abe-9366-a209a7595427, creationTime=1568285070528, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:30,542 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ac2c2a75-1299-4abe-9366-a209a7595427} | ret=SUCCESS |  
2019-09-12 10:44:30,543 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ac2c2a75-1299-4abe-9366-a209a7595427/f1762693-4f22-455d-9a5d-394d47e6b904, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:30,552 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285070544} | ret=SUCCESS |  
2019-09-12 10:44:30,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904} | ret=SUCCESS |  
2019-09-12 10:44:30,567 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,590 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130385203435} | ret=SUCCESS |  
2019-09-12 10:44:30,621 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130386186476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,625 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130386186476 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,638 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130386186476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,642 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130386186476 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:30,653 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130386186476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,659 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130386186476 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:30,669 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130386186476 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,673 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130386186476 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:30,677 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,689 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130385203435} | ret=SUCCESS |  
2019-09-12 10:44:30,700 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130391888109 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,703 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130391888109 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130386186476
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130391888109
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,744 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,746 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,758 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130395492590} | ret=SUCCESS |  
2019-09-12 10:44:30,773 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130396410095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,776 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130396410095 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,786 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130396410095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,792 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130396410095 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:30,802 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130396410095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,805 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130396410095 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:30,815 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130396410095 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,817 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130396410095 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:30,820 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,832 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130395492590} | ret=SUCCESS |  
2019-09-12 10:44:30,842 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130401259760 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,844 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130401259760 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130396410095
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130401259760
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:30,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:30,881 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130404405489} | ret=SUCCESS |  
2019-09-12 10:44:30,906 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130405257458 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,910 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130405257458 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,920 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130405257458 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,923 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130405257458 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:30,932 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130405257458 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,935 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130405257458 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:30,943 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130405257458 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,946 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130405257458 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:30,952 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:30,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130404405489} | ret=SUCCESS |  
2019-09-12 10:44:30,982 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130409910515 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:30,985 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130409910515 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:30,986 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130405257458
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130409910515
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:31,002 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, uploadID=941bdcc8-1686-48ab-8c90-a36a5778ed75-102779130383892714, partNumberMarker=0, maxParts=2, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d} | ret=SUCCESS |  
2019-09-12 10:44:31,004 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=ac2c2a75-1299-4abe-9366-a209a7595427, bucket=f1762693-4f22-455d-9a5d-394d47e6b904, uploadID=941bdcc8-1686-48ab-8c90-a36a5778ed75-102779130383892714, partNumberMarker=2, maxParts=2, key=0c2ff077-18c5-4e81-931b-baf8ec8e081d} | ret=SUCCESS |  
2019-09-12 10:44:31,005 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-35984, with jenkins1000 as owner.
2019-09-12 10:44:31,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-35984, creationTime=1568285071005, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,019 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-35984} | ret=SUCCESS |  
2019-09-12 10:44:31,019 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-35984, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:31,021 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-35984, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-12 10:44:31,025 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 032cd1c8-98bf-4071-b9dd-6144030e2a40, with jenkins1000 as owner.
2019-09-12 10:44:31,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=032cd1c8-98bf-4071-b9dd-6144030e2a40, creationTime=1568285071026, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,038 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=032cd1c8-98bf-4071-b9dd-6144030e2a40} | ret=SUCCESS |  
2019-09-12 10:44:31,039 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 032cd1c8-98bf-4071-b9dd-6144030e2a40/95fda02f-2ef1-4191-9dd2-d0af7576b1f6, with Versioning false and Storage Type set to SSD and Encryption set to false 
2019-09-12 10:44:31,051 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=032cd1c8-98bf-4071-b9dd-6144030e2a40, bucket=95fda02f-2ef1-4191-9dd2-d0af7576b1f6, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=SSD, creationTime=1568285071040} | ret=SUCCESS |  
2019-09-12 10:44:31,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=032cd1c8-98bf-4071-b9dd-6144030e2a40, bucket=95fda02f-2ef1-4191-9dd2-d0af7576b1f6} | ret=SUCCESS |  
2019-09-12 10:44:31,053 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4, with jenkins1000 as owner.
2019-09-12 10:44:31,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4, creationTime=1568285071054, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,067 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4} | ret=SUCCESS |  
2019-09-12 10:44:31,068 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4/9a25e301-34dd-47ac-b2b9-10d95ef60b67, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,081 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4, bucket=9a25e301-34dd-47ac-b2b9-10d95ef60b67, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS], user:test1:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071069} | ret=SUCCESS |  
2019-09-12 10:44:31,098 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4, bucket=9a25e301-34dd-47ac-b2b9-10d95ef60b67, key=null} | ret=SUCCESS |  
2019-09-12 10:44:31,100 [IPC Server handler 11 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-775_850 to index:850
2019-09-12 10:44:31,100 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_775-850
2019-09-12 10:44:31,103 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,126 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851
2019-09-12 10:44:31,139 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=1dfa2fcb-4bc6-4408-ab98-fa81efd5f1a4, bucket=9a25e301-34dd-47ac-b2b9-10d95ef60b67, key=null} | ret=SUCCESS |  
2019-09-12 10:44:31,140 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6f7a5520-3d71-4598-8855-ad06ca48c212, with jenkins1000 as owner.
2019-09-12 10:44:31,150 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6f7a5520-3d71-4598-8855-ad06ca48c212, creationTime=1568285071140, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,151 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6f7a5520-3d71-4598-8855-ad06ca48c212} | ret=SUCCESS |  
2019-09-12 10:44:31,152 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6f7a5520-3d71-4598-8855-ad06ca48c212/aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,163 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071153} | ret=SUCCESS |  
2019-09-12 10:44:31,163 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515} | ret=SUCCESS |  
2019-09-12 10:44:31,165 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:31,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, key=9adf8e66-5829-43d6-a75c-95626dbd9e22, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130423869684
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:31,180 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130423869684 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:31,182 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130423869684 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:31,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, key=9adf8e66-5829-43d6-a75c-95626dbd9e22, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130423869684
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:31,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:31,197 [IPC Server handler 8 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:31,197 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:31,197 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, key=9adf8e66-5829-43d6-a75c-95626dbd9e22, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:31,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, key=9adf8e66-5829-43d6-a75c-95626dbd9e22, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,213 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6f7a5520-3d71-4598-8855-ad06ca48c212, bucket=aaad56c8-4f4d-47dc-b6de-e6b33ec1d515, key=9adf8e66-5829-43d6-a75c-95626dbd9e22, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-12 10:44:31,217 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 9befe28f-92b0-4720-ba67-bb0f2aa5975f, with jenkins1000 as owner.
2019-09-12 10:44:31,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=9befe28f-92b0-4720-ba67-bb0f2aa5975f, creationTime=1568285071217, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,252 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9befe28f-92b0-4720-ba67-bb0f2aa5975f} | ret=SUCCESS |  
2019-09-12 10:44:31,270 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_VOLUME {volume=9befe28f-92b0-4720-ba67-bb0f2aa5975f} | ret=SUCCESS |  
2019-09-12 10:44:31,272 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9befe28f-92b0-4720-ba67-bb0f2aa5975f} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume 9befe28f-92b0-4720-ba67-bb0f2aa5975f is not found
	at org.apache.hadoop.ozone.om.VolumeManagerImpl.getVolumeInfo(VolumeManagerImpl.java:326)
	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1933) 
2019-09-12 10:44:31,279 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 19a72062-7ae9-471e-b541-3a168ee7f47b, with jenkins1000 as owner.
2019-09-12 10:44:31,292 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=19a72062-7ae9-471e-b541-3a168ee7f47b, creationTime=1568285071280, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,293 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=19a72062-7ae9-471e-b541-3a168ee7f47b} | ret=SUCCESS |  
2019-09-12 10:44:31,299 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c2b34496-7518-41f7-afff-40dda52efae2, with jenkins1000 as owner.
2019-09-12 10:44:31,311 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c2b34496-7518-41f7-afff-40dda52efae2, creationTime=1568285071300, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,312 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c2b34496-7518-41f7-afff-40dda52efae2} | ret=SUCCESS |  
2019-09-12 10:44:31,313 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c2b34496-7518-41f7-afff-40dda52efae2/d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,325 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071313} | ret=SUCCESS |  
2019-09-12 10:44:31,327 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296} | ret=SUCCESS |  
2019-09-12 10:44:31,329 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:31,342 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, key=360097d9-4b7f-4e01-ad90-83bb859af5dd, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102779130434617590
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "80c267d5-f3cd-41d0-b18e-5a02e043b186"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:31,432 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102779130434617590 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:31,432 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,435 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102779130434617590 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:31,439 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-1ADF0D6B328E->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-1ADF0D6B328E->364f652f-ef6f-448e-9b53-5fc05d785e98@group-5A02E043B186, cid=40, SUCCESS, logIndex=1, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c2]
2019-09-12 10:44:31,445 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,513 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 8 locID: 102779130434617590 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:31,517 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-1ADF0D6B328E->364f652f-ef6f-448e-9b53-5fc05d785e98: receive RaftClientReply:client-1ADF0D6B328E->364f652f-ef6f-448e-9b53-5fc05d785e98@group-5A02E043B186, cid=41, SUCCESS, logIndex=3, commits[364f652f-ef6f-448e-9b53-5fc05d785e98:c4]
2019-09-12 10:44:31,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, key=360097d9-4b7f-4e01-ad90-83bb859af5dd, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102779130434617590
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "80c267d5-f3cd-41d0-b18e-5a02e043b186"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:31,533 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-12 10:44:31,534 [IPC Server handler 16 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:31,535 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:31,535 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, key=360097d9-4b7f-4e01-ad90-83bb859af5dd, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:31,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-12 10:44:31,551 [IPC Server handler 12 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:31,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:31,662 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c2b34496-7518-41f7-afff-40dda52efae2, bucket=d2cfa7da-1d8f-4e80-bb4f-f0bc0c7a8296, key=360097d9-4b7f-4e01-ad90-83bb859af5dd, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
Sep 12, 2019 10:44:31 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=132, target=192.168.36.114:41370} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:175)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:423)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:372)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:285)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:167)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:222)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagDisable(TestOzoneRpcClientAbstract.java:905)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

2019-09-12 10:44:31,703 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 8 locID: 102779130434617590 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:31,707 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 8 locID: 102779130434617590 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:31,708 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "164c6568c367f35f:164c6568c367f35f:0:0"
containerID: 8
datanodeUuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
readChunk {
  blockID {
    containerID: 8
    localID: 102779130434617590
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779130434617590_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 364f652f-ef6f-448e-9b53-5fc05d785e98
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagEnable(TestOzoneRpcClientAbstract.java:890)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:44:31,709 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "164c6568c367f35f:164c6568c367f35f:0:0"
containerID: 8
datanodeUuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
readChunk {
  blockID {
    containerID: 8
    localID: 102779130434617590
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779130434617590_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: 80c267d5-f3cd-41d0-b18e-5a02e043b186, Nodes: 364f652f-ef6f-448e-9b53-5fc05d785e98{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-12 10:44:31,710 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3f29238a-ffc1-4eea-9143-7bf3a448ad8d, with jenkins1000 as owner.
2019-09-12 10:44:31,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d, creationTime=1568285071712, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,726 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d} | ret=SUCCESS |  
2019-09-12 10:44:31,727 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 3f29238a-ffc1-4eea-9143-7bf3a448ad8d/939b9229-8739-4dc8-94dc-2f4fb7949a29, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,741 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d, bucket=939b9229-8739-4dc8-94dc-2f4fb7949a29, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071728} | ret=SUCCESS |  
2019-09-12 10:44:31,742 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d, bucket=939b9229-8739-4dc8-94dc-2f4fb7949a29} | ret=SUCCESS |  
2019-09-12 10:44:31,751 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d, bucket=939b9229-8739-4dc8-94dc-2f4fb7949a29, key=a1e3d34d-2de2-41eb-b593-29143030995e, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=3f29238a-ffc1-4eea-9143-7bf3a448ad8d, bucket=939b9229-8739-4dc8-94dc-2f4fb7949a29, key=a1e3d34d-2de2-41eb-b593-29143030995e, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,765 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0c8bcbed-ca47-48d4-b533-d7179daa367e, with jenkins1000 as owner.
2019-09-12 10:44:31,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0c8bcbed-ca47-48d4-b533-d7179daa367e, creationTime=1568285071766, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,780 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0c8bcbed-ca47-48d4-b533-d7179daa367e} | ret=SUCCESS |  
2019-09-12 10:44:31,781 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0c8bcbed-ca47-48d4-b533-d7179daa367e/7849e9c2-a031-45ba-87c6-7cb5ac17736d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,793 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0c8bcbed-ca47-48d4-b533-d7179daa367e, bucket=7849e9c2-a031-45ba-87c6-7cb5ac17736d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071781} | ret=SUCCESS |  
2019-09-12 10:44:31,794 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0c8bcbed-ca47-48d4-b533-d7179daa367e, bucket=7849e9c2-a031-45ba-87c6-7cb5ac17736d} | ret=SUCCESS |  
2019-09-12 10:44:31,795 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 93902335-d960-4eac-9a73-74718c4b6e36, with jenkins1000 as owner.
2019-09-12 10:44:31,802 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=93902335-d960-4eac-9a73-74718c4b6e36, creationTime=1568285071795, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=93902335-d960-4eac-9a73-74718c4b6e36} | ret=SUCCESS |  
2019-09-12 10:44:31,804 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 93902335-d960-4eac-9a73-74718c4b6e36/3468665f-d28a-4327-b479-1192d24c3275, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,817 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=93902335-d960-4eac-9a73-74718c4b6e36, bucket=3468665f-d28a-4327-b479-1192d24c3275, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071805} | ret=SUCCESS |  
2019-09-12 10:44:31,818 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=93902335-d960-4eac-9a73-74718c4b6e36, bucket=3468665f-d28a-4327-b479-1192d24c3275} | ret=SUCCESS |  
2019-09-12 10:44:31,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=93902335-d960-4eac-9a73-74718c4b6e36, bucket=3468665f-d28a-4327-b479-1192d24c3275, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-12 10:44:31,831 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=93902335-d960-4eac-9a73-74718c4b6e36, bucket=3468665f-d28a-4327-b479-1192d24c3275} | ret=SUCCESS |  
2019-09-12 10:44:31,832 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c, with jenkins1000 as owner.
2019-09-12 10:44:31,845 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c, creationTime=1568285071833, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c} | ret=SUCCESS |  
2019-09-12 10:44:31,846 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c/a0684f15-b9ce-4d2d-bae4-3a5990f3db37, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,858 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c, bucket=a0684f15-b9ce-4d2d-bae4-3a5990f3db37, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071847} | ret=SUCCESS |  
2019-09-12 10:44:31,859 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c, bucket=a0684f15-b9ce-4d2d-bae4-3a5990f3db37} | ret=SUCCESS |  
2019-09-12 10:44:31,873 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c, bucket=a0684f15-b9ce-4d2d-bae4-3a5990f3db37, key=818ffde8-d5b4-408b-b0a4-bbc0daa59734, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: fecb93c2-bbf3-4e5f-98f3-ddbaa882c86cbucket: a0684f15-b9ce-4d2d-bae4-3a5990f3db37key: 818ffde8-d5b4-408b-b0a4-bbc0daa59734
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:31,875 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest (S3MultipartUploadAbortRequest.java:validateAndUpdateCache(167)) - Abort Multipart request is failed for KeyName 818ffde8-d5b4-408b-b0a4-bbc0daa59734 in VolumeName/Bucket fecb93c2-bbf3-4e5f-98f3-ddbaa882c86c/a0684f15-b9ce-4d2d-bae4-3a5990f3db37
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: fecb93c2-bbf3-4e5f-98f3-ddbaa882c86cbucket: a0684f15-b9ce-4d2d-bae4-3a5990f3db37key: 818ffde8-d5b4-408b-b0a4-bbc0daa59734
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:31,888 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ad5bc699-2979-4eb3-82c8-44a4e58de9fb=s3Bucket, ozone=username} | ret=SUCCESS |  
2019-09-12 10:44:31,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone} | ret=SUCCESS |  
2019-09-12 10:44:31,892 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone, bucket=ad5bc699-2979-4eb3-82c8-44a4e58de9fb} | ret=SUCCESS |  
2019-09-12 10:44:31,895 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: d28f5a5e-0325-4eab-92d6-c2961807154c, with jenkins1000 as owner.
2019-09-12 10:44:31,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=d28f5a5e-0325-4eab-92d6-c2961807154c, creationTime=1568285071896, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:31,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=d28f5a5e-0325-4eab-92d6-c2961807154c} | ret=SUCCESS |  
2019-09-12 10:44:31,909 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: d28f5a5e-0325-4eab-92d6-c2961807154c/79c4f637-9388-4d2c-b29e-d4df438e044f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:31,911 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=d28f5a5e-0325-4eab-92d6-c2961807154c, bucket=79c4f637-9388-4d2c-b29e-d4df438e044f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285071910} | ret=SUCCESS |  
2019-09-12 10:44:31,912 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=d28f5a5e-0325-4eab-92d6-c2961807154c, bucket=79c4f637-9388-4d2c-b29e-d4df438e044f} | ret=SUCCESS |  
2019-09-12 10:44:31,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=d28f5a5e-0325-4eab-92d6-c2961807154c, bucket=79c4f637-9388-4d2c-b29e-d4df438e044f, key=06a9be88-86c0-41de-aba7-ebbef6d16d09, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=d28f5a5e-0325-4eab-92d6-c2961807154c, bucket=79c4f637-9388-4d2c-b29e-d4df438e044f, key=06a9be88-86c0-41de-aba7-ebbef6d16d09, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,935 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,935 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,935 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,936 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,936 [IPC Server handler 7 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,936 [IPC Server handler 7 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,937 [IPC Server handler 7 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,937 [IPC Server handler 7 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,937 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,938 [IPC Server handler 11 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38955, call Call#977 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,942 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:31,944 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,944 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,944 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,944 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,944 [IPC Server handler 13 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,945 [IPC Server handler 13 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,945 [IPC Server handler 13 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,945 [IPC Server handler 13 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,946 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,946 [IPC Server handler 6 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38955, call Call#977 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,948 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,950 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,950 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,950 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,950 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,951 [IPC Server handler 15 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,951 [IPC Server handler 15 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,951 [IPC Server handler 15 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,951 [IPC Server handler 15 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,952 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,952 [IPC Server handler 5 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38955, call Call#977 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,954 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,955 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,956 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,956 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,958 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,959 [IPC Server handler 17 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,959 [IPC Server handler 17 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,959 [IPC Server handler 17 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,959 [IPC Server handler 17 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,960 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,960 [IPC Server handler 4 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38955, call Call#977 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,962 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,963 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,964 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,964 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,964 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,964 [IPC Server handler 4 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,965 [IPC Server handler 4 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,965 [IPC Server handler 4 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,965 [IPC Server handler 4 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,966 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,966 [IPC Server handler 19 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 38955, call Call#977 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,968 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,970 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,970 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,970 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,971 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,971 [IPC Server handler 8 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,971 [IPC Server handler 8 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,971 [IPC Server handler 8 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,972 [IPC Server handler 8 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,972 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,972 [IPC Server handler 0 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 38955, call Call#977 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,978 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,979 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,980 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,980 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,980 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,980 [IPC Server handler 11 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,980 [IPC Server handler 11 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,984 [IPC Server handler 11 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,984 [IPC Server handler 11 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,984 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,985 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:31,985 [IPC Server handler 2 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 38955, call Call#977 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,989 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,994 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,994 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,994 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,994 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,994 [IPC Server handler 10 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,995 [IPC Server handler 10 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,995 [IPC Server handler 10 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:31,995 [IPC Server handler 10 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:31,995 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:31,996 [IPC Server handler 1 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 38955, call Call#977 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,997 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:31,998 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:31,998 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,998 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:31,999 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,999 [IPC Server handler 18 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:31,999 [IPC Server handler 18 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:31,999 [IPC Server handler 18 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,000 [IPC Server handler 18 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,000 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,000 [IPC Server handler 3 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 38955, call Call#977 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,001 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,002 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,002 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,003 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,003 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,003 [IPC Server handler 0 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,003 [IPC Server handler 0 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,004 [IPC Server handler 0 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,004 [IPC Server handler 0 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,004 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,005 [IPC Server handler 18 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 38955, call Call#977 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,005 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,006 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,007 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,007 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,007 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,007 [IPC Server handler 1 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,007 [IPC Server handler 1 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,008 [IPC Server handler 1 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,008 [IPC Server handler 1 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,008 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,008 [IPC Server handler 15 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 38955, call Call#977 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,009 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:32,010 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUploadOverride(TestOzoneRpcClientAbstract.java:1848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:44:32,016 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: eb4694ee-679b-4bc7-9b32-03a66f1f21de, with jenkins1000 as owner.
2019-09-12 10:44:32,025 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, creationTime=1568285072018, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,026 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de} | ret=SUCCESS |  
2019-09-12 10:44:32,027 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: eb4694ee-679b-4bc7-9b32-03a66f1f21de/97280fe0-281f-4059-a579-3c4928c1f8e0, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,036 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, bucket=97280fe0-281f-4059-a579-3c4928c1f8e0, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072028} | ret=SUCCESS |  
2019-09-12 10:44:32,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, bucket=97280fe0-281f-4059-a579-3c4928c1f8e0} | ret=SUCCESS |  
2019-09-12 10:44:32,039 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,054 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, bucket=97280fe0-281f-4059-a579-3c4928c1f8e0, key=9a16e48a-b81b-4419-9a8f-fbe67e9ef80a, dataSize=4194304, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130481148155
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,059 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130481148155 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,061 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130481148155 bcsId: 0,size=775]} | ret=SUCCESS |  
2019-09-12 10:44:32,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, bucket=97280fe0-281f-4059-a579-3c4928c1f8e0, key=9a16e48a-b81b-4419-9a8f-fbe67e9ef80a, dataSize=775, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130481148155
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 775
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,077 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,077 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=eb4694ee-679b-4bc7-9b32-03a66f1f21de, bucket=97280fe0-281f-4059-a579-3c4928c1f8e0, key=9a16e48a-b81b-4419-9a8f-fbe67e9ef80a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,078 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4d9cebc5-6679-4ea0-99d8-25b0ec316106, with jenkins1000 as owner.
2019-09-12 10:44:32,091 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106, creationTime=1568285072079, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,092 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106} | ret=SUCCESS |  
2019-09-12 10:44:32,092 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4d9cebc5-6679-4ea0-99d8-25b0ec316106/360e62d5-0dd0-4de5-89f6-85852855e1bf, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,104 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106, bucket=360e62d5-0dd0-4de5-89f6-85852855e1bf, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072093} | ret=SUCCESS |  
2019-09-12 10:44:32,105 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106, bucket=360e62d5-0dd0-4de5-89f6-85852855e1bf} | ret=SUCCESS |  
2019-09-12 10:44:32,117 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106, bucket=360e62d5-0dd0-4de5-89f6-85852855e1bf, key=0391dd59-f9e6-4fdd-81a9-7d2be4e63610, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:32,131 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=4d9cebc5-6679-4ea0-99d8-25b0ec316106, bucket=360e62d5-0dd0-4de5-89f6-85852855e1bf, key=0391dd59-f9e6-4fdd-81a9-7d2be4e63610, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=6b224fec-febf-470f-a0b3-1671900bb7ae}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 4d9cebc5-6679-4ea0-99d8-25b0ec316106bucket: 360e62d5-0dd0-4de5-89f6-85852855e1bfkey: 0391dd59-f9e6-4fdd-81a9-7d2be4e63610
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:32,134 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 0391dd59-f9e6-4fdd-81a9-7d2be4e63610 in Volume/Bucket 4d9cebc5-6679-4ea0-99d8-25b0ec316106/360e62d5-0dd0-4de5-89f6-85852855e1bf
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 4d9cebc5-6679-4ea0-99d8-25b0ec316106bucket: 360e62d5-0dd0-4de5-89f6-85852855e1bfkey: 0391dd59-f9e6-4fdd-81a9-7d2be4e63610
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:32,136 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 76cd9d70-cd01-4bb5-b23c-1d10ae37c965, with jenkins1000 as owner.
2019-09-12 10:44:32,148 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=76cd9d70-cd01-4bb5-b23c-1d10ae37c965, creationTime=1568285072136, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=76cd9d70-cd01-4bb5-b23c-1d10ae37c965} | ret=SUCCESS |  
2019-09-12 10:44:32,150 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 76cd9d70-cd01-4bb5-b23c-1d10ae37c965/a06e2588-334f-41e2-96aa-80978d37c5bb, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,163 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=76cd9d70-cd01-4bb5-b23c-1d10ae37c965, bucket=a06e2588-334f-41e2-96aa-80978d37c5bb, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072151} | ret=SUCCESS |  
2019-09-12 10:44:32,164 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=76cd9d70-cd01-4bb5-b23c-1d10ae37c965, bucket=a06e2588-334f-41e2-96aa-80978d37c5bb} | ret=SUCCESS |  
2019-09-12 10:44:32,177 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRequest (OMKeyRequest.java:prepareCreateKeyResponse(331)) - ALLOCATE_KEY failed for Key: df079c4e-6bbe-4f31-b22d-0079aa7b820c in volume/bucket:76cd9d70-cd01-4bb5-b23c-1d10ae37c965/a06e2588-334f-41e2-96aa-80978d37c5bb
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422)
	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:179)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:32,178 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=76cd9d70-cd01-4bb5-b23c-1d10ae37c965, bucket=a06e2588-334f-41e2-96aa-80978d37c5bb, key=df079c4e-6bbe-4f31-b22d-0079aa7b820c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422) 
2019-09-12 10:44:32,179 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6f3349a0-e90d-442d-aae2-5984e1c33f35, with jenkins1000 as owner.
2019-09-12 10:44:32,182 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6f3349a0-e90d-442d-aae2-5984e1c33f35, creationTime=1568285072180, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6f3349a0-e90d-442d-aae2-5984e1c33f35} | ret=SUCCESS |  
2019-09-12 10:44:32,183 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6f3349a0-e90d-442d-aae2-5984e1c33f35/13c8609d-8293-46ce-9c96-32d58e355bb1, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,186 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6f3349a0-e90d-442d-aae2-5984e1c33f35, bucket=13c8609d-8293-46ce-9c96-32d58e355bb1, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072184} | ret=SUCCESS |  
2019-09-12 10:44:32,187 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6f3349a0-e90d-442d-aae2-5984e1c33f35, bucket=13c8609d-8293-46ce-9c96-32d58e355bb1} | ret=SUCCESS |  
2019-09-12 10:44:32,189 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,190 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,190 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,190 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,190 [IPC Server handler 16 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,190 [IPC Server handler 16 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,191 [IPC Server handler 16 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,191 [IPC Server handler 16 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,191 [IPC Server handler 13 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 38955, call Call#1013 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,192 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:32,194 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,194 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,194 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,194 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,195 [IPC Server handler 12 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,195 [IPC Server handler 12 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,195 [IPC Server handler 12 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,195 [IPC Server handler 12 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,196 [IPC Server handler 16 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38955, call Call#1013 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,197 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,198 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,199 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,199 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,199 [IPC Server handler 14 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,199 [IPC Server handler 14 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,199 [IPC Server handler 14 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,200 [IPC Server handler 14 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,200 [IPC Server handler 14 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,200 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,200 [IPC Server handler 12 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38955, call Call#1013 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,201 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,202 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,203 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,203 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,203 [IPC Server handler 19 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,204 [IPC Server handler 19 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,204 [IPC Server handler 19 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,204 [IPC Server handler 19 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,205 [IPC Server handler 19 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,205 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,205 [IPC Server handler 10 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38955, call Call#1013 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,206 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,207 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,207 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,208 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,208 [IPC Server handler 5 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,208 [IPC Server handler 5 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,208 [IPC Server handler 5 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,209 [IPC Server handler 5 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,209 [IPC Server handler 5 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,209 [IPC Server handler 14 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38955, call Call#1013 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,210 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,211 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,211 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,212 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,212 [IPC Server handler 2 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,212 [IPC Server handler 2 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,212 [IPC Server handler 2 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,213 [IPC Server handler 2 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,213 [IPC Server handler 2 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,213 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,213 [IPC Server handler 7 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38955, call Call#1013 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,214 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,215 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,216 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,216 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,216 [IPC Server handler 6 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,216 [IPC Server handler 6 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,216 [IPC Server handler 6 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,217 [IPC Server handler 6 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,217 [IPC Server handler 6 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,217 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,217 [IPC Server handler 8 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38955, call Call#1013 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,218 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,220 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,220 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,220 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,220 [IPC Server handler 3 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,221 [IPC Server handler 3 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,221 [IPC Server handler 3 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,221 [IPC Server handler 3 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,221 [IPC Server handler 3 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,222 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,222 [IPC Server handler 9 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38955, call Call#1013 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,223 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,224 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,224 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,224 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,225 [IPC Server handler 7 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,225 [IPC Server handler 7 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,225 [IPC Server handler 7 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,226 [IPC Server handler 7 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,226 [IPC Server handler 7 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,227 [IPC Server handler 11 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38955, call Call#1013 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,227 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,228 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,229 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,229 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,229 [IPC Server handler 13 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,229 [IPC Server handler 13 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,230 [IPC Server handler 13 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,230 [IPC Server handler 13 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,230 [IPC Server handler 13 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,231 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,231 [IPC Server handler 6 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38955, call Call#1013 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,232 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,233 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,233 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,234 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,234 [IPC Server handler 15 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,234 [IPC Server handler 15 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,234 [IPC Server handler 15 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,235 [IPC Server handler 15 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,235 [IPC Server handler 15 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,235 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,236 [IPC Server handler 5 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38955, call Call#1013 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,236 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:32,238 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-13829, with jenkins1000 as owner.
2019-09-12 10:44:32,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-13829, creationTime=1568285072239, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,250 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-13829} | ret=SUCCESS |  
2019-09-12 10:44:32,251 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-13829/buc-66127, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,273 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-13829, bucket=buc-66127, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072252} | ret=SUCCESS |  
2019-09-12 10:44:32,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-13829, bucket=buc-66127} | ret=SUCCESS |  
2019-09-12 10:44:32,276 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-13829, bucket=buc-66127, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-12 10:44:32,277 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-13829, bucket=buc-66127, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-12 10:44:32,278 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa, with jenkins1000 as owner.
2019-09-12 10:44:32,290 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa, creationTime=1568285072279, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,291 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa} | ret=SUCCESS |  
2019-09-12 10:44:32,292 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa/19203c13-9e0f-4724-910c-68e95937877c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa, bucket=19203c13-9e0f-4724-910c-68e95937877c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072293} | ret=SUCCESS |  
2019-09-12 10:44:32,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=65ec098a-ec86-4fd3-a71f-5e47c3c7d7fa, bucket=19203c13-9e0f-4724-910c-68e95937877c} | ret=SUCCESS |  
2019-09-12 10:44:32,307 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,308 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,308 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,308 [IPC Server handler 17 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,308 [IPC Server handler 17 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,309 [IPC Server handler 17 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,309 [IPC Server handler 17 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,309 [IPC Server handler 17 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,309 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,310 [IPC Server handler 16 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 38955, call Call#1035 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,310 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955. Trying to failover immediately.
2019-09-12 10:44:32,312 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,312 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,312 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,313 [IPC Server handler 4 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,313 [IPC Server handler 4 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,313 [IPC Server handler 4 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,314 [IPC Server handler 4 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,314 [IPC Server handler 4 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,314 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,314 [IPC Server handler 12 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 38955, call Call#1035 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,315 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 1 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,317 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,317 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,317 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,317 [IPC Server handler 8 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,318 [IPC Server handler 8 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,318 [IPC Server handler 8 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,319 [IPC Server handler 8 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,319 [IPC Server handler 8 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,319 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,319 [IPC Server handler 10 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 38955, call Call#1035 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,320 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 2 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,322 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,322 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,322 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,323 [IPC Server handler 11 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,323 [IPC Server handler 11 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,323 [IPC Server handler 11 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,324 [IPC Server handler 11 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,324 [IPC Server handler 11 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,324 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,325 [IPC Server handler 14 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 38955, call Call#1035 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,325 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 3 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,327 [IPC Server handler 10 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,328 [IPC Server handler 10 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,328 [IPC Server handler 10 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,328 [IPC Server handler 7 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 38955, call Call#1035 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,329 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 4 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,330 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,331 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,331 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,331 [IPC Server handler 18 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,331 [IPC Server handler 18 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,331 [IPC Server handler 18 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,332 [IPC Server handler 18 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,332 [IPC Server handler 18 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,333 [IPC Server handler 8 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 38955, call Call#1035 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,333 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 5 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,335 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,335 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,335 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,335 [IPC Server handler 0 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,335 [IPC Server handler 0 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,336 [IPC Server handler 0 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,336 [IPC Server handler 0 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,336 [IPC Server handler 0 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,337 [IPC Server handler 9 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 38955, call Call#1035 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,337 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 6 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,339 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,339 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,339 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,339 [IPC Server handler 1 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,340 [IPC Server handler 1 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,340 [IPC Server handler 1 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,340 [IPC Server handler 1 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,340 [IPC Server handler 1 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,341 [IPC Server handler 11 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 38955, call Call#1035 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,342 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 7 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,343 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,343 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,343 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,343 [IPC Server handler 9 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,344 [IPC Server handler 9 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,344 [IPC Server handler 9 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,344 [IPC Server handler 9 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,344 [IPC Server handler 9 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,344 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,345 [IPC Server handler 6 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 38955, call Call#1035 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,345 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 8 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,347 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,347 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,347 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,348 [IPC Server handler 16 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,348 [IPC Server handler 16 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,348 [IPC Server handler 16 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,348 [IPC Server handler 16 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,349 [IPC Server handler 16 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,349 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,349 [IPC Server handler 5 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 38955, call Call#1035 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,350 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:38955 after 9 failover attempts. Trying to failover immediately.
2019-09-12 10:44:32,351 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-12 10:44:32,351 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,352 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(92)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-12 10:44:32,352 [IPC Server handler 12 on 45226] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(147)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,352 [IPC Server handler 12 on 45226] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-12 10:44:32,352 [IPC Server handler 12 on 45226] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:148)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:171)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:100)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-12 10:44:32,353 [IPC Server handler 12 on 45226] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-12 10:44:32,353 [IPC Server handler 12 on 45226] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-12 10:44:32,353 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-12 10:44:32,354 [IPC Server handler 4 on 38955] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 38955, call Call#1035 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:46102
java.lang.NullPointerException
2019-09-12 10:44:32,354 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-12 10:44:32,356 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 34b270bd-646d-49bd-8704-7b9696ea15b6, with jenkins1000 as owner.
2019-09-12 10:44:32,369 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=34b270bd-646d-49bd-8704-7b9696ea15b6, creationTime=1568285072357, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,370 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=34b270bd-646d-49bd-8704-7b9696ea15b6} | ret=SUCCESS |  
2019-09-12 10:44:32,371 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 34b270bd-646d-49bd-8704-7b9696ea15b6/20d5c166-8748-4581-b2b8-11ad4001e774, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,383 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072372} | ret=SUCCESS |  
2019-09-12 10:44:32,385 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774} | ret=SUCCESS |  
2019-09-12 10:44:32,386 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,400 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=9f2fb36e-1565-4d05-8696-3258c5c845aa, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130503889151
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,404 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130503889151 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,407 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130503889151 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,420 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=9f2fb36e-1565-4d05-8696-3258c5c845aa, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130503889151
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,422 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,423 [IPC Server handler 19 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,423 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,424 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=9f2fb36e-1565-4d05-8696-3258c5c845aa, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,426 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,427 [IPC Server handler 5 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,427 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,427 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=9f2fb36e-1565-4d05-8696-3258c5c845aa, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,430 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130503889151 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,432 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:32,440 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130503889151 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,441 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,442 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=9f2fb36e-1565-4d05-8696-3258c5c845aa, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,443 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,444 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,445 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:32,457 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a8ce346a-4272-4842-908f-12c8cbca8975, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130507690241
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,462 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130507690241 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,464 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130507690241 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,478 [Thread-141] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-851_955 to index:955
2019-09-12 10:44:32,479 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_851-955
2019-09-12 10:44:32,479 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a8ce346a-4272-4842-908f-12c8cbca8975, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130507690241
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,481 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,482 [IPC Server handler 6 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,483 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,483 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a8ce346a-4272-4842-908f-12c8cbca8975, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,485 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,486 [IPC Server handler 3 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,486 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,487 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a8ce346a-4272-4842-908f-12c8cbca8975, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,490 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130507690241 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,495 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130507690241 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,498 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a8ce346a-4272-4842-908f-12c8cbca8975, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,500 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,504 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956
2019-09-12 10:44:32,505 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=26a8d906-fd17-4057-826f-24526e66db4c, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130511360259
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,509 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130511360259 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,511 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130511360259 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=26a8d906-fd17-4057-826f-24526e66db4c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130511360259
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,524 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,525 [IPC Server handler 13 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,525 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,525 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=26a8d906-fd17-4057-826f-24526e66db4c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,527 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,531 [IPC Server handler 15 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,533 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=26a8d906-fd17-4057-826f-24526e66db4c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,538 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130511360259 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,542 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130511360259 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,544 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,545 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=26a8d906-fd17-4057-826f-24526e66db4c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,545 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,560 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=4c2759c3-eec4-497d-bed8-8c59a70f3e7b, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130514440453
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,564 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130514440453 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,566 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130514440453 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,580 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=4c2759c3-eec4-497d-bed8-8c59a70f3e7b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130514440453
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,583 [IPC Server handler 4 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,584 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=4c2759c3-eec4-497d-bed8-8c59a70f3e7b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,586 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,587 [IPC Server handler 8 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,587 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=4c2759c3-eec4-497d-bed8-8c59a70f3e7b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,590 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130514440453 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,594 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130514440453 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,595 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,596 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=4c2759c3-eec4-497d-bed8-8c59a70f3e7b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,597 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,598 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,611 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=6701bd95-ba14-4b2f-9aeb-704d053f46f3, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130517782791
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,614 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130517782791 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,617 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130517782791 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,630 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=6701bd95-ba14-4b2f-9aeb-704d053f46f3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130517782791
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,632 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,633 [IPC Server handler 10 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,633 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=6701bd95-ba14-4b2f-9aeb-704d053f46f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,635 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,636 [IPC Server handler 18 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,637 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,637 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=6701bd95-ba14-4b2f-9aeb-704d053f46f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,640 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130517782791 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,647 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130517782791 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,649 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,649 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=6701bd95-ba14-4b2f-9aeb-704d053f46f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,650 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,651 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,665 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=20676923-fe5a-4904-b29e-8a957ded5652, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130521256201
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,668 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130521256201 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,671 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130521256201 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,685 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=20676923-fe5a-4904-b29e-8a957ded5652, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130521256201
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,686 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,687 [IPC Server handler 1 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,688 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,688 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=20676923-fe5a-4904-b29e-8a957ded5652, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,690 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,691 [IPC Server handler 9 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,691 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=20676923-fe5a-4904-b29e-8a957ded5652, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,694 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130521256201 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,696 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130521256201 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,698 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,698 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=20676923-fe5a-4904-b29e-8a957ded5652, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,699 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,700 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,713 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a76433f5-7821-4b11-a3c1-609018d1e191, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130524467467
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,716 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130524467467 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,718 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130524467467 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,733 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a76433f5-7821-4b11-a3c1-609018d1e191, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130524467467
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,735 [IPC Server handler 12 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,736 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a76433f5-7821-4b11-a3c1-609018d1e191, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,739 [IPC Server handler 14 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,739 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a76433f5-7821-4b11-a3c1-609018d1e191, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,742 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130524467467 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,744 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130524467467 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,745 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,746 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=a76433f5-7821-4b11-a3c1-609018d1e191, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,746 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,748 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=445d8995-acf8-4867-a0eb-7a217d50435a, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130527613197
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,765 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130527613197 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,767 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130527613197 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,781 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=445d8995-acf8-4867-a0eb-7a217d50435a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130527613197
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,783 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,784 [IPC Server handler 5 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,784 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=445d8995-acf8-4867-a0eb-7a217d50435a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,786 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,787 [IPC Server handler 2 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,788 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=445d8995-acf8-4867-a0eb-7a217d50435a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,791 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130527613197 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,794 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130527613197 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,795 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,796 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=445d8995-acf8-4867-a0eb-7a217d50435a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,797 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,799 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=0b01d0fb-d7b1-46e4-a158-f7ded176a657, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130530955535
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,816 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130530955535 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,819 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130530955535 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,833 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=0b01d0fb-d7b1-46e4-a158-f7ded176a657, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130530955535
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,834 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,835 [IPC Server handler 3 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,836 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,836 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=0b01d0fb-d7b1-46e4-a158-f7ded176a657, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,838 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,839 [IPC Server handler 7 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,839 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=0b01d0fb-d7b1-46e4-a158-f7ded176a657, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,842 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130530955535 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,845 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130530955535 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,846 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,846 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=0b01d0fb-d7b1-46e4-a158-f7ded176a657, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,847 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,848 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=66a6f4f6-8092-4c66-9435-c22a21ee5f25, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130534166801
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,864 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130534166801 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,866 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130534166801 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:32,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=66a6f4f6-8092-4c66-9435-c22a21ee5f25, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130534166801
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,881 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,882 [IPC Server handler 15 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,882 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,882 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=66a6f4f6-8092-4c66-9435-c22a21ee5f25, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,884 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,885 [IPC Server handler 17 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:32,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:32,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=66a6f4f6-8092-4c66-9435-c22a21ee5f25, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,888 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102779130534166801 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,890 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102779130534166801 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:32,891 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-12 10:44:32,892 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=34b270bd-646d-49bd-8704-7b9696ea15b6, bucket=20d5c166-8748-4581-b2b8-11ad4001e774, key=66a6f4f6-8092-4c66-9435-c22a21ee5f25, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:32,892 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-12 10:44:32,893 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 622ba443-9de0-41e8-a2d7-363497943f62, with jenkins1000 as owner.
2019-09-12 10:44:32,906 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=622ba443-9de0-41e8-a2d7-363497943f62, creationTime=1568285072894, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:32,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=622ba443-9de0-41e8-a2d7-363497943f62} | ret=SUCCESS |  
2019-09-12 10:44:32,908 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 622ba443-9de0-41e8-a2d7-363497943f62/a012a54a-3580-440b-8a9d-b7e121108308, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:32,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285072908} | ret=SUCCESS |  
2019-09-12 10:44:32,921 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308} | ret=SUCCESS |  
2019-09-12 10:44:32,922 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:32,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308, key=686fa218-6db8-4b09-9747-5ba4747c938f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102779130539016467
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:32,985 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=25a00999-72ce-4fe5-a995-b18dc52f570d, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,042 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102779130539016467 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,043 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,059 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102779130539016467 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,064 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-6D2561240A92->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-6D2561240A92->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-D5A0C6A0C92A, cid=42, SUCCESS, logIndex=1, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c1]
2019-09-12 10:44:33,143 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 9 locID: 102779130539016467 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:33,147 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-6D2561240A92->8b56acbb-8697-4c0e-bb7c-14cea5d20b49: receive RaftClientReply:client-6D2561240A92->8b56acbb-8697-4c0e-bb7c-14cea5d20b49@group-D5A0C6A0C92A, cid=43, SUCCESS, logIndex=3, commits[8b56acbb-8697-4c0e-bb7c-14cea5d20b49:c4]
2019-09-12 10:44:33,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308, key=686fa218-6db8-4b09-9747-5ba4747c938f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102779130539016467
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 39190
    }
    ports {
      name: "RATIS"
      value: 34849
    }
    ports {
      name: "STANDALONE"
      value: 41370
    }
    networkName: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:33,164 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-12 10:44:33,165 [IPC Server handler 8 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:33,165 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:33,166 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308, key=686fa218-6db8-4b09-9747-5ba4747c938f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:33,171 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-12 10:44:33,172 [IPC Server handler 11 on 45226] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-12 10:44:33,172 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-12 10:44:33,172 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=622ba443-9de0-41e8-a2d7-363497943f62, bucket=a012a54a-3580-440b-8a9d-b7e121108308, key=686fa218-6db8-4b09-9747-5ba4747c938f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-12 10:44:33,178 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 9 locID: 102779130539016467 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:33,193 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 9 locID: 102779130539016467 bcsId: 3} | ret=SUCCESS |  
2019-09-12 10:44:33,195 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "1e44ee5f15f32b98:1e44ee5f15f32b98:0:0"
containerID: 9
datanodeUuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
readChunk {
  blockID {
    containerID: 9
    localID: 102779130539016467
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779130539016467_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 8b56acbb-8697-4c0e-bb7c-14cea5d20b49
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithCorruptedData(TestOzoneRpcClientAbstract.java:1108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-12 10:44:33,196 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "1e44ee5f15f32b98:1e44ee5f15f32b98:0:0"
containerID: 9
datanodeUuid: "8b56acbb-8697-4c0e-bb7c-14cea5d20b49"
readChunk {
  blockID {
    containerID: 9
    localID: 102779130539016467
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102779130539016467_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: 5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a, Nodes: 8b56acbb-8697-4c0e-bb7c-14cea5d20b49{ip: 192.168.36.114, host: pr-hdds-1569-58hkm-1881083799, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-12 10:44:33,197 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 977c5f41-49cc-4832-865e-96ade978c00a, with jenkins1000 as owner.
2019-09-12 10:44:33,210 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=977c5f41-49cc-4832-865e-96ade978c00a, creationTime=1568285073198, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=977c5f41-49cc-4832-865e-96ade978c00a} | ret=SUCCESS |  
2019-09-12 10:44:33,212 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 977c5f41-49cc-4832-865e-96ade978c00a/7a33a70e-5996-4d5c-bfda-65fcba3a6cee, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=977c5f41-49cc-4832-865e-96ade978c00a, bucket=7a33a70e-5996-4d5c-bfda-65fcba3a6cee, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073213} | ret=SUCCESS |  
2019-09-12 10:44:33,226 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=977c5f41-49cc-4832-865e-96ade978c00a, bucket=7a33a70e-5996-4d5c-bfda-65fcba3a6cee} | ret=SUCCESS |  
2019-09-12 10:44:33,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=977c5f41-49cc-4832-865e-96ade978c00a, bucket=7a33a70e-5996-4d5c-bfda-65fcba3a6cee, key=null} | ret=SUCCESS |  
2019-09-12 10:44:33,228 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e3328318-1067-4071-ac3e-9738d85fa45a, with jenkins1000 as owner.
2019-09-12 10:44:33,240 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e3328318-1067-4071-ac3e-9738d85fa45a, creationTime=1568285073229, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,241 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e3328318-1067-4071-ac3e-9738d85fa45a} | ret=SUCCESS |  
2019-09-12 10:44:33,242 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e3328318-1067-4071-ac3e-9738d85fa45a/ed3ffe6b-b58c-4319-bca2-ec26317d297a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,254 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073242} | ret=SUCCESS |  
2019-09-12 10:44:33,255 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a} | ret=SUCCESS |  
2019-09-12 10:44:33,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, key=7dee131e-81ad-41a4-9d03-5589e064cec1, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, key=7dee131e-81ad-41a4-9d03-5589e064cec1, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,288 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:33,299 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, key=7dee131e-81ad-41a4-9d03-5589e064cec1, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130561691926} | ret=SUCCESS |  
2019-09-12 10:44:33,303 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130563002647 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,306 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130563002647 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-12 10:44:33,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, key=7dee131e-81ad-41a4-9d03-5589e064cec1, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130563002647
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:33,335 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=e3328318-1067-4071-ac3e-9738d85fa45a, bucket=ed3ffe6b-b58c-4319-bca2-ec26317d297a, key=7dee131e-81ad-41a4-9d03-5589e064cec1, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=9f34aaf5-93aa-44e9-8660-5aa1d6220dd3}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: e3328318-1067-4071-ac3e-9738d85fa45abucket: ed3ffe6b-b58c-4319-bca2-ec26317d297akey: 7dee131e-81ad-41a4-9d03-5589e064cec1
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-12 10:44:33,337 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 7dee131e-81ad-41a4-9d03-5589e064cec1 in Volume/Bucket e3328318-1067-4071-ac3e-9738d85fa45a/ed3ffe6b-b58c-4319-bca2-ec26317d297a
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: e3328318-1067-4071-ac3e-9738d85fa45abucket: ed3ffe6b-b58c-4319-bca2-ec26317d297akey: 7dee131e-81ad-41a4-9d03-5589e064cec1
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-12 10:44:33,339 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a1d2d1c7-87d9-4ebb-9ca7-8cf1af7c36c6, with jenkins1000 as owner.
2019-09-12 10:44:33,352 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a1d2d1c7-87d9-4ebb-9ca7-8cf1af7c36c6, creationTime=1568285073340, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,353 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a1d2d1c7-87d9-4ebb-9ca7-8cf1af7c36c6} | ret=SUCCESS |  
2019-09-12 10:44:33,354 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1a406e10-2290-4837-ad73-1b47a0b987e7, with jenkins1000 as owner.
2019-09-12 10:44:33,367 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1a406e10-2290-4837-ad73-1b47a0b987e7, creationTime=1568285073354, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1a406e10-2290-4837-ad73-1b47a0b987e7} | ret=SUCCESS |  
2019-09-12 10:44:33,369 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1a406e10-2290-4837-ad73-1b47a0b987e7/fbe6282f-1942-4533-9046-239f21c7849d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,378 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1a406e10-2290-4837-ad73-1b47a0b987e7, bucket=fbe6282f-1942-4533-9046-239f21c7849d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073370} | ret=SUCCESS |  
2019-09-12 10:44:33,379 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1a406e10-2290-4837-ad73-1b47a0b987e7, bucket=fbe6282f-1942-4533-9046-239f21c7849d} | ret=SUCCESS |  
2019-09-12 10:44:33,380 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cf3da1b6-4822-46cb-851f-6deeb2a88dae, with jenkins1000 as owner.
2019-09-12 10:44:33,392 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, creationTime=1568285073380, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,393 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae} | ret=SUCCESS |  
2019-09-12 10:44:33,394 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: cf3da1b6-4822-46cb-851f-6deeb2a88dae/72a36333-a738-434d-8be1-661d0b7d59f1, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073394} | ret=SUCCESS |  
2019-09-12 10:44:33,407 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1} | ret=SUCCESS |  
2019-09-12 10:44:33,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, key=cfd405f4-2047-4571-90fc-082ec64b7449, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=364f652f-ef6f-448e-9b53-5fc05d785e98, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,434 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, key=cfd405f4-2047-4571-90fc-082ec64b7449, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:33,448 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, key=cfd405f4-2047-4571-90fc-082ec64b7449, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130571850009} | ret=SUCCESS |  
2019-09-12 10:44:33,456 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130572701978 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,463 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130572701978 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:33,473 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130572701978 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,475 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130572701978 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-12 10:44:33,482 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130572701978 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,485 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130572701978 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-12 10:44:33,493 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130572701978 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,497 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130572701978 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-12 10:44:33,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:33,512 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, key=cfd405f4-2047-4571-90fc-082ec64b7449, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130571850009} | ret=SUCCESS |  
2019-09-12 10:44:33,519 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130576830747 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,521 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130576830747 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-12 10:44:33,523 [IPC Server handler 19 on 38955] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-956_1032 to index:1032
2019-09-12 10:44:33,524 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_956-1032
2019-09-12 10:44:33,527 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_1033
2019-09-12 10:44:33,530 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, key=cfd405f4-2047-4571-90fc-082ec64b7449, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130572701978
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130576830747
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:33,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=cf3da1b6-4822-46cb-851f-6deeb2a88dae, bucket=72a36333-a738-434d-8be1-661d0b7d59f1, uploadID=c9b6318f-3fd0-4f52-8331-5d3ccb8bc859-102779130570866968, partNumberMarker=100, maxParts=2, key=cfd405f4-2047-4571-90fc-082ec64b7449} | ret=SUCCESS |  
2019-09-12 10:44:33,532 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1717d45f-18af-4d42-9534-c7f030e8d57d, with jenkins1000 as owner.
2019-09-12 10:44:33,572 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1717d45f-18af-4d42-9534-c7f030e8d57d, creationTime=1568285073532, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,574 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1717d45f-18af-4d42-9534-c7f030e8d57d} | ret=SUCCESS |  
2019-09-12 10:44:33,574 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1717d45f-18af-4d42-9534-c7f030e8d57d/094c744e-f56c-474c-8986-b97c32525f7b, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,588 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1717d45f-18af-4d42-9534-c7f030e8d57d, bucket=094c744e-f56c-474c-8986-b97c32525f7b, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073575} | ret=SUCCESS |  
2019-09-12 10:44:33,589 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1717d45f-18af-4d42-9534-c7f030e8d57d, bucket=094c744e-f56c-474c-8986-b97c32525f7b} | ret=SUCCESS |  
2019-09-12 10:44:33,589 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4a513441-9ebb-4b49-8190-d086b9f8a903, with jenkins1000 as owner.
2019-09-12 10:44:33,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4a513441-9ebb-4b49-8190-d086b9f8a903, creationTime=1568285073590, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4a513441-9ebb-4b49-8190-d086b9f8a903} | ret=SUCCESS |  
2019-09-12 10:44:33,604 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4a513441-9ebb-4b49-8190-d086b9f8a903/36c9f3f7-010c-4783-b68d-9bce4688ab99, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,616 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073604} | ret=SUCCESS |  
2019-09-12 10:44:33,617 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99} | ret=SUCCESS |  
2019-09-12 10:44:33,629 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99, key=a9ad22e0-307a-495b-8be1-748dc042926f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,642 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99, key=a9ad22e0-307a-495b-8be1-748dc042926f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,644 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=ALLOCATE_BLOCK {owner=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-12 10:44:33,656 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99, key=a9ad22e0-307a-495b-8be1-748dc042926f, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102779130585415965} | ret=SUCCESS |  
2019-09-12 10:44:33,659 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102779130586333470 bcsId: 0} | ret=SUCCESS |  
2019-09-12 10:44:33,662 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102779130586333470 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-12 10:44:33,676 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=4a513441-9ebb-4b49-8190-d086b9f8a903, bucket=36c9f3f7-010c-4783-b68d-9bce4688ab99, key=a9ad22e0-307a-495b-8be1-748dc042926f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102779130586333470
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    ipAddress: "192.168.36.114"
    hostName: "pr-hdds-1569-58hkm-1881083799"
    ports {
      name: "REST"
      value: 40472
    }
    ports {
      name: "RATIS"
      value: 45119
    }
    ports {
      name: "STANDALONE"
      value: 44454
    }
    networkName: "364f652f-ef6f-448e-9b53-5fc05d785e98"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "1a4ffa31-216e-4d9b-ad7b-5c0fa5e636f5"
  }
}
]} | ret=SUCCESS |  
2019-09-12 10:44:33,677 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 49941c8c-e443-41c2-bb4f-f54b24d7fab7, with jenkins1000 as owner.
2019-09-12 10:44:33,690 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7, creationTime=1568285073678, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-12 10:44:33,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7} | ret=SUCCESS |  
2019-09-12 10:44:33,691 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 49941c8c-e443-41c2-bb4f-f54b24d7fab7/4fb79491-a56f-40d7-a871-183c8bf0aa52, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-12 10:44:33,704 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7, bucket=4fb79491-a56f-40d7-a871-183c8bf0aa52, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568285073692} | ret=SUCCESS |  
2019-09-12 10:44:33,704 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7, bucket=4fb79491-a56f-40d7-a871-183c8bf0aa52} | ret=SUCCESS |  
2019-09-12 10:44:33,717 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7, bucket=4fb79491-a56f-40d7-a871-183c8bf0aa52, key=d9d28470-2cbf-406b-8e77-137d69e45230, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,730 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=49941c8c-e443-41c2-bb4f-f54b24d7fab7, bucket=4fb79491-a56f-40d7-a871-183c8bf0aa52, key=d9d28470-2cbf-406b-8e77-137d69e45230, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-12 10:44:33,737 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-09-12 10:44:33,737 | INFO  | SCMAudit | user=null | ip=null | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-12 10:44:33,737 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-09-12 10:44:33,738 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-09-12 10:44:33,738 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38955
2019-09-12 10:44:33,747 [IPC Server listener on 38955] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38955
2019-09-12 10:44:33,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:44:33,765 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: close
2019-09-12 10:44:33,767 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown group-C5BA1605619E
2019-09-12 10:44:33,768 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=05c0cccc-379a-4648-8f4a-ef7a7bfcfc63
2019-09-12 10:44:33,768 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown LeaderState
2019-09-12 10:44:33,769 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:33,777 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E: set stopIndex = 1058
2019-09-12 10:44:33,777 [StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-12 10:44:33,784 [StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1057
2019-09-12 10:44:33,784 [StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E: Took a snapshot at index 1057
2019-09-12 10:44:33,786 [StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E: snapshotIndex: updateIncreasingly -1 -> 1057
2019-09-12 10:44:33,790 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63:group-C5BA1605619E closes. The last applied log index is 1058
2019-09-12 10:44:33,792 [05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:33,794 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e close()
2019-09-12 10:44:33,797 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown server with port 9872 now
2019-09-12 10:44:33,800 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 05c0cccc-379a-4648-8f4a-ef7a7bfcfc63: shutdown server with port 9872 successfully
2019-09-12 10:44:33,800 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-12 10:44:33,801 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-12 10:44:33,802 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-12 10:44:33,808 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1debc91c{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-12 10:44:33,815 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:44:33,816 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-12 10:44:33,816 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:44:33,821 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-09-12 10:44:33,822 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:44:33,822 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:44:33,827 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@747f6c5a
2019-09-12 10:44:33,827 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-12 10:44:33,984 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:44:34,043 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:34,431 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:44:35,044 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:36,045 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:37,046 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:38,046 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.36.114 | op=SEND_HEARTBEAT {datanodeUUID=8b56acbb-8697-4c0e-bb7c-14cea5d20b49, command=[]} | ret=SUCCESS |  
2019-09-12 10:44:38,830 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:44:38,830 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:44:38,831 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: close
2019-09-12 10:44:38,831 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: close
2019-09-12 10:44:38,831 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-12F00208A22D
2019-09-12 10:44:38,831 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-49B6BB0610D6
2019-09-12 10:44:38,831 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12F00208A22D,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,831 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-49B6BB0610D6,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,832 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,832 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,832 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,832 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,839 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D: set stopIndex = 4
2019-09-12 10:44:38,843 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6: set stopIndex = 7
2019-09-12 10:44:38,839 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-12F00208A22D: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d/sm/snapshot.1_4
2019-09-12 10:44:38,843 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-49B6BB0610D6: Taking a snapshot at:(t:1, i:7) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6/sm/snapshot.1_7
2019-09-12 10:44:38,871 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-12F00208A22D: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d/sm/snapshot.1_4 time:32
2019-09-12 10:44:38,871 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-49B6BB0610D6: Finished taking a snapshot at:(t:1, i:7) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6/sm/snapshot.1_7 time:28
2019-09-12 10:44:38,871 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D: Took a snapshot at index 4
2019-09-12 10:44:38,872 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6: Took a snapshot at index 7
2019-09-12 10:44:38,872 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:44:38,872 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-12 10:44:38,872 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-12F00208A22D closes. The last applied log index is 4
2019-09-12 10:44:38,872 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-49B6BB0610D6 closes. The last applied log index is 7
2019-09-12 10:44:38,873 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,873 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,875 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/1389de10-6395-4041-b6ad-12f00208a22d close()
2019-09-12 10:44:38,876 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/66489fb9-4e62-4794-9107-49b6bb0610d6 close()
2019-09-12 10:44:38,878 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-7EA02E577151
2019-09-12 10:44:38,880 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-D221872E0F1A
2019-09-12 10:44:38,880 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7EA02E577151,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,880 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D221872E0F1A,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,880 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,881 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,881 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,881 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,882 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151: set stopIndex = 0
2019-09-12 10:44:38,882 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A: set stopIndex = 0
2019-09-12 10:44:38,882 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-7EA02E577151 closes. The last applied log index is 0
2019-09-12 10:44:38,882 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D221872E0F1A closes. The last applied log index is 0
2019-09-12 10:44:38,883 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,883 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,884 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/19d901b2-fa62-4606-bfe1-7ea02e577151 close()
2019-09-12 10:44:38,885 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/bdd0a805-d738-4d5d-9c75-d221872e0f1a close()
2019-09-12 10:44:38,887 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-37E11E9E741C
2019-09-12 10:44:38,889 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-5A02E043B186
2019-09-12 10:44:38,890 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-37E11E9E741C,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,890 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5A02E043B186,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,890 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,890 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,891 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,891 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,891 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C: set stopIndex = 0
2019-09-12 10:44:38,895 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-5A02E043B186: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186/sm/snapshot.1_4
2019-09-12 10:44:38,895 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186: set stopIndex = 4
2019-09-12 10:44:38,895 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-37E11E9E741C closes. The last applied log index is 0
2019-09-12 10:44:38,896 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,897 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/ec9c4673-de8a-495f-8890-37e11e9e741c close()
2019-09-12 10:44:38,899 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-C445A466EBC6
2019-09-12 10:44:38,900 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C445A466EBC6,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,900 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,901 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,908 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6: set stopIndex = 7
2019-09-12 10:44:38,908 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-C445A466EBC6: Taking a snapshot at:(t:1, i:7) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6/sm/snapshot.1_7
2019-09-12 10:44:38,920 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-5A02E043B186: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186/sm/snapshot.1_4 time:24
2019-09-12 10:44:38,920 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186: Took a snapshot at index 4
2019-09-12 10:44:38,920 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:44:38,920 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-5A02E043B186 closes. The last applied log index is 4
2019-09-12 10:44:38,921 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,921 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-C445A466EBC6: Finished taking a snapshot at:(t:1, i:7) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6/sm/snapshot.1_7 time:13
2019-09-12 10:44:38,922 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/80c267d5-f3cd-41d0-b18e-5a02e043b186 close()
2019-09-12 10:44:38,922 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6: Took a snapshot at index 7
2019-09-12 10:44:38,924 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-ACA02D7F7103
2019-09-12 10:44:38,924 [StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-12 10:44:38,925 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ACA02D7F7103,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,925 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C445A466EBC6 closes. The last applied log index is 7
2019-09-12 10:44:38,925 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,926 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,926 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,927 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/bdca2718-fb76-4226-b53d-c445a466ebc6 close()
2019-09-12 10:44:38,927 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-ACA02D7F7103: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103/sm/snapshot.1_4
2019-09-12 10:44:38,927 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103: set stopIndex = 4
2019-09-12 10:44:38,929 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-C2DE7A059854
2019-09-12 10:44:38,930 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2DE7A059854,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,930 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,931 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,931 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854: set stopIndex = 0
2019-09-12 10:44:38,932 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-C2DE7A059854 closes. The last applied log index is 0
2019-09-12 10:44:38,932 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,933 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/a50e3c16-bd20-4e78-9704-c2de7a059854 close()
2019-09-12 10:44:38,936 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown group-423FAB19B7B8
2019-09-12 10:44:38,936 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-423FAB19B7B8,id=25a00999-72ce-4fe5-a995-b18dc52f570d
2019-09-12 10:44:38,937 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown LeaderState
2019-09-12 10:44:38,937 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,938 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8: set stopIndex = 0
2019-09-12 10:44:38,939 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 25a00999-72ce-4fe5-a995-b18dc52f570d:group-423FAB19B7B8 closes. The last applied log index is 0
2019-09-12 10:44:38,939 [25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,941 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25a00999-72ce-4fe5-a995-b18dc52f570d-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/ratis/2874368b-e696-4f38-9193-423fab19b7b8 close()
2019-09-12 10:44:38,945 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-ACA02D7F7103: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103/sm/snapshot.1_4 time:17
2019-09-12 10:44:38,945 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown server with port 35072 now
2019-09-12 10:44:38,945 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103: Took a snapshot at index 4
2019-09-12 10:44:38,946 [StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:44:38,946 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 25a00999-72ce-4fe5-a995-b18dc52f570d: shutdown server with port 35072 successfully
2019-09-12 10:44:38,946 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-ACA02D7F7103 closes. The last applied log index is 4
2019-09-12 10:44:38,947 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,947 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/b0720546-750f-4111-baef-aca02d7f7103 close()
2019-09-12 10:44:38,949 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-17F9D13D9533
2019-09-12 10:44:38,949 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-17F9D13D9533,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,950 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,950 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,950 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533: set stopIndex = 0
2019-09-12 10:44:38,951 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-17F9D13D9533 closes. The last applied log index is 0
2019-09-12 10:44:38,951 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,951 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/c12f5bcd-1b43-4936-85ae-17f9d13d9533 close()
2019-09-12 10:44:38,953 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown group-D94854D67773
2019-09-12 10:44:38,953 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D94854D67773,id=364f652f-ef6f-448e-9b53-5fc05d785e98
2019-09-12 10:44:38,953 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown LeaderState
2019-09-12 10:44:38,954 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:38,954 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773: set stopIndex = 0
2019-09-12 10:44:38,954 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 364f652f-ef6f-448e-9b53-5fc05d785e98:group-D94854D67773 closes. The last applied log index is 0
2019-09-12 10:44:38,955 [364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:38,955 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 364f652f-ef6f-448e-9b53-5fc05d785e98-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/ratis/ac34390b-6158-449b-8b4f-d94854d67773 close()
2019-09-12 10:44:38,956 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown server with port 45119 now
2019-09-12 10:44:38,957 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 364f652f-ef6f-448e-9b53-5fc05d785e98: shutdown server with port 45119 successfully
2019-09-12 10:44:38,959 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:44:38,959 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:44:38,963 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:44:38,964 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:44:38,983 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:44:38,987 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:44:38,989 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73f6e07{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:44:38,990 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a87026{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:44:38,990 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c9d90fc{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:44:38,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@353e6389{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:44:38,991 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:44:38,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4be490da{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:44:38,992 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:44:38,993 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:44:38,994 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-12 10:44:38,995 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3be3e76c
2019-09-12 10:44:39,045 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-12 10:44:43,996 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-12 10:44:43,997 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: close
2019-09-12 10:44:43,998 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-D24E31EA21A7
2019-09-12 10:44:43,998 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-74B5B0006083
2019-09-12 10:44:43,998 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D24E31EA21A7,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:43,999 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-74B5B0006083,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:43,999 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:43,999 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:44,000 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,000 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,000 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7: set stopIndex = 0
2019-09-12 10:44:44,000 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083: set stopIndex = 0
2019-09-12 10:44:44,002 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D24E31EA21A7 closes. The last applied log index is 0
2019-09-12 10:44:44,002 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-74B5B0006083 closes. The last applied log index is 0
2019-09-12 10:44:44,003 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,003 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,003 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/35c1c3a7-11fc-4d93-80f8-d24e31ea21a7 close()
2019-09-12 10:44:44,003 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/bb56150b-c101-494c-856d-74b5b0006083 close()
2019-09-12 10:44:44,005 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-D5A0C6A0C92A
2019-09-12 10:44:44,006 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-ECAF23504DB6
2019-09-12 10:44:44,006 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5A0C6A0C92A,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:44,006 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ECAF23504DB6,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:44,007 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:44,007 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:44,007 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,007 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,008 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A: set stopIndex = 4
2019-09-12 10:44:44,008 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-ECAF23504DB6: Taking a snapshot at:(t:1, i:6) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6/sm/snapshot.1_6
2019-09-12 10:44:44,008 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-D5A0C6A0C92A: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a/sm/snapshot.1_4
2019-09-12 10:44:44,008 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6: set stopIndex = 7
2019-09-12 10:44:44,030 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-ECAF23504DB6: Finished taking a snapshot at:(t:1, i:6) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6/sm/snapshot.1_6 time:23
2019-09-12 10:44:44,030 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6: Took a snapshot at index 6
2019-09-12 10:44:44,030 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-D5A0C6A0C92A: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a/sm/snapshot.1_4 time:23
2019-09-12 10:44:44,031 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6: snapshotIndex: updateIncreasingly -1 -> 6
2019-09-12 10:44:44,031 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A: Took a snapshot at index 4
2019-09-12 10:44:44,031 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-12 10:44:44,031 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-ECAF23504DB6 closes. The last applied log index is 7
2019-09-12 10:44:44,031 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-D5A0C6A0C92A closes. The last applied log index is 4
2019-09-12 10:44:44,032 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,032 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,032 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/548ae151-a0b6-464f-bf17-ecaf23504db6 close()
2019-09-12 10:44:44,033 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/5b97f1d3-50b0-46c1-9afc-d5a0c6a0c92a close()
2019-09-12 10:44:44,034 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-DC8781F1BE95
2019-09-12 10:44:44,035 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown group-A3D78199B64D
2019-09-12 10:44:44,035 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC8781F1BE95,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:44,035 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A3D78199B64D,id=8b56acbb-8697-4c0e-bb7c-14cea5d20b49
2019-09-12 10:44:44,036 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:44,036 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown LeaderState
2019-09-12 10:44:44,036 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,037 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-PendingRequests: sendNotLeaderResponses
2019-09-12 10:44:44,037 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D: set stopIndex = 0
2019-09-12 10:44:44,038 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-DC8781F1BE95: Taking a snapshot at:(t:1, i:11) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95/sm/snapshot.1_11
2019-09-12 10:44:44,037 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95: set stopIndex = 11
2019-09-12 10:44:44,038 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-A3D78199B64D closes. The last applied log index is 0
2019-09-12 10:44:44,039 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,039 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/9851042b-e963-4fcc-a135-a3d78199b64d close()
2019-09-12 10:44:44,063 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-DC8781F1BE95: Finished taking a snapshot at:(t:1, i:11) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95/sm/snapshot.1_11 time:25
2019-09-12 10:44:44,063 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95: Took a snapshot at index 11
2019-09-12 10:44:44,063 [StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95: snapshotIndex: updateIncreasingly -1 -> 11
2019-09-12 10:44:44,063 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49:group-DC8781F1BE95 closes. The last applied log index is 11
2019-09-12 10:44:44,064 [8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-12 10:44:44,064 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/ratis/0edccb19-c6d4-4022-8d9f-dc8781f1be95 close()
2019-09-12 10:44:44,065 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown server with port 34849 now
2019-09-12 10:44:44,066 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 8b56acbb-8697-4c0e-bb7c-14cea5d20b49: shutdown server with port 34849 successfully
2019-09-12 10:44:44,070 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-12 10:44:44,075 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-78a45ab8-6c12-49f5-a912-dcce841895d0/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-12 10:44:44,089 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-12 10:44:44,090 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@743c3520{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-12 10:44:44,091 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6842c101{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:44:44,091 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2997ddfc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-12 10:44:44,091 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63d677f5{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:44:44,093 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-09-12 10:44:44,093 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(797)) - Stopping Replication Manager Service.
2019-09-12 10:44:44,093 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(192)) - Stopping Replication Monitor Thread.
2019-09-12 10:44:44,093 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Lease Manager of the command watchers
2019-09-12 10:44:44,094 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping datanode service RPC server
2019-09-12 10:44:44,094 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-12 10:44:44,094 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43971
2019-09-12 10:44:44,096 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:44:44,096 [IPC Server listener on 43971] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43971
2019-09-12 10:44:44,183 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-12 10:44:44,184 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(819)) - Stopping block service RPC server
2019-09-12 10:44:44,184 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-09-12 10:44:44,184 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45226
2019-09-12 10:44:44,186 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-12 10:44:44,186 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-12 10:44:44,186 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43713
2019-09-12 10:44:44,188 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping Storage Container Manager HTTP server.
2019-09-12 10:44:44,188 [IPC Server listener on 45226] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45226
2019-09-12 10:44:44,189 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:44:44,189 [IPC Server listener on 43713] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43713
2019-09-12 10:44:44,189 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-12 10:44:44,190 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43c67247{/,null,UNAVAILABLE}{/scm}
2019-09-12 10:44:44,191 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-12 10:44:44,191 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-12 10:44:44,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-12 10:44:44,194 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Block Manager Service.
2019-09-12 10:44:44,194 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-12 10:44:44,195 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-12 10:44:44,196 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(866)) - Stopping SCM Event Queue.
2019-09-12 10:44:44,203 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping XceiverClientMetrics metrics system...
2019-09-12 10:44:44,213 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - XceiverClientMetrics metrics system stopped.

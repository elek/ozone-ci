2019-09-26 13:23:14,521 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:14,645 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:14,649 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:14,668 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1024ms
2019-09-26 13:23:14,780 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-26 13:23:14,781 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-26 13:23:14,781 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-26 13:23:14,782 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-26 13:23:14,782 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-26 13:23:14,782 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-26 13:23:14,796 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 13:23:14,796 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 13:23:14,797 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 13:23:15,082 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@dd05255
2019-09-26 13:23:15,084 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-26 13:23:15,161 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 13:23:15,163 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-26 13:23:15,166 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-26 13:23:15,302 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-26 13:23:15,320 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:15,495 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-26 13:23:15,500 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:15,639 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-26 13:23:16,118 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 13:23:16,306 [Socket Reader #1 for port 45236] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45236
2019-09-26 13:23:16,339 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 13:23:16,340 [Socket Reader #1 for port 36299] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36299
2019-09-26 13:23:16,349 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 13:23:16,350 [Socket Reader #1 for port 39295] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39295
2019-09-26 13:23:16,373 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-26 13:23:16,531 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:16,548 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:16,559 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:16,562 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-26 13:23:16,562 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:16,562 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:16,593 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:39295
2019-09-26 13:23:16,648 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-26 13:23:16,661 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-26 13:23:16,661 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-26 13:23:16,895 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:39295
2019-09-26 13:23:16,895 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 13:23:16,895 [IPC Server listener on 39295] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39295: starting
2019-09-26 13:23:16,898 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:36299
2019-09-26 13:23:16,900 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:36299
2019-09-26 13:23:16,900 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 13:23:16,900 [IPC Server listener on 36299] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36299: starting
2019-09-26 13:23:16,902 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:45236
2019-09-26 13:23:16,902 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:45236
2019-09-26 13:23:16,903 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 13:23:16,903 [IPC Server listener on 45236] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45236: starting
2019-09-26 13:23:16,907 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45962
2019-09-26 13:23:16,908 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:16,943 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:16,944 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:17,017 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@aec50a1{/,file:///tmp/jetty-0.0.0.0-45962-scm-_-any-312016630298693237.dir/webapp/,AVAILABLE}{/scm}
2019-09-26 13:23:17,023 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:45962}
2019-09-26 13:23:17,023 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3379ms
2019-09-26 13:23:17,025 [JUnit] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-26 13:23:17,025 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-26 13:23:17,027 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:45962
2019-09-26 13:23:17,033 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1fca1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:17,037 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:17,160 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:17,161 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:17,162 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(652)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-26 13:23:17,162 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(658)) - OM Node ID is not set. Setting it to the OmStorage's OmID: fa369085-ee82-4923-81ad-266e72eaa9f3
2019-09-26 13:23:17,164 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(609)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-26 13:23:17,916 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-26 13:23:17,926 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-26 13:23:17,926 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-26 13:23:17,927 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-26 13:23:17,927 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-26 13:23:17,927 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-26 13:23:17,927 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-26 13:23:17,928 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-26 13:23:17,928 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-26 13:23:17,928 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-26 13:23:17,928 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-26 13:23:17,929 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-26 13:23:17,929 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-26 13:23:17,929 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-26 13:23:17,929 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-26 13:23:17,930 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-26 13:23:17,930 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-26 13:23:17,930 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-26 13:23:17,930 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-26 13:23:17,931 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-26 13:23:17,931 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-26 13:23:17,931 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-26 13:23:17,931 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-26 13:23:17,932 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-26 13:23:17,932 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-26 13:23:17,932 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-26 13:23:18,792 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-26 13:23:18,793 [Socket Reader #1 for port 45808] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45808
2019-09-26 13:23:18,834 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1243)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45808
2019-09-26 13:23:18,835 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-26 13:23:18,836 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-26 13:23:18,836 [IPC Server listener on 45808] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45808: starting
2019-09-26 13:23:18,842 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-26 13:23:18,845 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:18,846 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:18,849 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:18,850 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-26 13:23:18,850 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:18,851 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:18,986 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38526
2019-09-26 13:23:18,986 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:18,989 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:18,990 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:19,045 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7103ab0{/,file:///tmp/jetty-0.0.0.0-38526-ozoneManager-_-any-6068492268298201565.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-26 13:23:19,046 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:38526}
2019-09-26 13:23:19,047 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5403ms
2019-09-26 13:23:19,048 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:19,048 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:38526
2019-09-26 13:23:19,228 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 13:23:19,287 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-87zkn-1081879488 ip:192.168.164.238
2019-09-26 13:23:19,324 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 13:23:19,326 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/containers/hdds to VolumeSet
2019-09-26 13:23:19,329 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-26 13:23:19,348 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3fd2322d
2019-09-26 13:23:19,485 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 13:23:19,572 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 13:23:19,578 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 13:23:19,579 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 13:23:19,581 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:19,582 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 13:23:19,583 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 13:23:19,796 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:19,875 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 13:23:19,877 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:19,878 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:19,880 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:19,881 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 13:23:19,881 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:19,881 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:19,883 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 43223
2019-09-26 13:23:19,883 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:19,886 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:19,887 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:19,923 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73844119{/,file:///tmp/jetty-0.0.0.0-43223-hddsDatanode-_-any-8235142032271030217.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 13:23:19,924 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:43223}
2019-09-26 13:23:19,924 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6281ms
2019-09-26 13:23:19,925 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:19,926 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:43223
2019-09-26 13:23:19,927 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 13:23:19,930 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-87zkn-1081879488 ip:192.168.164.238
2019-09-26 13:23:19,932 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ef12d6e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:19,939 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 13:23:19,940 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/containers/hdds to VolumeSet
2019-09-26 13:23:19,940 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-26 13:23:19,942 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@333c8791
2019-09-26 13:23:19,965 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 13:23:19,965 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 13:23:19,965 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 13:23:19,966 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 13:23:19,966 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:19,966 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 13:23:19,967 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 13:23:19,967 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:19,969 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 13:23:19,971 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:19,973 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:19,975 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:19,976 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 13:23:19,976 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:19,977 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:19,978 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41034
2019-09-26 13:23:19,978 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:19,981 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16727bf0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:19,982 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@291373d3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:20,014 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48b4a043{/,file:///tmp/jetty-0.0.0.0-41034-hddsDatanode-_-any-70839789305439488.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 13:23:20,015 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f5b8250{HTTP/1.1,[http/1.1]}{0.0.0.0:41034}
2019-09-26 13:23:20,016 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6372ms
2019-09-26 13:23:20,016 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:20,017 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41034
2019-09-26 13:23:20,018 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 13:23:20,020 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5214289] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:20,022 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-87zkn-1081879488 ip:192.168.164.238
2019-09-26 13:23:20,030 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 13:23:20,030 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/containers/hdds to VolumeSet
2019-09-26 13:23:20,031 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-26 13:23:20,031 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6cf0a747
2019-09-26 13:23:20,056 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/meta/datanode.id
2019-09-26 13:23:20,059 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/meta/datanode.id
2019-09-26 13:23:20,061 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 13:23:20,062 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 13:23:20,062 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 13:23:20,062 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 13:23:20,062 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:20,063 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 13:23:20,063 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 13:23:20,064 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:20,066 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 13:23:20,068 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:20,068 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:20,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:20,071 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 13:23:20,071 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:20,071 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:20,072 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39881
2019-09-26 13:23:20,072 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:20,074 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@272ce069{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:20,075 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c26273d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:20,105 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29149030{/,file:///tmp/jetty-0.0.0.0-39881-hddsDatanode-_-any-4623925803608532886.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 13:23:20,105 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@38b8b6c0{HTTP/1.1,[http/1.1]}{0.0.0.0:39881}
2019-09-26 13:23:20,106 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6462ms
2019-09-26 13:23:20,106 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:20,107 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39881
2019-09-26 13:23:20,108 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 13:23:20,110 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-87zkn-1081879488 ip:192.168.164.238
2019-09-26 13:23:20,110 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5fd1b5b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:20,113 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/meta/datanode.id
2019-09-26 13:23:20,127 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 13:23:20,127 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/containers/hdds to VolumeSet
2019-09-26 13:23:20,127 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-26 13:23:20,128 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@53311681
2019-09-26 13:23:20,149 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 13:23:20,149 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 13:23:20,149 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 13:23:20,150 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 13:23:20,150 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:20,150 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 13:23:20,150 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 13:23:20,151 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:20,152 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 13:23:20,155 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:20,156 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:20,159 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:20,160 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 13:23:20,160 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:20,161 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:20,162 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46616
2019-09-26 13:23:20,162 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:20,166 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26350ea2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:20,167 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a08efdc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:20,197 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cd3ad8a{/,file:///tmp/jetty-0.0.0.0-46616-hddsDatanode-_-any-5106130856279778626.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 13:23:20,198 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@75181b50{HTTP/1.1,[http/1.1]}{0.0.0.0:46616}
2019-09-26 13:23:20,198 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6555ms
2019-09-26 13:23:20,199 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:20,200 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46616
2019-09-26 13:23:20,200 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-26 13:23:20,202 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ff9defc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:20,205 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-87zkn-1081879488 ip:192.168.164.238
2019-09-26 13:23:20,207 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/meta/datanode.id
2019-09-26 13:23:20,212 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-26 13:23:20,212 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/containers/hdds to VolumeSet
2019-09-26 13:23:20,212 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ae202c6
2019-09-26 13:23:20,213 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ae202c6
2019-09-26 13:23:20,235 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-26 13:23:20,236 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-26 13:23:20,236 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-26 13:23:20,236 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-26 13:23:20,237 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:20,237 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-26 13:23:20,237 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-26 13:23:20,238 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:20,239 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-26 13:23:20,241 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-26 13:23:20,242 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-26 13:23:20,244 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-26 13:23:20,245 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-26 13:23:20,245 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-26 13:23:20,245 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-26 13:23:20,246 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44224
2019-09-26 13:23:20,246 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-26 13:23:20,248 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57f9b467{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-26 13:23:20,248 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44b29496{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-26 13:23:20,275 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72e295cc{/,file:///tmp/jetty-0.0.0.0-44224-hddsDatanode-_-any-7710528076980329108.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-26 13:23:20,276 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c2584d3{HTTP/1.1,[http/1.1]}{0.0.0.0:44224}
2019-09-26 13:23:20,276 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6633ms
2019-09-26 13:23:20,276 [JUnit] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-26 13:23:20,277 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44224
2019-09-26 13:23:20,279 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 13:23:20,280 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d6be3e5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-26 13:23:20,289 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/meta/datanode.id
2019-09-26 13:23:21,279 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 13:23:21,984 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 13:23:21,987 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 13:23:21,987 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis e6d7f1d8-1aa8-4176-9696-232a32bf0999 at port 0
2019-09-26 13:23:22,013 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start RPC server
2019-09-26 13:23:22,038 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 13:23:22,043 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 13:23:22,043 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis b2271e47-a7e8-4366-9c95-78f4bcf85493 at port 0
2019-09-26 13:23:22,051 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start RPC server
2019-09-26 13:23:22,128 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 13:23:22,130 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 13:23:22,130 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 90ba3288-4391-43ec-9151-33e9d9c608f1 at port 0
2019-09-26 13:23:22,138 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start RPC server
2019-09-26 13:23:22,183 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: GrpcService started, listening on 0.0.0.0/0.0.0.0:42099
2019-09-26 13:23:22,183 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: GrpcService started, listening on 0.0.0.0/0.0.0.0:40981
2019-09-26 13:23:22,183 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: GrpcService started, listening on 0.0.0.0/0.0.0.0:35856
2019-09-26 13:23:22,184 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis e6d7f1d8-1aa8-4176-9696-232a32bf0999 is started using port 40981
2019-09-26 13:23:22,184 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 90ba3288-4391-43ec-9151-33e9d9c608f1 is started using port 42099
2019-09-26 13:23:22,185 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis b2271e47-a7e8-4366-9c95-78f4bcf85493 is started using port 35856
2019-09-26 13:23:22,191 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc b2271e47-a7e8-4366-9c95-78f4bcf85493 is started using port 46742
2019-09-26 13:23:22,192 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 90ba3288-4391-43ec-9151-33e9d9c608f1 is started using port 40661
2019-09-26 13:23:22,191 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc e6d7f1d8-1aa8-4176-9696-232a32bf0999 is started using port 33105
2019-09-26 13:23:22,242 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 13:23:22,244 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 13:23:22,244 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 4c44e235-1460-4483-9a9f-158dc5e2c846 at port 0
2019-09-26 13:23:22,250 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start RPC server
2019-09-26 13:23:22,252 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: GrpcService started, listening on 0.0.0.0/0.0.0.0:38731
2019-09-26 13:23:22,253 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 4c44e235-1460-4483-9a9f-158dc5e2c846 is started using port 38731
2019-09-26 13:23:22,254 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 4c44e235-1460-4483-9a9f-158dc5e2c846 is started using port 38229
2019-09-26 13:23:22,280 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 13:23:22,296 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-26 13:23:22,301 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-26 13:23:22,301 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 56bc7cae-2273-4ad2-9040-d97b9977dd91 at port 0
2019-09-26 13:23:22,307 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start RPC server
2019-09-26 13:23:22,310 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: GrpcService started, listening on 0.0.0.0/0.0.0.0:37374
2019-09-26 13:23:22,310 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 56bc7cae-2273-4ad2-9040-d97b9977dd91 is started using port 37374
2019-09-26 13:23:22,312 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 56bc7cae-2273-4ad2-9040-d97b9977dd91 is started using port 36216
2019-09-26 13:23:23,280 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-26 13:23:23,966 [IPC Server handler 9 on 45236] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:23,966 [IPC Server handler 9 on 45236] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}
2019-09-26 13:23:23,970 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-26 13:23:23,971 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-26 13:23:23,971 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-26 13:23:24,024 [IPC Server handler 19 on 45236] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:24,024 [IPC Server handler 19 on 45236] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}
2019-09-26 13:23:24,113 [IPC Server handler 4 on 45236] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:24,114 [IPC Server handler 4 on 45236] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}
2019-09-26 13:23:24,206 [IPC Server handler 5 on 45236] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:24,206 [IPC Server handler 5 on 45236] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}
2019-09-26 13:23:24,282 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-26 13:23:24,283 [IPC Server handler 9 on 45236] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:24,283 [IPC Server handler 9 on 45236] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}
2019-09-26 13:23:24,503 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-D2A0D070A417:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-D2A0D070A417:java.util.concurrent.CompletableFuture@45b503ff[Not completed]
2019-09-26 13:23:24,526 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-D2A0D070A417:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:24,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:24,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:24,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:24,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:24,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:24,539 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:24,540 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:24,547 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/75f48069-0590-4dd5-849a-d2a0d070a417 does not exist. Creating ...
2019-09-26 13:23:24,580 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/75f48069-0590-4dd5-849a-d2a0d070a417/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:24,599 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/75f48069-0590-4dd5-849a-d2a0d070a417 has been successfully formatted.
2019-09-26 13:23:24,602 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D2A0D070A417: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:24,602 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:24,604 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:24,610 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:24,610 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:24,613 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,618 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:24,624 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/75f48069-0590-4dd5-849a-d2a0d070a417
2019-09-26 13:23:24,625 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-26 13:23:24,632 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-26 13:23:24,665 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:24,665 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:24,669 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,669 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:24,669 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:24,670 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:24,671 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:24,671 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:24,672 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:24,681 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:24,686 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:24,690 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:24,691 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:24,692 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:24,692 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:24,729 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:24,731 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:24,733 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:24,735 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D2A0D070A417,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:24,809 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 75f48069-0590-4dd5-849a-d2a0d070a417, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:24,827 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-DBFD32718550:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-DBFD32718550:java.util.concurrent.CompletableFuture@2e0a8edf[Not completed]
2019-09-26 13:23:24,829 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-DBFD32718550:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:24,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:24,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:24,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:24,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:24,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:24,831 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:24,831 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:24,831 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/cc66bb70-f69f-4657-9f5b-dbfd32718550 does not exist. Creating ...
2019-09-26 13:23:24,853 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/cc66bb70-f69f-4657-9f5b-dbfd32718550/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:24,867 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/cc66bb70-f69f-4657-9f5b-dbfd32718550 has been successfully formatted.
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DBFD32718550: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:24,868 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/cc66bb70-f69f-4657-9f5b-dbfd32718550
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:24,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:24,870 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:24,871 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:24,871 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:24,871 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:24,875 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:24,875 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:24,875 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:24,876 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBFD32718550,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:24,889 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: cc66bb70-f69f-4657-9f5b-dbfd32718550, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:24,904 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-F9F4E78E5405:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-F9F4E78E5405:java.util.concurrent.CompletableFuture@327f87fa[Not completed]
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-F9F4E78E5405:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:24,906 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:24,907 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:24,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:24,907 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/e25d007b-47ab-4c86-9bc3-f9f4e78e5405 does not exist. Creating ...
2019-09-26 13:23:24,920 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/e25d007b-47ab-4c86-9bc3-f9f4e78e5405/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:24,935 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/e25d007b-47ab-4c86-9bc3-f9f4e78e5405 has been successfully formatted.
2019-09-26 13:23:24,935 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F9F4E78E5405: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,936 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/e25d007b-47ab-4c86-9bc3-f9f4e78e5405
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:24,937 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:24,938 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:24,938 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:24,938 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:24,938 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:24,938 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:24,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:24,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:24,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:24,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:24,944 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:24,944 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:24,944 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:24,945 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9F4E78E5405,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:24,960 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e25d007b-47ab-4c86-9bc3-f9f4e78e5405, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:24,975 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-DC9D3152C9CA:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-DC9D3152C9CA:java.util.concurrent.CompletableFuture@2821e7ac[Not completed]
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-DC9D3152C9CA:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:24,977 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:24,978 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/c99406da-0ba3-480f-895a-dc9d3152c9ca does not exist. Creating ...
2019-09-26 13:23:24,990 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/c99406da-0ba3-480f-895a-dc9d3152c9ca/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,003 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/c99406da-0ba3-480f-895a-dc9d3152c9ca has been successfully formatted.
2019-09-26 13:23:25,003 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-DC9D3152C9CA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,003 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/c99406da-0ba3-480f-895a-dc9d3152c9ca
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,004 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,005 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,010 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:25,010 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,010 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:25,011 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC9D3152C9CA,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:25,021 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c99406da-0ba3-480f-895a-dc9d3152c9ca, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,039 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-009D9498AD7E:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-009D9498AD7E:java.util.concurrent.CompletableFuture@2b45591e[Not completed]
2019-09-26 13:23:25,072 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-009D9498AD7E:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,073 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,074 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,074 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,074 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:25,074 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/17305bd0-da9f-497d-bfbe-009d9498ad7e does not exist. Creating ...
2019-09-26 13:23:25,089 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/17305bd0-da9f-497d-bfbe-009d9498ad7e/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,111 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/17305bd0-da9f-497d-bfbe-009d9498ad7e has been successfully formatted.
2019-09-26 13:23:25,113 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-009D9498AD7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,114 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,114 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,115 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,115 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/17305bd0-da9f-497d-bfbe-009d9498ad7e
2019-09-26 13:23:25,121 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,123 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,123 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,123 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,123 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,124 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,125 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,125 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,130 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:25,130 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,130 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:25,136 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-009D9498AD7E,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:25,145 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 17305bd0-da9f-497d-bfbe-009d9498ad7e, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,159 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-BF6CC37C7398:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-BF6CC37C7398:java.util.concurrent.CompletableFuture@5dba864b[Not completed]
2019-09-26 13:23:25,176 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-BF6CC37C7398:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,177 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,178 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,178 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:25,178 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/77273937-5fa0-441e-83c5-bf6cc37c7398 does not exist. Creating ...
2019-09-26 13:23:25,191 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/77273937-5fa0-441e-83c5-bf6cc37c7398/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,205 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/77273937-5fa0-441e-83c5-bf6cc37c7398 has been successfully formatted.
2019-09-26 13:23:25,206 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-BF6CC37C7398: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,206 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/77273937-5fa0-441e-83c5-bf6cc37c7398
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,207 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,208 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,209 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,209 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,210 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,245 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:25,245 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,245 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:25,245 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF6CC37C7398,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:25,260 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 77273937-5fa0-441e-83c5-bf6cc37c7398, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,271 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-7065E9FA7AFA:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-7065E9FA7AFA:java.util.concurrent.CompletableFuture@49c96f7d[Not completed]
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-7065E9FA7AFA:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,273 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,274 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:25,274 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/f1ab3451-7f00-4b86-96b9-7065e9fa7afa does not exist. Creating ...
2019-09-26 13:23:25,283 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-26 13:23:25,286 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/f1ab3451-7f00-4b86-96b9-7065e9fa7afa/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,299 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/f1ab3451-7f00-4b86-96b9-7065e9fa7afa has been successfully formatted.
2019-09-26 13:23:25,299 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7065E9FA7AFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,299 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,299 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,299 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,300 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/f1ab3451-7f00-4b86-96b9-7065e9fa7afa
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,305 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,309 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 13:23:25,310 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:25,310 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,310 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:25,310 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7065E9FA7AFA,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:25,324 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f1ab3451-7f00-4b86-96b9-7065e9fa7afa, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,337 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-E31664A251FC:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-E31664A251FC:java.util.concurrent.CompletableFuture@2fd82fb9[Not completed]
2019-09-26 13:23:25,340 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-E31664A251FC:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,341 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,341 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,341 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,341 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,341 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,342 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,342 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:25,342 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4868959e-35b9-434e-8ab9-e31664a251fc does not exist. Creating ...
2019-09-26 13:23:25,355 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4868959e-35b9-434e-8ab9-e31664a251fc/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,374 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4868959e-35b9-434e-8ab9-e31664a251fc has been successfully formatted.
2019-09-26 13:23:25,374 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E31664A251FC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,375 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4868959e-35b9-434e-8ab9-e31664a251fc
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,376 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,377 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,377 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,377 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,377 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,377 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,378 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,381 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:25,381 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,382 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:25,382 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E31664A251FC,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:25,391 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4868959e-35b9-434e-8ab9-e31664a251fc, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,401 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-D9D5A710E916:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-D9D5A710E916:java.util.concurrent.CompletableFuture@22036545[Not completed]
2019-09-26 13:23:25,403 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-D9D5A710E916:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,403 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,403 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,403 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,404 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,404 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,404 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,404 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:25,404 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/fc461b1a-70dd-4d08-8ad3-d9d5a710e916 does not exist. Creating ...
2019-09-26 13:23:25,417 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/fc461b1a-70dd-4d08-8ad3-d9d5a710e916/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,429 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/fc461b1a-70dd-4d08-8ad3-d9d5a710e916 has been successfully formatted.
2019-09-26 13:23:25,429 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-D9D5A710E916: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/fc461b1a-70dd-4d08-8ad3-d9d5a710e916
2019-09-26 13:23:25,430 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,431 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,435 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:25,435 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,436 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:25,436 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D5A710E916,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:25,445 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fc461b1a-70dd-4d08-8ad3-d9d5a710e916, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,457 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: addNew group-F0125CF0BD7C:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] returns group-F0125CF0BD7C:java.util.concurrent.CompletableFuture@4d07d15b[Not completed]
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: new RaftServerImpl for group-F0125CF0BD7C:[e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,459 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: ConfigurationManager, init=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,460 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis] (custom)
2019-09-26 13:23:25,460 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/72765cac-ff41-4307-a8e7-f0125cf0bd7c does not exist. Creating ...
2019-09-26 13:23:25,472 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/72765cac-ff41-4307-a8e7-f0125cf0bd7c/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,485 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/72765cac-ff41-4307-a8e7-f0125cf0bd7c has been successfully formatted.
2019-09-26 13:23:25,485 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-F0125CF0BD7C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,485 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/72765cac-ff41-4307-a8e7-f0125cf0bd7c
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,486 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,487 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,491 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: start as a follower, conf=-1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:25,491 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,491 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start FollowerState
2019-09-26 13:23:25,492 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0125CF0BD7C,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:23:25,501 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 72765cac-ff41-4307-a8e7-f0125cf0bd7c, Nodes: e6d7f1d8-1aa8-4176-9696-232a32bf0999{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,501 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,516 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-7E80AEAD5E3B:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-7E80AEAD5E3B:java.util.concurrent.CompletableFuture@90ba1ff[Not completed]
2019-09-26 13:23:25,518 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-7E80AEAD5E3B:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,518 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,519 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,519 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,519 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,519 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,520 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,520 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:25,520 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/bc69b7de-0409-4b1f-a957-7e80aead5e3b does not exist. Creating ...
2019-09-26 13:23:25,533 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/bc69b7de-0409-4b1f-a957-7e80aead5e3b/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,545 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/bc69b7de-0409-4b1f-a957-7e80aead5e3b has been successfully formatted.
2019-09-26 13:23:25,546 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-7E80AEAD5E3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,546 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,546 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,546 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,546 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,547 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,547 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,547 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/bc69b7de-0409-4b1f-a957-7e80aead5e3b
2019-09-26 13:23:25,549 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,550 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,550 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,550 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,550 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,550 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,551 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,551 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,551 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,551 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,552 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,552 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,552 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,552 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,553 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,555 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:25,555 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,556 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:25,556 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E80AEAD5E3B,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:25,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bc69b7de-0409-4b1f-a957-7e80aead5e3b, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,573 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,693 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-185088799101:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-185088799101:java.util.concurrent.CompletableFuture@5765a42e[Not completed]
2019-09-26 13:23:25,700 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-185088799101:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,700 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,701 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,708 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,711 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,723 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:25,726 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/b982c78c-198a-4709-913c-185088799101 does not exist. Creating ...
2019-09-26 13:23:25,753 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/b982c78c-198a-4709-913c-185088799101/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,765 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/b982c78c-198a-4709-913c-185088799101 has been successfully formatted.
2019-09-26 13:23:25,766 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-185088799101: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,766 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/b982c78c-198a-4709-913c-185088799101
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,767 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,768 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,769 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,769 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,769 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,769 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,770 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,770 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,773 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:25,773 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,773 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:25,773 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-185088799101,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:25,782 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b982c78c-198a-4709-913c-185088799101, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,782 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,794 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-1704B8D6F83F:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-1704B8D6F83F:java.util.concurrent.CompletableFuture@1458b176[Not completed]
2019-09-26 13:23:25,797 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-1704B8D6F83F:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,797 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,797 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,797 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,797 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,798 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,798 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,798 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:25,798 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/11142eeb-5e1a-4120-9048-1704b8d6f83f does not exist. Creating ...
2019-09-26 13:23:25,811 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/11142eeb-5e1a-4120-9048-1704b8d6f83f/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,824 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/11142eeb-5e1a-4120-9048-1704b8d6f83f has been successfully formatted.
2019-09-26 13:23:25,825 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-1704B8D6F83F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,825 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,825 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,825 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,825 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,826 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,826 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,826 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/11142eeb-5e1a-4120-9048-1704b8d6f83f
2019-09-26 13:23:25,826 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,826 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,827 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,828 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,828 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,828 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,829 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,829 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,829 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,829 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,835 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:25,836 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,836 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:25,837 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1704B8D6F83F,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:25,855 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 11142eeb-5e1a-4120-9048-1704b8d6f83f, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,856 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,869 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-114EAA4B39AF:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-114EAA4B39AF:java.util.concurrent.CompletableFuture@3a4d7b35[Not completed]
2019-09-26 13:23:25,872 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-114EAA4B39AF:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,872 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,873 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,873 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:25,874 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/e6fa1aa2-65e5-49e7-a603-114eaa4b39af does not exist. Creating ...
2019-09-26 13:23:25,886 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/e6fa1aa2-65e5-49e7-a603-114eaa4b39af/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,899 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/e6fa1aa2-65e5-49e7-a603-114eaa4b39af has been successfully formatted.
2019-09-26 13:23:25,899 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-114EAA4B39AF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,899 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,899 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,900 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,901 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/e6fa1aa2-65e5-49e7-a603-114eaa4b39af
2019-09-26 13:23:25,902 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,903 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,904 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,904 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,904 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,905 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,905 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,905 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,907 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:25,907 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,907 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:25,908 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-114EAA4B39AF,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:25,923 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e6fa1aa2-65e5-49e7-a603-114eaa4b39af, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,924 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,938 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-6DDA4A5AEB3D:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-6DDA4A5AEB3D:java.util.concurrent.CompletableFuture@79b6d659[Not completed]
2019-09-26 13:23:25,939 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-6DDA4A5AEB3D:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,939 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:25,940 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/00344d3d-7462-4420-a744-6dda4a5aeb3d does not exist. Creating ...
2019-09-26 13:23:25,953 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/00344d3d-7462-4420-a744-6dda4a5aeb3d/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:25,967 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/00344d3d-7462-4420-a744-6dda4a5aeb3d has been successfully formatted.
2019-09-26 13:23:25,968 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-6DDA4A5AEB3D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:25,971 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:25,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:25,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:25,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:25,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,972 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/00344d3d-7462-4420-a744-6dda4a5aeb3d
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:25,973 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:25,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:25,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:25,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:25,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:25,974 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:25,975 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:25,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:25,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:25,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:25,975 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:25,978 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:25,978 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:25,979 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:25,979 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6DDA4A5AEB3D,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:25,984 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 00344d3d-7462-4420-a744-6dda4a5aeb3d, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:25,984 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:25,995 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-AFDC6013013E:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-AFDC6013013E:java.util.concurrent.CompletableFuture@6d98d87b[Not completed]
2019-09-26 13:23:25,997 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-AFDC6013013E:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:25,998 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:25,998 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:25,998 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:25,998 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:25,998 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:25,999 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:25,999 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:25,999 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/6b110bb8-2460-4e4f-9403-afdc6013013e does not exist. Creating ...
2019-09-26 13:23:26,013 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/6b110bb8-2460-4e4f-9403-afdc6013013e/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,026 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/6b110bb8-2460-4e4f-9403-afdc6013013e has been successfully formatted.
2019-09-26 13:23:26,027 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AFDC6013013E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,027 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,027 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,028 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,028 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,028 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,028 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,028 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/6b110bb8-2460-4e4f-9403-afdc6013013e
2019-09-26 13:23:26,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,029 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,030 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,031 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,031 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,031 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,032 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,032 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,035 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:26,036 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,036 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:26,036 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFDC6013013E,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:26,040 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6b110bb8-2460-4e4f-9403-afdc6013013e, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,051 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,065 [Thread-227] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume25762, with user40115 as owner.
2019-09-26 13:23:26,066 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: addNew group-897EED66A8B2:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] returns group-897EED66A8B2:java.util.concurrent.CompletableFuture@167c179f[Not completed]
2019-09-26 13:23:26,068 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: new RaftServerImpl for group-897EED66A8B2:[b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,068 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,069 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,069 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: ConfigurationManager, init=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,070 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis] (custom)
2019-09-26 13:23:26,070 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4f76ea72-e2bd-4b64-8492-897eed66a8b2 does not exist. Creating ...
2019-09-26 13:23:26,083 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4f76ea72-e2bd-4b64-8492-897eed66a8b2/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,096 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4f76ea72-e2bd-4b64-8492-897eed66a8b2 has been successfully formatted.
2019-09-26 13:23:26,096 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-897EED66A8B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,096 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,096 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,096 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4f76ea72-e2bd-4b64-8492-897eed66a8b2
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,098 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,101 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: start as a follower, conf=-1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:26,101 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,101 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start FollowerState
2019-09-26 13:23:26,102 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-897EED66A8B2,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:23:26,108 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4f76ea72-e2bd-4b64-8492-897eed66a8b2, Nodes: b2271e47-a7e8-4366-9c95-78f4bcf85493{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,108 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,108 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,122 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-9BC1935950C4:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-9BC1935950C4:java.util.concurrent.CompletableFuture@150cd6f[Not completed]
2019-09-26 13:23:26,124 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-9BC1935950C4:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,124 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,125 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,125 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,125 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:26,125 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/c0476824-00da-4b48-a6ef-9bc1935950c4 does not exist. Creating ...
2019-09-26 13:23:26,138 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/c0476824-00da-4b48-a6ef-9bc1935950c4/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,151 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/c0476824-00da-4b48-a6ef-9bc1935950c4 has been successfully formatted.
2019-09-26 13:23:26,151 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-9BC1935950C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/c0476824-00da-4b48-a6ef-9bc1935950c4
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,153 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,156 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:26,156 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,157 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:26,157 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9BC1935950C4,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:26,162 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c0476824-00da-4b48-a6ef-9bc1935950c4, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,162 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,162 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,171 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-06D20AEB89AE:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-06D20AEB89AE:java.util.concurrent.CompletableFuture@5179f501[Not completed]
2019-09-26 13:23:26,172 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-06D20AEB89AE:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,172 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:26,173 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/85919377-df8e-4f7c-b711-06d20aeb89ae does not exist. Creating ...
2019-09-26 13:23:26,186 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/85919377-df8e-4f7c-b711-06d20aeb89ae/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,198 [IPC Server handler 1 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume25762 for user:user40115
2019-09-26 13:23:26,198 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/85919377-df8e-4f7c-b711-06d20aeb89ae has been successfully formatted.
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-06D20AEB89AE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,199 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/85919377-df8e-4f7c-b711-06d20aeb89ae
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,200 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,201 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,201 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,201 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,201 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,201 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,202 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,202 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,202 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,202 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,493 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:26,493 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,493 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:26,494 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-06D20AEB89AE,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:26,515 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 85919377-df8e-4f7c-b711-06d20aeb89ae, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,515 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,515 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,540 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: addNew group-3F5E84B78ED1:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] returns group-3F5E84B78ED1:java.util.concurrent.CompletableFuture@7851d7ca[Not completed]
2019-09-26 13:23:26,542 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: new RaftServerImpl for group-3F5E84B78ED1:[90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,542 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,542 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,543 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,543 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,543 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,543 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: ConfigurationManager, init=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,545 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis] (custom)
2019-09-26 13:23:26,551 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/a5352b2a-5300-416e-8fa7-3f5e84b78ed1 does not exist. Creating ...
2019-09-26 13:23:26,555 [Thread-227] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume25762/bucket83381, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:23:26,603 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/a5352b2a-5300-416e-8fa7-3f5e84b78ed1/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,620 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/a5352b2a-5300-416e-8fa7-3f5e84b78ed1 has been successfully formatted.
2019-09-26 13:23:26,620 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3F5E84B78ED1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,620 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,621 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,621 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,621 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,621 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,621 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/a5352b2a-5300-416e-8fa7-3f5e84b78ed1
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,622 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,623 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,623 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,623 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,623 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,624 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,624 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,625 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,625 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,625 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,625 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,629 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: start as a follower, conf=-1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:26,629 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,630 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start FollowerState
2019-09-26 13:23:26,634 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3F5E84B78ED1,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:23:26,647 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a5352b2a-5300-416e-8fa7-3f5e84b78ed1, Nodes: 90ba3288-4391-43ec-9151-33e9d9c608f1{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,648 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:26,648 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,648 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,659 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-4BF2348C5744:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-4BF2348C5744:java.util.concurrent.CompletableFuture@3f7c558c[Not completed]
2019-09-26 13:23:26,662 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-4BF2348C5744:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,662 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,662 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,662 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,663 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,663 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,663 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,664 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:26,664 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/835c4ee3-629a-4011-8cde-4bf2348c5744 does not exist. Creating ...
2019-09-26 13:23:26,706 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/835c4ee3-629a-4011-8cde-4bf2348c5744/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,721 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/835c4ee3-629a-4011-8cde-4bf2348c5744 has been successfully formatted.
2019-09-26 13:23:26,729 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-4BF2348C5744: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,729 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,729 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/835c4ee3-629a-4011-8cde-4bf2348c5744
2019-09-26 13:23:26,730 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,731 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,732 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,735 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,735 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,736 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,743 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,785 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:26,785 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,785 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:26,785 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BF2348C5744,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:26,792 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 835c4ee3-629a-4011-8cde-4bf2348c5744, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,793 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:26,793 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,793 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,804 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-929A645ACD65:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-929A645ACD65:java.util.concurrent.CompletableFuture@5c2adb2b[Not completed]
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-929A645ACD65:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,805 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,806 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,806 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:26,806 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/a9906cc7-58d0-4131-9c60-929a645acd65 does not exist. Creating ...
2019-09-26 13:23:26,818 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/a9906cc7-58d0-4131-9c60-929a645acd65/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,831 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/a9906cc7-58d0-4131-9c60-929a645acd65 has been successfully formatted.
2019-09-26 13:23:26,831 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-929A645ACD65: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,832 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/a9906cc7-58d0-4131-9c60-929a645acd65
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,833 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,834 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,834 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,835 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,835 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,835 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,838 [Thread-227] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket83381.volume25762 implemented by OzoneFileSystem{URI=o3fs://bucket83381.volume25762, workingDir=o3fs://bucket83381.volume25762/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-26 13:23:26,839 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:26,839 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,839 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:26,840 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-929A645ACD65,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:26,844 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a9906cc7-58d0-4131-9c60-929a645acd65, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,845 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:26,845 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,845 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,858 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-93A69816672F:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-93A69816672F:java.util.concurrent.CompletableFuture@3b44bdd5[Not completed]
2019-09-26 13:23:26,860 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-93A69816672F:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,860 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,860 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,861 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,861 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:26,862 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d394af28-7254-400a-b21a-93a69816672f does not exist. Creating ...
2019-09-26 13:23:26,875 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d394af28-7254-400a-b21a-93a69816672f/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,894 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d394af28-7254-400a-b21a-93a69816672f has been successfully formatted.
2019-09-26 13:23:26,894 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-93A69816672F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,894 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,894 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d394af28-7254-400a-b21a-93a69816672f
2019-09-26 13:23:26,895 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,907 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,908 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,909 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,916 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:26,916 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,916 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:26,916 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-93A69816672F,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:26,922 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d394af28-7254-400a-b21a-93a69816672f, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,922 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:26,922 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,923 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,932 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-3CD764665482:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-3CD764665482:java.util.concurrent.CompletableFuture@608ef8d[Not completed]
2019-09-26 13:23:26,933 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-3CD764665482:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,933 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,934 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:26,935 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/ee779456-8303-4fb3-9b29-3cd764665482 does not exist. Creating ...
2019-09-26 13:23:26,948 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/ee779456-8303-4fb3-9b29-3cd764665482/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:26,961 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/ee779456-8303-4fb3-9b29-3cd764665482 has been successfully formatted.
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-3CD764665482: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,962 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:26,963 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/ee779456-8303-4fb3-9b29-3cd764665482
2019-09-26 13:23:26,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:26,963 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:26,964 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:26,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:26,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:26,965 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:26,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:26,965 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:26,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:26,966 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:26,968 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:26,968 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:26,968 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:26,968 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3CD764665482,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:26,975 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ee779456-8303-4fb3-9b29-3cd764665482, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:26,975 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:26,976 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:26,976 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:26,979 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(163)) - Starting Replication Monitor Thread.
2019-09-26 13:23:26,981 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(226)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-26 13:23:26,986 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-197F107EA092:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-197F107EA092:java.util.concurrent.CompletableFuture@34fcc58c[Not completed]
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-197F107EA092:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:26,987 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:26,988 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:26,988 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:26,988 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/1222f19f-a345-4101-9df9-197f107ea092 does not exist. Creating ...
13:23:26.980 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:27,000 [Thread-227] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-26 13:23:27,002 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/1222f19f-a345-4101-9df9-197f107ea092/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,015 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/1222f19f-a345-4101-9df9-197f107ea092 has been successfully formatted.
2019-09-26 13:23:27,015 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-197F107EA092: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/1222f19f-a345-4101-9df9-197f107ea092
2019-09-26 13:23:27,016 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,017 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,020 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,021 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,022 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,022 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,022 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,023 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,023 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,031 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:27,032 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,038 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:27,039 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-197F107EA092,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:27,053 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1222f19f-a345-4101-9df9-197f107ea092, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,054 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,054 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,054 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,062 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-CC53F46D2D08:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-CC53F46D2D08:java.util.concurrent.CompletableFuture@75cde47b[Not completed]
2019-09-26 13:23:27,063 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-CC53F46D2D08:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:27,063 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:27,063 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:27,063 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:27,064 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:27,064 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:27,064 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:27,064 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:27,064 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/dffc67b0-5f46-492b-8e52-cc53f46d2d08 does not exist. Creating ...
2019-09-26 13:23:27,077 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/dffc67b0-5f46-492b-8e52-cc53f46d2d08/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,090 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/dffc67b0-5f46-492b-8e52-cc53f46d2d08 has been successfully formatted.
2019-09-26 13:23:27,090 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-CC53F46D2D08: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,090 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,090 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/dffc67b0-5f46-492b-8e52-cc53f46d2d08
2019-09-26 13:23:27,099 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,100 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,101 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,101 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,102 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,104 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,104 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,104 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,110 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:27,110 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,110 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:27,111 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC53F46D2D08,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:27,122 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: dffc67b0-5f46-492b-8e52-cc53f46d2d08, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,122 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,122 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,122 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,139 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-329B5FCE35F4:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-329B5FCE35F4:java.util.concurrent.CompletableFuture@4e96fb2b[Not completed]
2019-09-26 13:23:27,140 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-329B5FCE35F4:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:27,141 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/fb1676ad-02a2-4f8e-bba9-329b5fce35f4 does not exist. Creating ...
2019-09-26 13:23:27,145 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/fb1676ad-02a2-4f8e-bba9-329b5fce35f4/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,158 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/fb1676ad-02a2-4f8e-bba9-329b5fce35f4 has been successfully formatted.
2019-09-26 13:23:27,158 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-329B5FCE35F4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/fb1676ad-02a2-4f8e-bba9-329b5fce35f4
2019-09-26 13:23:27,159 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,160 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,161 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,161 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,161 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,161 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,161 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,164 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:27,164 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,164 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:27,164 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-329B5FCE35F4,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:27,169 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fb1676ad-02a2-4f8e-bba9-329b5fce35f4, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,170 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,170 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,170 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,178 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: addNew group-2307A7EEA691:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] returns group-2307A7EEA691:java.util.concurrent.CompletableFuture@2061a1e3[Not completed]
2019-09-26 13:23:27,179 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: new RaftServerImpl for group-2307A7EEA691:[56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374] with ContainerStateMachine:uninitialized
2019-09-26 13:23:27,179 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:27,179 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:27,179 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:27,179 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:27,180 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:27,180 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: ConfigurationManager, init=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:27,180 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis] (custom)
2019-09-26 13:23:27,180 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/26f7e70e-9b91-4905-b0cd-2307a7eea691 does not exist. Creating ...
2019-09-26 13:23:27,187 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/26f7e70e-9b91-4905-b0cd-2307a7eea691/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,200 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/26f7e70e-9b91-4905-b0cd-2307a7eea691 has been successfully formatted.
2019-09-26 13:23:27,200 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-2307A7EEA691: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,200 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/26f7e70e-9b91-4905-b0cd-2307a7eea691
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,201 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,202 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,203 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,212 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,212 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,212 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,212 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,215 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: start as a follower, conf=-1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:27,215 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,215 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start FollowerState
2019-09-26 13:23:27,215 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2307A7EEA691,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:23:27,221 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 26f7e70e-9b91-4905-b0cd-2307a7eea691, Nodes: 56bc7cae-2273-4ad2-9040-d97b9977dd91{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,221 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,222 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,222 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,222 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:23:27,222 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,231 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-BCE5DC64F2CE:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-BCE5DC64F2CE:java.util.concurrent.CompletableFuture@61972f6e[Not completed]
2019-09-26 13:23:27,234 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-BCE5DC64F2CE:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:27,234 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:27,234 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:27,234 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:27,234 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:27,237 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:27,238 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:27,238 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:27,238 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d6e8ddc8-74b8-4151-9335-bce5dc64f2ce does not exist. Creating ...
2019-09-26 13:23:27,255 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d6e8ddc8-74b8-4151-9335-bce5dc64f2ce/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,265 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:23:27,267 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d6e8ddc8-74b8-4151-9335-bce5dc64f2ce has been successfully formatted.
2019-09-26 13:23:27,268 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-BCE5DC64F2CE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,268 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,268 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,270 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d6e8ddc8-74b8-4151-9335-bce5dc64f2ce
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,271 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,272 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,273 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,275 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,276 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,276 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,276 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,276 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,279 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:27,279 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,280 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:27,280 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCE5DC64F2CE,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:27,286 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d6e8ddc8-74b8-4151-9335-bce5dc64f2ce, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,287 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,287 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,287 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,287 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,297 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: addNew group-AEAD992D16BC:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] returns group-AEAD992D16BC:java.util.concurrent.CompletableFuture@5df79c22[Not completed]
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: new RaftServerImpl for group-AEAD992D16BC:[4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731] with ContainerStateMachine:uninitialized
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-26 13:23:27,299 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-26 13:23:27,300 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: ConfigurationManager, init=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null, confs=<EMPTY_MAP>
2019-09-26 13:23:27,300 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis] (custom)
2019-09-26 13:23:27,300 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d798c7ca-cb33-43f6-bde9-aead992d16bc does not exist. Creating ...
2019-09-26 13:23:27,313 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d798c7ca-cb33-43f6-bde9-aead992d16bc/in_use.lock acquired by nodename 28506@pr-hdds-1569-87zkn-1081879488
2019-09-26 13:23:27,325 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d798c7ca-cb33-43f6-bde9-aead992d16bc has been successfully formatted.
2019-09-26 13:23:27,326 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AEAD992D16BC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-26 13:23:27,326 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-26 13:23:27,326 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-26 13:23:27,326 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-26 13:23:27,326 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d798c7ca-cb33-43f6-bde9-aead992d16bc
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-26 13:23:27,327 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-26 13:23:27,328 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-26 13:23:27,329 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-26 13:23:27,329 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-26 13:23:27,329 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-26 13:23:27,329 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-26 13:23:27,330 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-26 13:23:27,330 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-26 13:23:27,333 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: start as a follower, conf=-1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:27,333 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-26 13:23:27,333 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start FollowerState
2019-09-26 13:23:27,333 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AEAD992D16BC,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:23:27,343 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d798c7ca-cb33-43f6-bde9-aead992d16bc, Nodes: 4c44e235-1460-4483-9a9f-158dc5e2c846{ip: 192.168.164.238, host: pr-hdds-1569-87zkn-1081879488, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-26 13:23:27,343 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,343 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,344 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:27,344 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,344 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,344 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:27,346 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:27,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:27,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,348 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,349 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:27,349 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:27,349 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,349 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,349 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:27,350 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,350 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,350 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:27,350 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:27,350 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:27,351 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.createPipelines(BackgroundPipelineCreator.java:99)
	at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.lambda$startFixedIntervalPipelineCreator$0(BackgroundPipelineCreator.java:70)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:23:27.356 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:27,476 [Thread-227] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 13:23:27,476 [Thread-227] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 13:23:27,478 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-26 13:23:27,478 [Thread-227] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-26 13:23:27,511 [Thread-227] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:23:27,522 [Thread-227] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:23:27,529 [Thread-227] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:23:27,558 [Thread-227] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 13:23:27,634 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-26 13:23:27,771 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1609083128_0001
2019-09-26 13:23:27,771 [Thread-227] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 13:23:27,957 [Thread-227] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 13:23:27,957 [Thread-227] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1609083128_0001
2019-09-26 13:23:27,958 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1609083128_0001
2019-09-26 13:23:27,964 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 13:23:27,978 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:27,978 [Thread-371] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:27,980 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 13:23:28,043 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 13:23:28,046 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:28,079 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:28,080 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:28,110 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:28,114 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:586+532
2019-09-26 13:23:28,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:28,123 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:23:28.146 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:28,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
13:23:28.155 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:28,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:28,184 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:28,184 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:28,184 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:28,184 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:28,184 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:28,185 [IPC Server handler 0 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:28,185 [IPC Server handler 0 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:28,185 [IPC Server handler 0 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:28,185 [IPC Server handler 0 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:28,186 [IPC Server handler 0 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:28.191 [IPC Server handler 13 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:28,193 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:28,193 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:28,963 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1609083128_0001 running in uber mode : false
2019-09-26 13:23:28,966 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 13:23:29,916 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-D2A0D070A417 changes to CANDIDATE, lastRpcTime:5183, electionTimeout:5182ms
2019-09-26 13:23:29,921 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:29,922 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:29,926 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:29,944 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:29,947 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:29,948 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:29,948 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5345ms
2019-09-26 13:23:29,957 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:29,957 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:29,960 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:29,963 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:29,964 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:29,964 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:29,970 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-F9F4E78E5405 changes to CANDIDATE, lastRpcTime:5025, electionTimeout:5025ms
2019-09-26 13:23:29,972 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:29,972 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:29,972 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:29,981 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:29,989 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:29,996 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:29,996 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5061ms
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:29,997 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:29,998 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,000 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:30,014 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,014 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,023 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,023 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,042 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-DC9D3152C9CA changes to CANDIDATE, lastRpcTime:5031, electionTimeout:5031ms
2019-09-26 13:23:30,042 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:30,042 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,043 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:30,057 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-DBFD32718550 changes to CANDIDATE, lastRpcTime:5181, electionTimeout:5181ms
2019-09-26 13:23:30,057 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:30,057 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,057 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:30,060 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:30,060 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:30,060 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5057ms
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,061 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,063 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:30,064 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,064 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,073 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5206ms
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,075 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,077 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:30,078 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,078 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,186 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:30,192 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:30,192 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:30,192 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:30,192 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:30,193 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:30,193 [IPC Server handler 17 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:30,193 [IPC Server handler 17 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:30,194 [IPC Server handler 17 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:30,194 [IPC Server handler 17 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:30,194 [IPC Server handler 17 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:30.199 [IPC Server handler 12 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:30,201 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:30,201 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:30,209 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/e25d007b-47ab-4c86-9bc3-f9f4e78e5405/current/log_inprogress_0
2019-09-26 13:23:30,209 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/75f48069-0590-4dd5-849a-d2a0d070a417/current/log_inprogress_0
2019-09-26 13:23:30,209 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/cc66bb70-f69f-4657-9f5b-dbfd32718550/current/log_inprogress_0
2019-09-26 13:23:30,209 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/c99406da-0ba3-480f-895a-dc9d3152c9ca/current/log_inprogress_0
2019-09-26 13:23:30,312 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-7065E9FA7AFA changes to CANDIDATE, lastRpcTime:5002, electionTimeout:5002ms
2019-09-26 13:23:30,313 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:30,313 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,313 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:30,319 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-009D9498AD7E changes to CANDIDATE, lastRpcTime:5188, electionTimeout:5183ms
2019-09-26 13:23:30,319 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:30,319 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,320 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:30,338 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:30,338 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:30,338 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:30,338 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:30,338 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,338 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,338 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5224ms
2019-09-26 13:23:30,338 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5039ms
2019-09-26 13:23:30,340 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,341 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,341 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,342 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,342 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,342 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,342 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,342 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,342 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,342 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,342 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,342 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,346 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:30,346 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,346 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:30,347 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,347 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:30,376 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:30,407 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/17305bd0-da9f-497d-bfbe-009d9498ad7e/current/log_inprogress_0
2019-09-26 13:23:30,416 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-E31664A251FC changes to CANDIDATE, lastRpcTime:5034, electionTimeout:5034ms
2019-09-26 13:23:30,417 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:30,417 [Thread-232] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,417 [Thread-232] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:30,421 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/f1ab3451-7f00-4b86-96b9-7065e9fa7afa/current/log_inprogress_0
2019-09-26 13:23:30,434 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:30,434 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:30,434 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,435 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5060ms
2019-09-26 13:23:30,435 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,435 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,435 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,436 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,436 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,436 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,437 [Thread-225] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-BF6CC37C7398 changes to CANDIDATE, lastRpcTime:5192, electionTimeout:5192ms
2019-09-26 13:23:30,438 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:30,438 [Thread-225] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,438 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:30,443 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:30,443 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,444 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:30,485 [Thread-235] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-D9D5A710E916 changes to CANDIDATE, lastRpcTime:5049, electionTimeout:5020ms
2019-09-26 13:23:30,485 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:30,485 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:30,485 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:30,485 [Thread-235] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,485 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,486 [Thread-235] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:30,486 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5279ms
2019-09-26 13:23:30,486 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,488 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,490 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,490 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,490 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,490 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,493 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:30,493 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,493 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,527 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4868959e-35b9-434e-8ab9-e31664a251fc/current/log_inprogress_0
2019-09-26 13:23:30,527 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:30,527 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:30,527 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5098ms
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,528 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,530 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:30,531 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,531 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:30,571 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/77273937-5fa0-441e-83c5-bf6cc37c7398/current/log_inprogress_0
2019-09-26 13:23:30,608 [Thread-238] INFO  impl.FollowerState (FollowerState.java:run(106)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999:group-F0125CF0BD7C changes to CANDIDATE, lastRpcTime:5116, electionTimeout:5116ms
2019-09-26 13:23:30,608 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown FollowerState
2019-09-26 13:23:30,608 [Thread-238] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,609 [Thread-238] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderElection
2019-09-26 13:23:30,707 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/fc461b1a-70dd-4d08-8ad3-d9d5a710e916/current/log_inprogress_0
2019-09-26 13:23:30,707 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10: begin an election at term 1 for -1: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null
2019-09-26 13:23:30,708 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderElection
2019-09-26 13:23:30,708 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,709 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: change Leader from null to e6d7f1d8-1aa8-4176-9696-232a32bf0999 at term 1 for becomeLeader, leader elected after 5223ms
2019-09-26 13:23:30,709 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,709 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,710 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,710 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,710 [Thread-241] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-7E80AEAD5E3B changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5154ms
2019-09-26 13:23:30,710 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,711 [Thread-241] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:30,711 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,711 [Thread-241] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,711 [Thread-241] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:30,719 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: start LeaderState
2019-09-26 13:23:30,719 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,720 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: set configuration 0: [e6d7f1d8-1aa8-4176-9696-232a32bf0999:192.168.164.238:40981], old=null at 0
2019-09-26 13:23:30,756 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:30,756 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:30,756 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,756 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5210ms
2019-09-26 13:23:30,757 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,758 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,758 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,758 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,758 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,758 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,761 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:30,761 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,761 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:30,792 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/ratis/72765cac-ff41-4307-a8e7-f0125cf0bd7c/current/log_inprogress_0
2019-09-26 13:23:30,805 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/bc69b7de-0409-4b1f-a957-7e80aead5e3b/current/log_inprogress_0
2019-09-26 13:23:30,952 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-185088799101 changes to CANDIDATE, lastRpcTime:5179, electionTimeout:5179ms
2019-09-26 13:23:30,953 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:30,953 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,953 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:30,976 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-1704B8D6F83F changes to CANDIDATE, lastRpcTime:5139, electionTimeout:5139ms
2019-09-26 13:23:30,976 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:30,976 [Thread-248] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,976 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:30,981 [Thread-255] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-6DDA4A5AEB3D changes to CANDIDATE, lastRpcTime:5002, electionTimeout:5002ms
2019-09-26 13:23:30,982 [Thread-255] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:30,982 [Thread-255] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:30,982 [Thread-255] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:30,987 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:30,988 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:30,988 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,988 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5222ms
2019-09-26 13:23:30,988 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,988 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,989 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,989 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,989 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,989 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,990 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:30,990 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:30,990 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:30,990 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:30,990 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,991 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:30,991 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5165ms
2019-09-26 13:23:30,991 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5019ms
2019-09-26 13:23:30,991 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,991 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:30,991 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,991 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:30,991 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,991 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:30,992 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,992 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:30,992 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,992 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:30,992 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,992 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:30,993 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:30,993 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:30,994 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:31,031 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:31,032 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,032 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:31,032 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:31,072 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-AFDC6013013E changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5029ms
2019-09-26 13:23:31,072 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/b982c78c-198a-4709-913c-185088799101/current/log_inprogress_0
2019-09-26 13:23:31,072 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,072 [Thread-251] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-114EAA4B39AF changes to CANDIDATE, lastRpcTime:5164, electionTimeout:5161ms
2019-09-26 13:23:31,072 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:31,072 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:31,072 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,072 [Thread-251] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,073 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:31,073 [Thread-251] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:31,073 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:31,104 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/11142eeb-5e1a-4120-9048-1704b8d6f83f/current/log_inprogress_0
2019-09-26 13:23:31,117 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/00344d3d-7462-4420-a744-6dda4a5aeb3d/current/log_inprogress_0
2019-09-26 13:23:31,117 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:31,117 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:31,117 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:31,118 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:31,118 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,118 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,118 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5218ms
2019-09-26 13:23:31,118 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5090ms
2019-09-26 13:23:31,120 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,120 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,120 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,120 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,121 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,121 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,121 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,121 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,121 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,121 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,121 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,122 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,125 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:31,125 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,126 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:31,126 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,126 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:31,158 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - b2271e47-a7e8-4366-9c95-78f4bcf85493:group-897EED66A8B2 changes to CANDIDATE, lastRpcTime:5057, electionTimeout:5053ms
2019-09-26 13:23:31,159 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:31,159 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown FollowerState
2019-09-26 13:23:31,196 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/e6fa1aa2-65e5-49e7-a603-114eaa4b39af/current/log_inprogress_0
2019-09-26 13:23:31,197 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,197 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderElection
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/6b110bb8-2460-4e4f-9403-afdc6013013e/current/log_inprogress_0
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17: begin an election at term 1 for -1: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderElection
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: change Leader from null to b2271e47-a7e8-4366-9c95-78f4bcf85493 at term 1 for becomeLeader, leader elected after 5113ms
2019-09-26 13:23:31,209 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,210 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,210 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,210 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,210 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,210 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,213 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: start LeaderState
2019-09-26 13:23:31,213 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,214 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: set configuration 0: [b2271e47-a7e8-4366-9c95-78f4bcf85493:192.168.164.238:35856], old=null at 0
2019-09-26 13:23:31,275 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/ratis/4f76ea72-e2bd-4b64-8492-897eed66a8b2/current/log_inprogress_0
2019-09-26 13:23:31,342 [Thread-265] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-9BC1935950C4 changes to CANDIDATE, lastRpcTime:5185, electionTimeout:5185ms
2019-09-26 13:23:31,342 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:31,343 [Thread-265] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,343 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:31,361 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:31,362 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:31,362 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,362 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5210ms
2019-09-26 13:23:31,362 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,362 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,363 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,363 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,363 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,363 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,366 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:31,366 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,367 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:31,418 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/c0476824-00da-4b48-a6ef-9bc1935950c4/current/log_inprogress_0
2019-09-26 13:23:31,670 [Thread-268] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-06D20AEB89AE changes to CANDIDATE, lastRpcTime:5176, electionTimeout:5176ms
2019-09-26 13:23:31,671 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:31,671 [Thread-268] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,671 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:31,689 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:31,689 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:31,689 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,689 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5490ms
2019-09-26 13:23:31,690 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,690 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,690 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,690 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,690 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,691 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,694 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:31,694 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,695 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:31,748 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/85919377-df8e-4f7c-b711-06d20aeb89ae/current/log_inprogress_0
2019-09-26 13:23:31,792 [Thread-272] INFO  impl.FollowerState (FollowerState.java:run(106)) - 90ba3288-4391-43ec-9151-33e9d9c608f1:group-3F5E84B78ED1 changes to CANDIDATE, lastRpcTime:5162, electionTimeout:5162ms
2019-09-26 13:23:31,793 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown FollowerState
2019-09-26 13:23:31,793 [Thread-272] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,793 [Thread-272] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderElection
2019-09-26 13:23:31,837 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20: begin an election at term 1 for -1: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null
2019-09-26 13:23:31,837 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderElection
2019-09-26 13:23:31,837 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,837 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: change Leader from null to 90ba3288-4391-43ec-9151-33e9d9c608f1 at term 1 for becomeLeader, leader elected after 5217ms
2019-09-26 13:23:31,838 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,838 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,838 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,838 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,838 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,839 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,842 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: start LeaderState
2019-09-26 13:23:31,842 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,842 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: set configuration 0: [90ba3288-4391-43ec-9151-33e9d9c608f1:192.168.164.238:42099], old=null at 0
2019-09-26 13:23:31,878 [Thread-276] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-4BF2348C5744 changes to CANDIDATE, lastRpcTime:5093, electionTimeout:5090ms
2019-09-26 13:23:31,885 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:31,885 [Thread-276] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,885 [Thread-276] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:31,891 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/ratis/a5352b2a-5300-416e-8fa7-3f5e84b78ed1/current/log_inprogress_0
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5162ms
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:31,892 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:31,893 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:31,893 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:31,893 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:31,895 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:31,896 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:31,896 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:31,937 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/835c4ee3-629a-4011-8cde-4bf2348c5744/current/log_inprogress_0
2019-09-26 13:23:31,983 [Thread-285] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-93A69816672F changes to CANDIDATE, lastRpcTime:5067, electionTimeout:5067ms
2019-09-26 13:23:31,984 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:31,984 [Thread-285] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:31,984 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:31,999 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5105ms
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,000 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,001 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,003 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:32,003 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,004 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:32,033 [Thread-279] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-929A645ACD65 changes to CANDIDATE, lastRpcTime:5194, electionTimeout:5191ms
2019-09-26 13:23:32,034 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:32,034 [Thread-279] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,034 [Thread-279] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:32,046 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d394af28-7254-400a-b21a-93a69816672f/current/log_inprogress_0
2019-09-26 13:23:32,046 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:32,046 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:32,046 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,046 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5214ms
2019-09-26 13:23:32,046 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,047 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,047 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,047 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,047 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,047 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,049 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:32,049 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,050 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:32,081 [Thread-288] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-3CD764665482 changes to CANDIDATE, lastRpcTime:5113, electionTimeout:5109ms
2019-09-26 13:23:32,081 [Thread-296] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-197F107EA092 changes to CANDIDATE, lastRpcTime:5044, electionTimeout:5011ms
2019-09-26 13:23:32,082 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:32,082 [Thread-296] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:32,082 [Thread-288] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,082 [Thread-296] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,082 [Thread-288] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:32,082 [Thread-296] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:32,084 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/a9906cc7-58d0-4131-9c60-929a645acd65/current/log_inprogress_0
2019-09-26 13:23:32,099 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:32,099 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:32,099 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:32,099 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:32,099 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,099 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,099 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5137ms
2019-09-26 13:23:32,100 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5084ms
2019-09-26 13:23:32,100 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,100 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,100 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,100 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,100 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,100 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,100 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,100 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,100 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,101 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,101 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,101 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,103 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:32,103 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,104 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:32,104 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:32,104 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,138 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:32,176 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/ee779456-8303-4fb3-9b29-3cd764665482/current/log_inprogress_0
2019-09-26 13:23:32,189 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/1222f19f-a345-4101-9df9-197f107ea092/current/log_inprogress_0
2019-09-26 13:23:32,225 [Thread-307] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-CC53F46D2D08 changes to CANDIDATE, lastRpcTime:5114, electionTimeout:5114ms
2019-09-26 13:23:32,225 [Thread-307] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:32,225 [Thread-307] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,225 [Thread-307] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:32,242 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:32,242 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:32,242 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,242 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5152ms
2019-09-26 13:23:32,242 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,243 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,243 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,243 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,243 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,243 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,246 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:32,246 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,247 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:32,283 [Thread-315] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-329B5FCE35F4 changes to CANDIDATE, lastRpcTime:5119, electionTimeout:5119ms
2019-09-26 13:23:32,284 [Thread-315] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:32,284 [Thread-315] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,284 [Thread-315] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/dffc67b0-5f46-492b-8e52-cc53f46d2d08/current/log_inprogress_0
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5138ms
2019-09-26 13:23:32,297 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,298 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,298 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,298 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,298 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,298 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,303 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:32,303 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,304 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:32,356 [Thread-318] INFO  impl.FollowerState (FollowerState.java:run(106)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91:group-2307A7EEA691 changes to CANDIDATE, lastRpcTime:5140, electionTimeout:5140ms
2019-09-26 13:23:32,356 [Thread-318] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown FollowerState
2019-09-26 13:23:32,356 [Thread-318] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,357 [Thread-318] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderElection
2019-09-26 13:23:32,473 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/fb1676ad-02a2-4f8e-bba9-329b5fce35f4/current/log_inprogress_0
2019-09-26 13:23:32,473 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28: begin an election at term 1 for -1: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null
2019-09-26 13:23:32,473 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderElection
2019-09-26 13:23:32,473 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,473 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: change Leader from null to 56bc7cae-2273-4ad2-9040-d97b9977dd91 at term 1 for becomeLeader, leader elected after 5272ms
2019-09-26 13:23:32,474 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,474 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,474 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,474 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,475 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,475 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,478 [Thread-331] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-AEAD992D16BC changes to CANDIDATE, lastRpcTime:5144, electionTimeout:5144ms
2019-09-26 13:23:32,478 [Thread-331] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:32,478 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: start LeaderState
2019-09-26 13:23:32,478 [Thread-331] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,479 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,479 [Thread-331] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:32,479 [Thread-328] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4c44e235-1460-4483-9a9f-158dc5e2c846:group-BCE5DC64F2CE changes to CANDIDATE, lastRpcTime:5199, electionTimeout:5199ms
2019-09-26 13:23:32,480 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: set configuration 0: [56bc7cae-2273-4ad2-9040-d97b9977dd91:192.168.164.238:37374], old=null at 0
2019-09-26 13:23:32,480 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown FollowerState
2019-09-26 13:23:32,522 [Thread-328] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-26 13:23:32,522 [Thread-328] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderElection
2019-09-26 13:23:32,527 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/ratis/26f7e70e-9b91-4905-b0cd-2307a7eea691/current/log_inprogress_0
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5202ms
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,528 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,529 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,529 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,529 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,529 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30: begin an election at term 1 for -1: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderElection
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: change Leader from null to 4c44e235-1460-4483-9a9f-158dc5e2c846 at term 1 for becomeLeader, leader elected after 5263ms
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-26 13:23:32,531 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-26 13:23:32,532 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-26 13:23:32,532 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-26 13:23:32,532 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-26 13:23:32,532 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-26 13:23:32,533 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:32,533 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,534 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:32,537 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: start LeaderState
2019-09-26 13:23:32,537 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-26 13:23:32,538 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: set configuration 0: [4c44e235-1460-4483-9a9f-158dc5e2c846:192.168.164.238:38731], old=null at 0
2019-09-26 13:23:32,585 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d6e8ddc8-74b8-4151-9335-bce5dc64f2ce/current/log_inprogress_0
2019-09-26 13:23:32,585 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/ratis/d798c7ca-cb33-43f6-bde9-aead992d16bc/current/log_inprogress_0
2019-09-26 13:23:33,237 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:33,242 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:33,243 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:33,243 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:33,243 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:33,243 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:33,244 [IPC Server handler 1 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:33,244 [IPC Server handler 1 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:33,245 [IPC Server handler 1 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:33,245 [IPC Server handler 1 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:33,245 [IPC Server handler 1 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:33.249 [IPC Server handler 14 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:33,250 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000000_0
2019-09-26 13:23:33,250 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:33,251 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:33,259 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000001_0
2019-09-26 13:23:33,269 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:33,269 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:33,270 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:33,272 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:0+324
2019-09-26 13:23:33,273 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:33,273 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:23:33.291 [IPC Server handler 16 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:33,293 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
13:23:33.299 [IPC Server handler 17 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:33,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:33,333 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000001_0 is done. And is in the process of committing
2019-09-26 13:23:33,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:33,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000001_0 is allowed to commit now
2019-09-26 13:23:33,338 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:33,339 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-26 13:23:33,339 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000001_0' done.
2019-09-26 13:23:33,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=208815
		FILE: Number of bytes written=822951
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:33,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000001_0
2019-09-26 13:23:33,346 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:33,347 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:33,347 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:33,348 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:33,349 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:1396+290
2019-09-26 13:23:33,349 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:33,349 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:33,365 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
13:23:33.371 [IPC Server handler 0 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:33,372 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:33,375 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:33,378 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:33,378 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:33,378 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:33,378 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:33,379 [IPC Server handler 18 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:33,379 [IPC Server handler 18 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:33,379 [IPC Server handler 18 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:33,380 [IPC Server handler 18 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:33,380 [IPC Server handler 18 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:33.383 [IPC Server handler 2 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:33,384 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:33,384 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:33,974 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 13:23:35,592 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:35,597 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:35,597 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:35,598 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:35,598 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:35,598 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:35,598 [IPC Server handler 16 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:35,598 [IPC Server handler 16 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:35,599 [IPC Server handler 16 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:35,599 [IPC Server handler 16 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:35,599 [IPC Server handler 16 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:35.603 [IPC Server handler 4 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:35,604 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:35,605 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:40,101 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-26 13:23:40,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:40,691 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:40,691 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:40,691 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:40,692 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:40,692 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:40,692 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:40,692 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:40,693 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:40,693 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:40,693 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:40.700 [IPC Server handler 7 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:40,704 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000002_0
2019-09-26 13:23:40,704 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:40,705 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:40,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:40,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:40,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:40,708 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:40,710 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:1948+290
2019-09-26 13:23:40,711 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:40,711 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:40,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
13:23:40.736 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:40,739 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:40,743 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:40,743 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:40,743 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:40,743 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:40,744 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:40,744 [IPC Server handler 19 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:40,744 [IPC Server handler 19 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:40,745 [IPC Server handler 19 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:40,745 [IPC Server handler 19 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:40,745 [IPC Server handler 19 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:40.750 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:40,752 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:40,752 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:40,979 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-26 13:23:43,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:43,140 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:43,141 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:43,141 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:43,141 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:43,142 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:43,142 [IPC Server handler 0 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:43,142 [IPC Server handler 0 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:43,143 [IPC Server handler 0 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:43,143 [IPC Server handler 0 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:43,143 [IPC Server handler 0 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:43.150 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:43,154 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:43,154 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:45,366 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 13:23:45,983 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 25% reduce 0%
2019-09-26 13:23:47,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:47,714 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:47,715 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:47,715 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:47,715 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:47,715 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:47,716 [IPC Server handler 19 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:47,716 [IPC Server handler 19 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:47,716 [IPC Server handler 19 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:47,717 [IPC Server handler 19 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:47,717 [IPC Server handler 19 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:47.719 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:47,721 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000003_0
2019-09-26 13:23:47,721 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:47,721 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:47,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:47,724 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:47,724 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:47,725 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:47,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:2778+290
2019-09-26 13:23:47,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:47,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:47,743 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
13:23:47.749 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:47,750 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:47,753 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:47,753 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:47,754 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:47,754 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:47,754 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:47,754 [IPC Server handler 8 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:47,754 [IPC Server handler 8 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:47,755 [IPC Server handler 8 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:47,755 [IPC Server handler 8 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:47,756 [IPC Server handler 8 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:47.758 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:47,759 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:47,759 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:49,007 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:49,016 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:49,016 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:49,016 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:49,017 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:49,017 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:49,017 [IPC Server handler 15 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:49,017 [IPC Server handler 15 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:49,017 [IPC Server handler 15 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:49,018 [IPC Server handler 15 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:49,018 [IPC Server handler 15 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:49.023 [IPC Server handler 15 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:49,025 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:49,025 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:51,367 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 13:23:52,718 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-26 13:23:52,987 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 35% reduce 0%
2019-09-26 13:23:53,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:53,077 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:53,078 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:53,078 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:53,078 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:53,078 [IPC Server handler 0 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:53,078 [IPC Server handler 0 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:53,079 [IPC Server handler 0 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:53,079 [IPC Server handler 0 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:53,079 [IPC Server handler 0 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:53,079 [IPC Server handler 0 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:53.081 [IPC Server handler 16 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:53,082 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1609083128_0001_m_000004_0
2019-09-26 13:23:53,082 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:53,083 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:53,084 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000005_0
2019-09-26 13:23:53,084 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,084 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,085 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:53,086 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:1118+278
2019-09-26 13:23:53,086 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,086 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
13:23:53.104 [IPC Server handler 19 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:53,108 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000005_0 is done. And is in the process of committing
2019-09-26 13:23:53,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,109 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000005_0 is allowed to commit now
2019-09-26 13:23:53,111 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:53,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 13:23:53,111 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000005_0' done.
2019-09-26 13:23:53,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=226691
		FILE: Number of bytes written=822983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=28
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:53,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000005_0
2019-09-26 13:23:53,112 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000006_0
2019-09-26 13:23:53,113 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,113 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:53,114 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:2500+278
2019-09-26 13:23:53,115 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,115 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,127 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
13:23:53.131 [IPC Server handler 1 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:53,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000006_0 is done. And is in the process of committing
2019-09-26 13:23:53,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,136 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000006_0 is allowed to commit now
2019-09-26 13:23:53,138 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:53,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 13:23:53,138 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000006_0' done.
2019-09-26 13:23:53,139 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=230904
		FILE: Number of bytes written=822991
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=30
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:53,139 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000006_0
2019-09-26 13:23:53,140 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000007_0
2019-09-26 13:23:53,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,140 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,141 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:53,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:324+262
2019-09-26 13:23:53,142 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,142 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-26 13:23:53,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,162 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000007_0 is done. And is in the process of committing
2019-09-26 13:23:53,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000007_0 is allowed to commit now
2019-09-26 13:23:53,164 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:53,164 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-26 13:23:53,164 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000007_0' done.
2019-09-26 13:23:53,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=234605
		FILE: Number of bytes written=822999
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=32
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:53,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000007_0
2019-09-26 13:23:53,165 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000008_0
2019-09-26 13:23:53,166 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,166 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,166 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:53,167 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:1686+262
2019-09-26 13:23:53,167 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,167 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,177 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-26 13:23:53,184 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,184 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000008_0 is done. And is in the process of committing
2019-09-26 13:23:53,185 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,185 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000008_0 is allowed to commit now
2019-09-26 13:23:53,186 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-26 13:23:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000008_0' done.
2019-09-26 13:23:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=238306
		FILE: Number of bytes written=823007
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=34
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000008_0
2019-09-26 13:23:53,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1609083128_0001_m_000009_0
2019-09-26 13:23:53,188 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,188 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:53,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/fileList.seq:2238+262
2019-09-26 13:23:53,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:53,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:53,201 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
13:23:53.205 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25762, bucket=bucket83381, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25762 bucket: bucket83381 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:53,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,210 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1609083128_0001_m_000009_0 is done. And is in the process of committing
2019-09-26 13:23:53,211 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:53,211 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1609083128_0001_m_000009_0 is allowed to commit now
2019-09-26 13:23:53,212 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1609083128_0001_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612/_logs
2019-09-26 13:23:53,212 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-26 13:23:53,212 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1609083128_0001_m_000009_0' done.
2019-09-26 13:23:53,213 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1609083128_0001_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=242007
		FILE: Number of bytes written=823015
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=36
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:53,213 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1609083128_0001_m_000009_0
2019-09-26 13:23:53,213 [Thread-371] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 13:23:53,246 [Thread-371] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins100034201710/.staging/_distcp-1102727612
2019-09-26 13:23:53,248 [Thread-371] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1609083128_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket83381.volume25762/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:53,988 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 13:23:53,989 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1609083128_0001 failed with state FAILED due to: NA
2019-09-26 13:23:54,056 [Thread-227] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=2039824
		FILE: Number of bytes written=7406855
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=236
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=189
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1413
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=18525192192
	File Input Format Counters 
		Bytes Read=28116
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-26 13:23:54,116 [Thread-487] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 13:23:54,146 [Thread-487] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume90272, with user31277 as owner.
2019-09-26 13:23:54,148 [IPC Server handler 10 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume90272 for user:user31277
2019-09-26 13:23:54,152 [Thread-487] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume90272/bucket24976, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:23:54,205 [Thread-487] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket24976.volume90272 implemented by OzoneFileSystem{URI=o3fs://bucket24976.volume90272, workingDir=o3fs://bucket24976.volume90272/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 43 read ops, 0 large read ops, 26 write ops}
13:23:54.222 [IPC Server handler 4 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:54,225 [Thread-487] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-26 13:23:54,287 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:23:54,296 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
13:23:54.308 [IPC Server handler 5 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:54,364 [Thread-487] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 13:23:54,364 [Thread-487] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 13:23:54,381 [Thread-487] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:23:54,390 [Thread-487] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:23:54,391 [Thread-487] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:23:54,402 [Thread-487] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 13:23:54,445 [Thread-487] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-26 13:23:54,478 [Thread-487] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1396996654_0002
2019-09-26 13:23:54,478 [Thread-487] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 13:23:54,583 [Thread-487] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 13:23:54,586 [Thread-551] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 13:23:54,586 [Thread-487] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1396996654_0002
2019-09-26 13:23:54,586 [Thread-551] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:54,586 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1396996654_0002
2019-09-26 13:23:54,587 [Thread-551] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:54,587 [Thread-551] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 13:23:54,608 [Thread-551] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 13:23:54,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:54,609 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:54,609 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:54,610 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:54,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:861+546
2019-09-26 13:23:54,614 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:54,614 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:23:54.632 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:54,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
13:23:54.640 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:54,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:54,645 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:54,646 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:54,646 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:54,646 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:54,646 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:54.648 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:54,649 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:54,650 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:55,587 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1396996654_0002 running in uber mode : false
2019-09-26 13:23:55,588 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 13:23:57,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:57,081 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:57,081 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:57,081 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:57,081 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:57,082 [IPC Server handler 17 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:57,082 [IPC Server handler 17 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:57,082 [IPC Server handler 17 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:57,082 [IPC Server handler 17 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:57,082 [IPC Server handler 17 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:57,083 [IPC Server handler 17 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:57.085 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:57,086 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:57,089 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:58,719 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-26 13:23:59,373 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:59,376 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:59,376 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:59,377 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:59,377 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:59,377 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:59,377 [IPC Server handler 18 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:59,377 [IPC Server handler 18 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:59,378 [IPC Server handler 18 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:59,378 [IPC Server handler 18 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:59,378 [IPC Server handler 18 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:59.381 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:59,382 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000000_0
2019-09-26 13:23:59,382 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:59,383 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:23:59,383 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000001_0
2019-09-26 13:23:59,385 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:59,385 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:59,385 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:59,386 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:0+323
2019-09-26 13:23:59,386 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:59,386 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:23:59.400 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:59,402 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
13:23:59.407 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:59,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:59,412 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000001_0 is done. And is in the process of committing
2019-09-26 13:23:59,413 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:23:59,413 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000001_0 is allowed to commit now
2019-09-26 13:23:59,415 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:23:59,416 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-26 13:23:59,416 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000001_0' done.
2019-09-26 13:23:59,416 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=450765
		FILE: Number of bytes written=1645945
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:23:59,416 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000001_0
2019-09-26 13:23:59,417 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000002_0
2019-09-26 13:23:59,417 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:59,417 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:59,418 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:23:59,419 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:2218+289
2019-09-26 13:23:59,419 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:23:59,419 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:23:59,432 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
13:23:59.436 [IPC Server handler 12 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:59,437 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:23:59,444 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:23:59,446 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:23:59,446 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:23:59,446 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:23:59,447 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:23:59,447 [IPC Server handler 16 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:23:59,447 [IPC Server handler 16 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:59,456 [IPC Server handler 16 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:23:59,456 [IPC Server handler 16 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:23:59,456 [IPC Server handler 16 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:23:59.459 [IPC Server handler 14 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:23:59,460 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:23:59,460 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:23:59,590 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 13:23:59,731 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 13:24:00,842 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:24:00,847 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:00,848 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:00,848 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:00,848 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:00,848 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:00,849 [IPC Server handler 6 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:00,849 [IPC Server handler 6 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:00,849 [IPC Server handler 6 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:00,850 [IPC Server handler 6 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:00,850 [IPC Server handler 6 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:00.853 [IPC Server handler 17 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:00,854 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:24:00,854 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:06,366 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:24:06,370 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:06,370 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:06,371 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:06,371 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:06,371 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:06,371 [IPC Server handler 18 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:06,371 [IPC Server handler 18 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:06,372 [IPC Server handler 18 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:06,372 [IPC Server handler 18 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:06,372 [IPC Server handler 18 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:06.375 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:06,377 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000002_0
2019-09-26 13:24:06,377 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:06,378 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:06,379 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:06,380 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:06,380 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:06,381 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:06,382 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:2768+289
2019-09-26 13:24:06,383 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:06,383 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:06,402 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
13:24:06.409 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:06,410 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:06,413 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:06,413 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:06,414 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:06,414 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:06,414 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:06,414 [IPC Server handler 16 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:06,414 [IPC Server handler 16 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:06,415 [IPC Server handler 16 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:06,415 [IPC Server handler 16 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:06,415 [IPC Server handler 16 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:06.417 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:06,419 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:06,419 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:06,630 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 13:24:07,594 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-26 13:24:08,459 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:08,462 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:08,463 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:08,464 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:08,464 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:08,464 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:08.467 [IPC Server handler 17 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:08,468 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:08,468 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:11,114 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:11,117 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:11,117 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:11,118 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:11,118 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:11,118 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:11,118 [IPC Server handler 1 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:11,118 [IPC Server handler 1 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:11,119 [IPC Server handler 1 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:11,119 [IPC Server handler 1 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:11,119 [IPC Server handler 1 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:11.122 [IPC Server handler 18 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:11,123 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000003_0
2019-09-26 13:24:11,123 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:11,124 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:11,124 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000004_0
2019-09-26 13:24:11,125 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,125 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,126 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:11,126 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:584+277
2019-09-26 13:24:11,127 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,127 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
13:24:11.148 [IPC Server handler 1 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:11,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:11,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000004_0 is done. And is in the process of committing
2019-09-26 13:24:11,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:11,154 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000004_0 is allowed to commit now
2019-09-26 13:24:11,156 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:24:11,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 13:24:11,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000004_0' done.
2019-09-26 13:24:11,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=464425
		FILE: Number of bytes written=1645969
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=66
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:11,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000004_0
2019-09-26 13:24:11,157 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000005_0
2019-09-26 13:24:11,159 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,159 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,159 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:11,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:1941+277
2019-09-26 13:24:11,161 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,162 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,177 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
13:24:11.182 [IPC Server handler 4 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:11,186 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:11,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000005_0 is done. And is in the process of committing
2019-09-26 13:24:11,187 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:11,188 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000005_0 is allowed to commit now
2019-09-26 13:24:11,190 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:24:11,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 13:24:11,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000005_0' done.
2019-09-26 13:24:11,191 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=468637
		FILE: Number of bytes written=1645977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=68
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:11,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000005_0
2019-09-26 13:24:11,192 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:11,192 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,193 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,193 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:11,194 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:1668+273
2019-09-26 13:24:11,194 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:11,194 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:11,209 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
13:24:11.214 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:11,215 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:11,217 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:11,220 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:11,220 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:11,220 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:11,220 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:11,221 [IPC Server handler 18 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:11,221 [IPC Server handler 18 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:11,221 [IPC Server handler 18 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:11,221 [IPC Server handler 18 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:11,221 [IPC Server handler 18 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:11.223 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:11,224 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:11,225 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:11,437 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-26 13:24:11,596 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 45% reduce 0%
2019-09-26 13:24:13,597 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:13,601 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:13,602 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:13,602 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:13,602 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:13,602 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:13,603 [IPC Server handler 19 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:13,603 [IPC Server handler 19 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:13,604 [IPC Server handler 19 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:13,604 [IPC Server handler 19 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:13,604 [IPC Server handler 19 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:13.607 [IPC Server handler 18 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:13,608 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:13,609 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:16,100 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:16,107 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:16,107 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:16,107 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:16,107 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:16,107 [IPC Server handler 1 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:16,108 [IPC Server handler 1 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:16,108 [IPC Server handler 1 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:16,108 [IPC Server handler 1 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:16,108 [IPC Server handler 1 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:16,108 [IPC Server handler 1 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:16.112 [IPC Server handler 1 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:16,113 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1396996654_0002_m_000006_0
2019-09-26 13:24:16,113 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:16,114 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:16,115 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000007_0
2019-09-26 13:24:16,116 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,116 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:16,118 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:323+261
2019-09-26 13:24:16,118 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,118 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,134 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 13:24:16,145 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,146 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000007_0 is done. And is in the process of committing
2019-09-26 13:24:16,146 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,146 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000007_0 is allowed to commit now
2019-09-26 13:24:16,147 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:24:16,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 13:24:16,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000007_0' done.
2019-09-26 13:24:16,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=476549
		FILE: Number of bytes written=1645993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=75
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:16,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000007_0
2019-09-26 13:24:16,148 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000008_0
2019-09-26 13:24:16,149 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,149 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,149 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:16,150 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:1407+261
2019-09-26 13:24:16,150 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,151 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,163 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
13:24:16.169 [IPC Server handler 5 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume90272, bucket=bucket24976, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume90272 bucket: bucket24976 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:16,173 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,173 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000008_0 is done. And is in the process of committing
2019-09-26 13:24:16,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,174 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000008_0 is allowed to commit now
2019-09-26 13:24:16,175 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:24:16,175 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-26 13:24:16,175 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000008_0' done.
2019-09-26 13:24:16,176 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=480249
		FILE: Number of bytes written=1646001
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=77
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:16,176 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000008_0
2019-09-26 13:24:16,176 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1396996654_0002_m_000009_0
2019-09-26 13:24:16,176 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,176 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,177 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:16,177 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/fileList.seq:2507+261
2019-09-26 13:24:16,178 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:16,178 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:16,189 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 13:24:16,197 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1396996654_0002_m_000009_0 is done. And is in the process of committing
2019-09-26 13:24:16,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:16,198 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1396996654_0002_m_000009_0 is allowed to commit now
2019-09-26 13:24:16,199 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1396996654_0002_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094/_logs
2019-09-26 13:24:16,199 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 13:24:16,199 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1396996654_0002_m_000009_0' done.
2019-09-26 13:24:16,200 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1396996654_0002_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=483949
		FILE: Number of bytes written=1646009
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=79
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=51
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3113
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:16,200 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1396996654_0002_m_000009_0
2019-09-26 13:24:16,200 [Thread-551] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 13:24:16,216 [Thread-551] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001716130956/.staging/_distcp1629439094
2019-09-26 13:24:16,220 [Thread-551] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1396996654_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket24976.volume90272/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:16,600 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 13:24:16,601 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1396996654_0002 failed with state FAILED due to: NA
2019-09-26 13:24:16,670 [Thread-487] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=3757636
		FILE: Number of bytes written=13167840
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=552
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=364
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1264
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16466837504
	File Input Format Counters 
		Bytes Read=24904
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-26 13:24:16,732 [Thread-599] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 13:24:16,773 [Thread-599] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume23652, with user43138 as owner.
2019-09-26 13:24:16,777 [IPC Server handler 15 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume23652 for user:user43138
2019-09-26 13:24:16,782 [Thread-599] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume23652/bucket91465, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:24:16,832 [Thread-599] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket91465.volume23652 implemented by OzoneFileSystem{URI=o3fs://bucket91465.volume23652, workingDir=o3fs://bucket91465.volume23652/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 86 read ops, 0 large read ops, 52 write ops}
13:24:16.856 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:16,859 [Thread-599] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-26 13:24:16,868 [Thread-599] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-26 13:24:17,116 [Thread-599] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:24:17,124 [Thread-599] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
13:24:17.134 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:17,164 [Thread-599] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-26 13:24:17,167 [Thread-599] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 13:24:17,177 [Thread-599] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-26 13:24:17,187 [Thread-599] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-26 13:24:17,189 [Thread-599] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:24:17,195 [Thread-599] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 13:24:17,239 [Thread-599] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-26 13:24:17,286 [Thread-599] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1544285658_0003
2019-09-26 13:24:17,287 [Thread-599] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 13:24:17,396 [Thread-599] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 13:24:17,399 [Thread-647] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 13:24:17,399 [Thread-599] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1544285658_0003
2019-09-26 13:24:17,399 [Thread-647] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:17,400 [Thread-599] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1544285658_0003
2019-09-26 13:24:17,400 [Thread-647] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:17,400 [Thread-647] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 13:24:17,417 [Thread-647] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 13:24:17,418 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:17,418 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:17,418 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:17,419 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:17,420 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000116559433/.staging/_distcp1868584561/fileList.seq:0+771
2019-09-26 13:24:17,420 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:17,421 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:17,438 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
13:24:17.438 [IPC Server handler 13 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:17,440 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
13:24:17.445 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:17,449 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
13:24:17.454 [IPC Server handler 15 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:17,455 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:17,457 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:17,458 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:17,458 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:17,458 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:17,458 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:17,459 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:17,459 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:17,459 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:17,460 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:17,460 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:17.462 [IPC Server handler 16 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:17,463 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:17,463 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:18,388 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-26 13:24:18,400 [Thread-599] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1544285658_0003 running in uber mode : false
2019-09-26 13:24:18,401 [Thread-599] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 13:24:20,260 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:20,264 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:20,264 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:20,265 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:20,265 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:20,265 [IPC Server handler 16 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:20,265 [IPC Server handler 16 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:20,265 [IPC Server handler 16 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:20,266 [IPC Server handler 16 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:20,266 [IPC Server handler 16 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:20,267 [IPC Server handler 16 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:20.269 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:20,271 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:20,271 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:22,448 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:22,452 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:22,452 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:22,453 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:22,453 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:22,453 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:22,453 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:22,454 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:22,454 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:22,455 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:22,455 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:22.458 [IPC Server handler 14 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:22,459 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000000_0
2019-09-26 13:24:22,460 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:22,460 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:22,476 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:22,477 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:22,477 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:22,478 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:22,479 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000116559433/.staging/_distcp1868584561/fileList.seq:771+235
2019-09-26 13:24:22,479 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:22,480 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:22,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
13:24:22.504 [IPC Server handler 19 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:22,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:22,509 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:22,509 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:22,509 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:22,510 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:22,510 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:22,510 [IPC Server handler 19 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:22,510 [IPC Server handler 19 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:22,511 [IPC Server handler 19 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:22,511 [IPC Server handler 19 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:22,511 [IPC Server handler 19 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:22.513 [IPC Server handler 0 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:22,515 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:22,515 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:23,200 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-26 13:24:23,567 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:23,570 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:23,570 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:23,570 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:23,571 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:23,571 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:23,571 [IPC Server handler 8 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:23,571 [IPC Server handler 8 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:23,572 [IPC Server handler 8 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:23,572 [IPC Server handler 8 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:23,572 [IPC Server handler 8 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:23.574 [IPC Server handler 2 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:23,575 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:23,575 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:25,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:25,804 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:25,804 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:25,805 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:25,805 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:25,805 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:25,805 [IPC Server handler 6 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:25,805 [IPC Server handler 6 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:25,806 [IPC Server handler 6 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:25,806 [IPC Server handler 6 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:25,806 [IPC Server handler 6 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:25.809 [IPC Server handler 4 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume23652, bucket=bucket91465, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume23652 bucket: bucket91465 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:25,810 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local1544285658_0003_m_000001_0
2019-09-26 13:24:25,810 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:25,811 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:25,812 [Thread-647] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 13:24:25,825 [Thread-647] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000116559433/.staging/_distcp1868584561
2019-09-26 13:24:25,826 [Thread-647] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1544285658_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket91465.volume23652/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:26,406 [Thread-599] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1544285658_0003 failed with state FAILED due to: NA
2019-09-26 13:24:26,406 [Thread-599] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 0
2019-09-26 13:24:26,464 [Thread-670] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 13:24:26,492 [Thread-670] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume11814, with user63592 as owner.
2019-09-26 13:24:26,494 [IPC Server handler 2 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume11814 for user:user63592
2019-09-26 13:24:26,497 [Thread-670] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume11814/bucket57766, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:24:26,574 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket57766.volume11814 implemented by OzoneFileSystem{URI=o3fs://bucket57766.volume11814, workingDir=o3fs://bucket57766.volume11814/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 108 read ops, 0 large read ops, 66 write ops}
13:24:26.598 [IPC Server handler 16 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume11814, bucket=bucket57766, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume11814 bucket: bucket57766 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:26,603 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-26 13:24:26,605 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-26 13:24:26,622 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:26,622 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:26,622 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:26,622 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:26,622 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:26,623 [IPC Server handler 6 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:26,623 [IPC Server handler 6 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:26,624 [IPC Server handler 6 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:26,624 [IPC Server handler 6 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:26,624 [IPC Server handler 6 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-26 13:24:26,689 [Thread-674] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume06750, with user31906 as owner.
2019-09-26 13:24:26,690 [IPC Server handler 9 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume06750 for user:user31906
2019-09-26 13:24:26,693 [Thread-674] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume06750/bucket90968, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:24:26,743 [Thread-674] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket90968.volume06750 implemented by OzoneFileSystem{URI=o3fs://bucket90968.volume06750, workingDir=o3fs://bucket90968.volume06750/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 114 read ops, 0 large read ops, 69 write ops}
13:24:26.764 [IPC Server handler 3 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:26,767 [Thread-674] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-26 13:24:26,851 [Thread-674] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:24:26,860 [Thread-674] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
13:24:26.872 [IPC Server handler 7 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:26,934 [Thread-674] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-26 13:24:26,934 [Thread-674] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-26 13:24:26,946 [Thread-674] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:24:26,955 [Thread-674] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-26 13:24:26,957 [Thread-674] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-26 13:24:26,964 [Thread-674] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-26 13:24:27,007 [Thread-674] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-26 13:24:27,040 [Thread-674] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1146271049_0004
2019-09-26 13:24:27,040 [Thread-674] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-26 13:24:27,137 [Thread-674] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-26 13:24:27,139 [Thread-737] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-26 13:24:27,140 [Thread-674] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1146271049_0004
2019-09-26 13:24:27,140 [Thread-737] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:27,140 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1146271049_0004
2019-09-26 13:24:27,140 [Thread-737] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:27,140 [Thread-737] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-26 13:24:27,159 [Thread-737] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-26 13:24:27,160 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:27,160 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:27,160 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:27,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:27,161 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:2198+870
2019-09-26 13:24:27,162 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:27,162 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:24:27.179 [IPC Server handler 5 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:27,180 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
13:24:27.184 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:27,185 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:27,188 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:27,188 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:27,188 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:27,188 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:27,188 [IPC Server handler 18 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:27,189 [IPC Server handler 18 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:27,189 [IPC Server handler 18 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:27,189 [IPC Server handler 18 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:27,189 [IPC Server handler 18 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:27,189 [IPC Server handler 18 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:27.191 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:27,192 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:27,192 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:28,140 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1146271049_0004 running in uber mode : false
2019-09-26 13:24:28,141 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-26 13:24:28,284 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:28,287 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:28,287 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:28,288 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:28,288 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:28,288 [IPC Server handler 14 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:28,288 [IPC Server handler 14 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:28,288 [IPC Server handler 14 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:28,289 [IPC Server handler 14 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:28,289 [IPC Server handler 14 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:28,289 [IPC Server handler 14 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:28.291 [IPC Server handler 13 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:28,291 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:28,292 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:29,425 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-26 13:24:30,887 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:30,891 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:30,891 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:30,891 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:30,891 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:30,892 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:30,892 [IPC Server handler 11 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:30,892 [IPC Server handler 11 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:30,893 [IPC Server handler 11 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:30,893 [IPC Server handler 11 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:30,894 [IPC Server handler 11 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:30.896 [IPC Server handler 6 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:30,897 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000000_0
2019-09-26 13:24:30,897 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:30,898 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:30,898 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000001_0
2019-09-26 13:24:30,899 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,899 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,900 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:30,901 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:0+324
2019-09-26 13:24:30,901 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,902 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
13:24:30.916 [IPC Server handler 8 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:30,917 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
13:24:30.924 [IPC Server handler 9 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:30,928 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,929 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000001_0 is done. And is in the process of committing
2019-09-26 13:24:30,929 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,930 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000001_0 is allowed to commit now
2019-09-26 13:24:30,931 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:30,931 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-26 13:24:30,931 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000001_0' done.
2019-09-26 13:24:30,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=884427
		FILE: Number of bytes written=12793782
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=125
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:30,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000001_0
2019-09-26 13:24:30,932 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000002_0
2019-09-26 13:24:30,933 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,933 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,933 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:30,934 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:324+278
2019-09-26 13:24:30,934 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,934 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,948 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
13:24:30.955 [IPC Server handler 11 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:30,958 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000002_0 is done. And is in the process of committing
2019-09-26 13:24:30,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000002_0 is allowed to commit now
2019-09-26 13:24:30,961 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:30,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-26 13:24:30,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000002_0' done.
2019-09-26 13:24:30,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=889009
		FILE: Number of bytes written=12793790
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=127
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:30,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000002_0
2019-09-26 13:24:30,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000003_0
2019-09-26 13:24:30,962 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,962 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,963 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:30,963 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:1396+278
2019-09-26 13:24:30,964 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,964 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,977 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
13:24:30.982 [IPC Server handler 14 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:30,986 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,986 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000003_0 is done. And is in the process of committing
2019-09-26 13:24:30,987 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:30,987 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000003_0 is allowed to commit now
2019-09-26 13:24:30,988 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:30,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-26 13:24:30,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000003_0' done.
2019-09-26 13:24:30,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=893591
		FILE: Number of bytes written=12793798
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:30,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000003_0
2019-09-26 13:24:30,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:30,990 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,990 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:30,990 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:30,991 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:1122+274
2019-09-26 13:24:30,991 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:30,992 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:31,005 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
13:24:31.009 [IPC Server handler 19 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:31,010 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:31,012 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:31,014 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:31,014 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:31,014 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:31,015 [IPC Server handler 15 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:31,015 [IPC Server handler 15 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:31,015 [IPC Server handler 15 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:31,015 [IPC Server handler 15 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:31,016 [IPC Server handler 15 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:31,016 [IPC Server handler 15 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:31.017 [IPC Server handler 0 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:31,018 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:31,018 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:31,143 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-26 13:24:32,556 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:32,559 [IPC Server handler 8 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:32,560 [IPC Server handler 8 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:32,560 [IPC Server handler 8 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:32,560 [IPC Server handler 8 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:32.562 [IPC Server handler 2 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:32,563 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:32,563 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:34,493 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
2019-09-26 13:24:35,492 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:35,495 [IPC Server handler 19 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:35,496 [IPC Server handler 19 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:35,496 [IPC Server handler 19 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:35,496 [IPC Server handler 19 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:35.498 [IPC Server handler 2 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:35,498 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000004_0
2019-09-26 13:24:35,499 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:35,499 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:35,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000005_0
2019-09-26 13:24:35,500 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,500 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:35,502 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:860+262
2019-09-26 13:24:35,502 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,502 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,513 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 13:24:35,519 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,520 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000005_0 is done. And is in the process of committing
2019-09-26 13:24:35,520 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,520 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000005_0 is allowed to commit now
2019-09-26 13:24:35,521 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:35,521 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-26 13:24:35,522 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000005_0' done.
2019-09-26 13:24:35,522 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=901731
		FILE: Number of bytes written=12793814
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=136
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:35,522 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000005_0
2019-09-26 13:24:35,522 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000006_0
2019-09-26 13:24:35,522 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,523 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,523 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:35,523 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:1674+262
2019-09-26 13:24:35,524 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,524 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,534 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 13:24:35,541 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,541 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000006_0 is done. And is in the process of committing
2019-09-26 13:24:35,541 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000006_0 is allowed to commit now
2019-09-26 13:24:35,542 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:35,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-26 13:24:35,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000006_0' done.
2019-09-26 13:24:35,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=905801
		FILE: Number of bytes written=12793822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=138
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:35,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000006_0
2019-09-26 13:24:35,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000007_0
2019-09-26 13:24:35,544 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,544 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:35,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:1936+262
2019-09-26 13:24:35,545 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,545 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,555 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
13:24:35.559 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:35,562 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,563 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1146271049_0004_m_000007_0 is done. And is in the process of committing
2019-09-26 13:24:35,563 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-26 13:24:35,563 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1146271049_0004_m_000007_0 is allowed to commit now
2019-09-26 13:24:35,564 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1146271049_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/_logs
2019-09-26 13:24:35,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-26 13:24:35,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1146271049_0004_m_000007_0' done.
2019-09-26 13:24:35,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1146271049_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=909359
		FILE: Number of bytes written=12793830
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=140
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=159
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1991245824
	File Input Format Counters 
		Bytes Read=3124
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-26 13:24:35,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1146271049_0004_m_000007_0
2019-09-26 13:24:35,565 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:35,566 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,566 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,566 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-26 13:24:35,567 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403/fileList.seq:602+258
2019-09-26 13:24:35,567 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-26 13:24:35,567 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-26 13:24:35,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
13:24:35.580 [IPC Server handler 12 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:35,581 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:35,583 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:35,585 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:35,585 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:35,585 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:35,586 [IPC Server handler 6 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:35.588 [IPC Server handler 14 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:35,588 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:35,589 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:36,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:36,975 [IPC Server handler 5 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:36,975 [IPC Server handler 5 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:36,975 [IPC Server handler 5 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:36,975 [IPC Server handler 5 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:36,975 [IPC Server handler 5 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:36,976 [IPC Server handler 5 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:36,976 [IPC Server handler 5 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:36,976 [IPC Server handler 5 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:36,976 [IPC Server handler 5 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:36,976 [IPC Server handler 5 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:36.978 [IPC Server handler 17 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:36,979 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:36,979 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:39,165 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 > map
2019-09-26 13:24:40,149 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 70% reduce 0%
2019-09-26 13:24:42,873 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:42,876 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:42,876 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:42,877 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:42,877 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:42,877 [IPC Server handler 11 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:42,877 [IPC Server handler 11 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:42,877 [IPC Server handler 11 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:42,878 [IPC Server handler 11 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:42,878 [IPC Server handler 11 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:42,879 [IPC Server handler 11 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
13:24:42.881 [IPC Server handler 17 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume06750, bucket=bucket90968, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume06750 bucket: bucket90968 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:42,882 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(442)) - delete: Path does not exist: o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1146271049_0004_m_000008_0
2019-09-26 13:24:42,882 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-26 13:24:42,882 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:42,883 [Thread-737] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-26 13:24:42,895 [Thread-737] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001450504917/.staging/_distcp-1261296403
2019-09-26 13:24:42,897 [Thread-737] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1146271049_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket90968.volume06750/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:732)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1536)
	at sun.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy41.createFile(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:1006)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:537)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:205)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:250)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:231)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-26 13:24:42,996 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-26 13:24:43,150 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 81% reduce 0%
2019-09-26 13:24:43,151 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local1146271049_0004 failed with state FAILED due to: NA
2019-09-26 13:24:43,157 [Thread-674] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=7209752
		FILE: Number of bytes written=102350512
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1088
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=648
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1272
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=15929966592
	File Input Format Counters 
		Bytes Read=24992
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-26 13:24:43,211 [Thread-781] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-26 13:24:43,240 [Thread-781] INFO  rpc.RpcClient (RpcClient.java:createVolume(276)) - Creating Volume: volume72753, with user10486 as owner.
2019-09-26 13:24:43,242 [IPC Server handler 16 on 45808] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(189)) - created volume:volume72753 for user:user10486
2019-09-26 13:24:43,246 [Thread-781] INFO  rpc.RpcClient (RpcClient.java:createBucket(415)) - Creating Bucket: volume72753/bucket01958, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-26 13:24:43,304 [Thread-781] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket01958.volume72753 implemented by OzoneFileSystem{URI=o3fs://bucket01958.volume72753, workingDir=o3fs://bucket01958.volume72753/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 152 read ops, 0 large read ops, 89 write ops}
13:24:43.529 [IPC Server handler 10 on 45808] ERROR OMAudit - user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume72753, bucket=bucket01958, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume72753 bucket: bucket01958 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1742) ~[hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2892) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1051) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:338) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:233) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:157) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:111) [hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [hadoop-ozone-common-0.5.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-09-26 13:24:43,534 [Thread-781] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-26 13:24:43,541 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 90ba3288-4391-43ec-9151-33e9d9c608f1 Heaviness: 6 limit: 5
2019-09-26 13:24:43,542 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： b2271e47-a7e8-4366-9c95-78f4bcf85493 Heaviness: 6 limit: 5
2019-09-26 13:24:43,542 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 4c44e235-1460-4483-9a9f-158dc5e2c846 Heaviness: 6 limit: 5
2019-09-26 13:24:43,542 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： e6d7f1d8-1aa8-4176-9696-232a32bf0999 Heaviness: 6 limit: 5
2019-09-26 13:24:43,542 [IPC Server handler 8 on 36299] INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: can't place more pipeline on heavy datanode： 56bc7cae-2273-4ad2-9040-d97b9977dd91 Heaviness: 6 limit: 5
2019-09-26 13:24:43,543 [IPC Server handler 8 on 36299] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(148)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-26 13:24:43,543 [IPC Server handler 8 on 36299] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(167)) - Pipeline creation failed.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:43,543 [IPC Server handler 8 on 36299] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:149)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:172)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:58)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:155)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:182)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:183)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:141)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:116)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-26 13:24:43,544 [IPC Server handler 8 on 36299] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-26 13:24:43,544 [IPC Server handler 8 on 36299] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-26 13:24:43,564 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-26 13:24:43,565 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-26 13:24:43,565 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-26 13:24:43,565 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45808
2019-09-26 13:24:43,572 [JUnit] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-26 13:24:43,574 [IPC Server listener on 45808] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45808
2019-09-26 13:24:43,579 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 13:24:43,579 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-26 13:24:43,592 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-26 13:24:43,596 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7103ab0{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-26 13:24:43,601 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19ccca5{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:43,601 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78e89bfe{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:43,601 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ac9af2a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:43,767 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-26 13:24:44,052 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 13:24:44,146 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 13:24:47,574 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-26 13:24:48,771 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 13:24:48,771 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 13:24:48,773 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: close
2019-09-26 13:24:48,773 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: close
2019-09-26 13:24:48,775 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: shutdown
2019-09-26 13:24:48,775 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: shutdown
2019-09-26 13:24:48,776 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFDC6013013E,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,776 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-009D9498AD7E,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,776 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,777 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,778 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,778 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,783 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,783 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,785 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E: closes. applyIndex: 0
2019-09-26 13:24:48,785 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E: closes. applyIndex: 0
2019-09-26 13:24:48,788 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,788 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,790 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-AFDC6013013E-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,790 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-009D9498AD7E-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,797 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: shutdown
2019-09-26 13:24:48,797 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: shutdown
2019-09-26 13:24:48,797 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-897EED66A8B2,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,797 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6DDA4A5AEB3D,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,798 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,798 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,798 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,798 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,799 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,799 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,800 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D: closes. applyIndex: 0
2019-09-26 13:24:48,799 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2: closes. applyIndex: 0
2019-09-26 13:24:48,800 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,802 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,803 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-6DDA4A5AEB3D-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,804 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-897EED66A8B2-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,808 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: shutdown
2019-09-26 13:24:48,811 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: shutdown
2019-09-26 13:24:48,811 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9BC1935950C4,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,812 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7065E9FA7AFA,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,812 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,812 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,812 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,813 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,813 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,813 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,814 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4: closes. applyIndex: 0
2019-09-26 13:24:48,814 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA: closes. applyIndex: 0
2019-09-26 13:24:48,814 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,815 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,816 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-9BC1935950C4-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,818 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-7065E9FA7AFA-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,821 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: shutdown
2019-09-26 13:24:48,824 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: shutdown
2019-09-26 13:24:48,825 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-06D20AEB89AE,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,825 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E31664A251FC,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,825 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,825 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,826 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,826 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,827 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,827 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,827 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE: closes. applyIndex: 0
2019-09-26 13:24:48,828 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC: closes. applyIndex: 0
2019-09-26 13:24:48,828 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,828 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,832 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-06D20AEB89AE-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,832 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-E31664A251FC-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,836 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: shutdown
2019-09-26 13:24:48,839 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: shutdown
2019-09-26 13:24:48,839 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-185088799101,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,840 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1704B8D6F83F,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,840 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,840 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,840 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,841 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,841 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,841 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,842 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101: closes. applyIndex: 0
2019-09-26 13:24:48,842 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F: closes. applyIndex: 0
2019-09-26 13:24:48,843 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,844 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,845 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-185088799101-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,846 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-1704B8D6F83F-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,850 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: shutdown
2019-09-26 13:24:48,862 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: shutdown
2019-09-26 13:24:48,862 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3F5E84B78ED1,id=90ba3288-4391-43ec-9151-33e9d9c608f1
2019-09-26 13:24:48,862 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D5A710E916,id=b2271e47-a7e8-4366-9c95-78f4bcf85493
2019-09-26 13:24:48,863 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown LeaderState
2019-09-26 13:24:48,863 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown LeaderState
2019-09-26 13:24:48,863 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 90ba3288-4391-43ec-9151-33e9d9c608f1-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,863 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - b2271e47-a7e8-4366-9c95-78f4bcf85493-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:48,864 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,864 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:48,864 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916: closes. applyIndex: 0
2019-09-26 13:24:48,864 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1: closes. applyIndex: 0
2019-09-26 13:24:48,865 [b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,865 [90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:48,865 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 90ba3288-4391-43ec-9151-33e9d9c608f1@group-3F5E84B78ED1-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,865 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - b2271e47-a7e8-4366-9c95-78f4bcf85493@group-D9D5A710E916-SegmentedRaftLogWorker close()
2019-09-26 13:24:48,870 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown server with port 42099 now
2019-09-26 13:24:48,870 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown server with port 35856 now
2019-09-26 13:24:48,875 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 90ba3288-4391-43ec-9151-33e9d9c608f1: shutdown server with port 42099 successfully
2019-09-26 13:24:48,877 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - b2271e47-a7e8-4366-9c95-78f4bcf85493: shutdown server with port 35856 successfully
2019-09-26 13:24:48,880 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 13:24:48,887 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 13:24:48,917 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 13:24:48,921 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 13:24:48,923 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29149030{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 13:24:48,923 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@38b8b6c0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:48,923 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 13:24:48,924 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c26273d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:48,927 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 13:24:48,927 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@272ce069{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:48,931 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48b4a043{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 13:24:48,932 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f5b8250{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:48,934 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@291373d3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:48,935 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16727bf0{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:48,944 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 13:24:49,533 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 13:24:53,575 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-26 13:24:53,931 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 13:24:53,931 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: close
2019-09-26 13:24:53,932 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: shutdown
2019-09-26 13:24:53,932 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC53F46D2D08,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,933 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,933 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,933 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,934 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08: closes. applyIndex: 0
2019-09-26 13:24:53,934 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,935 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-CC53F46D2D08-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,937 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: shutdown
2019-09-26 13:24:53,937 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 13:24:53,938 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-114EAA4B39AF,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,938 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: close
2019-09-26 13:24:53,939 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,939 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: shutdown
2019-09-26 13:24:53,939 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,940 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D2A0D070A417,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,940 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,940 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,941 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF: closes. applyIndex: 0
2019-09-26 13:24:53,941 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,942 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,942 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,942 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-114EAA4B39AF-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,942 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417: closes. applyIndex: 0
2019-09-26 13:24:53,944 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: shutdown
2019-09-26 13:24:53,944 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,944 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-929A645ACD65,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,945 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-D2A0D070A417-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,945 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,946 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: shutdown
2019-09-26 13:24:53,946 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,947 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0125CF0BD7C,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,947 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,948 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65: closes. applyIndex: 0
2019-09-26 13:24:53,948 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,949 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,949 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,949 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-929A645ACD65-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,949 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,951 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C: closes. applyIndex: 0
2019-09-26 13:24:53,951 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: shutdown
2019-09-26 13:24:53,952 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,952 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2307A7EEA691,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,952 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F0125CF0BD7C-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,953 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,954 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: shutdown
2019-09-26 13:24:53,955 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,955 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9F4E78E5405,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,955 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,955 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,956 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,956 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691: closes. applyIndex: 0
2019-09-26 13:24:53,956 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,957 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,957 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405: closes. applyIndex: 0
2019-09-26 13:24:53,957 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-2307A7EEA691-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,957 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,960 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: shutdown
2019-09-26 13:24:53,960 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-F9F4E78E5405-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,961 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3CD764665482,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,962 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: shutdown
2019-09-26 13:24:53,962 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,962 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF6CC37C7398,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,963 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,963 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,963 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,964 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,964 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,964 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482: closes. applyIndex: 0
2019-09-26 13:24:53,965 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398: closes. applyIndex: 0
2019-09-26 13:24:53,965 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,965 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,965 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-3CD764665482-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,966 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-BF6CC37C7398-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,971 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: shutdown
2019-09-26 13:24:53,971 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: shutdown
2019-09-26 13:24:53,972 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-329B5FCE35F4,id=56bc7cae-2273-4ad2-9040-d97b9977dd91
2019-09-26 13:24:53,972 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBFD32718550,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,972 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown LeaderState
2019-09-26 13:24:53,973 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,973 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,973 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,974 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,974 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,974 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4: closes. applyIndex: 0
2019-09-26 13:24:53,975 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550: closes. applyIndex: 0
2019-09-26 13:24:53,975 [56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,975 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,975 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91@group-329B5FCE35F4-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,975 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DBFD32718550-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,976 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown server with port 37374 now
2019-09-26 13:24:53,976 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: shutdown
2019-09-26 13:24:53,977 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC9D3152C9CA,id=e6d7f1d8-1aa8-4176-9696-232a32bf0999
2019-09-26 13:24:53,978 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 56bc7cae-2273-4ad2-9040-d97b9977dd91: shutdown server with port 37374 successfully
2019-09-26 13:24:53,978 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown LeaderState
2019-09-26 13:24:53,978 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:53,979 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:53,979 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA: closes. applyIndex: 0
2019-09-26 13:24:53,980 [e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:53,980 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999@group-DC9D3152C9CA-SegmentedRaftLogWorker close()
2019-09-26 13:24:53,980 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown server with port 40981 now
2019-09-26 13:24:53,982 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - e6d7f1d8-1aa8-4176-9696-232a32bf0999: shutdown server with port 40981 successfully
2019-09-26 13:24:53,984 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 13:24:53,987 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 13:24:54,011 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 13:24:54,011 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 13:24:54,016 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 13:24:54,017 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 13:24:54,021 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72e295cc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 13:24:54,021 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73844119{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 13:24:54,022 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:54,022 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c2584d3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:54,023 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23f3da8b{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:54,023 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44b29496{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:54,024 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7640a5b1{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:54,024 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57f9b467{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:54,214 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-26 13:24:59,026 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-26 13:24:59,026 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: close
2019-09-26 13:24:59,027 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: shutdown
2019-09-26 13:24:59,027 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-93A69816672F,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,027 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,028 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,028 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,028 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F: closes. applyIndex: 0
2019-09-26 13:24:59,029 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,029 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-93A69816672F-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,030 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: shutdown
2019-09-26 13:24:59,030 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E80AEAD5E3B,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,030 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,030 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,031 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,031 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B: closes. applyIndex: 0
2019-09-26 13:24:59,031 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,032 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-7E80AEAD5E3B-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,032 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: shutdown
2019-09-26 13:24:59,032 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BF2348C5744,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,032 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,033 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,033 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,033 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744: closes. applyIndex: 0
2019-09-26 13:24:59,034 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,034 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-4BF2348C5744-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,034 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: shutdown
2019-09-26 13:24:59,035 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AEAD992D16BC,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,035 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,035 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,035 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,036 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC: closes. applyIndex: 0
2019-09-26 13:24:59,036 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,036 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-AEAD992D16BC-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,036 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: shutdown
2019-09-26 13:24:59,037 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-197F107EA092,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,037 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,037 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,037 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,038 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092: closes. applyIndex: 0
2019-09-26 13:24:59,038 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,038 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-197F107EA092-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,039 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: shutdown
2019-09-26 13:24:59,039 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCE5DC64F2CE,id=4c44e235-1460-4483-9a9f-158dc5e2c846
2019-09-26 13:24:59,039 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown LeaderState
2019-09-26 13:24:59,039 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4c44e235-1460-4483-9a9f-158dc5e2c846-PendingRequests: sendNotLeaderResponses
2019-09-26 13:24:59,040 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-StateMachineUpdater: set stopIndex = 0
2019-09-26 13:24:59,040 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE: closes. applyIndex: 0
2019-09-26 13:24:59,040 [4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-26 13:24:59,041 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4c44e235-1460-4483-9a9f-158dc5e2c846@group-BCE5DC64F2CE-SegmentedRaftLogWorker close()
2019-09-26 13:24:59,041 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown server with port 38731 now
2019-09-26 13:24:59,043 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 4c44e235-1460-4483-9a9f-158dc5e2c846: shutdown server with port 38731 successfully
2019-09-26 13:24:59,057 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-f22d74ff-7257-4368-b174-d179af7eab52/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-26 13:24:59,090 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-26 13:24:59,093 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-26 13:24:59,096 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cd3ad8a{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-26 13:24:59,097 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@75181b50{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:59,098 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a08efdc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:59,099 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26350ea2{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:59,100 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-26 13:24:59,100 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-26 13:24:59,100 [JUnit] INFO  container.ReplicationManager (ReplicationManager.java:stop(204)) - Stopping Replication Monitor Thread.
2019-09-26 13:24:59,101 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-26 13:24:59,101 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-26 13:24:59,101 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-26 13:24:59,101 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45236
2019-09-26 13:24:59,102 [IPC Server listener on 45236] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45236
2019-09-26 13:24:59,103 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 13:24:59,159 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-26 13:24:59,159 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-26 13:24:59,160 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-26 13:24:59,160 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36299
2019-09-26 13:24:59,161 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-26 13:24:59,161 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-26 13:24:59,162 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39295
2019-09-26 13:24:59,162 [IPC Server listener on 36299] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36299
2019-09-26 13:24:59,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 13:24:59,163 [IPC Server listener on 39295] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39295
2019-09-26 13:24:59,163 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-26 13:24:59,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-26 13:24:59,165 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@aec50a1{/,null,UNAVAILABLE}{/scm}
2019-09-26 13:24:59,165 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-26 13:24:59,166 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e70a728{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-26 13:24:59,166 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b70da4c{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-26 13:24:59,167 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-26 13:24:59,167 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 13:24:59,168 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-26 13:24:59,168 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-26 13:24:59,174 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JobTracker metrics system...
2019-09-26 13:24:59,186 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-26 13:24:59,186 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JobTracker metrics system stopped.

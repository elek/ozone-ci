2019-09-24 02:57:55,672 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:57:57,247 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:57:57,251 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:57:57,272 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4329ms
2019-09-24 02:57:58,142 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-24 02:57:58,143 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-24 02:57:58,144 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-24 02:57:58,144 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-24 02:57:58,144 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-24 02:57:58,145 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-24 02:57:58,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 02:57:58,162 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 02:57:58,164 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 02:57:58,409 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@55141def
2019-09-24 02:57:58,412 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-24 02:57:58,502 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 02:57:58,504 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 1000000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 02:57:58,507 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-24 02:57:58,580 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-24 02:57:58,594 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:57:58,653 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-24 02:57:58,656 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:57:58,759 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-24 02:57:59,161 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 02:57:59,190 [Socket Reader #1 for port 46528] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46528
2019-09-24 02:57:59,355 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 02:57:59,356 [Socket Reader #1 for port 36026] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36026
2019-09-24 02:57:59,366 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 02:57:59,367 [Socket Reader #1 for port 40389] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40389
2019-09-24 02:57:59,392 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-24 02:57:59,539 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 02:57:59,547 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 02:57:59,555 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 02:57:59,558 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-24 02:57:59,558 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 02:57:59,558 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 02:57:59,589 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40389
2019-09-24 02:57:59,645 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-24 02:57:59,658 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-24 02:57:59,659 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-24 02:57:59,879 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:40389
2019-09-24 02:57:59,880 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 02:57:59,880 [IPC Server listener on 40389] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40389: starting
2019-09-24 02:57:59,884 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:36026
2019-09-24 02:57:59,885 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:36026
2019-09-24 02:57:59,886 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 02:57:59,886 [IPC Server listener on 36026] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36026: starting
2019-09-24 02:57:59,889 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46528
2019-09-24 02:57:59,890 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46528
2019-09-24 02:57:59,890 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 02:57:59,890 [IPC Server listener on 46528] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46528: starting
2019-09-24 02:57:59,896 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36229
2019-09-24 02:57:59,898 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 02:57:59,933 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 02:57:59,934 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-24 02:57:59,964 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5398edd0{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-24 02:57:59,969 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:36229}
2019-09-24 02:57:59,969 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7027ms
2019-09-24 02:57:59,972 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-24 02:57:59,972 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-24 02:57:59,974 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:36229
2019-09-24 02:57:59,980 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1095f122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 02:57:59,982 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:58:00,111 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(138)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-24 02:58:00,111 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address: 127.0.0.1:0
2019-09-24 02:58:00,112 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address: 0.0.0.0:9875
2019-09-24 02:58:00,112 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-bind-host with value of key ozone.om.http-bind-host: 0.0.0.0
2019-09-24 02:58:00,112 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-bind-host with value of key ozone.om.https-bind-host: 0.0.0.0
2019-09-24 02:58:00,112 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.keytab with value of key ozone.om.http.kerberos.keytab: /etc/security/keytabs/HTTP.keytab
2019-09-24 02:58:00,112 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.principal with value of key ozone.om.http.kerberos.principal: HTTP/_HOST@EXAMPLE.COM
2019-09-24 02:58:00,113 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.address with value of key ozone.om.address: 127.0.0.1:0
2019-09-24 02:58:00,113 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(192)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-24 02:58:00,114 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:58:00,114 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:58:06,723 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 02:58:06,732 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-24 02:58:06,732 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-24 02:58:06,732 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-24 02:58:06,732 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-24 02:58:06,733 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-24 02:58:06,733 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-24 02:58:06,733 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-24 02:58:06,733 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-24 02:58:06,734 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-24 02:58:06,734 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-24 02:58:06,734 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-24 02:58:06,734 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-24 02:58:06,734 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-24 02:58:06,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-24 02:58:06,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-24 02:58:06,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-24 02:58:06,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-24 02:58:06,735 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-24 02:58:06,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-24 02:58:06,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-24 02:58:06,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-24 02:58:06,736 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-24 02:58:06,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 02:58:06,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 02:58:06,737 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 02:58:07,299 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 02:58:07,300 [Socket Reader #1 for port 38706] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38706
2019-09-24 02:58:07,324 [main] INFO  om.OzoneManager (OzoneManager.java:start(1075)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38706
2019-09-24 02:58:07,324 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-24 02:58:07,325 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 02:58:07,326 [IPC Server listener on 38706] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38706: starting
2019-09-24 02:58:07,332 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-24 02:58:07,334 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 02:58:07,335 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 02:58:07,338 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 02:58:07,340 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-24 02:58:07,340 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 02:58:07,340 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 02:58:07,344 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45964
2019-09-24 02:58:07,344 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 02:58:07,347 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 02:58:07,348 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-24 02:58:07,353 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@529cfee5{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-24 02:58:07,354 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:45964}
2019-09-24 02:58:07,355 [main] INFO  server.Server (Server.java:doStart(419)) - Started @14413ms
2019-09-24 02:58:07,355 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 02:58:07,356 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45964
2019-09-24 02:58:07,649 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 02:58:07,702 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 02:58:07,737 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 02:58:07,739 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/containers/hdds to VolumeSet
2019-09-24 02:58:07,742 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-24 02:58:07,761 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@26a4551a
2019-09-24 02:58:07,879 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 02:58:07,952 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 02:58:07,958 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 02:58:07,958 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 02:58:07,960 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:07,961 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 02:58:07,962 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 02:58:08,143 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis] (custom)
2019-09-24 02:58:08,210 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 02:58:08,212 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 02:58:08,213 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 02:58:08,215 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 02:58:08,216 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 02:58:08,216 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 02:58:08,216 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 02:58:08,217 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38302
2019-09-24 02:58:08,218 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 02:58:08,222 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 02:58:08,223 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 02:58:08,254 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7aac8884{/,file:///tmp/jetty-0.0.0.0-38302-hddsDatanode-_-any-7396904596251576081.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 02:58:08,255 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:38302}
2019-09-24 02:58:08,256 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15313ms
2019-09-24 02:58:08,256 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 02:58:08,257 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38302
2019-09-24 02:58:08,258 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 02:58:08,263 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 02:58:08,267 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36b00b47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 02:58:08,273 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 02:58:08,274 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/containers/hdds to VolumeSet
2019-09-24 02:58:08,275 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-24 02:58:08,278 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@117525fe
2019-09-24 02:58:08,302 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 02:58:08,303 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 02:58:08,303 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 02:58:08,304 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 02:58:08,304 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:08,304 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 02:58:08,305 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 02:58:08,305 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis] (custom)
2019-09-24 02:58:08,307 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 02:58:08,309 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 02:58:08,310 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 02:58:08,313 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 02:58:08,314 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 02:58:08,315 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 02:58:08,315 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 02:58:08,316 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36789
2019-09-24 02:58:08,316 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 02:58:08,319 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 02:58:08,319 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 02:58:08,352 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e519ad3{/,file:///tmp/jetty-0.0.0.0-36789-hddsDatanode-_-any-4312692590945039650.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 02:58:08,353 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:36789}
2019-09-24 02:58:08,354 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15412ms
2019-09-24 02:58:08,354 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 02:58:08,355 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36789
2019-09-24 02:58:08,356 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 02:58:08,359 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b6d0db7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 02:58:08,360 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 02:58:08,369 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 02:58:08,369 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/containers/hdds to VolumeSet
2019-09-24 02:58:08,370 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-24 02:58:08,370 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7baf1f5a
2019-09-24 02:58:08,388 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 02:58:08,388 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 02:58:08,389 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 02:58:08,389 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 02:58:08,389 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:08,389 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 02:58:08,390 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 02:58:08,390 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis] (custom)
2019-09-24 02:58:08,393 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 02:58:08,394 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 02:58:08,395 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 02:58:08,397 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 02:58:08,398 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 02:58:08,398 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 02:58:08,398 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 02:58:08,399 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45933
2019-09-24 02:58:08,400 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 02:58:08,407 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-24 02:58:08,407 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 02:58:08,416 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/meta/datanode.id
2019-09-24 02:58:08,422 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/meta/datanode.id
2019-09-24 02:58:08,438 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd903be{/,file:///tmp/jetty-0.0.0.0-45933-hddsDatanode-_-any-7740248194489350171.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 02:58:08,439 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:45933}
2019-09-24 02:58:08,439 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15497ms
2019-09-24 02:58:08,440 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 02:58:08,441 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45933
2019-09-24 02:58:08,443 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 02:58:08,444 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@94849ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 02:58:08,446 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/meta/datanode.id
2019-09-24 02:58:09,444 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 02:58:10,321 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 02:58:10,324 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 02:58:10,324 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0fab8ded-0a01-458c-ba37-63116df8f1e5 at port 0
2019-09-24 02:58:10,343 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start RPC server
2019-09-24 02:58:10,378 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 02:58:10,383 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 02:58:10,383 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 176fb140-5a52-4f85-9b1d-a71612629d1e at port 0
2019-09-24 02:58:10,392 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start RPC server
2019-09-24 02:58:10,444 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 02:58:10,461 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 02:58:10,462 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 02:58:10,463 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 at port 0
2019-09-24 02:58:10,472 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start RPC server
2019-09-24 02:58:10,474 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: GrpcService started, listening on 0.0.0.0/0.0.0.0:43466
2019-09-24 02:58:10,474 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: GrpcService started, listening on 0.0.0.0/0.0.0.0:42257
2019-09-24 02:58:10,476 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: GrpcService started, listening on 0.0.0.0/0.0.0.0:44913
2019-09-24 02:58:10,476 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0fab8ded-0a01-458c-ba37-63116df8f1e5 is started using port 43466
2019-09-24 02:58:10,476 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 is started using port 44913
2019-09-24 02:58:10,476 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 176fb140-5a52-4f85-9b1d-a71612629d1e is started using port 42257
2019-09-24 02:58:10,481 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0fab8ded-0a01-458c-ba37-63116df8f1e5 is started using port 40366
2019-09-24 02:58:10,482 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 176fb140-5a52-4f85-9b1d-a71612629d1e is started using port 42213
2019-09-24 02:58:10,481 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 is started using port 35134
2019-09-24 02:58:11,446 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 02:58:12,318 [IPC Server handler 1 on 46528] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0fab8ded-0a01-458c-ba37-63116df8f1e5
2019-09-24 02:58:12,319 [IPC Server handler 1 on 46528] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0fab8ded-0a01-458c-ba37-63116df8f1e5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 02:58:12,325 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-24 02:58:12,325 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-24 02:58:12,325 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-24 02:58:12,362 [IPC Server handler 3 on 46528] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/176fb140-5a52-4f85-9b1d-a71612629d1e
2019-09-24 02:58:12,363 [IPC Server handler 3 on 46528] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 176fb140-5a52-4f85-9b1d-a71612629d1e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 02:58:12,448 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-24 02:58:12,449 [IPC Server handler 4 on 46528] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 02:58:12,450 [IPC Server handler 4 on 46528] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 02:58:12,897 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: addNew group-00207094249E:[0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] returns group-00207094249E:java.util.concurrent.CompletableFuture@60a0e6a[Not completed]
2019-09-24 02:58:12,919 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: new RaftServerImpl for group-00207094249E:[0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] with ContainerStateMachine:uninitialized
2019-09-24 02:58:12,923 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:12,924 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:12,924 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:12,925 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:12,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:12,938 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: ConfigurationManager, init=-1: [0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:12,939 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis] (custom)
2019-09-24 02:58:12,949 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/f34496d9-0d35-4767-88e7-00207094249e does not exist. Creating ...
2019-09-24 02:58:12,967 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/f34496d9-0d35-4767-88e7-00207094249e/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:12,984 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/f34496d9-0d35-4767-88e7-00207094249e has been successfully formatted.
2019-09-24 02:58:12,986 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-00207094249E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:12,987 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:12,990 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:12,997 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:12,997 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,000 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,006 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,013 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/f34496d9-0d35-4767-88e7-00207094249e
2019-09-24 02:58:13,014 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-24 02:58:13,022 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-24 02:58:13,062 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,063 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,067 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,068 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,069 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,070 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,080 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,086 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,091 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,092 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,092 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,093 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,123 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: start as a follower, conf=-1: [0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:13,124 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,125 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start FollowerState
2019-09-24 02:58:13,127 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-00207094249E,id=0fab8ded-0a01-458c-ba37-63116df8f1e5
2019-09-24 02:58:13,201 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f34496d9-0d35-4767-88e7-00207094249e, Nodes: 0fab8ded-0a01-458c-ba37-63116df8f1e5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 02:58:13,225 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: addNew group-E8F2E586D29A:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913] returns group-E8F2E586D29A:java.util.concurrent.CompletableFuture@1409d7b4[Not completed]
2019-09-24 02:58:13,266 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: new RaftServerImpl for group-E8F2E586D29A:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913] with ContainerStateMachine:uninitialized
2019-09-24 02:58:13,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:13,268 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:13,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:13,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:13,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:13,269 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: ConfigurationManager, init=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:13,269 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis] (custom)
2019-09-24 02:58:13,270 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/3bb93223-62af-4c93-9bc7-e8f2e586d29a does not exist. Creating ...
2019-09-24 02:58:13,344 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/3bb93223-62af-4c93-9bc7-e8f2e586d29a/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:13,358 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/3bb93223-62af-4c93-9bc7-e8f2e586d29a has been successfully formatted.
2019-09-24 02:58:13,360 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E8F2E586D29A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:13,362 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:13,362 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:13,362 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:13,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,363 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,363 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/3bb93223-62af-4c93-9bc7-e8f2e586d29a
2019-09-24 02:58:13,371 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,371 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,372 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,373 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,373 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,374 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,374 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,374 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,374 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,379 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: start as a follower, conf=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913], old=null
2019-09-24 02:58:13,379 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,379 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start FollowerState
2019-09-24 02:58:13,381 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8F2E586D29A,id=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 02:58:13,393 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3bb93223-62af-4c93-9bc7-e8f2e586d29a, Nodes: 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 02:58:13,414 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: addNew group-EC8E1A1CD15A:[176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257] returns group-EC8E1A1CD15A:java.util.concurrent.CompletableFuture@1f3b3cec[Not completed]
2019-09-24 02:58:13,431 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: new RaftServerImpl for group-EC8E1A1CD15A:[176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257] with ContainerStateMachine:uninitialized
2019-09-24 02:58:13,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:13,432 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:13,433 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:13,433 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:13,433 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:13,433 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: ConfigurationManager, init=-1: [176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:13,433 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis] (custom)
2019-09-24 02:58:13,434 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/da0d29dc-d718-43db-8294-ec8e1a1cd15a does not exist. Creating ...
2019-09-24 02:58:13,447 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/da0d29dc-d718-43db-8294-ec8e1a1cd15a/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:13,448 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-24 02:58:13,461 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/da0d29dc-d718-43db-8294-ec8e1a1cd15a has been successfully formatted.
2019-09-24 02:58:13,461 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-EC8E1A1CD15A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:13,461 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:13,461 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:13,461 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:13,462 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,462 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,462 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,462 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/da0d29dc-d718-43db-8294-ec8e1a1cd15a
2019-09-24 02:58:13,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,479 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,481 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,481 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,481 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,482 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,482 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,482 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,486 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: start as a follower, conf=-1: [176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257], old=null
2019-09-24 02:58:13,486 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,487 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start FollowerState
2019-09-24 02:58:13,487 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EC8E1A1CD15A,id=176fb140-5a52-4f85-9b1d-a71612629d1e
2019-09-24 02:58:13,495 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: da0d29dc-d718-43db-8294-ec8e1a1cd15a, Nodes: 176fb140-5a52-4f85-9b1d-a71612629d1e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 02:58:13,524 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: addNew group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] returns group-C87293D91C6C:java.util.concurrent.CompletableFuture@19f80fc[Not completed]
2019-09-24 02:58:13,526 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: addNew group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] returns group-C87293D91C6C:java.util.concurrent.CompletableFuture@3d42de1[Not completed]
2019-09-24 02:58:13,527 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: addNew group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] returns group-C87293D91C6C:java.util.concurrent.CompletableFuture@345bde5[Not completed]
2019-09-24 02:58:13,528 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: new RaftServerImpl for group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] with ContainerStateMachine:uninitialized
2019-09-24 02:58:13,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:13,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:13,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:13,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:13,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:13,529 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: ConfigurationManager, init=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:13,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis] (custom)
2019-09-24 02:58:13,529 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: new RaftServerImpl for group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] with ContainerStateMachine:uninitialized
2019-09-24 02:58:13,529 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c does not exist. Creating ...
2019-09-24 02:58:13,529 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:13,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:13,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:13,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:13,530 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: new RaftServerImpl for group-C87293D91C6C:[59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466] with ContainerStateMachine:uninitialized
2019-09-24 02:58:13,530 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 02:58:13,531 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: ConfigurationManager, init=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 02:58:13,531 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis] (custom)
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 1000s (custom)
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:13,531 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c does not exist. Creating ...
2019-09-24 02:58:13,531 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: ConfigurationManager, init=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null, confs=<EMPTY_MAP>
2019-09-24 02:58:13,532 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis] (custom)
2019-09-24 02:58:13,532 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c does not exist. Creating ...
2019-09-24 02:58:13,543 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:13,543 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:13,543 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/in_use.lock acquired by nodename 26864@pr-hdds-2162-tjkd5-3209850126
2019-09-24 02:58:13,574 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c has been successfully formatted.
2019-09-24 02:58:13,574 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c has been successfully formatted.
2019-09-24 02:58:13,574 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c has been successfully formatted.
2019-09-24 02:58:13,574 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C87293D91C6C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:13,574 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C87293D91C6C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:13,574 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-C87293D91C6C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 02:58:13,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:13,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:13,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:13,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 1000s (custom)
2019-09-24 02:58:13,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:13,575 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:13,575 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,575 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 02:58:13,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:13,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 02:58:13,576 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c
2019-09-24 02:58:13,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,576 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:13,576 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,576 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,577 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,577 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 02:58:13,577 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,577 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c
2019-09-24 02:58:13,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,578 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c
2019-09-24 02:58:13,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,578 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 02:58:13,578 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,578 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,578 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 02:58:13,579 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,579 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 02:58:13,579 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,579 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,579 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,579 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 02:58:13,579 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,579 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,580 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,580 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 02:58:13,580 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,580 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 02:58:13,580 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,580 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 02:58:13,580 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,580 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 02:58:13,581 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 02:58:13,581 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,581 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 02:58:13,581 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,581 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 02:58:13,581 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,582 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 02:58:13,582 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 02:58:13,582 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 02:58:13,582 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 02:58:13,584 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: start as a follower, conf=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:13,584 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,584 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start FollowerState
2019-09-24 02:58:13,584 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=0fab8ded-0a01-458c-ba37-63116df8f1e5
2019-09-24 02:58:13,592 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: start as a follower, conf=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:13,593 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: start as a follower, conf=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:13,593 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,593 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 02:58:13,593 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start FollowerState
2019-09-24 02:58:13,593 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start FollowerState
2019-09-24 02:58:13,595 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 02:58:13,595 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=176fb140-5a52-4f85-9b1d-a71612629d1e
2019-09-24 02:58:13,611 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c0bad780-0481-4c18-84c3-c87293d91c6c, Nodes: 0fab8ded-0a01-458c-ba37-63116df8f1e5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}59a9a8f5-2df6-4d0f-bee5-d77c297e06b1{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}176fb140-5a52-4f85-9b1d-a71612629d1e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 02:58:14,676 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:15,331 [Thread-181] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-24 02:58:15,336 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-24 02:58:15,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:16,679 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:17,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:18,153 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5:group-00207094249E changes to CANDIDATE, lastRpcTime:5028, electionTimeout:5027ms
2019-09-24 02:58:18,157 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown FollowerState
2019-09-24 02:58:18,157 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 02:58:18,164 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start LeaderElection
2019-09-24 02:58:18,182 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1: begin an election at term 1 for -1: [0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:18,184 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown LeaderElection
2019-09-24 02:58:18,185 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 02:58:18,185 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: change Leader from null to 0fab8ded-0a01-458c-ba37-63116df8f1e5 at term 1 for becomeLeader, leader elected after 5198ms
2019-09-24 02:58:18,193 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 02:58:18,193 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 02:58:18,197 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 02:58:18,200 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 02:58:18,200 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 02:58:18,201 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 02:58:18,216 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start LeaderState
2019-09-24 02:58:18,240 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,250 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: set configuration 0: [0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null at 0
2019-09-24 02:58:18,451 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/f34496d9-0d35-4767-88e7-00207094249e/current/log_inprogress_0
2019-09-24 02:58:18,546 [Thread-189] INFO  impl.FollowerState (FollowerState.java:run(106)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:group-E8F2E586D29A changes to CANDIDATE, lastRpcTime:5166, electionTimeout:5165ms
2019-09-24 02:58:18,548 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown FollowerState
2019-09-24 02:58:18,548 [Thread-189] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 02:58:18,549 [Thread-189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start LeaderElection
2019-09-24 02:58:18,565 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2: begin an election at term 1 for -1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913], old=null
2019-09-24 02:58:18,567 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown LeaderElection
2019-09-24 02:58:18,567 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 02:58:18,567 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: change Leader from null to 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 at term 1 for becomeLeader, leader elected after 5205ms
2019-09-24 02:58:18,567 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 02:58:18,568 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 02:58:18,568 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 02:58:18,568 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 02:58:18,568 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 02:58:18,569 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 02:58:18,575 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start LeaderState
2019-09-24 02:58:18,576 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,576 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: set configuration 0: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913], old=null at 0
2019-09-24 02:58:18,609 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(106)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:group-C87293D91C6C changes to CANDIDATE, lastRpcTime:5015, electionTimeout:5015ms
2019-09-24 02:58:18,610 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown FollowerState
2019-09-24 02:58:18,610 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 02:58:18,610 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start LeaderElection
2019-09-24 02:58:18,622 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/3bb93223-62af-4c93-9bc7-e8f2e586d29a/current/log_inprogress_0
2019-09-24 02:58:18,623 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3: begin an election at term 1 for -1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:18,636 [Thread-192] INFO  impl.FollowerState (FollowerState.java:run(106)) - 176fb140-5a52-4f85-9b1d-a71612629d1e:group-EC8E1A1CD15A changes to CANDIDATE, lastRpcTime:5148, electionTimeout:5148ms
2019-09-24 02:58:18,637 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown FollowerState
2019-09-24 02:58:18,637 [Thread-192] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 02:58:18,638 [Thread-192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start LeaderElection
2019-09-24 02:58:18,662 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4: begin an election at term 1 for -1: [176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257], old=null
2019-09-24 02:58:18,662 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown LeaderElection
2019-09-24 02:58:18,662 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 02:58:18,662 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: change Leader from null to 176fb140-5a52-4f85-9b1d-a71612629d1e at term 1 for becomeLeader, leader elected after 5201ms
2019-09-24 02:58:18,663 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 02:58:18,663 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 02:58:18,663 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 02:58:18,663 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 02:58:18,663 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 02:58:18,664 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 02:58:18,666 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 02:58:18,666 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 02:58:18,666 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown FollowerState
2019-09-24 02:58:18,666 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown FollowerState
2019-09-24 02:58:18,666 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: start FollowerState
2019-09-24 02:58:18,666 [Thread-200] INFO  impl.FollowerState (FollowerState.java:run(115)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 02:58:18,666 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start FollowerState
2019-09-24 02:58:18,666 [Thread-203] INFO  impl.FollowerState (FollowerState.java:run(115)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 02:58:18,672 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: start LeaderState
2019-09-24 02:58:18,672 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,673 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: set configuration 0: [176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257], old=null at 0
2019-09-24 02:58:18,702 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:18,716 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/da0d29dc-d718-43db-8294-ec8e1a1cd15a/current/log_inprogress_0
2019-09-24 02:58:18,722 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3: Election PASSED; received 1 response(s) [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1<-176fb140-5a52-4f85-9b1d-a71612629d1e#0:OK-t1] and 0 exception(s); 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:t1, leader=null, voted=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1, raftlog=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null
2019-09-24 02:58:18,722 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown LeaderElection
2019-09-24 02:58:18,723 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 02:58:18,725 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: change Leader from null to 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 at term 1 for becomeLeader, leader elected after 5150ms
2019-09-24 02:58:18,725 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 02:58:18,725 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 02:58:18,725 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 02:58:18,726 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 02:58:18,726 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 02:58:18,726 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 02:58:18,732 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 02:58:18,733 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:18,733 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 02:58:18,737 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 02:58:18,742 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 02:58:18,742 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:18,743 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 02:58:18,744 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 02:58:18,744 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 02:58:18,744 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 02:58:18,744 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 02:58:18,744 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 02:58:18,748 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: start LeaderState
2019-09-24 02:58:18,748 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,750 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: set configuration 0: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null at 0
2019-09-24 02:58:18,794 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/current/log_inprogress_0
2019-09-24 02:58:18,810 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: change Leader from null to 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 at term 1 for appendEntries, leader elected after 5235ms
2019-09-24 02:58:18,810 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: change Leader from null to 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1 at term 1 for appendEntries, leader elected after 5235ms
2019-09-24 02:58:18,841 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: set configuration 0: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null at 0
2019-09-24 02:58:18,841 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: set configuration 0: [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1:192.168.151.121:44913, 176fb140-5a52-4f85-9b1d-a71612629d1e:192.168.151.121:42257, 0fab8ded-0a01-458c-ba37-63116df8f1e5:192.168.151.121:43466], old=null at 0
2019-09-24 02:58:18,841 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,841 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 02:58:18,880 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/current/log_inprogress_0
2019-09-24 02:58:18,880 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/ratis/c0bad780-0481-4c18-84c3-c87293d91c6c/current/log_inprogress_0
2019-09-24 02:58:19,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:20,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:21,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:22,707 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:23,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:24,713 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:25,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:26,716 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:27,719 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:28,720 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:29,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:30,730 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:31,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:32,733 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:33,734 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:33,735 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 02:58:34,737 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:35,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:36,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:37,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:38,742 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:39,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:40,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:41,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:42,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:43,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:43,750 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 02:58:44,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:45,753 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:46,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:47,755 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:48,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:49,758 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:50,760 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:51,761 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:52,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:53,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:53,766 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 02:58:54,767 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:55,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:56,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:57,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:58,772 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:58:59,773 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:00,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:01,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:02,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:03,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:03,780 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 02:59:04,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:05,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:06,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:07,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:08,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:09,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:10,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:11,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:12,913 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:13,921 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:13,923 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 02:59:14,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:15,926 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:16,928 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:17,929 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:18,931 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:19,932 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:20,933 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:21,935 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:22,936 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:23,938 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:23,940 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 02:59:24,941 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:25,943 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:26,944 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:27,945 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:28,947 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:29,948 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:30,949 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:31,951 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:32,953 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:33,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:33,956 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 02:59:34,957 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:35,959 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:36,960 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:37,961 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:38,962 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:39,963 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:40,965 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:41,966 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:42,968 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:43,969 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:43,970 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 02:59:44,971 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:45,973 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:46,974 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:47,976 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:48,980 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:49,982 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:50,983 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:51,985 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:52,986 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:53,988 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:53,989 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 02:59:54,991 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:55,992 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:56,993 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:57,994 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:58,996 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 02:59:59,997 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 03:00:00,998 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 03:00:01,999 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 03:00:03,000 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 03:00:04,001 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 03:00:04,003 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 03:00:04,007 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.client.rpc.TestDeleteWithSlowFollower.init(TestDeleteWithSlowFollower.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 45 more
2019-09-24 03:00:04,011 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-24 03:00:04,012 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-24 03:00:04,012 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-24 03:00:04,012 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38706
2019-09-24 03:00:04,023 [IPC Server listener on 38706] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38706
2019-09-24 03:00:04,024 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-24 03:00:04,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 03:00:04,029 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-24 03:00:04,045 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-24 03:00:04,051 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@529cfee5{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-24 03:00:04,058 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7ca0863b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 03:00:04,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1542af63{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-24 03:00:04,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58cec85b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 03:00:04,064 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-24 03:00:04,072 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 03:00:04,072 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 03:00:09,067 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 03:00:09,068 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 03:00:09,069 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: close
2019-09-24 03:00:09,069 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: close
2019-09-24 03:00:09,072 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: shutdown
2019-09-24 03:00:09,072 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: shutdown
2019-09-24 03:00:09,072 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=176fb140-5a52-4f85-9b1d-a71612629d1e
2019-09-24 03:00:09,072 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-00207094249E,id=0fab8ded-0a01-458c-ba37-63116df8f1e5
2019-09-24 03:00:09,073 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown FollowerState
2019-09-24 03:00:09,073 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown LeaderState
2019-09-24 03:00:09,073 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(115)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 03:00:09,073 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:09,076 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5-PendingRequests: sendNotLeaderResponses
2019-09-24 03:00:09,077 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C: closes. applyIndex: 0
2019-09-24 03:00:09,078 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:09,080 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E: closes. applyIndex: 0
2019-09-24 03:00:09,081 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:09,081 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:09,083 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-00207094249E-SegmentedRaftLogWorker close()
2019-09-24 03:00:09,083 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-C87293D91C6C-SegmentedRaftLogWorker close()
2019-09-24 03:00:09,085 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: shutdown
2019-09-24 03:00:09,087 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: shutdown
2019-09-24 03:00:09,087 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=0fab8ded-0a01-458c-ba37-63116df8f1e5
2019-09-24 03:00:09,087 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EC8E1A1CD15A,id=176fb140-5a52-4f85-9b1d-a71612629d1e
2019-09-24 03:00:09,087 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown FollowerState
2019-09-24 03:00:09,088 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown LeaderState
2019-09-24 03:00:09,088 [Thread-232] INFO  impl.FollowerState (FollowerState.java:run(115)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 03:00:09,088 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:09,088 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 176fb140-5a52-4f85-9b1d-a71612629d1e-PendingRequests: sendNotLeaderResponses
2019-09-24 03:00:09,090 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C: closes. applyIndex: 0
2019-09-24 03:00:09,091 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:09,091 [0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:09,092 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A: closes. applyIndex: 0
2019-09-24 03:00:09,093 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5@group-C87293D91C6C-SegmentedRaftLogWorker close()
2019-09-24 03:00:09,093 [176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:09,095 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 176fb140-5a52-4f85-9b1d-a71612629d1e@group-EC8E1A1CD15A-SegmentedRaftLogWorker close()
2019-09-24 03:00:09,095 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown server with port 43466 now
2019-09-24 03:00:09,097 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown server with port 42257 now
2019-09-24 03:00:09,104 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: shutdown server with port 43466 successfully
2019-09-24 03:00:09,104 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: shutdown server with port 42257 successfully
2019-09-24 03:00:09,104 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 0fab8ded-0a01-458c-ba37-63116df8f1e5: installSnapshot onError, lastRequest: 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1->0fab8ded-0a01-458c-ba37-63116df8f1e5#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-24 03:00:09,105 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 176fb140-5a52-4f85-9b1d-a71612629d1e: installSnapshot onError, lastRequest: 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1->176fb140-5a52-4f85-9b1d-a71612629d1e#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-24 03:00:09,108 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-24 03:00:09,108 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-24 03:00:09,116 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 03:00:09,117 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 03:00:09,116 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 03:00:09,117 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
Sep 24, 2019 3:00:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@414935d9
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Sep 24, 2019 3:00:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@11050074
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-24 03:00:09,140 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:09,140 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:09,142 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 03:00:09,144 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 03:00:09,150 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 03:00:09,151 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 03:00:09,154 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 03:00:09,158 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7aac8884{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 03:00:09,160 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 03:00:09,160 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a66e580{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 03:00:09,162 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@102ecc22{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 03:00:09,162 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e519ad3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 03:00:09,163 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433348bc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 03:00:09,164 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bc44ce8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 03:00:09,164 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cd64ee8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 03:00:09,165 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77774571{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 03:00:09,183 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 03:00:11,636 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:11,637 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:11,638 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 03:00:11,645 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 03:00:14,140 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:14,140 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 03:00:14,143 [grpc-default-executor-6] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 03:00:14,144 [grpc-default-executor-5] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 03:00:14,165 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 03:00:14,166 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: close
2019-09-24 03:00:14,166 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: shutdown
2019-09-24 03:00:14,166 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C87293D91C6C,id=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 03:00:14,167 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown LeaderState
2019-09-24 03:00:14,168 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1-PendingRequests: sendNotLeaderResponses
2019-09-24 03:00:14,168 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$377/105595479@5d86b1d1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->176fb140-5a52-4f85-9b1d-a71612629d1e-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 03:00:14,168 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$377/105595479@5bc24894] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C->0fab8ded-0a01-458c-ba37-63116df8f1e5-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 03:00:14,169 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:14,170 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C: closes. applyIndex: 0
2019-09-24 03:00:14,171 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:14,172 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-C87293D91C6C-SegmentedRaftLogWorker close()
2019-09-24 03:00:14,174 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: shutdown
2019-09-24 03:00:14,174 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8F2E586D29A,id=59a9a8f5-2df6-4d0f-bee5-d77c297e06b1
2019-09-24 03:00:14,174 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown LeaderState
2019-09-24 03:00:14,175 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1-PendingRequests: sendNotLeaderResponses
2019-09-24 03:00:14,175 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-StateMachineUpdater: set stopIndex = 0
2019-09-24 03:00:14,176 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A: closes. applyIndex: 0
2019-09-24 03:00:14,177 [59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 03:00:14,184 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1@group-E8F2E586D29A-SegmentedRaftLogWorker close()
2019-09-24 03:00:14,186 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown server with port 44913 now
2019-09-24 03:00:14,187 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 59a9a8f5-2df6-4d0f-bee5-d77c297e06b1: shutdown server with port 44913 successfully
2019-09-24 03:00:14,198 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c6c32367-e887-4081-b00f-7c5cb3cf5ace/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 03:00:14,220 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 03:00:14,223 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 03:00:14,226 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd903be{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 03:00:14,226 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 03:00:14,227 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5624657a{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 03:00:14,228 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28da7d11{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 03:00:14,229 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-24 03:00:14,229 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-24 03:00:14,230 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-24 03:00:14,230 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-24 03:00:14,230 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-24 03:00:14,230 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-24 03:00:14,231 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46528
2019-09-24 03:00:14,232 [IPC Server listener on 46528] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46528
2019-09-24 03:00:14,233 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 03:00:14,303 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-24 03:00:14,303 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-24 03:00:14,304 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-24 03:00:14,304 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36026
2019-09-24 03:00:14,307 [IPC Server listener on 36026] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36026
2019-09-24 03:00:14,307 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-24 03:00:14,307 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 03:00:14,308 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-24 03:00:14,308 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40389
2019-09-24 03:00:14,311 [IPC Server listener on 40389] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40389
2019-09-24 03:00:14,311 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-24 03:00:14,311 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 03:00:14,312 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5398edd0{/,null,UNAVAILABLE}{/scm}
2019-09-24 03:00:14,313 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3f093abe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 03:00:14,314 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64ba3208{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-24 03:00:14,314 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@299321e2{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-24 03:00:14,315 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-24 03:00:14,316 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 03:00:14,316 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 03:00:14,317 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-24 03:00:14,325 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-24 03:00:14,332 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-24 03:00:14,333 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

2019-09-24 06:49:21,245 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:21,362 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:21,365 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:21,384 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @985ms
2019-09-24 06:49:21,489 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-24 06:49:21,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-24 06:49:21,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-24 06:49:21,490 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-24 06:49:21,491 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-24 06:49:21,491 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-24 06:49:21,505 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 06:49:21,505 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 06:49:21,507 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 06:49:21,774 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@65fb9ffc
2019-09-24 06:49:21,775 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-24 06:49:21,849 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-24 06:49:21,946 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-24 06:49:21,964 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:22,030 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-24 06:49:22,033 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:22,165 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-24 06:49:22,561 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:49:22,589 [Socket Reader #1 for port 44521] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44521
2019-09-24 06:49:22,722 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:49:22,723 [Socket Reader #1 for port 37167] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37167
2019-09-24 06:49:22,731 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:49:22,732 [Socket Reader #1 for port 35975] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35975
2019-09-24 06:49:22,759 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-24 06:49:22,927 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:49:22,947 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:49:22,958 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:49:22,961 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-24 06:49:22,961 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:49:22,961 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:49:22,991 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35975
2019-09-24 06:49:23,056 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-24 06:49:23,072 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-24 06:49:23,072 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-24 06:49:23,316 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:35975
2019-09-24 06:49:23,317 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:49:23,317 [IPC Server listener on 35975] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35975: starting
2019-09-24 06:49:23,321 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37167
2019-09-24 06:49:23,324 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:37167
2019-09-24 06:49:23,325 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:49:23,325 [IPC Server listener on 37167] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37167: starting
2019-09-24 06:49:23,327 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:44521
2019-09-24 06:49:23,328 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:44521
2019-09-24 06:49:23,328 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:49:23,328 [IPC Server listener on 44521] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44521: starting
2019-09-24 06:49:23,332 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41206
2019-09-24 06:49:23,334 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:49:23,376 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:49:23,377 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:49:23,471 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-41206-scm-_-any-886843831290989646.dir/webapp/,AVAILABLE}{/scm}
2019-09-24 06:49:23,476 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:41206}
2019-09-24 06:49:23,476 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3078ms
2019-09-24 06:49:23,479 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-24 06:49:23,479 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-24 06:49:23,480 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:41206
2019-09-24 06:49:23,489 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:49:23,493 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:23,611 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(138)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-24 06:49:23,611 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address: 127.0.0.1:0
2019-09-24 06:49:23,612 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address: 0.0.0.0:9875
2019-09-24 06:49:23,612 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-bind-host with value of key ozone.om.http-bind-host: 0.0.0.0
2019-09-24 06:49:23,612 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-bind-host with value of key ozone.om.https-bind-host: 0.0.0.0
2019-09-24 06:49:23,612 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.keytab with value of key ozone.om.http.kerberos.keytab: /etc/security/keytabs/HTTP.keytab
2019-09-24 06:49:23,612 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.principal with value of key ozone.om.http.kerberos.principal: HTTP/_HOST@EXAMPLE.COM
2019-09-24 06:49:23,613 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.address with value of key ozone.om.address: 127.0.0.1:0
2019-09-24 06:49:23,613 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(192)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-24 06:49:23,614 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:23,614 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:24,409 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:49:24,417 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-24 06:49:24,417 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-24 06:49:24,417 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-24 06:49:24,418 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-24 06:49:24,418 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-24 06:49:24,418 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-24 06:49:24,418 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-24 06:49:24,419 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-24 06:49:24,419 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-24 06:49:24,419 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-24 06:49:24,419 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-24 06:49:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-24 06:49:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-24 06:49:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-24 06:49:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-24 06:49:24,420 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-24 06:49:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-24 06:49:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-24 06:49:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-24 06:49:24,421 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-24 06:49:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-24 06:49:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-24 06:49:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 06:49:24,422 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 06:49:24,423 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 06:49:25,017 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:49:25,019 [Socket Reader #1 for port 42843] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42843
2019-09-24 06:49:25,047 [main] INFO  om.OzoneManager (OzoneManager.java:start(1075)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42843
2019-09-24 06:49:25,047 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-24 06:49:25,049 [IPC Server listener on 42843] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42843: starting
2019-09-24 06:49:25,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:49:25,056 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-24 06:49:25,059 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:49:25,060 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:49:25,063 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:49:25,065 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-24 06:49:25,065 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:49:25,065 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:49:25,068 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39530
2019-09-24 06:49:25,068 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:49:25,071 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:49:25,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:49:25,132 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-39530-ozoneManager-_-any-4087513886580838786.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-24 06:49:25,134 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:39530}
2019-09-24 06:49:25,139 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4740ms
2019-09-24 06:49:25,139 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:49:25,140 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:39530
2019-09-24 06:49:25,477 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:49:25,531 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:49:25,565 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:49:25,567 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/containers/hdds to VolumeSet
2019-09-24 06:49:25,569 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@889d9e8
2019-09-24 06:49:25,588 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@889d9e8
2019-09-24 06:49:25,705 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:49:25,800 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:49:25,806 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:49:25,808 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:49:25,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:25,810 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:49:25,811 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:49:26,056 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis] (custom)
2019-09-24 06:49:26,137 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:49:26,140 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:49:26,141 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:49:26,144 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:49:26,146 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:49:26,146 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:49:26,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:49:26,149 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39797
2019-09-24 06:49:26,149 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:49:26,153 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cdb2d95{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:49:26,155 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:49:26,198 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26cb5207{/,file:///tmp/jetty-0.0.0.0-39797-hddsDatanode-_-any-8047280504297270136.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:49:26,198 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15400fff{HTTP/1.1,[http/1.1]}{0.0.0.0:39797}
2019-09-24 06:49:26,199 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5801ms
2019-09-24 06:49:26,200 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:49:26,201 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39797
2019-09-24 06:49:26,202 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:49:26,206 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:49:26,209 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b805390] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:49:26,217 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:49:26,218 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/containers/hdds to VolumeSet
2019-09-24 06:49:26,218 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f0f7849
2019-09-24 06:49:26,219 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f0f7849
2019-09-24 06:49:26,244 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:49:26,244 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:49:26,245 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:49:26,245 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:49:26,246 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:26,246 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:49:26,247 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:49:26,248 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis] (custom)
2019-09-24 06:49:26,252 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:49:26,253 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:49:26,254 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:49:26,256 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:49:26,256 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:49:26,256 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:49:26,257 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:49:26,257 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46537
2019-09-24 06:49:26,258 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:49:26,261 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53e800f9{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:49:26,262 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:49:26,291 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5fcfde70{/,file:///tmp/jetty-0.0.0.0-46537-hddsDatanode-_-any-8047509909224959506.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:49:26,291 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d95a72e{HTTP/1.1,[http/1.1]}{0.0.0.0:46537}
2019-09-24 06:49:26,292 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5893ms
2019-09-24 06:49:26,292 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:49:26,294 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46537
2019-09-24 06:49:26,294 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:49:26,297 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:49:26,298 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50663c4c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:49:26,307 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:49:26,308 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/containers/hdds to VolumeSet
2019-09-24 06:49:26,308 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5a6d30e2
2019-09-24 06:49:26,309 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5a6d30e2
2019-09-24 06:49:26,323 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:49:26,323 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:49:26,323 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:49:26,323 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:49:26,325 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:26,325 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:49:26,325 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:49:26,326 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis] (custom)
2019-09-24 06:49:26,328 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:49:26,329 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:49:26,329 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/meta/datanode.id
2019-09-24 06:49:26,329 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:49:26,334 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:49:26,334 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:49:26,335 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/meta/datanode.id
2019-09-24 06:49:26,335 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:49:26,335 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:49:26,336 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34309
2019-09-24 06:49:26,336 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:49:26,338 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e642b88{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:49:26,339 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ecec90d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:49:26,367 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36480b2d{/,file:///tmp/jetty-0.0.0.0-34309-hddsDatanode-_-any-6267194421677011420.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:49:26,367 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@27d33393{HTTP/1.1,[http/1.1]}{0.0.0.0:34309}
2019-09-24 06:49:26,368 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5970ms
2019-09-24 06:49:26,369 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:49:26,370 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34309
2019-09-24 06:49:26,372 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 06:49:26,373 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ff6d1d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:49:26,377 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/meta/datanode.id
2019-09-24 06:49:27,372 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 06:49:28,289 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:49:28,292 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:49:28,293 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 8db08815-a622-4224-848f-0e621a4acc84 at port 0
2019-09-24 06:49:28,309 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:49:28,315 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:49:28,316 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c48ecdd5-5a40-42d9-b088-f4c013e40b26 at port 0
2019-09-24 06:49:28,330 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8db08815-a622-4224-848f-0e621a4acc84: start RPC server
2019-09-24 06:49:28,333 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start RPC server
2019-09-24 06:49:28,373 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 06:49:28,393 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:49:28,396 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:49:28,396 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 51541ad7-eb77-483b-9b30-443fd4f4cdd4 at port 0
2019-09-24 06:49:28,407 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start RPC server
2019-09-24 06:49:28,482 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: GrpcService started, listening on 0.0.0.0/0.0.0.0:34055
2019-09-24 06:49:28,482 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 8db08815-a622-4224-848f-0e621a4acc84: GrpcService started, listening on 0.0.0.0/0.0.0.0:36487
2019-09-24 06:49:28,482 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: GrpcService started, listening on 0.0.0.0/0.0.0.0:33695
2019-09-24 06:49:28,483 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 8db08815-a622-4224-848f-0e621a4acc84 is started using port 36487
2019-09-24 06:49:28,483 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c48ecdd5-5a40-42d9-b088-f4c013e40b26 is started using port 34055
2019-09-24 06:49:28,484 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 51541ad7-eb77-483b-9b30-443fd4f4cdd4 is started using port 33695
2019-09-24 06:49:28,490 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c48ecdd5-5a40-42d9-b088-f4c013e40b26 is started using port 43839
2019-09-24 06:49:28,490 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 51541ad7-eb77-483b-9b30-443fd4f4cdd4 is started using port 42727
2019-09-24 06:49:28,491 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 8db08815-a622-4224-848f-0e621a4acc84 is started using port 39548
2019-09-24 06:49:29,374 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-24 06:49:30,244 [IPC Server handler 17 on 44521] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/8db08815-a622-4224-848f-0e621a4acc84
2019-09-24 06:49:30,244 [IPC Server handler 17 on 44521] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 8db08815-a622-4224-848f-0e621a4acc84{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:49:30,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-24 06:49:30,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-24 06:49:30,250 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-24 06:49:30,303 [IPC Server handler 15 on 44521] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:49:30,303 [IPC Server handler 15 on 44521] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c48ecdd5-5a40-42d9-b088-f4c013e40b26{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:49:30,375 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-24 06:49:30,378 [IPC Server handler 17 on 44521] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/51541ad7-eb77-483b-9b30-443fd4f4cdd4
2019-09-24 06:49:30,378 [IPC Server handler 17 on 44521] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 51541ad7-eb77-483b-9b30-443fd4f4cdd4{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:49:30,804 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8db08815-a622-4224-848f-0e621a4acc84: addNew group-FF3CC9FF939A:[8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487] returns group-FF3CC9FF939A:java.util.concurrent.CompletableFuture@67d28290[Not completed]
2019-09-24 06:49:30,824 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8db08815-a622-4224-848f-0e621a4acc84: new RaftServerImpl for group-FF3CC9FF939A:[8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487] with ContainerStateMachine:uninitialized
2019-09-24 06:49:30,827 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:30,829 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:30,829 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:30,830 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:30,831 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:30,842 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: ConfigurationManager, init=-1: [8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:30,842 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis] (custom)
2019-09-24 06:49:30,851 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/631de155-6d8a-4001-b70b-ff3cc9ff939a does not exist. Creating ...
2019-09-24 06:49:30,869 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/631de155-6d8a-4001-b70b-ff3cc9ff939a/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:30,884 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/631de155-6d8a-4001-b70b-ff3cc9ff939a has been successfully formatted.
2019-09-24 06:49:30,887 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-FF3CC9FF939A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:30,887 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:30,889 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:30,896 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:30,896 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:30,901 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:30,907 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:30,913 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/631de155-6d8a-4001-b70b-ff3cc9ff939a
2019-09-24 06:49:30,915 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-24 06:49:30,925 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-24 06:49:30,965 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:30,965 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:30,969 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:30,970 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:30,970 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:30,971 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:30,972 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:30,972 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:30,973 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:30,985 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:30,990 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:30,995 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:30,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:30,996 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:30,997 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,024 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: start as a follower, conf=-1: [8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487], old=null
2019-09-24 06:49:31,025 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,026 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8db08815-a622-4224-848f-0e621a4acc84: start FollowerState
2019-09-24 06:49:31,028 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF3CC9FF939A,id=8db08815-a622-4224-848f-0e621a4acc84
2019-09-24 06:49:31,094 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 631de155-6d8a-4001-b70b-ff3cc9ff939a, Nodes: 8db08815-a622-4224-848f-0e621a4acc84{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:49:31,115 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: addNew group-B1DF6239A333:[51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] returns group-B1DF6239A333:java.util.concurrent.CompletableFuture@565d1f8c[Not completed]
2019-09-24 06:49:31,148 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: new RaftServerImpl for group-B1DF6239A333:[51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] with ContainerStateMachine:uninitialized
2019-09-24 06:49:31,150 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:31,150 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:31,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:31,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:31,151 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:31,152 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: ConfigurationManager, init=-1: [51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:31,152 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis] (custom)
2019-09-24 06:49:31,153 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/e18622c6-6609-4b5f-b1f1-b1df6239a333 does not exist. Creating ...
2019-09-24 06:49:31,167 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/e18622c6-6609-4b5f-b1f1-b1df6239a333/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:31,180 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/e18622c6-6609-4b5f-b1f1-b1df6239a333 has been successfully formatted.
2019-09-24 06:49:31,181 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B1DF6239A333: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:31,182 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:31,182 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:31,183 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:31,183 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:31,183 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,184 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:31,184 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/e18622c6-6609-4b5f-b1f1-b1df6239a333
2019-09-24 06:49:31,190 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:31,190 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:31,190 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,190 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:31,191 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:31,191 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:31,191 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:31,191 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:31,191 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:31,192 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:31,192 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:31,192 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:31,193 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:31,193 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:31,193 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,198 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: start as a follower, conf=-1: [51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:31,198 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,199 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start FollowerState
2019-09-24 06:49:31,200 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B1DF6239A333,id=51541ad7-eb77-483b-9b30-443fd4f4cdd4
2019-09-24 06:49:31,213 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e18622c6-6609-4b5f-b1f1-b1df6239a333, Nodes: 51541ad7-eb77-483b-9b30-443fd4f4cdd4{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:49:31,232 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: addNew group-E3710298D074:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055] returns group-E3710298D074:java.util.concurrent.CompletableFuture@7c0bcc10[Not completed]
2019-09-24 06:49:31,248 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: new RaftServerImpl for group-E3710298D074:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055] with ContainerStateMachine:uninitialized
2019-09-24 06:49:31,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:31,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:31,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:31,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:31,249 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:31,250 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: ConfigurationManager, init=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:31,250 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis] (custom)
2019-09-24 06:49:31,250 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/0f88e9d2-d7c6-4773-a027-e3710298d074 does not exist. Creating ...
2019-09-24 06:49:31,263 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/0f88e9d2-d7c6-4773-a027-e3710298d074/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:31,277 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/0f88e9d2-d7c6-4773-a027-e3710298d074 has been successfully formatted.
2019-09-24 06:49:31,277 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-E3710298D074: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:31,278 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:31,278 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:31,278 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:31,278 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:31,278 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,279 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:31,279 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/0f88e9d2-d7c6-4773-a027-e3710298d074
2019-09-24 06:49:31,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:31,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:31,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,300 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:31,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:31,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:31,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:31,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:31,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:31,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:31,302 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:31,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:31,302 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:31,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:31,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,307 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: start as a follower, conf=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055], old=null
2019-09-24 06:49:31,307 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,307 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start FollowerState
2019-09-24 06:49:31,308 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E3710298D074,id=c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:49:31,316 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0f88e9d2-d7c6-4773-a027-e3710298d074, Nodes: c48ecdd5-5a40-42d9-b088-f4c013e40b26{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:49:31,344 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: addNew group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] returns group-B8E979DAE79F:java.util.concurrent.CompletableFuture@7c462b71[Not completed]
2019-09-24 06:49:31,347 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: addNew group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] returns group-B8E979DAE79F:java.util.concurrent.CompletableFuture@42012ebc[Not completed]
2019-09-24 06:49:31,349 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8db08815-a622-4224-848f-0e621a4acc84: addNew group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] returns group-B8E979DAE79F:java.util.concurrent.CompletableFuture@3944aa9d[Not completed]
2019-09-24 06:49:31,349 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: new RaftServerImpl for group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] with ContainerStateMachine:uninitialized
2019-09-24 06:49:31,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:31,349 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:31,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:31,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:31,350 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:31,350 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: ConfigurationManager, init=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:31,351 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: new RaftServerImpl for group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] with ContainerStateMachine:uninitialized
2019-09-24 06:49:31,351 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis] (custom)
2019-09-24 06:49:31,351 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:31,351 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:31,351 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f does not exist. Creating ...
2019-09-24 06:49:31,352 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:31,352 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:31,352 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 8db08815-a622-4224-848f-0e621a4acc84: new RaftServerImpl for group-B8E979DAE79F:[c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695] with ContainerStateMachine:uninitialized
2019-09-24 06:49:31,352 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:31,353 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:49:31,353 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: ConfigurationManager, init=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:31,353 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:49:31,353 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis] (custom)
2019-09-24 06:49:31,353 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:49:31,354 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:49:31,354 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f does not exist. Creating ...
2019-09-24 06:49:31,354 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:31,354 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: ConfigurationManager, init=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null, confs=<EMPTY_MAP>
2019-09-24 06:49:31,355 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis] (custom)
2019-09-24 06:49:31,355 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f does not exist. Creating ...
2019-09-24 06:49:31,365 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:31,365 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:31,365 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/in_use.lock acquired by nodename 19100@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:49:31,376 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-24 06:49:31,379 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f has been successfully formatted.
2019-09-24 06:49:31,379 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f has been successfully formatted.
2019-09-24 06:49:31,380 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B8E979DAE79F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:31,379 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f has been successfully formatted.
2019-09-24 06:49:31,380 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:31,380 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B8E979DAE79F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:31,380 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:31,380 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B8E979DAE79F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:49:31,381 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:31,381 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:31,381 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:31,381 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:49:31,382 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,381 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:31,382 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:31,382 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:49:31,382 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f
2019-09-24 06:49:31,382 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:31,383 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:31,383 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:49:31,383 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:31,383 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:31,383 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,383 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:31,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:31,384 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:31,384 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,385 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:31,384 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:31,385 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:31,385 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:49:31,385 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:31,385 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f
2019-09-24 06:49:31,386 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:31,386 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f
2019-09-24 06:49:31,386 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:31,386 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:31,386 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:49:31,387 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:31,387 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:31,387 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,387 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:49:31,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:31,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:31,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:31,388 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:49:31,388 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:31,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:31,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:31,389 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:49:31,389 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:31,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:31,390 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:31,389 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:49:31,390 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:31,390 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,390 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:49:31,391 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:31,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:49:31,391 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:31,391 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:49:31,391 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:31,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:49:31,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:31,392 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:49:31,392 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,393 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:49:31,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:49:31,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:49:31,393 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:49:31,394 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:49:31,397 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: start as a follower, conf=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:31,397 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,397 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start FollowerState
2019-09-24 06:49:31,398 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:49:31,402 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: start as a follower, conf=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:31,403 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,403 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start FollowerState
2019-09-24 06:49:31,403 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: start as a follower, conf=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:31,403 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:49:31,403 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=51541ad7-eb77-483b-9b30-443fd4f4cdd4
2019-09-24 06:49:31,404 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8db08815-a622-4224-848f-0e621a4acc84: start FollowerState
2019-09-24 06:49:31,406 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=8db08815-a622-4224-848f-0e621a4acc84
2019-09-24 06:49:31,423 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5cede5d8-95c6-40fd-b4c1-b8e979dae79f, Nodes: 8db08815-a622-4224-848f-0e621a4acc84{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}51541ad7-eb77-483b-9b30-443fd4f4cdd4{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}c48ecdd5-5a40-42d9-b088-f4c013e40b26{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 06:49:32,615 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:33,256 [Thread-178] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-24 06:49:33,260 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-24 06:49:33,616 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:34,618 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:35,620 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:36,169 [Thread-180] INFO  impl.FollowerState (FollowerState.java:run(106)) - 8db08815-a622-4224-848f-0e621a4acc84:group-FF3CC9FF939A changes to CANDIDATE, lastRpcTime:5143, electionTimeout:5142ms
2019-09-24 06:49:36,173 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown FollowerState
2019-09-24 06:49:36,174 [Thread-180] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:49:36,183 [Thread-180] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8db08815-a622-4224-848f-0e621a4acc84: start LeaderElection
2019-09-24 06:49:36,214 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1: begin an election at term 1 for -1: [8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487], old=null
2019-09-24 06:49:36,216 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown LeaderElection
2019-09-24 06:49:36,217 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:49:36,217 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: change Leader from null to 8db08815-a622-4224-848f-0e621a4acc84 at term 1 for becomeLeader, leader elected after 5330ms
2019-09-24 06:49:36,225 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:49:36,226 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:49:36,230 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:49:36,233 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:49:36,234 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:49:36,235 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:49:36,257 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8db08815-a622-4224-848f-0e621a4acc84: start LeaderState
2019-09-24 06:49:36,288 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,297 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(106)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4:group-B1DF6239A333 changes to CANDIDATE, lastRpcTime:5098, electionTimeout:5097ms
2019-09-24 06:49:36,299 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown FollowerState
2019-09-24 06:49:36,299 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:49:36,307 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start LeaderElection
2019-09-24 06:49:36,312 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: set configuration 0: [8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487], old=null at 0
2019-09-24 06:49:36,324 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2: begin an election at term 1 for -1: [51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:36,325 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown LeaderElection
2019-09-24 06:49:36,325 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:49:36,326 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: change Leader from null to 51541ad7-eb77-483b-9b30-443fd4f4cdd4 at term 1 for becomeLeader, leader elected after 5143ms
2019-09-24 06:49:36,326 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:49:36,326 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:49:36,326 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:49:36,327 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:49:36,327 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:49:36,327 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:49:36,330 [Thread-186] INFO  impl.FollowerState (FollowerState.java:run(106)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26:group-E3710298D074 changes to CANDIDATE, lastRpcTime:5022, electionTimeout:5022ms
2019-09-24 06:49:36,330 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown FollowerState
2019-09-24 06:49:36,330 [Thread-186] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:49:36,330 [Thread-186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start LeaderElection
2019-09-24 06:49:36,335 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start LeaderState
2019-09-24 06:49:36,336 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,337 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: set configuration 0: [51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null at 0
2019-09-24 06:49:36,346 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3: begin an election at term 1 for -1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055], old=null
2019-09-24 06:49:36,346 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown LeaderElection
2019-09-24 06:49:36,346 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: change Leader from null to c48ecdd5-5a40-42d9-b088-f4c013e40b26 at term 1 for becomeLeader, leader elected after 5069ms
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:49:36,347 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:49:36,351 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start LeaderState
2019-09-24 06:49:36,351 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,352 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: set configuration 0: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055], old=null at 0
2019-09-24 06:49:36,429 [Thread-191] INFO  impl.FollowerState (FollowerState.java:run(106)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26:group-B8E979DAE79F changes to CANDIDATE, lastRpcTime:5031, electionTimeout:5031ms
2019-09-24 06:49:36,430 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown FollowerState
2019-09-24 06:49:36,430 [Thread-191] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:49:36,430 [Thread-191] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start LeaderElection
2019-09-24 06:49:36,446 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4: begin an election at term 1 for -1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:36,487 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:49:36,487 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:49:36,487 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown FollowerState
2019-09-24 06:49:36,487 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown FollowerState
2019-09-24 06:49:36,488 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8db08815-a622-4224-848f-0e621a4acc84: start FollowerState
2019-09-24 06:49:36,488 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: start FollowerState
2019-09-24 06:49:36,488 [Thread-194] INFO  impl.FollowerState (FollowerState.java:run(115)) - 8db08815-a622-4224-848f-0e621a4acc84: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:49:36,488 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(115)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:49:36,517 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4: Election PASSED; received 1 response(s) [c48ecdd5-5a40-42d9-b088-f4c013e40b26<-8db08815-a622-4224-848f-0e621a4acc84#0:OK-t1] and 0 exception(s); c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:t1, leader=null, voted=c48ecdd5-5a40-42d9-b088-f4c013e40b26, raftlog=c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null
2019-09-24 06:49:36,517 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown LeaderElection
2019-09-24 06:49:36,518 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:49:36,520 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: change Leader from null to c48ecdd5-5a40-42d9-b088-f4c013e40b26 at term 1 for becomeLeader, leader elected after 5139ms
2019-09-24 06:49:36,520 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:49:36,520 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:49:36,520 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:49:36,521 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:49:36,521 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:49:36,521 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:49:36,527 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 06:49:36,527 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:36,527 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 06:49:36,531 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 06:49:36,532 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:49:36,533 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:36,534 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 06:49:36,534 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:49:36,534 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 06:49:36,535 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 06:49:36,535 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:49:36,535 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:49:36,539 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: start LeaderState
2019-09-24 06:49:36,539 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,540 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: set configuration 0: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null at 0
2019-09-24 06:49:36,615 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/e18622c6-6609-4b5f-b1f1-b1df6239a333/current/log_inprogress_0
2019-09-24 06:49:36,615 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/631de155-6d8a-4001-b70b-ff3cc9ff939a/current/log_inprogress_0
2019-09-24 06:49:36,615 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/current/log_inprogress_0
2019-09-24 06:49:36,615 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/ratis/0f88e9d2-d7c6-4773-a027-e3710298d074/current/log_inprogress_0
2019-09-24 06:49:36,620 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: change Leader from null to c48ecdd5-5a40-42d9-b088-f4c013e40b26 at term 1 for appendEntries, leader elected after 5238ms
2019-09-24 06:49:36,620 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: change Leader from null to c48ecdd5-5a40-42d9-b088-f4c013e40b26 at term 1 for appendEntries, leader elected after 5238ms
2019-09-24 06:49:36,621 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:36,650 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: set configuration 0: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null at 0
2019-09-24 06:49:36,650 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: set configuration 0: [c48ecdd5-5a40-42d9-b088-f4c013e40b26:192.168.151.121:34055, 8db08815-a622-4224-848f-0e621a4acc84:192.168.151.121:36487, 51541ad7-eb77-483b-9b30-443fd4f4cdd4:192.168.151.121:33695], old=null at 0
2019-09-24 06:49:36,650 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,650 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:49:36,698 [8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/current/log_inprogress_0
2019-09-24 06:49:36,698 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/ratis/5cede5d8-95c6-40fd-b4c1-b8e979dae79f/current/log_inprogress_0
2019-09-24 06:49:37,624 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:38,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:39,627 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:40,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:41,630 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:42,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:43,639 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:44,641 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:45,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:46,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:47,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:48,646 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:49,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:50,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:51,652 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:51,654 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 06:49:52,655 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:53,657 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:54,659 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:55,661 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:56,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:57,663 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:58,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:59,666 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:00,668 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:01,669 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:01,671 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 06:50:02,672 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:03,674 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:04,675 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:05,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:06,678 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:07,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:08,682 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:09,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:10,684 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:11,685 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:11,687 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 06:50:12,688 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:13,690 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:14,691 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:15,695 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:16,696 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:17,698 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:18,699 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:19,701 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:20,703 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:21,704 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:21,707 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 06:50:22,708 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:23,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:24,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:25,713 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:26,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:27,716 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:28,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:29,720 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:30,721 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:31,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:31,724 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 06:50:32,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:33,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:34,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:35,730 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:36,732 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:37,733 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:38,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:39,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:40,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:41,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:41,741 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 06:50:42,742 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:43,744 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:44,745 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:45,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:46,749 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:47,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:48,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:49,753 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:50,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:51,756 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:51,757 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 06:50:52,759 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:53,760 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:54,762 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:55,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:56,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:57,765 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:58,767 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:50:59,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:00,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:01,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:01,773 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 06:51:02,774 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:03,776 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:04,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:05,779 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:06,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:07,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:08,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:09,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:10,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:11,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:11,790 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 06:51:12,791 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:13,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:14,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:15,795 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:16,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:17,797 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:18,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:19,800 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:20,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:21,803 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:51:21,805 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 06:51:21,809 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.startFreon(TestFreonWithPipelineDestroy.java:87)
	at org.apache.hadoop.ozone.freon.TestFreonWithPipelineDestroy.testRestart(TestFreonWithPipelineDestroy.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 57 more
2019-09-24 06:51:21,831 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-24 06:51:21,831 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-24 06:51:21,831 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-24 06:51:21,832 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42843
2019-09-24 06:51:21,847 [IPC Server listener on 42843] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42843
2019-09-24 06:51:21,848 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-24 06:51:21,853 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:51:21,856 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-24 06:51:21,863 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-24 06:51:21,868 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-24 06:51:21,873 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:51:21,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:51:21,874 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:51:21,882 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-24 06:51:22,253 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:51:22,315 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:51:26,885 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:51:26,885 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:51:26,887 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8db08815-a622-4224-848f-0e621a4acc84: close
2019-09-24 06:51:26,887 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: close
2019-09-24 06:51:26,890 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: shutdown
2019-09-24 06:51:26,890 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: shutdown
2019-09-24 06:51:26,891 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF3CC9FF939A,id=8db08815-a622-4224-848f-0e621a4acc84
2019-09-24 06:51:26,891 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:51:26,891 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown LeaderState
2019-09-24 06:51:26,892 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown LeaderState
2019-09-24 06:51:26,896 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$352/488678571@58bce2ed] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->8db08815-a622-4224-848f-0e621a4acc84-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 06:51:26,896 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 8db08815-a622-4224-848f-0e621a4acc84-PendingRequests: sendNotLeaderResponses
2019-09-24 06:51:26,896 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26-PendingRequests: sendNotLeaderResponses
2019-09-24 06:51:26,896 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$352/488678571@2f15e78a] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->51541ad7-eb77-483b-9b30-443fd4f4cdd4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 06:51:26,901 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:26,901 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:26,905 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F: closes. applyIndex: 0
2019-09-24 06:51:26,905 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 8db08815-a622-4224-848f-0e621a4acc84: Completed APPEND_ENTRIES, lastRequest: c48ecdd5-5a40-42d9-b088-f4c013e40b26->8db08815-a622-4224-848f-0e621a4acc84#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 06:51:26,905 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: Completed APPEND_ENTRIES, lastRequest: c48ecdd5-5a40-42d9-b088-f4c013e40b26->51541ad7-eb77-483b-9b30-443fd4f4cdd4#44-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 06:51:26,905 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A: closes. applyIndex: 0
2019-09-24 06:51:26,909 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:26,909 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->8db08815-a622-4224-848f-0e621a4acc84-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-24 06:51:26,909 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(293)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->51541ad7-eb77-483b-9b30-443fd4f4cdd4-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2019-09-24 06:51:26,909 [8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:26,911 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F-SegmentedRaftLogWorker close()
2019-09-24 06:51:26,913 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8db08815-a622-4224-848f-0e621a4acc84@group-FF3CC9FF939A-SegmentedRaftLogWorker close()
2019-09-24 06:51:26,918 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: shutdown
2019-09-24 06:51:26,919 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: shutdown
2019-09-24 06:51:26,920 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=8db08815-a622-4224-848f-0e621a4acc84
2019-09-24 06:51:26,921 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown FollowerState
2019-09-24 06:51:26,919 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->51541ad7-eb77-483b-9b30-443fd4f4cdd4: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 06:51:26,919 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-B8E979DAE79F->8db08815-a622-4224-848f-0e621a4acc84: nextIndex: updateUnconditionally 1 -> 0
2019-09-24 06:51:26,921 [Thread-208] INFO  impl.FollowerState (FollowerState.java:run(115)) - 8db08815-a622-4224-848f-0e621a4acc84: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:51:26,921 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:26,920 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E3710298D074,id=c48ecdd5-5a40-42d9-b088-f4c013e40b26
2019-09-24 06:51:26,924 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F: closes. applyIndex: 0
2019-09-24 06:51:26,924 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown LeaderState
2019-09-24 06:51:26,924 [8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:26,925 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26-PendingRequests: sendNotLeaderResponses
2019-09-24 06:51:26,925 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 8db08815-a622-4224-848f-0e621a4acc84@group-B8E979DAE79F-SegmentedRaftLogWorker close()
2019-09-24 06:51:26,926 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:26,928 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074: closes. applyIndex: 0
2019-09-24 06:51:26,929 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown server with port 36487 now
2019-09-24 06:51:26,929 [c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:26,930 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26@group-E3710298D074-SegmentedRaftLogWorker close()
2019-09-24 06:51:26,932 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown server with port 34055 now
2019-09-24 06:51:26,934 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c48ecdd5-5a40-42d9-b088-f4c013e40b26: shutdown server with port 34055 successfully
2019-09-24 06:51:26,934 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 8db08815-a622-4224-848f-0e621a4acc84: shutdown server with port 36487 successfully
2019-09-24 06:51:26,942 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:51:26,944 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:51:26,963 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:51:26,965 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:51:26,968 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26cb5207{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:51:26,968 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:51:26,970 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15400fff{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:51:26,970 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:51:26,971 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:51:26,972 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cdb2d95{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:51:26,973 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5fcfde70{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:51:26,973 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d95a72e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:51:26,974 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:51:26,974 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53e800f9{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:51:27,382 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:51:31,974 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:51:31,975 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: close
2019-09-24 06:51:31,975 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: shutdown
2019-09-24 06:51:31,976 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B1DF6239A333,id=51541ad7-eb77-483b-9b30-443fd4f4cdd4
2019-09-24 06:51:31,976 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown LeaderState
2019-09-24 06:51:31,976 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4-PendingRequests: sendNotLeaderResponses
2019-09-24 06:51:31,977 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:31,978 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333: closes. applyIndex: 0
2019-09-24 06:51:31,979 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:31,980 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B1DF6239A333-SegmentedRaftLogWorker close()
2019-09-24 06:51:31,982 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: shutdown
2019-09-24 06:51:31,982 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B8E979DAE79F,id=51541ad7-eb77-483b-9b30-443fd4f4cdd4
2019-09-24 06:51:31,982 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown FollowerState
2019-09-24 06:51:31,983 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:51:31,983 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(115)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:51:31,984 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F: closes. applyIndex: 0
2019-09-24 06:51:31,985 [51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:51:31,986 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4@group-B8E979DAE79F-SegmentedRaftLogWorker close()
2019-09-24 06:51:31,988 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown server with port 33695 now
2019-09-24 06:51:31,988 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 51541ad7-eb77-483b-9b30-443fd4f4cdd4: shutdown server with port 33695 successfully
2019-09-24 06:51:32,002 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-5dbf7d1a-e0f0-47fe-8770-d5dc95679ffb/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:51:32,019 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:51:32,021 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:51:32,024 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36480b2d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:51:32,025 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@27d33393{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:51:32,025 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ecec90d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:51:32,026 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e642b88{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:51:32,027 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-24 06:51:32,027 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-24 06:51:32,027 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-24 06:51:32,028 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-24 06:51:32,028 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-24 06:51:32,028 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-24 06:51:32,028 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44521
2019-09-24 06:51:32,031 [IPC Server listener on 44521] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44521
2019-09-24 06:51:32,031 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:51:32,885 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-24 06:51:32,886 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-24 06:51:32,886 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-24 06:51:32,886 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37167
2019-09-24 06:51:32,889 [IPC Server listener on 37167] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37167
2019-09-24 06:51:32,889 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-24 06:51:32,889 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:51:32,889 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-24 06:51:32,889 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35975
2019-09-24 06:51:32,892 [IPC Server listener on 35975] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35975
2019-09-24 06:51:32,892 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-24 06:51:32,892 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:51:32,893 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-24 06:51:32,895 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:51:32,895 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:51:32,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:51:32,897 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-24 06:51:32,897 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 06:51:32,898 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 06:51:32,898 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-24 06:51:32,905 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-24 06:51:32,912 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-24 06:51:32,912 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

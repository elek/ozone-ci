2019-09-24 06:45:12,966 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:13,095 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:13,099 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:13,120 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @943ms
2019-09-24 06:45:13,273 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-24 06:45:13,274 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-24 06:45:13,274 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-24 06:45:13,274 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-24 06:45:13,275 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-24 06:45:13,275 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-24 06:45:13,291 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 06:45:13,292 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 06:45:13,293 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 06:45:13,636 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@411f53a0
2019-09-24 06:45:13,639 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-24 06:45:13,720 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 06:45:13,722 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 06:45:13,724 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-24 06:45:13,798 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-24 06:45:13,812 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:13,902 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-24 06:45:13,905 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:14,046 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-24 06:45:14,442 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:45:14,473 [Socket Reader #1 for port 34614] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34614
2019-09-24 06:45:14,665 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:45:14,667 [Socket Reader #1 for port 43858] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43858
2019-09-24 06:45:14,679 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:45:14,680 [Socket Reader #1 for port 42615] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42615
2019-09-24 06:45:14,711 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-24 06:45:14,839 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:14,855 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:14,865 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:14,868 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-24 06:45:14,868 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:14,869 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:14,897 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42615
2019-09-24 06:45:14,952 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-24 06:45:14,966 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-24 06:45:14,966 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-24 06:45:15,150 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:42615
2019-09-24 06:45:15,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:45:15,150 [IPC Server listener on 42615] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42615: starting
2019-09-24 06:45:15,153 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:43858
2019-09-24 06:45:15,154 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:43858
2019-09-24 06:45:15,154 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:45:15,154 [IPC Server listener on 43858] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43858: starting
2019-09-24 06:45:15,157 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:34614
2019-09-24 06:45:15,157 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:34614
2019-09-24 06:45:15,157 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:45:15,158 [IPC Server listener on 34614] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34614: starting
2019-09-24 06:45:15,161 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45019
2019-09-24 06:45:15,162 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:15,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:15,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:15,249 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@544630b7{/,file:///tmp/jetty-0.0.0.0-45019-scm-_-any-8267481466322410323.dir/webapp/,AVAILABLE}{/scm}
2019-09-24 06:45:15,253 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:45019}
2019-09-24 06:45:15,253 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3076ms
2019-09-24 06:45:15,255 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-24 06:45:15,256 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-24 06:45:15,257 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:45019
2019-09-24 06:45:15,266 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@790174f2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:15,271 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:15,405 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(138)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-24 06:45:15,405 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address: 127.0.0.1:0
2019-09-24 06:45:15,405 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address: 0.0.0.0:9875
2019-09-24 06:45:15,406 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-bind-host with value of key ozone.om.http-bind-host: 0.0.0.0
2019-09-24 06:45:15,406 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-bind-host with value of key ozone.om.https-bind-host: 0.0.0.0
2019-09-24 06:45:15,406 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.keytab with value of key ozone.om.http.kerberos.keytab: /etc/security/keytabs/HTTP.keytab
2019-09-24 06:45:15,406 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.principal with value of key ozone.om.http.kerberos.principal: HTTP/_HOST@EXAMPLE.COM
2019-09-24 06:45:15,406 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.address with value of key ozone.om.address: 127.0.0.1:0
2019-09-24 06:45:15,407 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(192)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-24 06:45:15,408 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:15,408 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:16,162 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 06:45:16,171 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-24 06:45:16,171 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-24 06:45:16,172 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-24 06:45:16,172 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-24 06:45:16,172 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-24 06:45:16,173 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-24 06:45:16,173 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-24 06:45:16,173 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-24 06:45:16,173 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-24 06:45:16,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-24 06:45:16,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-24 06:45:16,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-24 06:45:16,174 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-24 06:45:16,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-24 06:45:16,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-24 06:45:16,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-24 06:45:16,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-24 06:45:16,175 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-24 06:45:16,176 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-24 06:45:16,176 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-24 06:45:16,176 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-24 06:45:16,177 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-24 06:45:16,177 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 06:45:16,177 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 06:45:16,177 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 06:45:16,748 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 06:45:16,750 [Socket Reader #1 for port 41436] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41436
2019-09-24 06:45:16,777 [main] INFO  om.OzoneManager (OzoneManager.java:start(1075)) - OzoneManager RPC server is listening at localhost/127.0.0.1:41436
2019-09-24 06:45:16,777 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-24 06:45:16,779 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 06:45:16,779 [IPC Server listener on 41436] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41436: starting
2019-09-24 06:45:16,785 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-24 06:45:16,788 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:16,788 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:16,791 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:16,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-24 06:45:16,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:16,793 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:16,795 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35495
2019-09-24 06:45:16,795 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:16,798 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:16,799 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:16,854 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27fde870{/,file:///tmp/jetty-0.0.0.0-35495-ozoneManager-_-any-3708350051477607848.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-24 06:45:16,855 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:35495}
2019-09-24 06:45:16,856 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4678ms
2019-09-24 06:45:16,856 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:16,857 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:35495
2019-09-24 06:45:17,202 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:45:17,253 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:45:17,288 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:45:17,290 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/containers/hdds to VolumeSet
2019-09-24 06:45:17,294 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-24 06:45:17,313 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6df3e44c
2019-09-24 06:45:17,347 [main] WARN  impl.ChunkManagerFactory (ChunkManagerFactory.java:createChunkManager(83)) - hdds.container.chunk.persistdata is set to false. This should be used only for testing. All user data will be discarded.
2019-09-24 06:45:17,427 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:45:17,496 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:45:17,502 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:45:17,503 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:45:17,504 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:17,505 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:45:17,506 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:17,722 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis] (custom)
2019-09-24 06:45:17,778 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:45:17,782 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:17,782 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:17,785 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:17,786 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:45:17,787 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:17,787 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:17,788 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44232
2019-09-24 06:45:17,789 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:17,792 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71a06021{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:17,793 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6edcad64{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:17,836 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77774571{/,file:///tmp/jetty-0.0.0.0-44232-hddsDatanode-_-any-8622227578311048913.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:45:17,837 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@277b8fa4{HTTP/1.1,[http/1.1]}{0.0.0.0:44232}
2019-09-24 06:45:17,838 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5660ms
2019-09-24 06:45:17,839 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:17,840 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44232
2019-09-24 06:45:17,841 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:45:17,844 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:45:17,847 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4acef680] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:17,854 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:45:17,855 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/containers/hdds to VolumeSet
2019-09-24 06:45:17,855 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4d41ba0f
2019-09-24 06:45:17,856 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4d41ba0f
2019-09-24 06:45:17,874 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:45:17,874 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:45:17,874 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:45:17,875 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:45:17,875 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:17,875 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:45:17,875 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:17,876 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis] (custom)
2019-09-24 06:45:17,878 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:45:17,880 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:17,881 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:17,884 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:17,885 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:45:17,885 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:17,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:17,887 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34010
2019-09-24 06:45:17,888 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:17,892 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:17,893 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2924f1d8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:17,933 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5624657a{/,file:///tmp/jetty-0.0.0.0-34010-hddsDatanode-_-any-6795145957286034594.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:45:17,934 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@36681447{HTTP/1.1,[http/1.1]}{0.0.0.0:34010}
2019-09-24 06:45:17,935 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5757ms
2019-09-24 06:45:17,936 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:17,937 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34010
2019-09-24 06:45:17,937 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:45:17,941 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7763c5e1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:17,942 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:45:17,952 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:45:17,953 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/containers/hdds to VolumeSet
2019-09-24 06:45:17,953 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2b680207
2019-09-24 06:45:17,954 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2b680207
2019-09-24 06:45:17,965 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/meta/datanode.id
2019-09-24 06:45:17,970 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/meta/datanode.id
2019-09-24 06:45:17,978 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:45:17,978 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:45:17,979 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:45:17,979 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:45:17,979 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:17,979 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:45:17,980 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:17,980 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis] (custom)
2019-09-24 06:45:17,983 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:45:17,985 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:17,986 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:17,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:17,990 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:45:17,990 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:17,991 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:17,992 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38397
2019-09-24 06:45:17,992 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:17,995 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@118ffcfd{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:17,996 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74174a23{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:18,044 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e7c141d{/,file:///tmp/jetty-0.0.0.0-38397-hddsDatanode-_-any-6408144324989603386.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:45:18,045 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@43af351a{HTTP/1.1,[http/1.1]}{0.0.0.0:38397}
2019-09-24 06:45:18,047 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5869ms
2019-09-24 06:45:18,047 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:18,048 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38397
2019-09-24 06:45:18,049 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:45:18,052 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3bf6e85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:18,053 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:45:18,055 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/meta/datanode.id
2019-09-24 06:45:18,063 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:45:18,063 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/containers/hdds to VolumeSet
2019-09-24 06:45:18,064 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@20ab3e3a
2019-09-24 06:45:18,064 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@20ab3e3a
2019-09-24 06:45:18,084 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:45:18,085 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:45:18,085 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:45:18,086 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:45:18,086 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:18,086 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:45:18,087 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:18,088 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis] (custom)
2019-09-24 06:45:18,090 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:45:18,092 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:18,093 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:18,096 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:18,097 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:45:18,097 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:18,098 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:18,099 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44107
2019-09-24 06:45:18,099 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:18,103 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@350d3f4d{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:18,104 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73844119{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:18,150 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2cae9b8{/,file:///tmp/jetty-0.0.0.0-44107-hddsDatanode-_-any-4615318216001659947.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:45:18,151 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1457fde{HTTP/1.1,[http/1.1]}{0.0.0.0:44107}
2019-09-24 06:45:18,152 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5974ms
2019-09-24 06:45:18,152 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:18,153 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44107
2019-09-24 06:45:18,153 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 06:45:18,157 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c0654f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:18,157 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 06:45:18,160 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/meta/datanode.id
2019-09-24 06:45:18,166 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 06:45:18,166 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/containers/hdds to VolumeSet
2019-09-24 06:45:18,167 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f89331f
2019-09-24 06:45:18,167 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@4f89331f
2019-09-24 06:45:18,181 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 06:45:18,181 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 06:45:18,182 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 06:45:18,182 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 06:45:18,182 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:18,182 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 06:45:18,183 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:18,183 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis] (custom)
2019-09-24 06:45:18,185 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 06:45:18,187 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 06:45:18,188 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 06:45:18,191 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 06:45:18,192 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 06:45:18,192 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 06:45:18,192 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 06:45:18,194 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34909
2019-09-24 06:45:18,194 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 06:45:18,197 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a1c3cb4{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 06:45:18,198 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56637cff{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 06:45:18,243 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58fef7f7{/,file:///tmp/jetty-0.0.0.0-34909-hddsDatanode-_-any-1017137771905482917.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 06:45:18,245 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@31ddb930{HTTP/1.1,[http/1.1]}{0.0.0.0:34909}
2019-09-24 06:45:18,245 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6067ms
2019-09-24 06:45:18,245 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 06:45:18,246 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34909
2019-09-24 06:45:18,249 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 06:45:18,250 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f9e940f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 06:45:18,253 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/meta/datanode.id
2019-09-24 06:45:19,249 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 06:45:19,925 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:45:19,927 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:45:19,927 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 25c32c4e-7edd-46c0-8321-2a409aa68b7d at port 0
2019-09-24 06:45:19,955 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: start RPC server
2019-09-24 06:45:19,958 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:45:19,961 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:45:19,961 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis dd9ea8fb-5fab-438f-82e2-b2f2116100d9 at port 0
2019-09-24 06:45:19,971 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start RPC server
2019-09-24 06:45:20,068 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:45:20,070 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:45:20,071 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1 at port 0
2019-09-24 06:45:20,080 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: start RPC server
2019-09-24 06:45:20,130 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: GrpcService started, listening on 0.0.0.0/0.0.0.0:36740
2019-09-24 06:45:20,130 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: GrpcService started, listening on 0.0.0.0/0.0.0.0:41354
2019-09-24 06:45:20,130 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: GrpcService started, listening on 0.0.0.0/0.0.0.0:34615
2019-09-24 06:45:20,131 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis dd9ea8fb-5fab-438f-82e2-b2f2116100d9 is started using port 41354
2019-09-24 06:45:20,131 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 25c32c4e-7edd-46c0-8321-2a409aa68b7d is started using port 36740
2019-09-24 06:45:20,132 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1 is started using port 34615
2019-09-24 06:45:20,139 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 25c32c4e-7edd-46c0-8321-2a409aa68b7d is started using port 42002
2019-09-24 06:45:20,139 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1 is started using port 39668
2019-09-24 06:45:20,139 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc dd9ea8fb-5fab-438f-82e2-b2f2116100d9 is started using port 40043
2019-09-24 06:45:20,173 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:45:20,175 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:45:20,175 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c7182883-8de4-4c00-9645-5e46eefe0720 at port 0
2019-09-24 06:45:20,184 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c7182883-8de4-4c00-9645-5e46eefe0720: start RPC server
2019-09-24 06:45:20,187 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c7182883-8de4-4c00-9645-5e46eefe0720: GrpcService started, listening on 0.0.0.0/0.0.0.0:32998
2019-09-24 06:45:20,188 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c7182883-8de4-4c00-9645-5e46eefe0720 is started using port 32998
2019-09-24 06:45:20,191 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c7182883-8de4-4c00-9645-5e46eefe0720 is started using port 35721
2019-09-24 06:45:20,250 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 06:45:20,266 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 06:45:20,272 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 06:45:20,273 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 21edc98c-4e3e-4966-bece-df5609ac098e at port 0
2019-09-24 06:45:20,283 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start RPC server
2019-09-24 06:45:20,286 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 21edc98c-4e3e-4966-bece-df5609ac098e: GrpcService started, listening on 0.0.0.0/0.0.0.0:42664
2019-09-24 06:45:20,287 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 21edc98c-4e3e-4966-bece-df5609ac098e is started using port 42664
2019-09-24 06:45:20,290 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 21edc98c-4e3e-4966-bece-df5609ac098e is started using port 45442
2019-09-24 06:45:21,250 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 06:45:21,895 [IPC Server handler 1 on 34614] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/25c32c4e-7edd-46c0-8321-2a409aa68b7d
2019-09-24 06:45:21,896 [IPC Server handler 1 on 34614] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 25c32c4e-7edd-46c0-8321-2a409aa68b7d{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:45:21,903 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-24 06:45:21,903 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-24 06:45:21,903 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-24 06:45:21,947 [IPC Server handler 4 on 34614] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/dd9ea8fb-5fab-438f-82e2-b2f2116100d9
2019-09-24 06:45:21,947 [IPC Server handler 4 on 34614] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : dd9ea8fb-5fab-438f-82e2-b2f2116100d9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:45:22,055 [IPC Server handler 5 on 34614] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/1b746f8b-3ba7-46c0-88f8-8a236f5c85a1
2019-09-24 06:45:22,056 [IPC Server handler 5 on 34614] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:45:22,160 [IPC Server handler 2 on 34614] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c7182883-8de4-4c00-9645-5e46eefe0720
2019-09-24 06:45:22,160 [IPC Server handler 2 on 34614] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c7182883-8de4-4c00-9645-5e46eefe0720{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:45:22,252 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-24 06:45:22,253 [IPC Server handler 0 on 34614] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:45:22,253 [IPC Server handler 0 on 34614] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 21edc98c-4e3e-4966-bece-df5609ac098e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 06:45:22,489 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: addNew group-B70F5077003C:[25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740] returns group-B70F5077003C:java.util.concurrent.CompletableFuture@1e22283e[Not completed]
2019-09-24 06:45:22,513 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: new RaftServerImpl for group-B70F5077003C:[25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740] with ContainerStateMachine:uninitialized
2019-09-24 06:45:22,515 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:22,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:22,517 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:22,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:22,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:22,530 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: ConfigurationManager, init=-1: [25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:22,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis] (custom)
2019-09-24 06:45:22,539 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis/8ff6e278-6670-471f-ae9f-b70f5077003c does not exist. Creating ...
2019-09-24 06:45:22,566 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis/8ff6e278-6670-471f-ae9f-b70f5077003c/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:22,582 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis/8ff6e278-6670-471f-ae9f-b70f5077003c has been successfully formatted.
2019-09-24 06:45:22,584 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-B70F5077003C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:22,585 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:22,587 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:22,595 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:22,595 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:22,598 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:22,604 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:22,611 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis/8ff6e278-6670-471f-ae9f-b70f5077003c
2019-09-24 06:45:22,612 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-24 06:45:22,620 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-24 06:45:22,654 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:22,654 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:22,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:22,658 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:22,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:22,659 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:22,660 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:22,661 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:22,661 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:22,672 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:22,677 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:22,681 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:22,682 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:22,683 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:22,683 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:22,710 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: start as a follower, conf=-1: [25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740], old=null
2019-09-24 06:45:22,711 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:22,712 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: start FollowerState
2019-09-24 06:45:22,713 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B70F5077003C,id=25c32c4e-7edd-46c0-8321-2a409aa68b7d
2019-09-24 06:45:22,789 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8ff6e278-6670-471f-ae9f-b70f5077003c, Nodes: 25c32c4e-7edd-46c0-8321-2a409aa68b7d{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:45:22,814 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7182883-8de4-4c00-9645-5e46eefe0720: addNew group-AB090D14355A:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998] returns group-AB090D14355A:java.util.concurrent.CompletableFuture@404eaed0[Not completed]
2019-09-24 06:45:22,861 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c7182883-8de4-4c00-9645-5e46eefe0720: new RaftServerImpl for group-AB090D14355A:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998] with ContainerStateMachine:uninitialized
2019-09-24 06:45:22,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:22,862 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:22,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:22,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:22,863 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:22,863 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: ConfigurationManager, init=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:22,864 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis] (custom)
2019-09-24 06:45:22,865 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/12d582f9-a672-444b-a689-ab090d14355a does not exist. Creating ...
2019-09-24 06:45:22,879 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/12d582f9-a672-444b-a689-ab090d14355a/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:22,894 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/12d582f9-a672-444b-a689-ab090d14355a has been successfully formatted.
2019-09-24 06:45:22,895 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-AB090D14355A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:22,896 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:22,897 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:22,898 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/12d582f9-a672-444b-a689-ab090d14355a
2019-09-24 06:45:22,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:22,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:22,906 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:22,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:22,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:22,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:22,907 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:22,908 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:22,908 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:22,908 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:22,909 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:22,909 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:22,909 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:22,910 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:22,910 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:22,916 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: start as a follower, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998], old=null
2019-09-24 06:45:22,917 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:22,917 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start FollowerState
2019-09-24 06:45:22,919 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AB090D14355A,id=c7182883-8de4-4c00-9645-5e46eefe0720
2019-09-24 06:45:22,934 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 12d582f9-a672-444b-a689-ab090d14355a, Nodes: c7182883-8de4-4c00-9645-5e46eefe0720{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:45:22,954 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 21edc98c-4e3e-4966-bece-df5609ac098e: addNew group-064F578204D0:[21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] returns group-064F578204D0:java.util.concurrent.CompletableFuture@58efd101[Not completed]
2019-09-24 06:45:22,971 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 21edc98c-4e3e-4966-bece-df5609ac098e: new RaftServerImpl for group-064F578204D0:[21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] with ContainerStateMachine:uninitialized
2019-09-24 06:45:22,971 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:22,971 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:22,972 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:22,972 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:22,972 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:22,972 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: ConfigurationManager, init=-1: [21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:22,973 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis] (custom)
2019-09-24 06:45:22,973 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/458ea373-266c-4bca-b097-064f578204d0 does not exist. Creating ...
2019-09-24 06:45:23,010 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/458ea373-266c-4bca-b097-064f578204d0/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,023 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/458ea373-266c-4bca-b097-064f578204d0 has been successfully formatted.
2019-09-24 06:45:23,024 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-064F578204D0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,024 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,024 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,024 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,024 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,025 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,025 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,025 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/458ea373-266c-4bca-b097-064f578204d0
2019-09-24 06:45:23,067 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,070 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,070 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,070 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,070 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,071 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,075 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: start as a follower, conf=-1: [21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:23,075 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,075 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start FollowerState
2019-09-24 06:45:23,076 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-064F578204D0,id=21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:45:23,090 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 458ea373-266c-4bca-b097-064f578204d0, Nodes: 21edc98c-4e3e-4966-bece-df5609ac098e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:45:23,113 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: addNew group-27D7C8C64E49:[dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354] returns group-27D7C8C64E49:java.util.concurrent.CompletableFuture@1dce9b9b[Not completed]
2019-09-24 06:45:23,115 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: new RaftServerImpl for group-27D7C8C64E49:[dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354] with ContainerStateMachine:uninitialized
2019-09-24 06:45:23,116 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:23,116 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:23,116 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:23,116 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:23,116 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:23,117 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: ConfigurationManager, init=-1: [dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:23,117 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis] (custom)
2019-09-24 06:45:23,118 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f71bd3df-3a09-46ff-a0fc-27d7c8c64e49 does not exist. Creating ...
2019-09-24 06:45:23,130 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f71bd3df-3a09-46ff-a0fc-27d7c8c64e49/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,143 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f71bd3df-3a09-46ff-a0fc-27d7c8c64e49 has been successfully formatted.
2019-09-24 06:45:23,143 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-27D7C8C64E49: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,144 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,145 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,145 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f71bd3df-3a09-46ff-a0fc-27d7c8c64e49
2019-09-24 06:45:23,150 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,150 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,150 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,150 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,151 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,152 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,152 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,152 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,153 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,159 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: start as a follower, conf=-1: [dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354], old=null
2019-09-24 06:45:23,159 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,159 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start FollowerState
2019-09-24 06:45:23,160 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-27D7C8C64E49,id=dd9ea8fb-5fab-438f-82e2-b2f2116100d9
2019-09-24 06:45:23,173 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f71bd3df-3a09-46ff-a0fc-27d7c8c64e49, Nodes: dd9ea8fb-5fab-438f-82e2-b2f2116100d9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:45:23,202 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: addNew group-57D8AED34546:[1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615] returns group-57D8AED34546:java.util.concurrent.CompletableFuture@65c85858[Not completed]
2019-09-24 06:45:23,207 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: new RaftServerImpl for group-57D8AED34546:[1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615] with ContainerStateMachine:uninitialized
2019-09-24 06:45:23,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:23,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:23,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:23,208 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:23,209 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:23,209 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: ConfigurationManager, init=-1: [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:23,209 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis] (custom)
2019-09-24 06:45:23,209 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis/603386e7-1b09-4cfb-9dd6-57d8aed34546 does not exist. Creating ...
2019-09-24 06:45:23,223 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis/603386e7-1b09-4cfb-9dd6-57d8aed34546/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,243 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis/603386e7-1b09-4cfb-9dd6-57d8aed34546 has been successfully formatted.
2019-09-24 06:45:23,244 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-57D8AED34546: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,244 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,244 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,244 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,245 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,245 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,245 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,245 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis/603386e7-1b09-4cfb-9dd6-57d8aed34546
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,249 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,250 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,250 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,250 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,250 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,250 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,251 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,251 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,251 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,251 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,253 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-24 06:45:23,254 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: start as a follower, conf=-1: [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615], old=null
2019-09-24 06:45:23,254 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,254 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: start FollowerState
2019-09-24 06:45:23,255 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-57D8AED34546,id=1b746f8b-3ba7-46c0-88f8-8a236f5c85a1
2019-09-24 06:45:23,267 [main] INFO  freon.TestDataValidate (TestDataValidateWithDummyContainers.java:validateWriteTest(64)) - Skipping validateWriteTest for non-persistent containers.
2019-09-24 06:45:23,272 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 603386e7-1b09-4cfb-9dd6-57d8aed34546, Nodes: 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 06:45:23,282 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-24 06:45:23,337 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 21edc98c-4e3e-4966-bece-df5609ac098e: addNew group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] returns group-20F90CBF37B0:java.util.concurrent.CompletableFuture@33e6278[Not completed]
2019-09-24 06:45:23,337 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7182883-8de4-4c00-9645-5e46eefe0720: addNew group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] returns group-20F90CBF37B0:java.util.concurrent.CompletableFuture@3d11439f[Not completed]
2019-09-24 06:45:23,337 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: addNew group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] returns group-20F90CBF37B0:java.util.concurrent.CompletableFuture@536370f[Not completed]
2019-09-24 06:45:23,340 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c7182883-8de4-4c00-9645-5e46eefe0720: new RaftServerImpl for group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] with ContainerStateMachine:uninitialized
2019-09-24 06:45:23,341 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:23,341 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:23,341 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:23,341 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:23,341 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:23,342 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: ConfigurationManager, init=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:23,342 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis] (custom)
2019-09-24 06:45:23,342 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: new RaftServerImpl for group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] with ContainerStateMachine:uninitialized
2019-09-24 06:45:23,342 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:23,342 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 does not exist. Creating ...
2019-09-24 06:45:23,343 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:23,343 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:23,343 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 21edc98c-4e3e-4966-bece-df5609ac098e: new RaftServerImpl for group-20F90CBF37B0:[c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664] with ContainerStateMachine:uninitialized
2019-09-24 06:45:23,343 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:23,343 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 06:45:23,343 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:23,344 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 06:45:23,344 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: ConfigurationManager, init=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:23,344 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 06:45:23,344 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 06:45:23,344 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis] (custom)
2019-09-24 06:45:23,344 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:23,345 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: ConfigurationManager, init=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null, confs=<EMPTY_MAP>
2019-09-24 06:45:23,345 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 does not exist. Creating ...
2019-09-24 06:45:23,345 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis] (custom)
2019-09-24 06:45:23,345 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 does not exist. Creating ...
2019-09-24 06:45:23,369 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,369 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,369 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/in_use.lock acquired by nodename 17851@pr-hdds-2162-tjkd5-3209850126
2019-09-24 06:45:23,383 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 has been successfully formatted.
2019-09-24 06:45:23,383 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 has been successfully formatted.
2019-09-24 06:45:23,383 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0 has been successfully formatted.
2019-09-24 06:45:23,383 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-20F90CBF37B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,384 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-20F90CBF37B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,384 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-20F90CBF37B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 06:45:23,384 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,384 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 06:45:23,384 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,384 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,385 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,384 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 06:45:23,385 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,385 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,385 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,385 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 06:45:23,385 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0
2019-09-24 06:45:23,385 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,385 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,385 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:23,386 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,386 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,386 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,386 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,386 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,386 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 06:45:23,387 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,387 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0
2019-09-24 06:45:23,387 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,387 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0
2019-09-24 06:45:23,387 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,387 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,387 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,387 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 06:45:23,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,388 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 06:45:23,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,388 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 06:45:23,388 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,389 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,388 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 06:45:23,389 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,389 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 06:45:23,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,389 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 06:45:23,389 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,389 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 06:45:23,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,390 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 06:45:23,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,390 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 06:45:23,390 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,391 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 06:45:23,391 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,391 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 06:45:23,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 06:45:23,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 06:45:23,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,392 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 06:45:23,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,393 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 06:45:23,393 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: start as a follower, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:23,393 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,393 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start FollowerState
2019-09-24 06:45:23,394 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:45:23,408 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: start as a follower, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:23,408 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,408 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: start as a follower, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:23,408 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start FollowerState
2019-09-24 06:45:23,409 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 06:45:23,409 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start FollowerState
2019-09-24 06:45:23,409 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=dd9ea8fb-5fab-438f-82e2-b2f2116100d9
2019-09-24 06:45:23,409 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=c7182883-8de4-4c00-9645-5e46eefe0720
2019-09-24 06:45:23,429 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f6f8e412-637b-497c-8f9a-20f90cbf37b0, Nodes: c7182883-8de4-4c00-9645-5e46eefe0720{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}21edc98c-4e3e-4966-bece-df5609ac098e{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}dd9ea8fb-5fab-438f-82e2-b2f2116100d9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 06:45:24,570 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:24,910 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-24 06:45:24,915 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-24 06:45:25,572 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:26,573 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:27,574 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:27,735 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(106)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d:group-B70F5077003C changes to CANDIDATE, lastRpcTime:5023, electionTimeout:5022ms
2019-09-24 06:45:27,737 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: shutdown FollowerState
2019-09-24 06:45:27,738 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:27,745 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: start LeaderElection
2019-09-24 06:45:27,765 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1: begin an election at term 1 for -1: [25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740], old=null
2019-09-24 06:45:27,768 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: shutdown LeaderElection
2019-09-24 06:45:27,768 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:45:27,769 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: change Leader from null to 25c32c4e-7edd-46c0-8321-2a409aa68b7d at term 1 for becomeLeader, leader elected after 5184ms
2019-09-24 06:45:27,783 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:27,783 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:27,787 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:27,791 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:27,791 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:27,792 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:27,813 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: start LeaderState
2019-09-24 06:45:27,838 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:27,846 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: set configuration 0: [25c32c4e-7edd-46c0-8321-2a409aa68b7d:192.168.151.121:36740], old=null at 0
2019-09-24 06:45:28,050 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/ratis/8ff6e278-6670-471f-ae9f-b70f5077003c/current/log_inprogress_0
2019-09-24 06:45:28,077 [Thread-213] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7182883-8de4-4c00-9645-5e46eefe0720:group-AB090D14355A changes to CANDIDATE, lastRpcTime:5160, electionTimeout:5159ms
2019-09-24 06:45:28,080 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown FollowerState
2019-09-24 06:45:28,080 [Thread-213] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,080 [Thread-213] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start LeaderElection
2019-09-24 06:45:28,096 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2: begin an election at term 1 for -1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998], old=null
2019-09-24 06:45:28,098 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown LeaderElection
2019-09-24 06:45:28,098 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:45:28,098 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: change Leader from null to c7182883-8de4-4c00-9645-5e46eefe0720 at term 1 for becomeLeader, leader elected after 5202ms
2019-09-24 06:45:28,100 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:28,100 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:28,100 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:28,101 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:28,101 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:28,101 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:28,105 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start LeaderState
2019-09-24 06:45:28,105 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:28,106 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: set configuration 0: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998], old=null at 0
2019-09-24 06:45:28,168 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/12d582f9-a672-444b-a689-ab090d14355a/current/log_inprogress_0
2019-09-24 06:45:28,210 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9:group-27D7C8C64E49 changes to CANDIDATE, lastRpcTime:5050, electionTimeout:5050ms
2019-09-24 06:45:28,210 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown FollowerState
2019-09-24 06:45:28,210 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,211 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start LeaderElection
2019-09-24 06:45:28,227 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3: begin an election at term 1 for -1: [dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354], old=null
2019-09-24 06:45:28,227 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown LeaderElection
2019-09-24 06:45:28,227 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:45:28,228 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: change Leader from null to dd9ea8fb-5fab-438f-82e2-b2f2116100d9 at term 1 for becomeLeader, leader elected after 5084ms
2019-09-24 06:45:28,229 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:28,229 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:28,230 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:28,230 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:28,230 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:28,230 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:28,234 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start LeaderState
2019-09-24 06:45:28,235 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:28,235 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: set configuration 0: [dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354], old=null at 0
2019-09-24 06:45:28,274 [Thread-216] INFO  impl.FollowerState (FollowerState.java:run(106)) - 21edc98c-4e3e-4966-bece-df5609ac098e:group-064F578204D0 changes to CANDIDATE, lastRpcTime:5198, electionTimeout:5189ms
2019-09-24 06:45:28,275 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown FollowerState
2019-09-24 06:45:28,275 [Thread-216] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,277 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:group-57D8AED34546 changes to CANDIDATE, lastRpcTime:5022, electionTimeout:5021ms
2019-09-24 06:45:28,277 [Thread-216] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start LeaderElection
2019-09-24 06:45:28,277 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: shutdown FollowerState
2019-09-24 06:45:28,277 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,279 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: start LeaderElection
2019-09-24 06:45:28,286 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f71bd3df-3a09-46ff-a0fc-27d7c8c64e49/current/log_inprogress_0
2019-09-24 06:45:28,301 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5: begin an election at term 1 for -1: [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615], old=null
2019-09-24 06:45:28,301 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4: begin an election at term 1 for -1: [21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,301 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: shutdown LeaderElection
2019-09-24 06:45:28,301 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown LeaderElection
2019-09-24 06:45:28,301 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:45:28,302 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 06:45:28,302 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: change Leader from null to 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1 at term 1 for becomeLeader, leader elected after 5057ms
2019-09-24 06:45:28,302 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: change Leader from null to 21edc98c-4e3e-4966-bece-df5609ac098e at term 1 for becomeLeader, leader elected after 5277ms
2019-09-24 06:45:28,303 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:28,305 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:28,305 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:28,305 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:28,307 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:28,307 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:28,307 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:28,307 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:28,308 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:28,308 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:28,308 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:28,308 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:28,313 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: start LeaderState
2019-09-24 06:45:28,313 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:28,313 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start LeaderState
2019-09-24 06:45:28,314 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:28,314 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: set configuration 0: [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1:192.168.151.121:34615], old=null at 0
2019-09-24 06:45:28,356 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: set configuration 0: [21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null at 0
2019-09-24 06:45:28,398 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/ratis/603386e7-1b09-4cfb-9dd6-57d8aed34546/current/log_inprogress_0
2019-09-24 06:45:28,410 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/458ea373-266c-4bca-b097-064f578204d0/current/log_inprogress_0
2019-09-24 06:45:28,552 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9:group-20F90CBF37B0 changes to CANDIDATE, lastRpcTime:5143, electionTimeout:5143ms
2019-09-24 06:45:28,553 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown FollowerState
2019-09-24 06:45:28,553 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,553 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start LeaderElection
2019-09-24 06:45:28,567 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 21edc98c-4e3e-4966-bece-df5609ac098e:group-20F90CBF37B0 changes to CANDIDATE, lastRpcTime:5173, electionTimeout:5173ms
2019-09-24 06:45:28,567 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown FollowerState
2019-09-24 06:45:28,568 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,568 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start LeaderElection
2019-09-24 06:45:28,572 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6: begin an election at term 1 for -1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,576 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:28,590 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7: begin an election at term 1 for -1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,609 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7182883-8de4-4c00-9645-5e46eefe0720:group-20F90CBF37B0 changes to CANDIDATE, lastRpcTime:5198, electionTimeout:5197ms
2019-09-24 06:45:28,609 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown FollowerState
2019-09-24 06:45:28,610 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 06:45:28,610 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start LeaderElection
2019-09-24 06:45:28,628 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8: begin an election at term 1 for -1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,658 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6: Election REJECTED; received 2 response(s) [dd9ea8fb-5fab-438f-82e2-b2f2116100d9<-c7182883-8de4-4c00-9645-5e46eefe0720#0:FAIL-t1, dd9ea8fb-5fab-438f-82e2-b2f2116100d9<-21edc98c-4e3e-4966-bece-df5609ac098e#0:FAIL-t1] and 0 exception(s); dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:t1, leader=null, voted=dd9ea8fb-5fab-438f-82e2-b2f2116100d9, raftlog=dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,658 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7: Election REJECTED; received 2 response(s) [21edc98c-4e3e-4966-bece-df5609ac098e<-c7182883-8de4-4c00-9645-5e46eefe0720#0:FAIL-t1, 21edc98c-4e3e-4966-bece-df5609ac098e<-dd9ea8fb-5fab-438f-82e2-b2f2116100d9#0:FAIL-t1] and 0 exception(s); 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:t1, leader=null, voted=21edc98c-4e3e-4966-bece-df5609ac098e, raftlog=21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,660 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-24 06:45:28,662 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-24 06:45:28,664 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown LeaderElection
2019-09-24 06:45:28,664 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown LeaderElection
2019-09-24 06:45:28,664 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start FollowerState
2019-09-24 06:45:28,665 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start FollowerState
2019-09-24 06:45:28,677 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8: Election REJECTED; received 2 response(s) [c7182883-8de4-4c00-9645-5e46eefe0720<-dd9ea8fb-5fab-438f-82e2-b2f2116100d9#0:FAIL-t1, c7182883-8de4-4c00-9645-5e46eefe0720<-21edc98c-4e3e-4966-bece-df5609ac098e#0:FAIL-t1] and 0 exception(s); c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:t1, leader=null, voted=c7182883-8de4-4c00-9645-5e46eefe0720, raftlog=c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:28,677 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-24 06:45:28,677 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown LeaderElection
2019-09-24 06:45:28,680 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start FollowerState
2019-09-24 06:45:29,578 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:30,580 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:31,582 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:32,583 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:33,585 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:33,668 [Thread-255] INFO  impl.FollowerState (FollowerState.java:run(106)) - 21edc98c-4e3e-4966-bece-df5609ac098e:group-20F90CBF37B0 changes to CANDIDATE, lastRpcTime:5002, electionTimeout:5000ms
2019-09-24 06:45:33,668 [Thread-255] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown FollowerState
2019-09-24 06:45:33,669 [Thread-255] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-09-24 06:45:33,669 [Thread-255] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start LeaderElection
2019-09-24 06:45:33,698 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9: begin an election at term 2 for -1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:33,709 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:45:33,709 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:45:33,709 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown FollowerState
2019-09-24 06:45:33,709 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown FollowerState
2019-09-24 06:45:33,710 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7182883-8de4-4c00-9645-5e46eefe0720: start FollowerState
2019-09-24 06:45:33,710 [Thread-254] INFO  impl.FollowerState (FollowerState.java:run(115)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:45:33,710 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: start FollowerState
2019-09-24 06:45:33,710 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(115)) - c7182883-8de4-4c00-9645-5e46eefe0720: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:45:33,740 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9: Election PASSED; received 1 response(s) [21edc98c-4e3e-4966-bece-df5609ac098e<-dd9ea8fb-5fab-438f-82e2-b2f2116100d9#0:OK-t2] and 0 exception(s); 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:t2, leader=null, voted=21edc98c-4e3e-4966-bece-df5609ac098e, raftlog=21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null
2019-09-24 06:45:33,740 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown LeaderElection
2019-09-24 06:45:33,742 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-09-24 06:45:33,742 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: change Leader from null to 21edc98c-4e3e-4966-bece-df5609ac098e at term 2 for becomeLeader, leader elected after 10358ms
2019-09-24 06:45:33,742 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 06:45:33,743 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 06:45:33,743 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 06:45:33,743 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 06:45:33,743 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 06:45:33,744 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 06:45:33,752 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 06:45:33,752 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:33,753 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 06:45:33,758 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 06:45:33,766 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:33,766 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:33,768 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 06:45:33,768 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 06:45:33,768 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 06:45:33,768 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 06:45:33,769 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 06:45:33,769 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 06:45:33,773 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e: start LeaderState
2019-09-24 06:45:33,774 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:33,775 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: set configuration 0: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null at 0
2019-09-24 06:45:33,830 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/current/log_inprogress_0
2019-09-24 06:45:33,849 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: change Leader from null to 21edc98c-4e3e-4966-bece-df5609ac098e at term 2 for appendEntries, leader elected after 10464ms
2019-09-24 06:45:33,849 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: change Leader from null to 21edc98c-4e3e-4966-bece-df5609ac098e at term 2 for appendEntries, leader elected after 10464ms
2019-09-24 06:45:33,896 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: set configuration 0: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null at 0
2019-09-24 06:45:33,896 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: set configuration 0: [c7182883-8de4-4c00-9645-5e46eefe0720:192.168.151.121:32998, dd9ea8fb-5fab-438f-82e2-b2f2116100d9:192.168.151.121:41354, 21edc98c-4e3e-4966-bece-df5609ac098e:192.168.151.121:42664], old=null at 0
2019-09-24 06:45:33,897 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:33,897 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 06:45:33,947 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/current/log_inprogress_0
2019-09-24 06:45:33,947 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/ratis/f6f8e412-637b-497c-8f9a-20f90cbf37b0/current/log_inprogress_0
2019-09-24 06:45:34,592 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:35,594 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:36,595 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:37,597 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:38,598 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:39,600 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:40,602 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:41,603 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:42,605 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:43,606 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:43,608 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 06:45:44,609 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:45,611 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:46,613 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:47,614 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:48,616 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:49,617 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:50,619 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:51,620 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:52,622 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:53,623 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:53,625 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 06:45:54,626 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:55,628 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:56,629 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:57,630 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:58,631 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:45:59,632 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:00,634 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:01,635 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:02,637 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:03,638 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:03,640 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 06:46:04,642 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:05,643 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:06,645 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:07,647 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:08,649 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:09,650 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:10,651 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:11,653 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:12,654 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:13,656 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:13,658 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 06:46:14,659 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:15,660 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:16,662 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:17,664 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:18,665 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:19,667 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:20,668 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:21,669 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:22,671 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:23,672 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:23,674 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 06:46:24,674 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:25,676 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:26,677 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:27,678 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:28,680 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:29,681 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:30,682 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:31,683 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:32,685 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:33,686 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:33,688 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 06:46:34,689 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:35,690 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:36,692 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:37,693 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:38,694 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:39,696 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:40,697 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:41,699 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:42,700 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:43,702 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:43,703 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 06:46:44,705 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:45,706 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:46,708 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:47,709 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:48,710 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:49,712 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:50,714 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:51,715 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:52,717 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:53,718 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:53,720 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 06:46:54,721 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:55,722 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:56,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:57,725 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:58,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:46:59,728 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:00,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:01,732 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:02,734 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:03,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:03,737 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 06:47:04,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:05,740 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:06,741 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:07,743 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:08,744 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:09,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:10,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:11,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:12,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:13,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:13,753 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 06:47:13,757 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-24 06:47:13,778 [main] INFO  freon.RandomKeyGenerator (RandomKeyGenerator.java:call(258)) - Override validateWrites to false, because hdds.container.chunk.persistdata is set to false.
2019-09-24 06:47:14,782 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:15,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:16,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:17,786 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:18,788 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:19,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:20,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:21,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:22,793 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:23,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:24,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:25,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:26,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:27,803 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:28,805 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:29,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:30,807 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:31,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:32,810 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:33,811 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:33,813 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 06:47:34,814 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:35,816 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:36,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:37,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:38,819 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:39,820 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:40,822 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:41,823 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:42,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:43,826 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:43,828 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 06:47:44,829 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:45,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:46,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:47,834 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:48,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:49,837 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:50,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:51,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:52,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:53,842 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:53,844 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 06:47:54,847 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:55,848 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:56,849 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:57,851 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:58,852 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:47:59,853 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:00,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:01,855 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:02,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:03,858 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:03,860 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 06:48:04,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:05,863 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:06,864 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:07,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:08,867 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:09,869 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:10,870 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:11,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:12,872 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:13,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:13,875 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 06:48:14,876 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:15,877 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:16,879 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:17,880 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:18,881 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:19,882 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:20,884 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:21,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:22,886 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:23,887 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:23,889 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 06:48:24,901 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:25,905 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:26,906 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:27,908 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:28,909 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:29,910 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:30,912 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:31,914 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:32,915 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:33,916 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:33,918 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 06:48:34,919 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:35,922 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:36,924 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:37,925 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:38,926 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:39,928 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:40,930 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:41,931 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:42,932 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:43,934 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:43,936 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 06:48:44,937 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:45,939 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:46,940 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:47,941 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:48,943 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:49,944 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:50,945 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:51,947 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:52,948 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:53,950 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:53,951 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 06:48:54,952 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:55,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:56,955 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:57,957 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:58,958 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:48:59,959 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:00,960 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:01,962 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:02,963 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:03,965 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 06:49:03,966 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 06:49:03,967 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-24 06:49:03,971 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-24 06:49:03,972 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-24 06:49:03,972 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-24 06:49:03,972 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41436
2019-09-24 06:49:03,985 [IPC Server listener on 41436] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41436
2019-09-24 06:49:03,994 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-24 06:49:03,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:49:04,003 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-24 06:49:04,019 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-24 06:49:04,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27fde870{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-24 06:49:04,033 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b4c3c29{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:04,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@529cfee5{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:04,035 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7df60067{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:04,042 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-24 06:49:04,080 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:49:04,976 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:49:09,045 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:49:09,045 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:49:09,047 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: close
2019-09-24 06:49:09,047 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: close
2019-09-24 06:49:09,050 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: shutdown
2019-09-24 06:49:09,050 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: shutdown
2019-09-24 06:49:09,051 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-57D8AED34546,id=1b746f8b-3ba7-46c0-88f8-8a236f5c85a1
2019-09-24 06:49:09,051 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=dd9ea8fb-5fab-438f-82e2-b2f2116100d9
2019-09-24 06:49:09,051 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: shutdown LeaderState
2019-09-24 06:49:09,051 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown FollowerState
2019-09-24 06:49:09,052 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:09,052 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(115)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:49:09,055 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:09,057 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0: closes. applyIndex: 0
2019-09-24 06:49:09,059 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:09,063 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546: closes. applyIndex: 0
2019-09-24 06:49:09,063 [1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:09,063 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:09,066 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-20F90CBF37B0-SegmentedRaftLogWorker close()
2019-09-24 06:49:09,066 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1@group-57D8AED34546-SegmentedRaftLogWorker close()
2019-09-24 06:49:09,070 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: shutdown
2019-09-24 06:49:09,072 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-27D7C8C64E49,id=dd9ea8fb-5fab-438f-82e2-b2f2116100d9
2019-09-24 06:49:09,072 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown LeaderState
2019-09-24 06:49:09,072 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: shutdown server with port 34615 now
2019-09-24 06:49:09,073 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:09,075 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:09,082 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49: closes. applyIndex: 0
2019-09-24 06:49:09,084 [dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:09,085 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9@group-27D7C8C64E49-SegmentedRaftLogWorker close()
2019-09-24 06:49:09,089 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown server with port 41354 now
2019-09-24 06:49:09,089 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 1b746f8b-3ba7-46c0-88f8-8a236f5c85a1: shutdown server with port 34615 successfully
2019-09-24 06:49:09,101 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: installSnapshot onError, lastRequest: 21edc98c-4e3e-4966-bece-df5609ac098e->dd9ea8fb-5fab-438f-82e2-b2f2116100d9#86-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-24 06:49:09,103 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - dd9ea8fb-5fab-438f-82e2-b2f2116100d9: shutdown server with port 41354 successfully
2019-09-24 06:49:09,524 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-09-24 06:49:09,530 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:49:09,531 [grpc-default-executor-5] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9: nextIndex: updateUnconditionally 1 -> 0
Sep 24, 2019 6:49:09 AM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed@7c8ba29d
org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: call already cancelled
	at org.apache.ratis.thirdparty.io.grpc.Status.asRuntimeException(Status.java:517)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:356)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onError(GrpcServerProtocolService.java:121)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onCancel(ServerCalls.java:269)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.closed(ServerCallImpl.java:293)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1Closed.runInContext(ServerImpl.java:741)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2019-09-24 06:49:09,535 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:49:09,562 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:49:09,562 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:49:09,567 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:49:09,570 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:49:09,572 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e7c141d{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:49:09,573 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5624657a{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:49:09,574 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@43af351a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:09,574 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74174a23{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:09,574 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@36681447{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:09,575 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@118ffcfd{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:09,576 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2924f1d8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:09,578 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:09,599 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 06:49:09,602 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 06:49:09,872 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:49:10,510 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:49:12,096 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 06:49:12,105 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 06:49:14,580 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:49:14,581 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:49:14,581 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 21edc98c-4e3e-4966-bece-df5609ac098e: close
2019-09-24 06:49:14,582 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: close
2019-09-24 06:49:14,582 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: shutdown
2019-09-24 06:49:14,582 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: shutdown
2019-09-24 06:49:14,583 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-064F578204D0,id=21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:49:14,583 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B70F5077003C,id=25c32c4e-7edd-46c0-8321-2a409aa68b7d
2019-09-24 06:49:14,583 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown LeaderState
2019-09-24 06:49:14,584 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: shutdown LeaderState
2019-09-24 06:49:14,584 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 21edc98c-4e3e-4966-bece-df5609ac098e-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:14,584 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:14,585 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:14,585 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:14,586 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0: closes. applyIndex: 0
2019-09-24 06:49:14,586 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C: closes. applyIndex: 0
2019-09-24 06:49:14,587 [21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:14,587 [25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:14,595 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-064F578204D0-SegmentedRaftLogWorker close()
2019-09-24 06:49:14,595 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d@group-B70F5077003C-SegmentedRaftLogWorker close()
2019-09-24 06:49:14,598 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-09-24 06:49:14,598 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: shutdown
2019-09-24 06:49:14,603 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: shutdown server with port 36740 now
2019-09-24 06:49:14,605 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(51)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9: nextIndex: updateUnconditionally 0 -> 0
2019-09-24 06:49:14,605 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=21edc98c-4e3e-4966-bece-df5609ac098e
2019-09-24 06:49:14,606 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 25c32c4e-7edd-46c0-8321-2a409aa68b7d: shutdown server with port 36740 successfully
2019-09-24 06:49:14,606 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown LeaderState
2019-09-24 06:49:14,610 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 21edc98c-4e3e-4966-bece-df5609ac098e-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:14,610 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$375/398679931@500cbd70] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->dd9ea8fb-5fab-438f-82e2-b2f2116100d9-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 06:49:14,610 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:14,610 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$375/398679931@6a4965b4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->c7182883-8de4-4c00-9645-5e46eefe0720-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 06:49:14,612 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0: closes. applyIndex: 0
2019-09-24 06:49:14,613 [21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:14,614 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0-SegmentedRaftLogWorker close()
2019-09-24 06:49:14,615 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - c7182883-8de4-4c00-9645-5e46eefe0720: Completed APPEND_ENTRIES, lastRequest: 21edc98c-4e3e-4966-bece-df5609ac098e->c7182883-8de4-4c00-9645-5e46eefe0720#89-t2, previous=(t:2, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 06:49:14,618 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown server with port 42664 now
2019-09-24 06:49:14,622 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 21edc98c-4e3e-4966-bece-df5609ac098e: shutdown server with port 42664 successfully
2019-09-24 06:49:14,627 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - 21edc98c-4e3e-4966-bece-df5609ac098e@group-20F90CBF37B0->c7182883-8de4-4c00-9645-5e46eefe0720-GrpcLogAppender is stopped
2019-09-24 06:49:14,628 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:49:14,641 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:49:14,648 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:49:14,652 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:49:14,653 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58fef7f7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:49:14,654 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@31ddb930{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:14,655 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56637cff{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:14,655 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a1c3cb4{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:14,661 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:49:14,664 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:49:14,666 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77774571{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:49:14,667 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@277b8fa4{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:14,668 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6edcad64{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:14,669 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71a06021{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:15,511 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 06:49:19,657 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 06:49:19,658 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c7182883-8de4-4c00-9645-5e46eefe0720: close
2019-09-24 06:49:19,659 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: shutdown
2019-09-24 06:49:19,659 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: shutdown
2019-09-24 06:49:19,660 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-20F90CBF37B0,id=c7182883-8de4-4c00-9645-5e46eefe0720
2019-09-24 06:49:19,660 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AB090D14355A,id=c7182883-8de4-4c00-9645-5e46eefe0720
2019-09-24 06:49:19,660 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown FollowerState
2019-09-24 06:49:19,661 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown LeaderState
2019-09-24 06:49:19,661 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(115)) - c7182883-8de4-4c00-9645-5e46eefe0720: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 06:49:19,661 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:19,663 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0: closes. applyIndex: 0
2019-09-24 06:49:19,661 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c7182883-8de4-4c00-9645-5e46eefe0720-PendingRequests: sendNotLeaderResponses
2019-09-24 06:49:19,664 [c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:19,664 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-StateMachineUpdater: set stopIndex = 0
2019-09-24 06:49:19,665 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-20F90CBF37B0-SegmentedRaftLogWorker close()
2019-09-24 06:49:19,666 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A: closes. applyIndex: 0
2019-09-24 06:49:19,668 [c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 06:49:19,669 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c7182883-8de4-4c00-9645-5e46eefe0720@group-AB090D14355A-SegmentedRaftLogWorker close()
2019-09-24 06:49:19,671 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown server with port 32998 now
2019-09-24 06:49:19,674 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c7182883-8de4-4c00-9645-5e46eefe0720: shutdown server with port 32998 successfully
2019-09-24 06:49:19,680 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-d1845b7f-12e2-4653-bdb9-238a56f2d5eb/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 06:49:19,704 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 06:49:19,708 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 06:49:19,709 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2cae9b8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 06:49:19,710 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1457fde{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:19,711 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73844119{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:19,711 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@350d3f4d{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:19,712 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-24 06:49:19,712 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-24 06:49:19,713 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-24 06:49:19,713 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-24 06:49:19,713 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-24 06:49:19,713 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-24 06:49:19,714 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34614
2019-09-24 06:49:19,716 [IPC Server listener on 34614] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34614
2019-09-24 06:49:19,716 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:49:19,726 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-24 06:49:19,726 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-24 06:49:19,727 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-24 06:49:19,727 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43858
2019-09-24 06:49:19,729 [IPC Server listener on 43858] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43858
2019-09-24 06:49:19,729 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-24 06:49:19,730 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-24 06:49:19,730 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:49:19,730 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42615
2019-09-24 06:49:19,733 [IPC Server listener on 42615] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42615
2019-09-24 06:49:19,733 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-24 06:49:19,733 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 06:49:19,734 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@544630b7{/,null,UNAVAILABLE}{/scm}
2019-09-24 06:49:19,735 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@514eedd8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 06:49:19,736 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44040454{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 06:49:19,736 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44e3a2b2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 06:49:19,737 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-24 06:49:19,737 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 06:49:19,738 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 06:49:19,738 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-24 06:49:19,745 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-24 06:49:19,755 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-24 06:49:19,755 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

2019-09-24 07:03:04,374 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:04,507 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:04,511 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:04,528 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @926ms
2019-09-24 07:03:04,645 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-24 07:03:04,646 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-24 07:03:04,647 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-24 07:03:04,647 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-24 07:03:04,648 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-24 07:03:04,648 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-24 07:03:04,666 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 07:03:04,667 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 07:03:04,669 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 07:03:04,936 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3e694b3f
2019-09-24 07:03:04,938 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-24 07:03:05,028 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 07:03:05,030 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-24 07:03:05,033 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(114)) - Entering startup safe mode.
2019-09-24 07:03:05,113 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(57)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-24 07:03:05,128 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:05,190 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(132)) - No pipeline exists in current db
2019-09-24 07:03:05,193 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:05,306 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(183)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-09-24 07:03:05,733 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 07:03:05,765 [Socket Reader #1 for port 39009] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39009
2019-09-24 07:03:05,921 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 07:03:05,922 [Socket Reader #1 for port 39455] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39455
2019-09-24 07:03:05,932 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 07:03:05,933 [Socket Reader #1 for port 38368] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38368
2019-09-24 07:03:05,960 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-24 07:03:06,099 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:06,115 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:06,125 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:06,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-24 07:03:06,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:06,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:06,157 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(770)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38368
2019-09-24 07:03:06,215 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-24 07:03:06,228 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-24 07:03:06,229 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-24 07:03:06,463 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:38368
2019-09-24 07:03:06,464 [IPC Server listener on 38368] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38368: starting
2019-09-24 07:03:06,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 07:03:06,466 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(780)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39455
2019-09-24 07:03:06,468 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(146)) - RPC server for Block Protocol is listening at /0.0.0.0:39455
2019-09-24 07:03:06,468 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 07:03:06,468 [IPC Server listener on 39455] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39455: starting
2019-09-24 07:03:06,470 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(784)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:39009
2019-09-24 07:03:06,470 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:39009
2019-09-24 07:03:06,471 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 07:03:06,471 [IPC Server listener on 39009] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39009: starting
2019-09-24 07:03:06,474 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35886
2019-09-24 07:03:06,476 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:06,510 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:06,511 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:06,584 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9573b3b{/,file:///tmp/jetty-0.0.0.0-35886-scm-_-any-1809493818674176135.dir/webapp/,AVAILABLE}{/scm}
2019-09-24 07:03:06,589 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:35886}
2019-09-24 07:03:06,589 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2988ms
2019-09-24 07:03:06,591 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2019-09-24 07:03:06,592 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2019-09-24 07:03:06,595 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of SCM is listening at http://0.0.0.0:35886
2019-09-24 07:03:06,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3670f00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:06,607 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:06,726 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(138)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-24 07:03:06,727 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-address with value of key ozone.om.http-address: 127.0.0.1:0
2019-09-24 07:03:06,727 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-address with value of key ozone.om.https-address: 0.0.0.0:9875
2019-09-24 07:03:06,727 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http-bind-host with value of key ozone.om.http-bind-host: 0.0.0.0
2019-09-24 07:03:06,727 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.https-bind-host with value of key ozone.om.https-bind-host: 0.0.0.0
2019-09-24 07:03:06,728 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.keytab with value of key ozone.om.http.kerberos.keytab: /etc/security/keytabs/HTTP.keytab
2019-09-24 07:03:06,728 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.http.kerberos.principal with value of key ozone.om.http.kerberos.principal: HTTP/_HOST@EXAMPLE.COM
2019-09-24 07:03:06,728 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:setOMNodeSpecificConfigs(240)) - Setting configuration key ozone.om.address with value of key ozone.om.address: 127.0.0.1:0
2019-09-24 07:03:06,728 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(192)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-24 07:03:06,729 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:06,730 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:07,508 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-24 07:03:07,516 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-24 07:03:07,517 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-24 07:03:07,517 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-24 07:03:07,517 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-24 07:03:07,518 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-24 07:03:07,518 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-24 07:03:07,518 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-24 07:03:07,518 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-24 07:03:07,519 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-24 07:03:07,519 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-24 07:03:07,519 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-24 07:03:07,519 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-24 07:03:07,519 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-24 07:03:07,520 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-24 07:03:07,520 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-24 07:03:07,520 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-24 07:03:07,520 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-24 07:03:07,521 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-24 07:03:07,521 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-24 07:03:07,521 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-24 07:03:07,521 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-24 07:03:07,522 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-24 07:03:07,522 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-24 07:03:07,522 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-24 07:03:07,522 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-24 07:03:08,005 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-24 07:03:08,006 [Socket Reader #1 for port 45362] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45362
2019-09-24 07:03:08,035 [main] INFO  om.OzoneManager (OzoneManager.java:start(1075)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45362
2019-09-24 07:03:08,035 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-24 07:03:08,037 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-24 07:03:08,037 [IPC Server listener on 45362] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45362: starting
2019-09-24 07:03:08,043 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-24 07:03:08,045 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:08,046 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:08,049 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:08,051 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-24 07:03:08,051 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:08,052 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:08,055 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35804
2019-09-24 07:03:08,055 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:08,058 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:08,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:08,127 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@151335cb{/,file:///tmp/jetty-0.0.0.0-35804-ozoneManager-_-any-631731332329433639.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-24 07:03:08,128 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:35804}
2019-09-24 07:03:08,128 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4527ms
2019-09-24 07:03:08,129 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:08,130 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:35804
2019-09-24 07:03:08,460 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 07:03:08,512 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 07:03:08,547 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 07:03:08,549 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/containers/hdds to VolumeSet
2019-09-24 07:03:08,552 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-24 07:03:08,570 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@ba354ca
2019-09-24 07:03:08,709 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 07:03:08,777 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 07:03:08,783 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 07:03:08,783 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 07:03:08,785 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:08,786 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 07:03:08,786 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:08,953 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis] (custom)
2019-09-24 07:03:09,010 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 07:03:09,016 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:09,018 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:09,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:09,022 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 07:03:09,023 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:09,023 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:09,025 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37542
2019-09-24 07:03:09,026 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:09,029 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:09,030 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:09,073 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d910b3{/,file:///tmp/jetty-0.0.0.0-37542-hddsDatanode-_-any-7500210947341376704.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 07:03:09,075 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:37542}
2019-09-24 07:03:09,075 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5473ms
2019-09-24 07:03:09,076 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:09,077 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37542
2019-09-24 07:03:09,079 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 07:03:09,085 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4ef45780] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:09,087 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 07:03:09,098 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 07:03:09,098 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/containers/hdds to VolumeSet
2019-09-24 07:03:09,099 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-24 07:03:09,100 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3ee0b4f7
2019-09-24 07:03:09,123 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 07:03:09,123 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 07:03:09,124 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 07:03:09,124 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 07:03:09,124 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:09,125 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 07:03:09,125 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:09,126 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis] (custom)
2019-09-24 07:03:09,129 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 07:03:09,131 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:09,132 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:09,135 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:09,136 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 07:03:09,136 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:09,137 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:09,138 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37204
2019-09-24 07:03:09,138 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:09,145 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:09,146 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:09,189 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28da7d11{/,file:///tmp/jetty-0.0.0.0-37204-hddsDatanode-_-any-768822720099443723.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 07:03:09,190 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:37204}
2019-09-24 07:03:09,191 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5589ms
2019-09-24 07:03:09,192 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:09,193 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37204
2019-09-24 07:03:09,194 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 07:03:09,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36edb5a2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:09,201 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 07:03:09,212 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 07:03:09,213 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/containers/hdds to VolumeSet
2019-09-24 07:03:09,213 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-24 07:03:09,214 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@40e37b06
2019-09-24 07:03:09,222 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/meta/datanode.id
2019-09-24 07:03:09,227 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/meta/datanode.id
2019-09-24 07:03:09,240 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 07:03:09,241 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 07:03:09,241 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 07:03:09,241 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 07:03:09,242 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:09,242 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 07:03:09,242 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:09,243 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis] (custom)
2019-09-24 07:03:09,246 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 07:03:09,248 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:09,248 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:09,251 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:09,252 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 07:03:09,252 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:09,252 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:09,253 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38915
2019-09-24 07:03:09,253 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:09,256 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:09,257 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:09,297 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41eb94bc{/,file:///tmp/jetty-0.0.0.0-38915-hddsDatanode-_-any-7281569652427458687.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 07:03:09,298 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:38915}
2019-09-24 07:03:09,299 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5697ms
2019-09-24 07:03:09,299 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:09,301 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38915
2019-09-24 07:03:09,302 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 07:03:09,307 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@587181e7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:09,310 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 07:03:09,312 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/meta/datanode.id
2019-09-24 07:03:09,320 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 07:03:09,320 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/containers/hdds to VolumeSet
2019-09-24 07:03:09,321 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@119aa36
2019-09-24 07:03:09,321 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@119aa36
2019-09-24 07:03:09,344 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 07:03:09,344 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 07:03:09,345 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 07:03:09,345 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 07:03:09,345 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:09,346 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 07:03:09,346 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:09,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis] (custom)
2019-09-24 07:03:09,349 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 07:03:09,350 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:09,351 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:09,352 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:09,353 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 07:03:09,353 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:09,353 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:09,354 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42407
2019-09-24 07:03:09,354 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:09,358 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@715b886f{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:09,359 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e253c9d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:09,387 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a1d3225{/,file:///tmp/jetty-0.0.0.0-42407-hddsDatanode-_-any-1280443400592063089.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 07:03:09,387 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67e13bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:42407}
2019-09-24 07:03:09,388 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5786ms
2019-09-24 07:03:09,388 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:09,389 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42407
2019-09-24 07:03:09,389 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-24 07:03:09,392 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-2162-tjkd5-3209850126 ip:192.168.151.121
2019-09-24 07:03:09,393 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7621adbe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:09,395 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/meta/datanode.id
2019-09-24 07:03:09,400 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-24 07:03:09,400 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/containers/hdds to VolumeSet
2019-09-24 07:03:09,401 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(139)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-24 07:03:09,401 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3bd2af5b
2019-09-24 07:03:09,425 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-24 07:03:09,425 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-24 07:03:09,425 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-24 07:03:09,426 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-24 07:03:09,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:09,426 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-24 07:03:09,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:09,427 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis] (custom)
2019-09-24 07:03:09,429 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-24 07:03:09,431 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-24 07:03:09,433 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-24 07:03:09,435 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-24 07:03:09,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-24 07:03:09,437 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-24 07:03:09,437 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-24 07:03:09,438 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42574
2019-09-24 07:03:09,439 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.25.v20180904, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
2019-09-24 07:03:09,442 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,AVAILABLE}
2019-09-24 07:03:09,443 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-24 07:03:09,488 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6cf0a747{/,file:///tmp/jetty-0.0.0.0-42574-hddsDatanode-_-any-3258579536466954871.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-24 07:03:09,490 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:42574}
2019-09-24 07:03:09,490 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5889ms
2019-09-24 07:03:09,490 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2019-09-24 07:03:09,492 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(215)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42574
2019-09-24 07:03:09,494 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 07:03:09,495 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@49d92aec] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-24 07:03:09,498 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/meta/datanode.id
2019-09-24 07:03:10,495 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 07:03:11,147 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 07:03:11,149 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 07:03:11,149 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c1ba685c-4bc7-4c26-b843-7f4f93713ee9 at port 0
2019-09-24 07:03:11,172 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start RPC server
2019-09-24 07:03:11,215 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 07:03:11,221 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 07:03:11,222 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis 0f09050e-a9d0-40e3-be5f-b91dd40c4695 at port 0
2019-09-24 07:03:11,231 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: start RPC server
2019-09-24 07:03:11,315 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: GrpcService started, listening on 0.0.0.0/0.0.0.0:33276
2019-09-24 07:03:11,315 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: GrpcService started, listening on 0.0.0.0/0.0.0.0:42461
2019-09-24 07:03:11,317 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c1ba685c-4bc7-4c26-b843-7f4f93713ee9 is started using port 33276
2019-09-24 07:03:11,317 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis 0f09050e-a9d0-40e3-be5f-b91dd40c4695 is started using port 42461
2019-09-24 07:03:11,321 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc 0f09050e-a9d0-40e3-be5f-b91dd40c4695 is started using port 46534
2019-09-24 07:03:11,321 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c1ba685c-4bc7-4c26-b843-7f4f93713ee9 is started using port 43012
2019-09-24 07:03:11,324 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 07:03:11,327 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 07:03:11,327 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 at port 0
2019-09-24 07:03:11,337 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start RPC server
2019-09-24 07:03:11,342 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: GrpcService started, listening on 0.0.0.0/0.0.0.0:40795
2019-09-24 07:03:11,342 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 is started using port 40795
2019-09-24 07:03:11,344 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 is started using port 36316
2019-09-24 07:03:11,409 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 07:03:11,412 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 07:03:11,412 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis c007157f-4a68-4110-8a9f-d1661c4fcb31 at port 0
2019-09-24 07:03:11,420 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: start RPC server
2019-09-24 07:03:11,423 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: GrpcService started, listening on 0.0.0.0/0.0.0.0:45795
2019-09-24 07:03:11,423 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis c007157f-4a68-4110-8a9f-d1661c4fcb31 is started using port 45795
2019-09-24 07:03:11,426 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc c007157f-4a68-4110-8a9f-d1661c4fcb31 is started using port 34475
2019-09-24 07:03:11,498 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 07:03:11,517 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(217)) - Attempting to start container services.
2019-09-24 07:03:11,524 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(179)) - Background container scanner has been disabled.
2019-09-24 07:03:11,524 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(411)) - Starting XceiverServerRatis d90dd00f-f61b-415a-a5b1-2ed5656799b5 at port 0
2019-09-24 07:03:11,533 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start RPC server
2019-09-24 07:03:11,537 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: GrpcService started, listening on 0.0.0.0/0.0.0.0:42323
2019-09-24 07:03:11,537 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(421)) - XceiverServerRatis d90dd00f-f61b-415a-a5b1-2ed5656799b5 is started using port 42323
2019-09-24 07:03:11,540 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(149)) - XceiverServerGrpc d90dd00f-f61b-415a-a5b1-2ed5656799b5 is started using port 39249
2019-09-24 07:03:12,499 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-24 07:03:13,133 [IPC Server handler 1 on 39009] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c1ba685c-4bc7-4c26-b843-7f4f93713ee9
2019-09-24 07:03:13,134 [IPC Server handler 1 on 39009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c1ba685c-4bc7-4c26-b843-7f4f93713ee9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 07:03:13,140 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-24 07:03:13,140 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-24 07:03:13,140 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-24 07:03:13,202 [IPC Server handler 3 on 39009] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0f09050e-a9d0-40e3-be5f-b91dd40c4695
2019-09-24 07:03:13,202 [IPC Server handler 3 on 39009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : 0f09050e-a9d0-40e3-be5f-b91dd40c4695{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 07:03:13,312 [IPC Server handler 4 on 39009] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:03:13,312 [IPC Server handler 4 on 39009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 07:03:13,396 [IPC Server handler 2 on 39009] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c007157f-4a68-4110-8a9f-d1661c4fcb31
2019-09-24 07:03:13,397 [IPC Server handler 2 on 39009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : c007157f-4a68-4110-8a9f-d1661c4fcb31{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 07:03:13,499 [IPC Server handler 0 on 39009] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d90dd00f-f61b-415a-a5b1-2ed5656799b5
2019-09-24 07:03:13,499 [IPC Server handler 0 on 39009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(266)) - Registered Data node : d90dd00f-f61b-415a-a5b1-2ed5656799b5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}
2019-09-24 07:03:13,499 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(147)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-09-24 07:03:13,760 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: addNew group-09937AABF206:[c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276] returns group-09937AABF206:java.util.concurrent.CompletableFuture@28acc8ed[Not completed]
2019-09-24 07:03:13,785 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: new RaftServerImpl for group-09937AABF206:[c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276] with ContainerStateMachine:uninitialized
2019-09-24 07:03:13,787 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:13,789 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:13,789 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:13,790 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:13,791 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:13,801 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: ConfigurationManager, init=-1: [c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:13,801 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis] (custom)
2019-09-24 07:03:13,810 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/0bd01567-b142-4067-a82a-09937aabf206 does not exist. Creating ...
2019-09-24 07:03:13,829 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/0bd01567-b142-4067-a82a-09937aabf206/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:13,842 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/0bd01567-b142-4067-a82a-09937aabf206 has been successfully formatted.
2019-09-24 07:03:13,846 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-09937AABF206: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:13,846 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:13,850 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:13,859 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:13,859 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:13,863 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:13,869 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:13,878 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/0bd01567-b142-4067-a82a-09937aabf206
2019-09-24 07:03:13,881 [pool-27-thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - ratis metrics system started (again)
2019-09-24 07:03:13,889 [pool-27-thread-1] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2019-09-24 07:03:13,926 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:13,927 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:13,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:13,931 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:13,932 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:13,932 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:13,933 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:13,933 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:13,934 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:13,945 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:13,950 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:13,954 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:13,955 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:13,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:13,956 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:13,982 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: start as a follower, conf=-1: [c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276], old=null
2019-09-24 07:03:13,983 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:13,984 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start FollowerState
2019-09-24 07:03:13,986 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09937AABF206,id=c1ba685c-4bc7-4c26-b843-7f4f93713ee9
2019-09-24 07:03:14,058 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0bd01567-b142-4067-a82a-09937aabf206, Nodes: c1ba685c-4bc7-4c26-b843-7f4f93713ee9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 07:03:14,081 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: addNew group-36E220DA5F1E:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795] returns group-36E220DA5F1E:java.util.concurrent.CompletableFuture@342530df[Not completed]
2019-09-24 07:03:14,119 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: new RaftServerImpl for group-36E220DA5F1E:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,120 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,121 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,121 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,121 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,121 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,122 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: ConfigurationManager, init=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,122 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis] (custom)
2019-09-24 07:03:14,123 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/45b009bd-5def-4dd7-a575-36e220da5f1e does not exist. Creating ...
2019-09-24 07:03:14,137 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/45b009bd-5def-4dd7-a575-36e220da5f1e/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,150 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/45b009bd-5def-4dd7-a575-36e220da5f1e has been successfully formatted.
2019-09-24 07:03:14,152 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-36E220DA5F1E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,154 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,155 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,155 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/45b009bd-5def-4dd7-a575-36e220da5f1e
2019-09-24 07:03:14,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,163 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,164 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,165 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,165 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,166 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,169 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: start as a follower, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795], old=null
2019-09-24 07:03:14,170 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,170 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start FollowerState
2019-09-24 07:03:14,171 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-36E220DA5F1E,id=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:03:14,190 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 45b009bd-5def-4dd7-a575-36e220da5f1e, Nodes: d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 07:03:14,210 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: addNew group-A0F1E6D6E679:[d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] returns group-A0F1E6D6E679:java.util.concurrent.CompletableFuture@388de01[Not completed]
2019-09-24 07:03:14,235 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: new RaftServerImpl for group-A0F1E6D6E679:[d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,235 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,235 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,236 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,236 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,236 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,236 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: ConfigurationManager, init=-1: [d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,236 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis] (custom)
2019-09-24 07:03:14,237 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/c32855df-b12b-4129-9217-a0f1e6d6e679 does not exist. Creating ...
2019-09-24 07:03:14,250 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/c32855df-b12b-4129-9217-a0f1e6d6e679/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,264 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/c32855df-b12b-4129-9217-a0f1e6d6e679 has been successfully formatted.
2019-09-24 07:03:14,264 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-A0F1E6D6E679: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,264 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,265 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,265 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,265 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,265 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,265 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,266 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/c32855df-b12b-4129-9217-a0f1e6d6e679
2019-09-24 07:03:14,304 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,304 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,304 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,305 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,305 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,305 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,305 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,306 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,307 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,307 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,308 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,308 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,308 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,308 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,314 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: start as a follower, conf=-1: [d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:14,314 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,314 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start FollowerState
2019-09-24 07:03:14,315 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0F1E6D6E679,id=d90dd00f-f61b-415a-a5b1-2ed5656799b5
2019-09-24 07:03:14,326 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c32855df-b12b-4129-9217-a0f1e6d6e679, Nodes: d90dd00f-f61b-415a-a5b1-2ed5656799b5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 07:03:14,345 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: addNew group-70BDF6C6599C:[c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795] returns group-70BDF6C6599C:java.util.concurrent.CompletableFuture@167792dc[Not completed]
2019-09-24 07:03:14,347 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: new RaftServerImpl for group-70BDF6C6599C:[c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,348 [pool-57-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: ConfigurationManager, init=-1: [c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,349 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis] (custom)
2019-09-24 07:03:14,349 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis/eed15e2a-ae77-4c32-87b8-70bdf6c6599c does not exist. Creating ...
2019-09-24 07:03:14,364 [pool-57-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis/eed15e2a-ae77-4c32-87b8-70bdf6c6599c/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,385 [pool-57-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis/eed15e2a-ae77-4c32-87b8-70bdf6c6599c has been successfully formatted.
2019-09-24 07:03:14,386 [pool-57-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-70BDF6C6599C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,386 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,387 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,387 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,387 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,387 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis/eed15e2a-ae77-4c32-87b8-70bdf6c6599c
2019-09-24 07:03:14,391 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,392 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,393 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,393 [pool-57-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,394 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,394 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,394 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,394 [pool-57-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,399 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: start as a follower, conf=-1: [c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795], old=null
2019-09-24 07:03:14,399 [pool-57-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,399 [pool-57-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: start FollowerState
2019-09-24 07:03:14,399 [pool-57-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-70BDF6C6599C,id=c007157f-4a68-4110-8a9f-d1661c4fcb31
2019-09-24 07:03:14,414 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: eed15e2a-ae77-4c32-87b8-70bdf6c6599c, Nodes: c007157f-4a68-4110-8a9f-d1661c4fcb31{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 07:03:14,438 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: addNew group-334338DF872F:[0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461] returns group-334338DF872F:java.util.concurrent.CompletableFuture@4a81d925[Not completed]
2019-09-24 07:03:14,440 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: new RaftServerImpl for group-334338DF872F:[0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,441 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,441 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,441 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,441 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,441 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: ConfigurationManager, init=-1: [0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis] (custom)
2019-09-24 07:03:14,442 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis/0ff2d76c-cd12-4eee-945c-334338df872f does not exist. Creating ...
2019-09-24 07:03:14,455 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis/0ff2d76c-cd12-4eee-945c-334338df872f/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,468 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis/0ff2d76c-cd12-4eee-945c-334338df872f has been successfully formatted.
2019-09-24 07:03:14,469 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-334338DF872F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,469 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,469 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,470 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,470 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,470 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,470 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,471 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis/0ff2d76c-cd12-4eee-945c-334338df872f
2019-09-24 07:03:14,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,475 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,476 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,477 [pool-37-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,477 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,480 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,485 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: start as a follower, conf=-1: [0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461], old=null
2019-09-24 07:03:14,485 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,485 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: start FollowerState
2019-09-24 07:03:14,486 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-334338DF872F,id=0f09050e-a9d0-40e3-be5f-b91dd40c4695
2019-09-24 07:03:14,498 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0ff2d76c-cd12-4eee-945c-334338df872f, Nodes: 0f09050e-a9d0-40e3-be5f-b91dd40c4695{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-24 07:03:14,548 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: addNew group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] returns group-184A3A309245:java.util.concurrent.CompletableFuture@37c9b412[Not completed]
2019-09-24 07:03:14,550 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: addNew group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] returns group-184A3A309245:java.util.concurrent.CompletableFuture@24aed027[Not completed]
2019-09-24 07:03:14,550 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: addNew group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] returns group-184A3A309245:java.util.concurrent.CompletableFuture@7fb7338d[Not completed]
2019-09-24 07:03:14,553 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: new RaftServerImpl for group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,553 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: new RaftServerImpl for group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,553 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,554 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: ConfigurationManager, init=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,554 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis] (custom)
2019-09-24 07:03:14,554 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,555 [pool-47-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: ConfigurationManager, init=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,555 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(95)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: new RaftServerImpl for group-184A3A309245:[d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323] with ContainerStateMachine:uninitialized
2019-09-24 07:03:14,555 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis] (custom)
2019-09-24 07:03:14,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-24 07:03:14,555 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 does not exist. Creating ...
2019-09-24 07:03:14,555 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-24 07:03:14,555 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 does not exist. Creating ...
2019-09-24 07:03:14,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-24 07:03:14,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-24 07:03:14,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:14,556 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: ConfigurationManager, init=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null, confs=<EMPTY_MAP>
2019-09-24 07:03:14,556 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis] (custom)
2019-09-24 07:03:14,557 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 does not exist. Creating ...
2019-09-24 07:03:14,569 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,569 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,569 [pool-47-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/in_use.lock acquired by nodename 22013@pr-hdds-2162-tjkd5-3209850126
2019-09-24 07:03:14,582 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 has been successfully formatted.
2019-09-24 07:03:14,582 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 has been successfully formatted.
2019-09-24 07:03:14,583 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-184A3A309245: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,582 [pool-47-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245 has been successfully formatted.
2019-09-24 07:03:14,583 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-184A3A309245: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,583 [pool-47-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(230)) - group-184A3A309245: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-24 07:03:14,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,583 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,583 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.notification.no-leader.timeout = 120s (custom)
2019-09-24 07:03:14,583 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,583 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,584 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,583 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-24 07:03:14,584 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,584 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,584 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-24 07:03:14,584 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,584 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,585 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245
2019-09-24 07:03:14,584 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:14,585 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,585 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,585 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,585 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,585 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,585 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,585 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,585 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-24 07:03:14,586 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,586 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245
2019-09-24 07:03:14,586 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,586 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker for RaftStorage:Storage Directory /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245
2019-09-24 07:03:14,586 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,586 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,586 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,586 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-24 07:03:14,587 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,586 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,587 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,587 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-24 07:03:14,587 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,587 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-24 07:03:14,587 [pool-47-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,587 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,587 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-24 07:03:14,588 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,588 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,588 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,588 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-24 07:03:14,588 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,588 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,588 [pool-47-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,588 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-24 07:03:14,589 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,589 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-24 07:03:14,589 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,589 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-24 07:03:14,589 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,589 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-24 07:03:14,590 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,590 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-24 07:03:14,590 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,590 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2019-09-24 07:03:14,590 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,590 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-24 07:03:14,590 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,591 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-24 07:03:14,591 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,591 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.retention.num.files = 5 (custom)
2019-09-24 07:03:14,591 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,591 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-24 07:03:14,594 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: start as a follower, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:14,594 [pool-47-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,594 [pool-47-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start FollowerState
2019-09-24 07:03:14,595 [pool-47-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:03:14,596 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: start as a follower, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:14,596 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,596 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start FollowerState
2019-09-24 07:03:14,596 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(185)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: start as a follower, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:14,598 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=d90dd00f-f61b-415a-a5b1-2ed5656799b5
2019-09-24 07:03:14,598 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: changes role from      null to FOLLOWER at term 0 for startAsFollower
2019-09-24 07:03:14,600 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start FollowerState
2019-09-24 07:03:14,604 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=c1ba685c-4bc7-4c26-b843-7f4f93713ee9
2019-09-24 07:03:14,629 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2125e89d-fd7d-49f0-9f47-184a3a309245, Nodes: d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}c1ba685c-4bc7-4c26-b843-7f4f93713ee9{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}d90dd00f-f61b-415a-a5b1-2ed5656799b5{ip: 192.168.151.121, host: pr-hdds-2162-tjkd5-3209850126, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-09-24 07:03:14,723 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:15,724 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:16,147 [Thread-208] INFO  container.ReplicationManager (ReplicationManager.java:start(162)) - Starting Replication Monitor Thread.
2019-09-24 07:03:16,152 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 07:03:16,726 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:17,727 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:18,729 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:18,996 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9:group-09937AABF206 changes to CANDIDATE, lastRpcTime:5012, electionTimeout:5011ms
2019-09-24 07:03:19,001 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown FollowerState
2019-09-24 07:03:19,001 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,009 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start LeaderElection
2019-09-24 07:03:19,031 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1: begin an election at term 1 for -1: [c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276], old=null
2019-09-24 07:03:19,033 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown LeaderElection
2019-09-24 07:03:19,034 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,034 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: change Leader from null to c1ba685c-4bc7-4c26-b843-7f4f93713ee9 at term 1 for becomeLeader, leader elected after 5188ms
2019-09-24 07:03:19,043 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,043 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,047 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,050 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,050 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,051 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,064 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start LeaderState
2019-09-24 07:03:19,088 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,096 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: set configuration 0: [c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276], old=null at 0
2019-09-24 07:03:19,263 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:group-36E220DA5F1E changes to CANDIDATE, lastRpcTime:5092, electionTimeout:5091ms
2019-09-24 07:03:19,288 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown FollowerState
2019-09-24 07:03:19,288 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,289 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start LeaderElection
2019-09-24 07:03:19,311 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/0bd01567-b142-4067-a82a-09937aabf206/current/log_inprogress_0
2019-09-24 07:03:19,311 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2: begin an election at term 1 for -1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795], old=null
2019-09-24 07:03:19,312 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown LeaderElection
2019-09-24 07:03:19,312 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,313 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: change Leader from null to d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 at term 1 for becomeLeader, leader elected after 5159ms
2019-09-24 07:03:19,315 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,316 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,316 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,316 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,316 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,316 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,317 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(106)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5:group-A0F1E6D6E679 changes to CANDIDATE, lastRpcTime:5002, electionTimeout:5002ms
2019-09-24 07:03:19,317 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown FollowerState
2019-09-24 07:03:19,317 [Thread-217] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,317 [Thread-217] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start LeaderElection
2019-09-24 07:03:19,322 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start LeaderState
2019-09-24 07:03:19,322 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,323 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: set configuration 0: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795], old=null at 0
2019-09-24 07:03:19,357 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3: begin an election at term 1 for -1: [d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:19,357 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown LeaderElection
2019-09-24 07:03:19,358 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,358 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: change Leader from null to d90dd00f-f61b-415a-a5b1-2ed5656799b5 at term 1 for becomeLeader, leader elected after 5093ms
2019-09-24 07:03:19,359 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,359 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,359 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,359 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,360 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,360 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,362 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start LeaderState
2019-09-24 07:03:19,362 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,363 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: set configuration 0: [d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null at 0
2019-09-24 07:03:19,395 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/45b009bd-5def-4dd7-a575-36e220da5f1e/current/log_inprogress_0
2019-09-24 07:03:19,407 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/c32855df-b12b-4129-9217-a0f1e6d6e679/current/log_inprogress_0
2019-09-24 07:03:19,448 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(106)) - c007157f-4a68-4110-8a9f-d1661c4fcb31:group-70BDF6C6599C changes to CANDIDATE, lastRpcTime:5048, electionTimeout:5048ms
2019-09-24 07:03:19,448 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: shutdown FollowerState
2019-09-24 07:03:19,448 [Thread-220] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,448 [Thread-220] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: start LeaderElection
2019-09-24 07:03:19,467 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4: begin an election at term 1 for -1: [c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795], old=null
2019-09-24 07:03:19,467 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: shutdown LeaderElection
2019-09-24 07:03:19,467 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,467 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: change Leader from null to c007157f-4a68-4110-8a9f-d1661c4fcb31 at term 1 for becomeLeader, leader elected after 5081ms
2019-09-24 07:03:19,470 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,470 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,471 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,471 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,471 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,471 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,475 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: start LeaderState
2019-09-24 07:03:19,475 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,476 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: set configuration 0: [c007157f-4a68-4110-8a9f-d1661c4fcb31:192.168.151.121:45795], old=null at 0
2019-09-24 07:03:19,526 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/ratis/eed15e2a-ae77-4c32-87b8-70bdf6c6599c/current/log_inprogress_0
2019-09-24 07:03:19,606 [Thread-228] INFO  impl.FollowerState (FollowerState.java:run(106)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:group-184A3A309245 changes to CANDIDATE, lastRpcTime:5011, electionTimeout:5011ms
2019-09-24 07:03:19,606 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown FollowerState
2019-09-24 07:03:19,606 [Thread-228] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,607 [Thread-228] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start LeaderElection
2019-09-24 07:03:19,623 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5: begin an election at term 1 for -1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:19,643 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5:group-184A3A309245 changes to CANDIDATE, lastRpcTime:5047, electionTimeout:5044ms
2019-09-24 07:03:19,644 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown FollowerState
2019-09-24 07:03:19,644 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,644 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start LeaderElection
2019-09-24 07:03:19,655 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(106)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695:group-334338DF872F changes to CANDIDATE, lastRpcTime:5169, electionTimeout:5168ms
2019-09-24 07:03:19,655 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: shutdown FollowerState
2019-09-24 07:03:19,655 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-24 07:03:19,655 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: start LeaderElection
2019-09-24 07:03:19,663 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7: begin an election at term 1 for -1: [0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461], old=null
2019-09-24 07:03:19,663 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(182)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6: begin an election at term 1 for -1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:19,663 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: shutdown LeaderElection
2019-09-24 07:03:19,663 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:03:19,664 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,664 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown FollowerState
2019-09-24 07:03:19,664 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: change Leader from null to 0f09050e-a9d0-40e3-be5f-b91dd40c4695 at term 1 for becomeLeader, leader elected after 5194ms
2019-09-24 07:03:19,664 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: start FollowerState
2019-09-24 07:03:19,666 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,664 [Thread-231] INFO  impl.FollowerState (FollowerState.java:run(115)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 07:03:19,666 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,668 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,668 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,669 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,669 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,684 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: start LeaderState
2019-09-24 07:03:19,684 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,685 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: set configuration 0: [0f09050e-a9d0-40e3-be5f-b91dd40c4695:192.168.151.121:42461], old=null at 0
2019-09-24 07:03:19,731 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:19,734 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/ratis/0ff2d76c-cd12-4eee-945c-334338df872f/current/log_inprogress_0
2019-09-24 07:03:19,743 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5: Election PASSED; received 2 response(s) [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732<-c1ba685c-4bc7-4c26-b843-7f4f93713ee9#0:OK-t1, d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732<-d90dd00f-f61b-415a-a5b1-2ed5656799b5#0:FAIL-t1] and 0 exception(s); d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:t1, leader=null, voted=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732, raftlog=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:19,743 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6: Election REJECTED; received 2 response(s) [d90dd00f-f61b-415a-a5b1-2ed5656799b5<-d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732#0:FAIL-t1, d90dd00f-f61b-415a-a5b1-2ed5656799b5<-c1ba685c-4bc7-4c26-b843-7f4f93713ee9#0:FAIL-t1] and 0 exception(s); d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:t1, leader=null, voted=d90dd00f-f61b-415a-a5b1-2ed5656799b5, raftlog=d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null
2019-09-24 07:03:19,743 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown LeaderElection
2019-09-24 07:03:19,745 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-09-24 07:03:19,748 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(174)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-24 07:03:19,749 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown LeaderElection
2019-09-24 07:03:19,751 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: change Leader from null to d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-24 07:03:19,751 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: start FollowerState
2019-09-24 07:03:19,751 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-24 07:03:19,752 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-24 07:03:19,754 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-24 07:03:19,754 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-24 07:03:19,754 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-24 07:03:19,754 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-24 07:03:19,760 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 07:03:19,760 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:19,761 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 07:03:19,765 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 07:03:19,767 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:19,768 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:19,769 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-09-24 07:03:19,769 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-24 07:03:19,769 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-09-24 07:03:19,770 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-09-24 07:03:19,770 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-24 07:03:19,770 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-24 07:03:19,773 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: start LeaderState
2019-09-24 07:03:19,774 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,775 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: set configuration 0: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null at 0
2019-09-24 07:03:19,825 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/current/log_inprogress_0
2019-09-24 07:03:19,843 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: change Leader from null to d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 at term 1 for appendEntries, leader elected after 5260ms
2019-09-24 07:03:19,843 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(253)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: change Leader from null to d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732 at term 1 for appendEntries, leader elected after 5260ms
2019-09-24 07:03:19,876 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: set configuration 0: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null at 0
2019-09-24 07:03:19,876 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(354)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: set configuration 0: [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732:192.168.151.121:40795, c1ba685c-4bc7-4c26-b843-7f4f93713ee9:192.168.151.121:33276, d90dd00f-f61b-415a-a5b1-2ed5656799b5:192.168.151.121:42323], old=null at 0
2019-09-24 07:03:19,876 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,876 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker: Starting segment from index:0
2019-09-24 07:03:19,923 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/current/log_inprogress_0
2019-09-24 07:03:19,923 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker: created new log segment /workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/ratis/2125e89d-fd7d-49f0-9f47-184a3a309245/current/log_inprogress_0
2019-09-24 07:03:20,735 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:21,736 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:22,738 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:23,739 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:24,746 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:25,747 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:26,748 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:27,750 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:28,751 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:29,752 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:30,754 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:31,755 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:32,756 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:33,757 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:33,762 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 07:03:34,763 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:35,764 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:36,766 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:37,768 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:38,769 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:39,770 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:40,771 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:41,773 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:42,773 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:43,775 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:43,777 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 07:03:44,778 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:45,780 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:46,781 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:47,783 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:48,784 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:49,785 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:50,787 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:51,789 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:52,790 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:53,792 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:53,793 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 07:03:54,794 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:55,796 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:56,798 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:57,799 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:58,801 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:03:59,802 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:00,804 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:01,806 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:02,807 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:03,808 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:03,811 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 07:04:04,812 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:05,814 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:06,815 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:07,817 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:08,818 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:09,820 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:10,821 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:11,823 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:12,824 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:13,825 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:13,827 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 07:04:14,828 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:15,830 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:16,831 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:17,832 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:18,834 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:19,835 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:20,836 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:21,838 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:22,839 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:23,841 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:23,843 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 07:04:24,844 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:25,845 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:26,847 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:27,848 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:28,850 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:29,851 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:30,852 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:31,854 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:32,855 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:33,856 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:33,858 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 07:04:34,860 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:35,861 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:36,863 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:37,865 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:38,866 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:39,868 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:40,869 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:41,871 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:42,872 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:43,873 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:43,875 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 07:04:44,876 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:45,877 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:46,878 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:47,880 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:48,881 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:49,882 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:50,884 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:51,885 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:52,887 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:53,888 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:53,890 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 07:04:54,891 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:55,892 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:56,894 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:57,895 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:58,896 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:04:59,898 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:00,899 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:01,901 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:02,902 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:03,903 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:03,905 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 07:05:03,909 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.ratisTestLargeKey(TestDataValidate.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 56 more
2019-09-24 07:05:04,934 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:05,935 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:06,937 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:07,938 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:08,940 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:09,941 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:10,943 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:11,944 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:12,946 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:13,947 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:14,950 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:15,951 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:16,952 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:17,954 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:18,955 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:19,956 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:20,958 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:21,959 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:22,961 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:23,963 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:23,964 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 07:05:24,966 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:25,967 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:26,968 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:27,970 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:28,971 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:29,972 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:30,974 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:31,975 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:32,977 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:33,978 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:33,980 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 07:05:34,981 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:35,982 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:36,984 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:37,986 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:38,987 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:39,988 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:40,989 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:41,991 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:42,992 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:43,993 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:43,995 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 07:05:44,997 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:45,998 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:46,999 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:48,001 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:49,002 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:50,004 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:51,005 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:52,006 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:53,008 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:54,009 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:54,011 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 07:05:55,012 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:56,014 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:57,015 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:58,017 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:05:59,018 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:00,019 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:01,021 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:02,022 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:03,024 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:04,025 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:04,027 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 07:06:05,028 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:06,029 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:07,031 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:08,032 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:09,033 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:10,035 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:11,036 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:12,038 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:13,039 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:14,040 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:14,042 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 07:06:15,052 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:16,054 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:17,056 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:18,058 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:19,060 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:20,061 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:21,063 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:22,064 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:23,066 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:24,067 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:24,069 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 07:06:25,070 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:26,072 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:27,074 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:28,075 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:29,077 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:30,078 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:31,079 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:32,081 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:33,082 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:34,083 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:34,085 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 07:06:35,086 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:36,088 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:37,089 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:38,090 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:39,092 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:40,093 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:41,094 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:42,096 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:43,097 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:44,098 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:44,100 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 07:06:45,101 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:46,103 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:47,104 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:48,105 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:49,106 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:50,108 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:51,109 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:52,110 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:53,114 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:54,115 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:54,116 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 07:06:54,116 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.standaloneTestLargeKey(TestDataValidate.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-24 07:06:55,123 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:56,124 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:57,125 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:58,126 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:06:59,127 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:00,128 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:01,129 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:02,130 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:03,131 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:04,133 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:05,135 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:06,136 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:07,137 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:08,140 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:09,141 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:10,142 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:11,143 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:12,144 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:13,145 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:14,146 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:14,148 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 1 failover attempts. Trying to failover immediately.
2019-09-24 07:07:15,149 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:16,150 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:17,151 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:18,153 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:19,154 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:20,155 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:21,156 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:22,157 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:23,158 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:24,159 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:24,161 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 2 failover attempts. Trying to failover immediately.
2019-09-24 07:07:25,161 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:26,163 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:27,164 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:28,165 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:29,166 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:30,167 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:31,168 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:32,169 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:33,170 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:34,172 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:34,173 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 3 failover attempts. Trying to failover immediately.
2019-09-24 07:07:35,175 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:36,177 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:37,178 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:38,180 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:39,181 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:40,182 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:41,183 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:42,184 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:43,186 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:44,187 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:44,189 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 4 failover attempts. Trying to failover immediately.
2019-09-24 07:07:45,190 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:46,191 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:47,192 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:48,193 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:49,194 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:50,195 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:51,197 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:52,198 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:53,199 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:54,200 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:54,202 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 5 failover attempts. Trying to failover immediately.
2019-09-24 07:07:55,203 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:56,204 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:57,205 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:58,207 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:07:59,208 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:00,210 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:01,211 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:02,212 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:03,213 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:04,214 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:04,216 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 6 failover attempts. Trying to failover immediately.
2019-09-24 07:08:05,217 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:06,218 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:07,220 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:08,221 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:09,222 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:10,224 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:11,225 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:12,226 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:13,227 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:14,229 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:14,230 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 7 failover attempts. Trying to failover immediately.
2019-09-24 07:08:15,232 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:16,153 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(225)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-24 07:08:16,233 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:17,234 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:18,235 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:19,236 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:20,237 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:21,239 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:22,240 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:23,241 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:24,242 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:24,243 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 8 failover attempts. Trying to failover immediately.
2019-09-24 07:08:25,244 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:26,245 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:27,246 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:28,247 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:29,248 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:30,250 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:31,251 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:32,252 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:33,253 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:34,255 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:34,257 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy36.submitRequest over nodeId=null,nodeAddress=127.0.0.1:0 after 9 failover attempts. Trying to failover immediately.
2019-09-24 07:08:35,258 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:36,259 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:37,259 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:38,261 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:39,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:40,262 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:41,263 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:42,265 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:43,266 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:44,267 [main] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-24 07:08:44,269 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(268)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-24 07:08:44,269 [main] ERROR client.OzoneClientFactory (OzoneClientFactory.java:getClientProtocol(259)) - Couldn't create RpcClient protocol exception: 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy36.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:338)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy37.getServiceInfo(Unknown Source)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:154)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:256)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:239)
	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClient(OzoneClientFactory.java:75)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.init(RandomKeyGenerator.java:242)
	at org.apache.hadoop.ozone.freon.RandomKeyGenerator.call(RandomKeyGenerator.java:262)
	at org.apache.hadoop.ozone.freon.TestDataValidate.validateWriteTest(TestDataValidate.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 55 more
2019-09-24 07:08:44,272 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(314)) - Shutting down the Mini Ozone Cluster
2019-09-24 07:08:44,273 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(330)) - Stopping the Mini Ozone Cluster
2019-09-24 07:08:44,273 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(400)) - Stopping the OzoneManager
2019-09-24 07:08:44,273 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 45362
2019-09-24 07:08:44,280 [IPC Server listener on 45362] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 45362
2019-09-24 07:08:44,280 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-24 07:08:44,282 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 07:08:44,288 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-24 07:08:44,297 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-24 07:08:44,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@151335cb{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-24 07:08:44,316 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a7761b1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:44,317 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22d1886d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:44,317 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a5f7e7c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:44,323 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(377)) - Stopping the HddsDatanodes
2019-09-24 07:08:44,443 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 07:08:45,245 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 07:08:49,325 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 07:08:49,325 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 07:08:49,327 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: close
2019-09-24 07:08:49,327 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: close
2019-09-24 07:08:49,329 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: shutdown
2019-09-24 07:08:49,329 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: shutdown
2019-09-24 07:08:49,329 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-36E220DA5F1E,id=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:08:49,329 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-334338DF872F,id=0f09050e-a9d0-40e3-be5f-b91dd40c4695
2019-09-24 07:08:49,329 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown LeaderState
2019-09-24 07:08:49,330 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: shutdown LeaderState
2019-09-24 07:08:49,330 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:49,330 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:49,334 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:49,334 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:49,338 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F: closes. applyIndex: 0
2019-09-24 07:08:49,338 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E: closes. applyIndex: 0
2019-09-24 07:08:49,339 [0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:49,339 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:49,342 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-36E220DA5F1E-SegmentedRaftLogWorker close()
2019-09-24 07:08:49,342 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695@group-334338DF872F-SegmentedRaftLogWorker close()
2019-09-24 07:08:49,344 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: shutdown
2019-09-24 07:08:49,346 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732
2019-09-24 07:08:49,346 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: shutdown server with port 42461 now
2019-09-24 07:08:49,346 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown LeaderState
2019-09-24 07:08:49,348 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:49,348 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$371/1077449736@32d542a6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245->d90dd00f-f61b-415a-a5b1-2ed5656799b5-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 07:08:49,349 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:49,348 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$371/1077449736@28e44e9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(143)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245->c1ba685c-4bc7-4c26-b843-7f4f93713ee9-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2019-09-24 07:08:49,353 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245: closes. applyIndex: 0
2019-09-24 07:08:49,357 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0f09050e-a9d0-40e3-be5f-b91dd40c4695: shutdown server with port 42461 successfully
2019-09-24 07:08:49,357 [d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:49,359 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245-SegmentedRaftLogWorker close()
2019-09-24 07:08:49,362 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown server with port 40795 now
2019-09-24 07:08:49,364 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: Completed APPEND_ENTRIES, lastRequest: d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732->c1ba685c-4bc7-4c26-b843-7f4f93713ee9#132-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 07:08:49,364 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(113)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: Completed APPEND_ENTRIES, lastRequest: d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732->d90dd00f-f61b-415a-a5b1-2ed5656799b5#132-t1, previous=(t:1, i:0), leaderCommit=0, initializing? false, entries: <empty>
2019-09-24 07:08:49,366 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732: shutdown server with port 40795 successfully
2019-09-24 07:08:49,367 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245->d90dd00f-f61b-415a-a5b1-2ed5656799b5-GrpcLogAppender is stopped
2019-09-24 07:08:49,367 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 07:08:49,367 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(282)) - d9eaf14c-3bbc-4fd5-8f51-c2e2285ea732@group-184A3A309245->c1ba685c-4bc7-4c26-b843-7f4f93713ee9-GrpcLogAppender is stopped
2019-09-24 07:08:49,381 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 07:08:49,409 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 07:08:49,411 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 07:08:49,416 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 07:08:49,424 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 07:08:49,424 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28da7d11{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 07:08:49,425 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41eb94bc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 07:08:49,425 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b919a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:49,425 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@378cfecf{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:49,427 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1981d861{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:49,427 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e5af8e1{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:49,427 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588f63c{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:49,429 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52d97ab6{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:49,948 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 07:08:50,125 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 07:08:54,430 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 07:08:54,430 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 07:08:54,431 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: close
2019-09-24 07:08:54,431 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: shutdown
2019-09-24 07:08:54,431 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: close
2019-09-24 07:08:54,431 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-09937AABF206,id=c1ba685c-4bc7-4c26-b843-7f4f93713ee9
2019-09-24 07:08:54,432 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: shutdown
2019-09-24 07:08:54,432 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown LeaderState
2019-09-24 07:08:54,432 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0F1E6D6E679,id=d90dd00f-f61b-415a-a5b1-2ed5656799b5
2019-09-24 07:08:54,433 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:54,433 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown LeaderState
2019-09-24 07:08:54,433 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:54,434 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:54,435 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206: closes. applyIndex: 0
2019-09-24 07:08:54,436 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:54,436 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:54,440 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679: closes. applyIndex: 0
2019-09-24 07:08:54,441 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-09937AABF206-SegmentedRaftLogWorker close()
2019-09-24 07:08:54,442 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:54,444 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: shutdown
2019-09-24 07:08:54,445 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-A0F1E6D6E679-SegmentedRaftLogWorker close()
2019-09-24 07:08:54,445 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=c1ba685c-4bc7-4c26-b843-7f4f93713ee9
2019-09-24 07:08:54,448 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: shutdown
2019-09-24 07:08:54,448 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown FollowerState
2019-09-24 07:08:54,448 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-184A3A309245,id=d90dd00f-f61b-415a-a5b1-2ed5656799b5
2019-09-24 07:08:54,449 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(115)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 07:08:54,449 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:54,449 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown FollowerState
2019-09-24 07:08:54,450 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245: closes. applyIndex: 0
2019-09-24 07:08:54,451 [Thread-252] INFO  impl.FollowerState (FollowerState.java:run(115)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-09-24 07:08:54,451 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:54,451 [c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:54,452 [main] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245: closes. applyIndex: 0
2019-09-24 07:08:54,454 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9@group-184A3A309245-SegmentedRaftLogWorker close()
2019-09-24 07:08:54,454 [d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:54,456 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown server with port 33276 now
2019-09-24 07:08:54,457 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5@group-184A3A309245-SegmentedRaftLogWorker close()
2019-09-24 07:08:54,459 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown server with port 42323 now
2019-09-24 07:08:54,459 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c1ba685c-4bc7-4c26-b843-7f4f93713ee9: shutdown server with port 33276 successfully
2019-09-24 07:08:54,463 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - d90dd00f-f61b-415a-a5b1-2ed5656799b5: shutdown server with port 42323 successfully
2019-09-24 07:08:54,466 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 07:08:54,476 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 07:08:54,488 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 07:08:54,492 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 07:08:54,495 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d910b3{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 07:08:54,496 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e7ab390{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:54,497 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@895416d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:54,498 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f5ac102{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:54,499 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 07:08:54,502 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 07:08:54,502 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6cf0a747{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 07:08:54,503 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21505815{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:54,503 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ea4300e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:54,504 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@934b52f{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:55,444 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-24 07:08:59,499 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(231)) - Attempting to stop container services.
2019-09-24 07:08:59,500 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: close
2019-09-24 07:08:59,500 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(251)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: shutdown
2019-09-24 07:08:59,501 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-70BDF6C6599C,id=c007157f-4a68-4110-8a9f-d1661c4fcb31
2019-09-24 07:08:59,501 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: shutdown LeaderState
2019-09-24 07:08:59,501 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - c007157f-4a68-4110-8a9f-d1661c4fcb31-PendingRequests: sendNotLeaderResponses
2019-09-24 07:08:59,502 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(125)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-StateMachineUpdater: set stopIndex = 0
2019-09-24 07:08:59,502 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(385)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C: closes. applyIndex: 0
2019-09-24 07:08:59,503 [c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-24 07:08:59,504 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - c007157f-4a68-4110-8a9f-d1661c4fcb31@group-70BDF6C6599C-SegmentedRaftLogWorker close()
2019-09-24 07:08:59,506 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: shutdown server with port 45795 now
2019-09-24 07:08:59,507 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c007157f-4a68-4110-8a9f-d1661c4fcb31: shutdown server with port 45795 successfully
2019-09-24 07:08:59,510 [refreshUsed-/workdir/hadoop-ozone/tools/target/test-dir/MiniOzoneClusterImpl-9f1911d8-2ed6-4907-8f1a-62744b51c6d9/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-24 07:08:59,530 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-24 07:08:59,533 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-24 07:08:59,535 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a1d3225{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-24 07:08:59,536 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67e13bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:59,537 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e253c9d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:59,538 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@715b886f{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:59,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(392)) - Stopping the StorageContainerManager
2019-09-24 07:08:59,539 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(808)) - Stopping Replication Manager Service.
2019-09-24 07:08:59,539 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(203)) - Stopping Replication Monitor Thread.
2019-09-24 07:08:59,539 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(815)) - Stopping Lease Manager of the command watchers
2019-09-24 07:08:59,539 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(822)) - Stopping datanode service RPC server
2019-09-24 07:08:59,540 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-24 07:08:59,540 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39009
2019-09-24 07:08:59,541 [IPC Server listener on 39009] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39009
2019-09-24 07:08:59,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 07:08:59,610 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(646)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-24 07:08:59,611 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping block service RPC server
2019-09-24 07:08:59,611 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(155)) - Stopping the RPC server for Block Protocol
2019-09-24 07:08:59,611 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39455
2019-09-24 07:08:59,613 [IPC Server listener on 39455] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39455
2019-09-24 07:08:59,613 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(837)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-24 07:08:59,613 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-24 07:08:59,613 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38368
2019-09-24 07:08:59,613 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 07:08:59,615 [IPC Server listener on 38368] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38368
2019-09-24 07:08:59,615 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Storage Container Manager HTTP server.
2019-09-24 07:08:59,616 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-24 07:08:59,617 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9573b3b{/,null,UNAVAILABLE}{/scm}
2019-09-24 07:08:59,617 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-24 07:08:59,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@101639ae{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-24 07:08:59,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@753432a2{/logs,file:///workdir/hadoop-ozone/tools/target/log,UNAVAILABLE}
2019-09-24 07:08:59,619 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(855)) - Stopping Block Manager Service.
2019-09-24 07:08:59,619 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 07:08:59,619 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-24 07:08:59,620 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(877)) - Stopping SCM Event Queue.
2019-09-24 07:08:59,625 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ratis metrics system...
2019-09-24 07:08:59,631 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2019-09-24 07:08:59,631 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ratis metrics system stopped.

2019-09-19 08:53:56,361 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:53:56,481 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:53:56,484 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:53:56,505 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1030ms
2019-09-19 08:53:56,648 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-19 08:53:56,648 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-19 08:53:56,649 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-19 08:53:56,649 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-19 08:53:56,650 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-19 08:53:56,650 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-19 08:53:56,664 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:53:56,664 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:53:56,666 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:53:57,080 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5ffead27
2019-09-19 08:53:57,083 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-19 08:53:57,166 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 08:53:57,167 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 08:53:57,170 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-19 08:53:57,241 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-19 08:53:57,256 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:53:57,924 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-19 08:53:57,928 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:00,058 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-19 08:54:01,026 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:01,064 [Socket Reader #1 for port 35862] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35862
2019-09-19 08:54:01,096 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:01,097 [Socket Reader #1 for port 41217] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41217
2019-09-19 08:54:01,106 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:01,106 [Socket Reader #1 for port 44546] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44546
2019-09-19 08:54:01,128 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-19 08:54:01,322 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:01,330 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:01,338 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:01,340 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-19 08:54:01,341 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:01,341 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:01,368 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:44546
2019-09-19 08:54:01,432 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-19 08:54:01,447 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-19 08:54:01,448 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-19 08:54:01,693 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:44546
2019-09-19 08:54:01,694 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:01,694 [IPC Server listener on 44546] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44546: starting
2019-09-19 08:54:01,698 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41217
2019-09-19 08:54:01,699 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:41217
2019-09-19 08:54:01,699 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:01,699 [IPC Server listener on 41217] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41217: starting
2019-09-19 08:54:01,702 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:35862
2019-09-19 08:54:01,702 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:35862
2019-09-19 08:54:01,703 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:01,703 [IPC Server listener on 35862] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35862: starting
2019-09-19 08:54:01,708 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38500
2019-09-19 08:54:01,710 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:01,751 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:01,752 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:54:01,796 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43c67247{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-19 08:54:01,806 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:38500}
2019-09-19 08:54:01,807 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6332ms
2019-09-19 08:54:01,808 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:38500
2019-09-19 08:54:01,818 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24f43aa3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:01,821 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:01,936 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:01,937 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:01,938 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-19 08:54:01,938 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: bbe3ba15-15a2-4629-a151-8dd09ebfd45a
2019-09-19 08:54:01,939 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-19 08:54:02,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 08:54:02,595 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:02,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-19 08:54:02,601 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-19 08:54:02,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-19 08:54:02,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-19 08:54:02,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-19 08:54:02,602 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-19 08:54:02,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-19 08:54:02,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-19 08:54:02,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-19 08:54:02,603 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-19 08:54:02,604 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-19 08:54:02,604 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-19 08:54:02,604 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-19 08:54:02,604 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-19 08:54:02,604 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-19 08:54:02,605 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-19 08:54:02,605 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-19 08:54:02,605 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-19 08:54:02,605 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-19 08:54:02,605 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-19 08:54:02,606 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-19 08:54:02,606 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-19 08:54:02,606 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:54:02,606 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:54:02,607 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:54:03,751 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3406)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-19 08:54:03,784 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:03,808 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: localhost:9872
2019-09-19 08:54:03,837 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:03,905 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:03,910 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9872 (custom)
2019-09-19 08:54:03,911 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-19 08:54:03,912 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:03,913 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:03,914 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:04,064 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis] (custom)
2019-09-19 08:54:04,069 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: addNew group-C5BA1605619E:[bbe3ba15-15a2-4629-a151-8dd09ebfd45a:localhost:9872] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@5496c165[Not completed]
2019-09-19 08:54:04,071 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1398)) - OzoneManager Ratis server initialized at port 9872
2019-09-19 08:54:04,074 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:04,075 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:04,087 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:04,087 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: new RaftServerImpl for group-C5BA1605619E:[bbe3ba15-15a2-4629-a151-8dd09ebfd45a:localhost:9872] with OzoneManagerStateMachine:uninitialized
2019-09-19 08:54:04,088 [Socket Reader #1 for port 40501] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40501
2019-09-19 08:54:04,090 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-19 08:54:04,091 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-19 08:54:04,091 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:04,092 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:04,093 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:04,102 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E ConfigurationManager, init=-1: [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:localhost:9872], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:04,103 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis] (custom)
2019-09-19 08:54:04,106 [main] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40501
2019-09-19 08:54:04,106 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-19 08:54:04,106 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer bbe3ba15-15a2-4629-a151-8dd09ebfd45a at port 9872
2019-09-19 08:54:04,114 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2019-09-19 08:54:04,129 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:04,138 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2019-09-19 08:54:04,141 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:04,144 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:04,151 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:04,151 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:04,152 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-19 08:54:04,157 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:04,162 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2019-09-19 08:54:04,174 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-19 08:54:04,174 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-19 08:54:04,180 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-19 08:54:04,180 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:04,181 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-19 08:54:04,182 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:04,183 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:04,183 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:04,184 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:04,192 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-19 08:54:04,198 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:04,202 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:04,203 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-19 08:54:04,203 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:04,224 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: start group-C5BA1605619E
2019-09-19 08:54:04,228 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:04,230 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: start FollowerState
2019-09-19 08:54:04,233 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=bbe3ba15-15a2-4629-a151-8dd09ebfd45a
2019-09-19 08:54:04,235 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: start RPC server
2019-09-19 08:54:04,359 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
2019-09-19 08:54:04,371 [IPC Server listener on 40501] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40501: starting
2019-09-19 08:54:04,371 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:04,379 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-19 08:54:04,381 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:04,382 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:04,385 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:04,387 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-19 08:54:04,387 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:04,387 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:04,390 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44342
2019-09-19 08:54:04,390 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:04,393 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:04,393 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:54:04,397 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1debc91c{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-19 08:54:04,398 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:44342}
2019-09-19 08:54:04,399 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8924ms
2019-09-19 08:54:04,399 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:44342
2019-09-19 08:54:04,538 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:04,626 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 08:54:04,657 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:04,659 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/containers/hdds to VolumeSet
2019-09-19 08:54:04,662 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-19 08:54:04,679 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-19 08:54:04,732 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:04,733 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:04,733 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:04,733 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:04,733 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:04,733 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:04,734 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:04,734 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:04,769 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:04,783 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:04,786 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:04,787 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:04,790 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:04,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:04,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:04,793 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:04,794 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35280
2019-09-19 08:54:04,794 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:04,798 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:04,799 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:04,845 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a87026{/,file:///tmp/jetty-0.0.0.0-35280-hddsDatanode-_-any-204084759264063411.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:04,846 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:35280}
2019-09-19 08:54:04,847 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9372ms
2019-09-19 08:54:04,848 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35280
Sep 19, 2019 8:54:05 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:05,406 [Thread-94] INFO  impl.FollowerState (FollowerState.java:run(106)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E changes to CANDIDATE, lastRpcTime:1176, electionTimeout:1175ms
2019-09-19 08:54:05,407 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown FollowerState
2019-09-19 08:54:05,408 [Thread-94] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:05,410 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: start LeaderElection
2019-09-19 08:54:05,840 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:34242 |  
2019-09-19 08:54:05,841 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-19 08:54:05,842 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:05,845 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 08:54:05,848 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@53336f01] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:07,458 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:07,468 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/containers/hdds to VolumeSet
2019-09-19 08:54:07,468 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2c1d57bc
2019-09-19 08:54:07,469 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2c1d57bc
2019-09-19 08:54:07,471 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1: begin an election at term 1 for -1: [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:localhost:9872], old=null
2019-09-19 08:54:07,472 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown LeaderElection
2019-09-19 08:54:07,473 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:07,473 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E change Leader from null to bbe3ba15-15a2-4629-a151-8dd09ebfd45a at term 1 for becomeLeader, leader elected after 3332ms
2019-09-19 08:54:07,480 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:07,481 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:07,485 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:07,488 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:07,489 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:07,491 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:07,492 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:07,492 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:07,493 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:07,493 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:07,493 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:07,494 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:07,494 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:07,495 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:07,496 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:07,498 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:07,500 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:07,501 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:07,502 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: start LeaderState
2019-09-19 08:54:07,503 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:07,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:07,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:07,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:07,505 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44908
2019-09-19 08:54:07,506 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:07,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2aa14ae6{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:07,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4168f3d9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:07,516 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/meta/datanode.id
2019-09-19 08:54:07,536 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Starting segment from index:0
2019-09-19 08:54:07,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e4d40ea{/,file:///tmp/jetty-0.0.0.0-44908-hddsDatanode-_-any-8748044585252254703.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:07,547 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73f6e07{HTTP/1.1,[http/1.1]}{0.0.0.0:44908}
2019-09-19 08:54:07,548 [main] INFO  server.Server (Server.java:doStart(419)) - Started @12073ms
2019-09-19 08:54:07,549 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44908
Sep 19, 2019 8:54:07 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:07,556 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E set configuration 0: [bbe3ba15-15a2-4629-a151-8dd09ebfd45a:localhost:9872], old=null at 0
2019-09-19 08:54:07,724 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:46319 |  
2019-09-19 08:54:07,724 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@686cf8ad
2019-09-19 08:54:07,725 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:07,728 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 08:54:07,728 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d9c76eb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:07,734 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/meta/datanode.id
2019-09-19 08:54:07,739 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:07,739 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/containers/hdds to VolumeSet
2019-09-19 08:54:07,739 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5dbab232
2019-09-19 08:54:07,740 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5dbab232
2019-09-19 08:54:07,755 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:07,756 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:07,756 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:07,756 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:07,756 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:07,756 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:07,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:07,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:07,758 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:07,759 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:07,762 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:07,763 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:07,765 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:07,766 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:07,767 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:07,767 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:07,768 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46857
2019-09-19 08:54:07,768 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:07,773 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52ba685a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:07,774 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71d55b7e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:07,813 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c18942{/,file:///tmp/jetty-0.0.0.0-46857-hddsDatanode-_-any-7089835668072355702.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:07,814 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@743c3520{HTTP/1.1,[http/1.1]}{0.0.0.0:46857}
2019-09-19 08:54:07,815 [main] INFO  server.Server (Server.java:doStart(419)) - Started @12340ms
2019-09-19 08:54:07,816 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46857
Sep 19, 2019 8:54:07 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:07,872 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:08,006 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:43927 |  
2019-09-19 08:54:08,006 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@79add732
2019-09-19 08:54:08,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:08,010 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a5d5599] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:08,013 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/meta/datanode.id
2019-09-19 08:54:08,183 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2019-09-19 08:54:08,184 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:08,185 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:08,186 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 18897f3d-a606-48ca-8ab1-50a74a285275 at port 0
2019-09-19 08:54:08,194 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start RPC server
2019-09-19 08:54:08,198 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 18897f3d-a606-48ca-8ab1-50a74a285275: GrpcService started, listening on 0.0.0.0/0.0.0.0:38850
2019-09-19 08:54:08,198 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 18897f3d-a606-48ca-8ab1-50a74a285275 is started using port 38850
2019-09-19 08:54:08,200 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 18897f3d-a606-48ca-8ab1-50a74a285275 is started using port 43534
2019-09-19 08:54:09,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:09,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:09,757 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:09,759 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:09,759 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at port 0
2019-09-19 08:54:09,766 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start RPC server
2019-09-19 08:54:09,768 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: GrpcService started, listening on 0.0.0.0/0.0.0.0:45142
2019-09-19 08:54:09,768 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis a448d85b-ec9b-4560-ae6c-b2c8a1634a11 is started using port 45142
2019-09-19 08:54:09,770 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc a448d85b-ec9b-4560-ae6c-b2c8a1634a11 is started using port 43743
2019-09-19 08:54:09,874 [IPC Server handler 17 on 35862] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:09,874 [IPC Server handler 17 on 35862] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:09,878 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-19 08:54:09,879 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-19 08:54:09,879 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-19 08:54:09,883 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:10,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:10,011 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 3 DN Heartbeats.
2019-09-19 08:54:10,034 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:10,035 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:10,035 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at port 0
2019-09-19 08:54:10,042 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start RPC server
2019-09-19 08:54:10,045 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: GrpcService started, listening on 0.0.0.0/0.0.0.0:43014
2019-09-19 08:54:10,046 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 6e2100fe-d804-4987-9ac5-bcccf3c0d596 is started using port 43014
2019-09-19 08:54:10,048 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 6e2100fe-d804-4987-9ac5-bcccf3c0d596 is started using port 39573
2019-09-19 08:54:10,705 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-39D909CCF0EF:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-39D909CCF0EF:java.util.concurrent.CompletableFuture@24fb94b6[Not completed]
2019-09-19 08:54:10,718 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-39D909CCF0EF:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:10,719 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:10,719 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:10,720 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:10,720 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:10,720 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:10,720 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:10,720 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:10,721 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef does not exist. Creating ...
2019-09-19 08:54:10,735 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:10,749 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef has been successfully formatted.
2019-09-19 08:54:10,751 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-39D909CCF0EF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:10,751 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:10,752 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:10,752 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:10,752 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:10,752 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,753 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:10,753 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef
2019-09-19 08:54:10,753 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:10,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:10,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:10,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:10,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:10,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:10,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:10,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:10,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:10,756 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:10,757 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:10,757 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:10,758 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:10,758 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-39D909CCF0EF
2019-09-19 08:54:10,758 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:10,759 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:10,759 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-39D909CCF0EF,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:10,821 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c18abddb-f074-4bdf-9d26-39d909ccf0ef, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:10,835 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-D630FD7012B2:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-D630FD7012B2:java.util.concurrent.CompletableFuture@74069d49[Not completed]
2019-09-19 08:54:10,836 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-D630FD7012B2:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:10,836 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:10,836 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:10,837 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2 does not exist. Creating ...
2019-09-19 08:54:10,861 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:10,873 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2 has been successfully formatted.
2019-09-19 08:54:10,874 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D630FD7012B2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:10,874 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:10,874 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:10,874 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:10,874 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:10,875 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:10,876 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-D630FD7012B2
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:10,877 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:10,878 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D630FD7012B2,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:10,890 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0f02329a-09b2-44ad-b105-d630fd7012b2, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:10,911 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-220F5C9DED30:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-220F5C9DED30:java.util.concurrent.CompletableFuture@27a56f25[Not completed]
2019-09-19 08:54:10,913 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-220F5C9DED30:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:10,913 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:10,913 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:10,913 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:10,914 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:10,914 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:10,914 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:10,914 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:10,915 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30 does not exist. Creating ...
2019-09-19 08:54:10,927 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:10,940 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30 has been successfully formatted.
2019-09-19 08:54:10,940 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-220F5C9DED30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:10,940 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:10,940 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:10,941 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:10,941 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:10,941 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,941 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:10,941 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:10,942 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:10,943 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:10,943 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:10,943 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:10,943 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:10,944 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:10,944 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:10,944 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:10,944 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:10,945 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-220F5C9DED30
2019-09-19 08:54:10,945 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:10,945 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:10,945 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-220F5C9DED30,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:10,953 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 99f0d179-1c0b-4b8a-81fa-220f5c9ded30, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:10,967 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-C2A181725365:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-C2A181725365:java.util.concurrent.CompletableFuture@16b8830b[Not completed]
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-C2A181725365:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:10,969 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:10,970 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:10,970 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365 does not exist. Creating ...
2019-09-19 08:54:10,982 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365 has been successfully formatted.
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C2A181725365: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:10,995 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:10,996 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:10,997 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-C2A181725365
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:10,998 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:10,999 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2A181725365,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:11,008 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 462adf1a-e0ab-434d-8265-c2a181725365, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,013 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 3 DN Heartbeats.
2019-09-19 08:54:11,021 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-864EE71594B1:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-864EE71594B1:java.util.concurrent.CompletableFuture@7492ffe9[Not completed]
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-864EE71594B1:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,023 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,024 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,024 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:11,024 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1 does not exist. Creating ...
2019-09-19 08:54:11,037 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,050 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1 has been successfully formatted.
2019-09-19 08:54:11,050 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-864EE71594B1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,050 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,050 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,050 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,051 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,052 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,053 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,053 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,053 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,053 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,054 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-864EE71594B1
2019-09-19 08:54:11,054 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,054 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:11,055 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-864EE71594B1,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:11,063 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3d4ae66b-cd08-4617-93af-864ee71594b1, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,078 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 18897f3d-a606-48ca-8ab1-50a74a285275: addNew group-DFFD32B43B1B:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] returns group-DFFD32B43B1B:java.util.concurrent.CompletableFuture@55851498[Not completed]
2019-09-19 08:54:11,079 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 18897f3d-a606-48ca-8ab1-50a74a285275: new RaftServerImpl for group-DFFD32B43B1B:[18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,080 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,080 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,080 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,080 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,080 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,081 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B ConfigurationManager, init=-1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,081 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis] (custom)
2019-09-19 08:54:11,081 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b does not exist. Creating ...
2019-09-19 08:54:11,094 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,107 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b has been successfully formatted.
2019-09-19 08:54:11,107 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DFFD32B43B1B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,107 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,108 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b
2019-09-19 08:54:11,109 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,109 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,109 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,109 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,109 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,110 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,110 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,110 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,110 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,110 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,111 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,111 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,111 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,111 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,112 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start group-DFFD32B43B1B
2019-09-19 08:54:11,112 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,112 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start FollowerState
2019-09-19 08:54:11,113 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFFD32B43B1B,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:11,122 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7b0dd393-2f2a-4958-bebe-dffd32b43b1b, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,123 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,123 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 1.
2019-09-19 08:54:11,124 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 1.
2019-09-19 08:54:11,124 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(129)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:54:11,124 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:54:11,125 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,125 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 1.
2019-09-19 08:54:11,125 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 1.
2019-09-19 08:54:11,125 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(129)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:54:11,125 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:54:11,734 [IPC Server handler 18 on 35862] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:11,734 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,734 [IPC Server handler 18 on 35862] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:11,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:11,761 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-E2EA6504FD1A:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-E2EA6504FD1A:java.util.concurrent.CompletableFuture@61c8601e[Not completed]
2019-09-19 08:54:11,796 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-E2EA6504FD1A:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,797 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,797 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,798 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,798 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,798 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,798 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,798 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:11,799 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a does not exist. Creating ...
2019-09-19 08:54:11,823 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,836 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a has been successfully formatted.
2019-09-19 08:54:11,837 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E2EA6504FD1A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,838 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,838 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,839 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,839 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,839 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,839 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,839 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a
2019-09-19 08:54:11,840 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,840 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,840 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,840 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,840 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,841 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,841 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,841 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,841 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,841 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,842 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,842 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,842 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,842 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,843 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-E2EA6504FD1A
2019-09-19 08:54:11,843 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,843 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:11,843 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E2EA6504FD1A,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:11,851 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,853 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,865 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-E6CB3D7A5F33:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-E6CB3D7A5F33:java.util.concurrent.CompletableFuture@21c7c792[Not completed]
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-E6CB3D7A5F33:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,867 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,868 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,868 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:11,868 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33 does not exist. Creating ...
2019-09-19 08:54:11,870 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:11,882 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,895 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33 has been successfully formatted.
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-E6CB3D7A5F33: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,896 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,897 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,898 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,899 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-E6CB3D7A5F33
2019-09-19 08:54:11,899 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,899 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:11,899 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E6CB3D7A5F33,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:11,908 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 1eaec501-0284-41dd-b955-e6cb3d7a5f33, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,909 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,918 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-0254FFF01EE2:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-0254FFF01EE2:java.util.concurrent.CompletableFuture@2b89e83e[Not completed]
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-0254FFF01EE2:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,920 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:11,921 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2 does not exist. Creating ...
2019-09-19 08:54:11,933 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2 has been successfully formatted.
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0254FFF01EE2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,946 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,947 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,948 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,949 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,949 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-0254FFF01EE2
2019-09-19 08:54:11,949 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,949 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:11,949 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0254FFF01EE2,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:11,955 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ee7782eb-17fe-4297-bac6-0254fff01ee2, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:11,956 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:11,964 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-0AB69DB7EA63:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-0AB69DB7EA63:java.util.concurrent.CompletableFuture@c0a5d4d[Not completed]
2019-09-19 08:54:11,965 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-0AB69DB7EA63:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:11,965 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:11,965 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:11,966 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63 does not exist. Creating ...
2019-09-19 08:54:11,978 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:11,990 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63 has been successfully formatted.
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0AB69DB7EA63: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:11,991 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:11,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-0AB69DB7EA63
2019-09-19 08:54:11,993 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:11,994 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:11,994 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0AB69DB7EA63,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:11,999 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5ff289c0-091f-4001-88d9-0ab69db7ea63, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,000 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,007 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-0FC12B4619A5:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-0FC12B4619A5:java.util.concurrent.CompletableFuture@7c5d3139[Not completed]
2019-09-19 08:54:12,008 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-0FC12B4619A5:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:12,009 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5 does not exist. Creating ...
2019-09-19 08:54:12,011 [IPC Server handler 19 on 35862] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,011 [IPC Server handler 19 on 35862] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:12,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:12,013 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-19 08:54:12,022 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,034 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5 has been successfully formatted.
2019-09-19 08:54:12,034 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0FC12B4619A5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,034 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,035 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,036 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-0FC12B4619A5
2019-09-19 08:54:12,037 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,038 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:12,038 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FC12B4619A5,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:12,043 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0a9538d9-48b8-4dd4-b485-0fc12b4619a5, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,044 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,058 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: addNew group-81350EB5AF8A:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] returns group-81350EB5AF8A:java.util.concurrent.CompletableFuture@46f6c2ed[Not completed]
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: new RaftServerImpl for group-81350EB5AF8A:[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A ConfigurationManager, init=-1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,059 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis] (custom)
2019-09-19 08:54:12,060 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a does not exist. Creating ...
2019-09-19 08:54:12,062 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,095 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a has been successfully formatted.
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-81350EB5AF8A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,096 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,097 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,098 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start group-81350EB5AF8A
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,099 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start FollowerState
2019-09-19 08:54:12,100 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-81350EB5AF8A,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:12,106 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f341dfde-b316-4baa-8be5-81350eb5af8a, Nodes: a448d85b-ec9b-4560-ae6c-b2c8a1634a11{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,107 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,107 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,118 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-A8BF8D7B4433:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-A8BF8D7B4433:java.util.concurrent.CompletableFuture@1c75f658[Not completed]
2019-09-19 08:54:12,129 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-A8BF8D7B4433:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,131 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,132 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433 does not exist. Creating ...
2019-09-19 08:54:12,145 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,157 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433 has been successfully formatted.
2019-09-19 08:54:12,157 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A8BF8D7B4433: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,157 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433
2019-09-19 08:54:12,158 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,159 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,160 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,160 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,160 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,160 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-A8BF8D7B4433
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,161 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,162 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A8BF8D7B4433,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,170 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: bb7493e2-a290-4d1a-bccb-a8bf8d7b4433, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,172 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,172 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,181 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-B5E39996ABB1:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-B5E39996ABB1:java.util.concurrent.CompletableFuture@3f39bcc4[Not completed]
2019-09-19 08:54:12,183 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-B5E39996ABB1:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,184 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,185 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,185 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1 does not exist. Creating ...
2019-09-19 08:54:12,199 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,212 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1 has been successfully formatted.
2019-09-19 08:54:12,212 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B5E39996ABB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,212 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,212 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,212 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,213 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,214 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,215 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,215 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,215 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,216 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,216 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,216 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-B5E39996ABB1
2019-09-19 08:54:12,216 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,216 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,217 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5E39996ABB1,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,226 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: dc4b7dc7-4444-4ee8-833c-b5e39996abb1, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,231 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,231 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,251 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-BF6F8028AA44:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-BF6F8028AA44:java.util.concurrent.CompletableFuture@437202d3[Not completed]
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-BF6F8028AA44:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,253 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,254 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,254 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,254 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44 does not exist. Creating ...
2019-09-19 08:54:12,268 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,282 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44 has been successfully formatted.
2019-09-19 08:54:12,285 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-BF6F8028AA44: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,286 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,287 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,288 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,288 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,288 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,289 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,289 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,289 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,289 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-BF6F8028AA44
2019-09-19 08:54:12,290 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,290 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,290 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF6F8028AA44,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,294 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: aec74c59-0e3e-46a1-a804-bf6f8028aa44, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,295 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,295 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,303 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-2D12FF14B091:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-2D12FF14B091:java.util.concurrent.CompletableFuture@6c9d7683[Not completed]
2019-09-19 08:54:12,305 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-2D12FF14B091:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,305 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,306 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,307 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091 does not exist. Creating ...
2019-09-19 08:54:12,321 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,332 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:getStorageContainerLocationClient(241)) - Creating StorageContainerLocationProtocol RPC client with address /0.0.0.0:44546
2019-09-19 08:54:12,350 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091 has been successfully formatted.
2019-09-19 08:54:12,351 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-2D12FF14B091: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,351 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,351 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,352 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,359 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,359 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,360 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,360 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091
2019-09-19 08:54:12,360 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,360 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,360 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,361 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,362 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,362 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,362 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,363 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,363 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,363 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-2D12FF14B091
2019-09-19 08:54:12,363 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,363 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,364 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D12FF14B091,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,366 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 527a363f-05fb-4f65-9a66-967a904c0f03, with jenkins1000 as owner.
2019-09-19 08:54:12,370 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a133b14e-2d0f-46d5-be51-2d12ff14b091, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,371 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,371 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,389 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-C2EA2C9D0439:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-C2EA2C9D0439:java.util.concurrent.CompletableFuture@7438eb47[Not completed]
2019-09-19 08:54:12,391 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-C2EA2C9D0439:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,391 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,391 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,392 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,392 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,392 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,392 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,392 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,393 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439 does not exist. Creating ...
2019-09-19 08:54:12,405 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,418 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439 has been successfully formatted.
2019-09-19 08:54:12,419 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-C2EA2C9D0439: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,419 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,419 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,419 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,420 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,421 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,421 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,421 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,421 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,421 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,422 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,422 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,422 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,422 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,423 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,423 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,423 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,423 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-C2EA2C9D0439
2019-09-19 08:54:12,423 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,424 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,424 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2EA2C9D0439,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,429 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: be3538ca-bfa3-4226-a0a0-c2ea2c9d0439, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,430 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,430 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,438 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: addNew group-F7D78E7DC516:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] returns group-F7D78E7DC516:java.util.concurrent.CompletableFuture@18ae8505[Not completed]
2019-09-19 08:54:12,441 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: new RaftServerImpl for group-F7D78E7DC516:[6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014] with ContainerStateMachine:uninitialized
2019-09-19 08:54:12,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:12,441 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:12,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:12,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:12,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:12,442 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 ConfigurationManager, init=-1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:12,442 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis] (custom)
2019-09-19 08:54:12,443 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516 does not exist. Creating ...
2019-09-19 08:54:12,457 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516/in_use.lock acquired by nodename 26979@pr-hdds-1569-cpgw4-1311585219
2019-09-19 08:54:12,470 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516 has been successfully formatted.
2019-09-19 08:54:12,470 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F7D78E7DC516: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:12,470 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:12,471 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:12,472 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:12,473 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:12,471 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=527a363f-05fb-4f65-9a66-967a904c0f03, creationTime=1568883252421, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:12,474 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:12,475 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:12,475 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:12,475 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:12,476 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:12,476 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:12,476 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:12,477 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start group-F7D78E7DC516
2019-09-19 08:54:12,478 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:12,478 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start FollowerState
2019-09-19 08:54:12,479 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F7D78E7DC516,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:12,485 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=527a363f-05fb-4f65-9a66-967a904c0f03} | ret=SUCCESS |  
2019-09-19 08:54:12,487 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 52e88d3a-be9a-49a2-b2a4-f7d78e7dc516, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,491 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,491 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,492 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,493 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,493 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,495 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 527a363f-05fb-4f65-9a66-967a904c0f03/6e467bdc-5c32-40a7-b1b8-e4767c5dd91f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:12,525 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=527a363f-05fb-4f65-9a66-967a904c0f03, bucket=6e467bdc-5c32-40a7-b1b8-e4767c5dd91f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883252506} | ret=SUCCESS |  
2019-09-19 08:54:12,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=527a363f-05fb-4f65-9a66-967a904c0f03, bucket=6e467bdc-5c32-40a7-b1b8-e4767c5dd91f} | ret=SUCCESS |  
2019-09-19 08:54:12,562 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,562 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,563 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,563 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,563 [IPC Server handler 19 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,563 [IPC Server handler 19 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,564 [IPC Server handler 19 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,564 [IPC Server handler 19 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,564 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,568 [IPC Server handler 2 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 40501, call Call#14 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,573 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:12,577 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,578 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,578 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,578 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,578 [IPC Server handler 18 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,578 [IPC Server handler 18 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,579 [IPC Server handler 18 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,580 [IPC Server handler 18 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,580 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,582 [IPC Server handler 1 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 40501, call Call#14 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,584 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,594 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,594 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,594 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,595 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,595 [IPC Server handler 13 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,595 [IPC Server handler 13 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,595 [IPC Server handler 13 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,595 [IPC Server handler 13 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,595 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,596 [IPC Server handler 6 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 40501, call Call#14 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,598 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,602 [IPC Server handler 12 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,603 [IPC Server handler 12 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,603 [IPC Server handler 12 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,603 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,603 [IPC Server handler 7 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 40501, call Call#14 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,606 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,609 [IPC Server handler 15 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,610 [IPC Server handler 15 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,610 [IPC Server handler 15 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,610 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,611 [IPC Server handler 17 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 40501, call Call#14 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,613 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,615 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,616 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,616 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,617 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,617 [IPC Server handler 14 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,617 [IPC Server handler 14 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,617 [IPC Server handler 14 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,617 [IPC Server handler 14 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,617 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,618 [IPC Server handler 18 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 40501, call Call#14 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,620 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,622 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,623 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,623 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,623 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,623 [IPC Server handler 10 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,623 [IPC Server handler 10 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,624 [IPC Server handler 10 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,624 [IPC Server handler 10 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,625 [IPC Server handler 19 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 40501, call Call#14 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,627 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,629 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,630 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,630 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,630 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,630 [IPC Server handler 17 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,630 [IPC Server handler 17 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,631 [IPC Server handler 17 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,631 [IPC Server handler 17 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,631 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,631 [IPC Server handler 16 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 40501, call Call#14 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,638 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,642 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,642 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,642 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,643 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,643 [IPC Server handler 8 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,643 [IPC Server handler 8 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,644 [IPC Server handler 8 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,644 [IPC Server handler 8 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,644 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,645 [IPC Server handler 14 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 40501, call Call#14 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,647 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,650 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,650 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,651 [IPC Server handler 9 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,652 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,652 [IPC Server handler 15 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 40501, call Call#14 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,655 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,658 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,659 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,659 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,659 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,659 [IPC Server handler 11 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,659 [IPC Server handler 11 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,660 [IPC Server handler 11 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,660 [IPC Server handler 11 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,660 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,661 [IPC Server handler 13 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 40501, call Call#14 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,663 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:12,676 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: db37d202-865e-4015-837f-fbbd8c880a38, with jenkins1000 as owner.
2019-09-19 08:54:12,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=db37d202-865e-4015-837f-fbbd8c880a38, creationTime=1568883252679, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:12,695 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=db37d202-865e-4015-837f-fbbd8c880a38} | ret=SUCCESS |  
2019-09-19 08:54:12,696 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: db37d202-865e-4015-837f-fbbd8c880a38/755eac99-d2b1-41a7-9f2b-3eb0f52142fa, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:12,703 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=db37d202-865e-4015-837f-fbbd8c880a38, bucket=755eac99-d2b1-41a7-9f2b-3eb0f52142fa, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883252700} | ret=SUCCESS |  
2019-09-19 08:54:12,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=db37d202-865e-4015-837f-fbbd8c880a38, bucket=755eac99-d2b1-41a7-9f2b-3eb0f52142fa} | ret=SUCCESS |  
2019-09-19 08:54:12,729 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=db37d202-865e-4015-837f-fbbd8c880a38, bucket=755eac99-d2b1-41a7-9f2b-3eb0f52142fa, key=948fe37b-d4ed-48f6-b550-4c8878f55e70, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:12,758 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=db37d202-865e-4015-837f-fbbd8c880a38, bucket=755eac99-d2b1-41a7-9f2b-3eb0f52142fa, key=948fe37b-d4ed-48f6-b550-4c8878f55e70, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:12,770 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,770 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,770 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,771 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,771 [IPC Server handler 0 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,771 [IPC Server handler 0 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,772 [IPC Server handler 0 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,772 [IPC Server handler 0 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,773 [IPC Server handler 5 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 40501, call Call#32 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,774 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:12,775 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,776 [IPC Server handler 19 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,777 [IPC Server handler 4 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 40501, call Call#32 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,780 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,782 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,782 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,782 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,782 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,783 [IPC Server handler 18 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,783 [IPC Server handler 18 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,783 [IPC Server handler 18 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,783 [IPC Server handler 18 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,784 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,784 [IPC Server handler 3 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 40501, call Call#32 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,787 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,788 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,788 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,788 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,788 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,788 [IPC Server handler 13 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,789 [IPC Server handler 13 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,789 [IPC Server handler 13 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,789 [IPC Server handler 13 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,789 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,789 [IPC Server handler 2 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 40501, call Call#32 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,792 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,794 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,794 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,794 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,794 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,794 [IPC Server handler 12 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,795 [IPC Server handler 12 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,795 [IPC Server handler 12 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,795 [IPC Server handler 12 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,795 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,796 [IPC Server handler 1 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 40501, call Call#32 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,798 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,799 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,800 [IPC Server handler 15 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,801 [IPC Server handler 15 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,801 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,801 [IPC Server handler 6 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 40501, call Call#32 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,803 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,805 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,805 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,805 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,805 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,805 [IPC Server handler 14 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,806 [IPC Server handler 14 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,806 [IPC Server handler 14 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,806 [IPC Server handler 14 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,806 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,807 [IPC Server handler 7 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 40501, call Call#32 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,809 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,810 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,811 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,811 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,811 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,811 [IPC Server handler 10 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,811 [IPC Server handler 10 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,812 [IPC Server handler 10 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,812 [IPC Server handler 10 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,812 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,812 [IPC Server handler 17 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 40501, call Call#32 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,818 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,819 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,819 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,820 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,820 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,820 [IPC Server handler 17 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,820 [IPC Server handler 17 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,823 [IPC Server handler 17 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,824 [IPC Server handler 17 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,824 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,824 [IPC Server handler 18 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 40501, call Call#32 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,829 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,830 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,830 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,830 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,831 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,831 [IPC Server handler 8 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,831 [IPC Server handler 8 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,831 [IPC Server handler 8 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,831 [IPC Server handler 8 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,831 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,832 [IPC Server handler 19 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 40501, call Call#32 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,837 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:12,838 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,838 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,838 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:12,839 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,839 [IPC Server handler 9 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:12,839 [IPC Server handler 9 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,839 [IPC Server handler 9 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:12,839 [IPC Server handler 9 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:12,839 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:12,840 [IPC Server handler 16 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 40501, call Call#32 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:12,841 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:12,842 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUpload(TestOzoneRpcClientAbstract.java:1833)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:12,843 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0f944ac1-921a-40af-a534-e86af64414a7, with jenkins1000 as owner.
2019-09-19 08:54:12,852 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:12,856 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0f944ac1-921a-40af-a534-e86af64414a7, creationTime=1568883252844, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:12,858 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0f944ac1-921a-40af-a534-e86af64414a7} | ret=SUCCESS |  
2019-09-19 08:54:12,859 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0f944ac1-921a-40af-a534-e86af64414a7/d57768b3-3b92-4eb9-bd18-f297a6c42f46, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:12,868 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0f944ac1-921a-40af-a534-e86af64414a7, bucket=d57768b3-3b92-4eb9-bd18-f297a6c42f46, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883252860} | ret=SUCCESS |  
2019-09-19 08:54:12,869 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0f944ac1-921a-40af-a534-e86af64414a7, bucket=d57768b3-3b92-4eb9-bd18-f297a6c42f46} | ret=SUCCESS |  
2019-09-19 08:54:12,881 [Thread-182] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-19 08:54:12,884 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-19 08:54:12,906 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=0f944ac1-921a-40af-a534-e86af64414a7, bucket=d57768b3-3b92-4eb9-bd18-f297a6c42f46, key=56e61b30-3763-427a-8c97-1591b37c317f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:12,919 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=0f944ac1-921a-40af-a534-e86af64414a7, bucket=d57768b3-3b92-4eb9-bd18-f297a6c42f46, key=56e61b30-3763-427a-8c97-1591b37c317f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:12,920 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 2f602716-ab9c-4961-baad-4c5b8011fd7a, with jenkins1000 as owner.
2019-09-19 08:54:12,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, creationTime=1568883252921, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:12,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a} | ret=SUCCESS |  
2019-09-19 08:54:12,933 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 2f602716-ab9c-4961-baad-4c5b8011fd7a/92728a92-c3f1-42ea-897d-73d54777c726, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:12,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883252934} | ret=SUCCESS |  
2019-09-19 08:54:12,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726} | ret=SUCCESS |  
2019-09-19 08:54:12,960 [IPC Server handler 11 on 41217] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4570369a-28f8-4c21-a1aa-eeb2289e9a9f, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
2019-09-19 08:54:12,979 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:13,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332867100676
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,031 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-09-19 08:54:13,307 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,330 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332867100676 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:13,440 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332867100676 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:13,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332867100676
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,487 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:13,504 [IPC Server handler 1 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:13,505 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:13,507 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:13,529 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | INVALID_KEY_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Key name is empty
	at org.apache.hadoop.ozone.om.request.key.OMKeyRenameRequest.validateAndUpdateCache(OMKeyRenameRequest.java:117)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:13,531 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRenameRequest (OMKeyRenameRequest.java:validateAndUpdateCache(194)) - Rename key failed for volume:2f602716-ab9c-4961-baad-4c5b8011fd7a bucket:92728a92-c3f1-42ea-897d-73d54777c726 fromKey:9bb545b9-ac0a-4400-8f6b-00a5f2f1364a toKey:. Key: 9bb545b9-ac0a-4400-8f6b-00a5f2f1364a not found.
2019-09-19 08:54:13,547 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,549 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=9bb545b9-ac0a-4400-8f6b-00a5f2f1364a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-19 08:54:13,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:13,554 [IPC Server handler 2 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:13,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:13,555 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=2f602716-ab9c-4961-baad-4c5b8011fd7a, bucket=92728a92-c3f1-42ea-897d-73d54777c726, key=60496703-c92f-4dbe-941f-218f35b1fef0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:13,557 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 011a6bf8-0197-45ba-b193-dd9a857f95d2, with jenkins1000 as owner.
2019-09-19 08:54:13,570 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=011a6bf8-0197-45ba-b193-dd9a857f95d2, creationTime=1568883253558, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:13,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=011a6bf8-0197-45ba-b193-dd9a857f95d2} | ret=SUCCESS |  
2019-09-19 08:54:13,572 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 011a6bf8-0197-45ba-b193-dd9a857f95d2/bd331f9c-94d7-440f-bd36-90c1e8f83c5c, with Versioning true and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:13,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=011a6bf8-0197-45ba-b193-dd9a857f95d2, bucket=bd331f9c-94d7-440f-bd36-90c1e8f83c5c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=true, storageType=DISK, creationTime=1568883253573} | ret=SUCCESS |  
2019-09-19 08:54:13,583 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=011a6bf8-0197-45ba-b193-dd9a857f95d2, bucket=bd331f9c-94d7-440f-bd36-90c1e8f83c5c} | ret=SUCCESS |  
2019-09-19 08:54:13,605 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {7333fd43-d15b-44c8-b150-9a06c47bfaab=s3Bucket, jenkins1000=username} | ret=SUCCESS |  
2019-09-19 08:54:13,610 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3jenkins1000} | ret=SUCCESS |  
2019-09-19 08:54:13,611 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3jenkins1000, bucket=7333fd43-d15b-44c8-b150-9a06c47bfaab} | ret=SUCCESS |  
2019-09-19 08:54:13,612 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 7bd55594-8f56-4311-974e-47d74518855b, with jenkins1000 as owner.
2019-09-19 08:54:13,625 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=7bd55594-8f56-4311-974e-47d74518855b, creationTime=1568883253613, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:13,627 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=7bd55594-8f56-4311-974e-47d74518855b} | ret=SUCCESS |  
2019-09-19 08:54:13,628 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 7bd55594-8f56-4311-974e-47d74518855b/f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:13,641 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883253629} | ret=SUCCESS |  
2019-09-19 08:54:13,643 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65} | ret=SUCCESS |  
2019-09-19 08:54:13,653 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,666 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,676 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:13,680 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818332911534087} | ret=SUCCESS |  
2019-09-19 08:54:13,690 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332912844808 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:13,699 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332912844808 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:13,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332912844808
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=19, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,727 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:13,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:13,743 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=19, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818332915859465} | ret=SUCCESS |  
2019-09-19 08:54:13,749 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332916252682 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:13,753 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332916252682 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:13,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=7bd55594-8f56-4311-974e-47d74518855b, bucket=f26d35b3-4f21-4bca-b7ba-5f43b7ef8e65, key=1eee7958-ba3b-40eb-a875-0ba65557be3f, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332916252682
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,768 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4f3363d6-2b1f-4b3a-b21b-a217e67e380c, with jenkins1000 as owner.
2019-09-19 08:54:13,782 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, creationTime=1568883253769, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:13,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c} | ret=SUCCESS |  
2019-09-19 08:54:13,785 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4f3363d6-2b1f-4b3a-b21b-a217e67e380c/1723c257-1df9-4e4f-a0c8-546867102f50, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:13,798 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883253786} | ret=SUCCESS |  
2019-09-19 08:54:13,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50} | ret=SUCCESS |  
2019-09-19 08:54:13,803 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:13,817 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332921167883
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,829 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332921167883 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:13,832 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332921167883 bcsId: 0,size=2350]} | ret=SUCCESS |  
2019-09-19 08:54:13,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=2350, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332921167883
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2350
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,852 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:13,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir2c0a5de02-4725-4a93-b9b1-477ad99e2592, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332924444685
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,870 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332924444685 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:13,875 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332924444685 bcsId: 0,size=2359]} | ret=SUCCESS |  
2019-09-19 08:54:13,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir2c0a5de02-4725-4a93-b9b1-477ad99e2592, dataSize=2359, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332924444685
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2359
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:13,928 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:13,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:13,953 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:13,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:13,958 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,008 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,010 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:14,019 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,034 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,036 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,055 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,093 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:14,096 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:14,237 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332940435471
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:14,245 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818332940435471 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:14,250 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818332940435471 bcsId: 0,size=2378]} | ret=SUCCESS |  
2019-09-19 08:54:14,263 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=2378, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818332940435471
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2378
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:14,265 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=null} | ret=SUCCESS |  
2019-09-19 08:54:14,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:14,294 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:14,309 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/} | ret=SUCCESS |  
2019-09-19 08:54:14,327 [IPC Server handler 3 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-0_96 to index:96
2019-09-19 08:54:14,330 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_0-96
2019-09-19 08:54:14,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:15,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:15,294 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:15,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:15,818 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF changes to CANDIDATE, lastRpcTime:5059, electionTimeout:5059ms
2019-09-19 08:54:15,820 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:15,820 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:15,820 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,003 [Thread-190] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 changes to CANDIDATE, lastRpcTime:5058, electionTimeout:5058ms
2019-09-19 08:54:16,004 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:16,004 [Thread-190] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,004 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:16,012 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 changes to CANDIDATE, lastRpcTime:5013, electionTimeout:5013ms
2019-09-19 08:54:16,012 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:16,012 [Thread-193] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,012 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,016 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 changes to CANDIDATE, lastRpcTime:5138, electionTimeout:5138ms
2019-09-19 08:54:16,016 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:16,016 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,016 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,075 [Thread-196] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 changes to CANDIDATE, lastRpcTime:5021, electionTimeout:5021ms
2019-09-19 08:54:16,076 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:16,076 [Thread-196] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,076 [Thread-196] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,177 [Thread-199] INFO  impl.FollowerState (FollowerState.java:run(106)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B changes to CANDIDATE, lastRpcTime:5065, electionTimeout:5065ms
2019-09-19 08:54:16,178 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown FollowerState
2019-09-19 08:54:16,178 [Thread-199] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,178 [Thread-199] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderElection
2019-09-19 08:54:16,294 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:16,701 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5957ms
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,709 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,703 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5: begin an election at term 1 for -1: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,710 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,710 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderElection
2019-09-19 08:54:16,710 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,710 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,712 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5716ms
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5771ms
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,711 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5838ms
2019-09-19 08:54:16,712 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,712 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5662ms
2019-09-19 08:54:16,712 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,712 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,713 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B change Leader from null to 18897f3d-a606-48ca-8ab1-50a74a285275 at term 1 for becomeLeader, leader elected after 5605ms
2019-09-19 08:54:16,714 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,714 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,714 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,714 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,714 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,715 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,717 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,717 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef: Starting segment from index:0
2019-09-19 08:54:16,717 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,717 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,716 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,719 [18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,718 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,755 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30: Starting segment from index:0
2019-09-19 08:54:16,755 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,719 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:16,756 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2: Starting segment from index:0
2019-09-19 08:54:16,756 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1: Starting segment from index:0
2019-09-19 08:54:16,755 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365: Starting segment from index:0
2019-09-19 08:54:16,756 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,756 [18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,757 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,758 [18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,758 [18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,758 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,803 [18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,805 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 18897f3d-a606-48ca-8ab1-50a74a285275: start LeaderState
2019-09-19 08:54:16,806 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b: Starting segment from index:0
2019-09-19 08:54:16,807 [18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B set configuration 0: [18897f3d-a606-48ca-8ab1-50a74a285275:192.168.157.204:38850], old=null at 0
2019-09-19 08:54:16,842 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365/current/log_inprogress_0
2019-09-19 08:54:16,842 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1/current/log_inprogress_0
2019-09-19 08:54:16,842 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef/current/log_inprogress_0
2019-09-19 08:54:16,842 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2/current/log_inprogress_0
2019-09-19 08:54:16,842 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30/current/log_inprogress_0
2019-09-19 08:54:16,870 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b/current/log_inprogress_0
2019-09-19 08:54:16,882 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:16,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:16,893 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A changes to CANDIDATE, lastRpcTime:5050, electionTimeout:5050ms
2019-09-19 08:54:16,893 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:16,894 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,894 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:16,898 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333123215377
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:16,904 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333123215377 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:16,907 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333123215377 bcsId: 0,size=2391]} | ret=SUCCESS |  
2019-09-19 08:54:16,911 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e, dataSize=2391, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333123215377
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2391
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:16,912 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/} | ret=SUCCESS |  
2019-09-19 08:54:16,914 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=4f3363d6-2b1f-4b3a-b21b-a217e67e380c, bucket=1723c257-1df9-4e4f-a0c8-546867102f50, key=dir1/dir22cdce7d2-d6e0-4d30-92df-65b4047e681e} | ret=SUCCESS |  
2019-09-19 08:54:16,915 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 673676cb-f432-4b48-a48f-f1fb06f156c2, with jenkins1000 as owner.
2019-09-19 08:54:16,924 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:16,924 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:16,924 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,924 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5086ms
2019-09-19 08:54:16,924 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,925 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=673676cb-f432-4b48-a48f-f1fb06f156c2, creationTime=1568883256916, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:16,925 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a: Starting segment from index:0
2019-09-19 08:54:16,926 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:16,928 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=673676cb-f432-4b48-a48f-f1fb06f156c2} | ret=SUCCESS |  
2019-09-19 08:54:16,928 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 673676cb-f432-4b48-a48f-f1fb06f156c2/a3c50e49-32e3-47c9-b4ea-2f36b7af0b93, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:16,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=673676cb-f432-4b48-a48f-f1fb06f156c2, bucket=a3c50e49-32e3-47c9-b4ea-2f36b7af0b93, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883256929} | ret=SUCCESS |  
2019-09-19 08:54:16,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=673676cb-f432-4b48-a48f-f1fb06f156c2, bucket=a3c50e49-32e3-47c9-b4ea-2f36b7af0b93} | ret=SUCCESS |  
2019-09-19 08:54:16,938 [Thread-205] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 changes to CANDIDATE, lastRpcTime:5039, electionTimeout:5039ms
2019-09-19 08:54:16,938 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:16,939 [Thread-205] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:16,939 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:16,954 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=673676cb-f432-4b48-a48f-f1fb06f156c2, bucket=a3c50e49-32e3-47c9-b4ea-2f36b7af0b93} | ret=SUCCESS |  
2019-09-19 08:54:16,955 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=673676cb-f432-4b48-a48f-f1fb06f156c2, bucket=a3c50e49-32e3-47c9-b4ea-2f36b7af0b93, key=null} | ret=SUCCESS |  
2019-09-19 08:54:16,955 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: aa769b13-54e5-45fb-8b94-cd5b1e004935, with jenkins1000 as owner.
2019-09-19 08:54:16,965 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a/current/log_inprogress_0
2019-09-19 08:54:16,965 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:16,965 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:16,965 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5069ms
2019-09-19 08:54:16,965 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, creationTime=1568883256956, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:16,966 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:16,967 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33: Starting segment from index:0
2019-09-19 08:54:16,967 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935} | ret=SUCCESS |  
2019-09-19 08:54:16,967 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:16,993 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: aa769b13-54e5-45fb-8b94-cd5b1e004935/a0f78cfd-9778-4a2f-abcc-8ae09c78982c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:16,999 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883256995} | ret=SUCCESS |  
2019-09-19 08:54:17,000 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c} | ret=SUCCESS |  
2019-09-19 08:54:17,003 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:17,010 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,013 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33/current/log_inprogress_0
2019-09-19 08:54:17,027 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c, key=15f6264f-63dc-416c-bb33-a66e7f9c0c04, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818333130883091
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "99f0d179-1c0b-4b8a-81fa-220f5c9ded30"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:17,054 [Thread-214] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 changes to CANDIDATE, lastRpcTime:5016, electionTimeout:5016ms
2019-09-19 08:54:17,054 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:17,054 [Thread-214] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,055 [Thread-214] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:17,071 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:17,071 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:17,071 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,071 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5036ms
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,072 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:17,073 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5: Starting segment from index:0
2019-09-19 08:54:17,073 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:17,105 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5/current/log_inprogress_0
2019-09-19 08:54:17,115 [Thread-208] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 changes to CANDIDATE, lastRpcTime:5165, electionTimeout:5165ms
2019-09-19 08:54:17,115 [Thread-208] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:17,115 [Thread-208] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,115 [Thread-208] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:17,120 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A changes to CANDIDATE, lastRpcTime:5020, electionTimeout:5020ms
2019-09-19 08:54:17,120 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:17,120 [Thread-219] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,120 [Thread-219] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5221ms
2019-09-19 08:54:17,167 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5071ms
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,168 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2: Starting segment from index:0
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a: Starting segment from index:0
2019-09-19 08:54:17,169 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:17,195 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(106)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 changes to CANDIDATE, lastRpcTime:5201, electionTimeout:5197ms
2019-09-19 08:54:17,195 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:17,195 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown FollowerState
2019-09-19 08:54:17,196 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,196 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderElection
2019-09-19 08:54:17,199 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2/current/log_inprogress_0
2019-09-19 08:54:17,199 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a/current/log_inprogress_0
2019-09-19 08:54:17,224 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13: begin an election at term 1 for -1: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null
2019-09-19 08:54:17,224 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderElection
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 change Leader from null to a448d85b-ec9b-4560-ae6c-b2c8a1634a11 at term 1 for becomeLeader, leader elected after 5234ms
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,225 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818333130883091 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,225 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,226 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,226 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,226 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: start LeaderState
2019-09-19 08:54:17,226 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63: Starting segment from index:0
2019-09-19 08:54:17,227 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 set configuration 0: [a448d85b-ec9b-4560-ae6c-b2c8a1634a11:192.168.157.204:45142], old=null at 0
2019-09-19 08:54:17,251 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818333130883091 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,263 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CE1EB35B62C6->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-CE1EB35B62C6->18897f3d-a606-48ca-8ab1-50a74a285275@group-220F5C9DED30, cid=18, SUCCESS, logIndex=1, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c1]
2019-09-19 08:54:17,274 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63/current/log_inprogress_0
2019-09-19 08:54:17,286 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 changes to CANDIDATE, lastRpcTime:5124, electionTimeout:5124ms
2019-09-19 08:54:17,286 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,286 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,286 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,369 [Thread-229] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 changes to CANDIDATE, lastRpcTime:5079, electionTimeout:5079ms
2019-09-19 08:54:17,369 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,370 [Thread-229] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,370 [Thread-229] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,376 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,376 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5219ms
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,377 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,378 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,378 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433: Starting segment from index:0
2019-09-19 08:54:17,378 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,413 [Thread-225] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 changes to CANDIDATE, lastRpcTime:5196, electionTimeout:5181ms
2019-09-19 08:54:17,413 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,413 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,413 [Thread-225] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,413 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,414 [Thread-225] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,414 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,414 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102818333130883091 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:17,414 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5128ms
2019-09-19 08:54:17,418 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,418 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,419 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,421 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,421 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,421 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,421 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,422 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44: Starting segment from index:0
2019-09-19 08:54:17,422 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,446 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433/current/log_inprogress_0
2019-09-19 08:54:17,447 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CE1EB35B62C6->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-CE1EB35B62C6->18897f3d-a606-48ca-8ab1-50a74a285275@group-220F5C9DED30, cid=19, SUCCESS, logIndex=3, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c4]
2019-09-19 08:54:17,447 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,447 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,447 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,447 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5235ms
2019-09-19 08:54:17,448 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,448 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,448 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,448 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 changes to CANDIDATE, lastRpcTime:5084, electionTimeout:5084ms
2019-09-19 08:54:17,448 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,448 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,448 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,449 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,449 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,449 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,449 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,453 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1: Starting segment from index:0
2019-09-19 08:54:17,453 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44/current/log_inprogress_0
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5130ms
2019-09-19 08:54:17,481 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,482 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,483 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091: Starting segment from index:0
2019-09-19 08:54:17,483 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,508 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1/current/log_inprogress_0
2019-09-19 08:54:17,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c, key=15f6264f-63dc-416c-bb33-a66e7f9c0c04, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818333130883091
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "99f0d179-1c0b-4b8a-81fa-220f5c9ded30"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:17,513 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:17,515 [IPC Server handler 5 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:17,515 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:17,516 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c, key=15f6264f-63dc-416c-bb33-a66e7f9c0c04, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:17,521 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091/current/log_inprogress_0
2019-09-19 08:54:17,574 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:17,575 [IPC Server handler 4 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:17,576 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:17,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=aa769b13-54e5-45fb-8b94-cd5b1e004935, bucket=a0f78cfd-9778-4a2f-abcc-8ae09c78982c, key=15f6264f-63dc-416c-bb33-a66e7f9c0c04, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:17,608 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 changes to CANDIDATE, lastRpcTime:5184, electionTimeout:5184ms
2019-09-19 08:54:17,608 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,608 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,609 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,622 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102818333130883091 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:17,626 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,626 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5207ms
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,627 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 changes to CANDIDATE, lastRpcTime:5149, electionTimeout:5149ms
2019-09-19 08:54:17,627 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,627 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown FollowerState
2019-09-19 08:54:17,628 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,628 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:17,628 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,628 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderElection
2019-09-19 08:54:17,628 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439: Starting segment from index:0
2019-09-19 08:54:17,631 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,668 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439/current/log_inprogress_0
2019-09-19 08:54:17,669 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19: begin an election at term 1 for -1: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null
2019-09-19 08:54:17,670 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102818333130883091 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:17,670 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderElection
2019-09-19 08:54:17,670 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:17,670 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 change Leader from null to 6e2100fe-d804-4987-9ac5-bcccf3c0d596 at term 1 for becomeLeader, leader elected after 5199ms
2019-09-19 08:54:17,670 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: start LeaderState
2019-09-19 08:54:17,671 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516: Starting segment from index:0
2019-09-19 08:54:17,674 [6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 set configuration 0: [6e2100fe-d804-4987-9ac5-bcccf3c0d596:192.168.157.204:43014], old=null at 0
2019-09-19 08:54:17,704 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ee01d913-5206-4625-b144-3b0dab84f3e5, with jenkins1000 as owner.
2019-09-19 08:54:17,716 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ee01d913-5206-4625-b144-3b0dab84f3e5, creationTime=1568883257705, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:17,718 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ee01d913-5206-4625-b144-3b0dab84f3e5} | ret=SUCCESS |  
2019-09-19 08:54:17,719 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ee01d913-5206-4625-b144-3b0dab84f3e5/a3918bc1-f999-4d1b-8af9-e9e120d8f1bc, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:17,727 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516/current/log_inprogress_0
2019-09-19 08:54:17,731 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883257720} | ret=SUCCESS |  
2019-09-19 08:54:17,733 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc} | ret=SUCCESS |  
2019-09-19 08:54:17,734 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc, key=null} | ret=SUCCESS |  
2019-09-19 08:54:17,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-19 08:54:17,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,756 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc} | ret=SUCCESS |  
2019-09-19 08:54:17,757 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=ee01d913-5206-4625-b144-3b0dab84f3e5, bucket=a3918bc1-f999-4d1b-8af9-e9e120d8f1bc, key=null} | ret=SUCCESS |  
2019-09-19 08:54:17,758 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 97208161-eee2-4d28-a09a-6e9909a99b5d, with jenkins1000 as owner.
2019-09-19 08:54:17,771 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=97208161-eee2-4d28-a09a-6e9909a99b5d, creationTime=1568883257759, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:17,772 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=97208161-eee2-4d28-a09a-6e9909a99b5d} | ret=SUCCESS |  
2019-09-19 08:54:17,773 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 97208161-eee2-4d28-a09a-6e9909a99b5d/1ed099fa-d891-4621-b117-2f4d75c4d9f7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:17,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883257773} | ret=SUCCESS |  
2019-09-19 08:54:17,787 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7} | ret=SUCCESS |  
2019-09-19 08:54:17,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,806 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:17,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333183377430} | ret=SUCCESS |  
2019-09-19 08:54:17,855 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333183705111 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,859 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333183705111 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:17,876 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333183705111 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,880 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333183705111 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:17,893 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333183705111 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,899 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333183705111 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:17,911 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333183705111 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,916 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333183705111 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:17,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:17,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333183377430} | ret=SUCCESS |  
2019-09-19 08:54:17,944 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333190914072 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:17,947 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333190914072 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:17,978 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333183705111
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333190914072
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:17,996 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:17,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:18,007 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333195239449} | ret=SUCCESS |  
2019-09-19 08:54:18,010 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,020 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333196222490 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,023 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333196222490 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:18,036 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333196222490 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,041 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333196222490 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:18,052 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333196222490 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,057 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333196222490 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:18,068 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333196222490 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,073 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333196222490 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:18,077 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:18,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333195239449} | ret=SUCCESS |  
2019-09-19 08:54:18,102 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333201268763 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,105 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333201268763 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:18,121 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333196222490
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333201268763
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:18,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,141 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:18,154 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333204545564} | ret=SUCCESS |  
2019-09-19 08:54:18,166 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333205528605 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,171 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333205528605 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:18,183 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333205528605 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,188 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333205528605 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:18,200 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333205528605 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,208 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333205528605 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:18,220 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333205528605 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,224 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333205528605 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:18,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:18,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818333204545564} | ret=SUCCESS |  
2019-09-19 08:54:18,245 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333211099166 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:18,249 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333211099166 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:18,258 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333205528605
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333211099166
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:18,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=97208161-eee2-4d28-a09a-6e9909a99b5d, bucket=1ed099fa-d891-4621-b117-2f4d75c4d9f7, uploadID=6ce22f68-5f67-47f8-8521-0ba413bcddb6-102818333182394389, partNumberMarker=0, maxParts=3, key=90fec2ce-bd4e-48f9-9ada-f84378d9fb95} | ret=SUCCESS |  
2019-09-19 08:54:18,272 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: bd7ddbda-e90c-4795-b21b-681bcadeac99, with jenkins1000 as owner.
2019-09-19 08:54:18,286 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, creationTime=1568883258273, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:18,287 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=bd7ddbda-e90c-4795-b21b-681bcadeac99} | ret=SUCCESS |  
2019-09-19 08:54:18,288 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bd7ddbda-e90c-4795-b21b-681bcadeac99/251a501e-b368-487d-b59d-0831d6ada7f4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:18,300 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883258288} | ret=SUCCESS |  
2019-09-19 08:54:18,301 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4} | ret=SUCCESS |  
2019-09-19 08:54:18,327 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,343 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,344 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,382 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,387 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4} | ret=SUCCESS |  
2019-09-19 08:54:18,446 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bd7ddbda-e90c-4795-b21b-681bcadeac99/251a501e-b368-487d-b59d-0831d6ada7f4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:18,459 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:remoteUser:r[ACCESS], group:remoteGroup:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883258447} | ret=SUCCESS |  
2019-09-19 08:54:18,462 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,464 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=bd7ddbda-e90c-4795-b21b-681bcadeac99, bucket=251a501e-b368-487d-b59d-0831d6ada7f4, key=null} | ret=SUCCESS |  
2019-09-19 08:54:18,483 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {51070bbb-fd14-46fb-9c01-ec919cbf3c82=s3Bucket} | ret=FAILURE | S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 51070bbb-fd14-46fb-9c01-ec919cbf3c82 not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:18,485 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.S3BucketDeleteRequest (S3BucketDeleteRequest.java:validateAndUpdateCache(175)) - S3Bucket Deletion failed for S3Bucket:51070bbb-fd14-46fb-9c01-ec919cbf3c82
S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 51070bbb-fd14-46fb-9c01-ec919cbf3c82 not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:18,490 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 74424209-3802-4d90-98e1-680f62ad7fab, with jenkins1000 as owner.
2019-09-19 08:54:18,504 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=74424209-3802-4d90-98e1-680f62ad7fab, creationTime=1568883258492, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:18,506 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=74424209-3802-4d90-98e1-680f62ad7fab} | ret=SUCCESS |  
2019-09-19 08:54:18,506 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 74424209-3802-4d90-98e1-680f62ad7fab/f23cfc74-5c01-41fb-b51c-b3957dcea3e2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:18,519 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=74424209-3802-4d90-98e1-680f62ad7fab, bucket=f23cfc74-5c01-41fb-b51c-b3957dcea3e2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883258507} | ret=SUCCESS |  
2019-09-19 08:54:18,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=74424209-3802-4d90-98e1-680f62ad7fab, bucket=f23cfc74-5c01-41fb-b51c-b3957dcea3e2} | ret=SUCCESS |  
2019-09-19 08:54:18,523 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=74424209-3802-4d90-98e1-680f62ad7fab, bucket=f23cfc74-5c01-41fb-b51c-b3957dcea3e2, uploadID=random, partNumberMarker=100, maxParts=2, key=ed0337c9-336c-4018-b1ef-738cafea73d4} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No Such Multipart upload exists for this key.
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listParts(KeyManagerImpl.java:1294)
	at org.apache.hadoop.ozone.om.OzoneManager.listParts(OzoneManager.java:2846) 
2019-09-19 08:54:18,524 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0fb1bc9e-be26-4ebc-bad2-54d865deb977, with jenkins1000 as owner.
2019-09-19 08:54:18,526 [IPC Server handler 6 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-97_190 to index:190
2019-09-19 08:54:18,526 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_97-190
2019-09-19 08:54:18,574 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191
2019-09-19 08:54:18,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977, creationTime=1568883258525, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:18,599 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977} | ret=SUCCESS |  
2019-09-19 08:54:18,600 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0fb1bc9e-be26-4ebc-bad2-54d865deb977/1fd663ba-0858-499c-b9dc-ac5cf3aeff30, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:18,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977, bucket=1fd663ba-0858-499c-b9dc-ac5cf3aeff30, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883258601} | ret=SUCCESS |  
2019-09-19 08:54:18,622 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977, bucket=1fd663ba-0858-499c-b9dc-ac5cf3aeff30} | ret=SUCCESS |  
2019-09-19 08:54:18,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977, bucket=1fd663ba-0858-499c-b9dc-ac5cf3aeff30, key=da72af71-29e2-421b-8727-24eba594e3ac, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,863 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=0fb1bc9e-be26-4ebc-bad2-54d865deb977, bucket=1fd663ba-0858-499c-b9dc-ac5cf3aeff30, key=da72af71-29e2-421b-8727-24eba594e3ac, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:18,866 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,867 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,867 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,867 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,867 [IPC Server handler 1 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,867 [IPC Server handler 1 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,868 [IPC Server handler 1 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,868 [IPC Server handler 1 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,868 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,868 [IPC Server handler 14 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 40501, call Call#245 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,871 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:18,873 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,873 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,873 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,873 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,873 [IPC Server handler 2 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,874 [IPC Server handler 2 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,874 [IPC Server handler 2 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,874 [IPC Server handler 2 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,874 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,875 [IPC Server handler 15 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 40501, call Call#245 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,877 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,878 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,878 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,878 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,878 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,879 [IPC Server handler 5 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,879 [IPC Server handler 5 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,879 [IPC Server handler 5 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,879 [IPC Server handler 5 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,879 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,880 [IPC Server handler 13 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 40501, call Call#245 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,882 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,883 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,883 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,883 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,884 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,884 [IPC Server handler 4 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,884 [IPC Server handler 4 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,884 [IPC Server handler 4 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,884 [IPC Server handler 4 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,885 [IPC Server handler 12 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 40501, call Call#245 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,887 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,888 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,888 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,888 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,888 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,889 [IPC Server handler 6 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,889 [IPC Server handler 6 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,889 [IPC Server handler 6 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,889 [IPC Server handler 6 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,889 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,890 [IPC Server handler 11 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 40501, call Call#245 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,891 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,893 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,893 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,893 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,894 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,894 [IPC Server handler 7 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,894 [IPC Server handler 7 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,894 [IPC Server handler 7 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,894 [IPC Server handler 7 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,895 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,895 [IPC Server handler 10 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 40501, call Call#245 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,897 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,898 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,899 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,899 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,899 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,899 [IPC Server handler 3 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,899 [IPC Server handler 3 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,900 [IPC Server handler 3 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,900 [IPC Server handler 3 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,900 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,901 [IPC Server handler 9 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 40501, call Call#245 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,903 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,904 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,904 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,904 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,905 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,905 [IPC Server handler 16 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,905 [IPC Server handler 16 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,906 [IPC Server handler 16 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,906 [IPC Server handler 16 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,906 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,906 [IPC Server handler 8 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 40501, call Call#245 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,908 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,909 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,910 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,910 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,910 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,910 [IPC Server handler 12 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,911 [IPC Server handler 12 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,911 [IPC Server handler 12 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,911 [IPC Server handler 12 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,911 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,912 [IPC Server handler 0 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 40501, call Call#245 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,914 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,915 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,915 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,915 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,916 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,916 [IPC Server handler 13 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,916 [IPC Server handler 13 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,916 [IPC Server handler 13 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,917 [IPC Server handler 13 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,917 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,917 [IPC Server handler 5 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 40501, call Call#245 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,919 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:18,920 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:18,921 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,921 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:18,921 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,921 [IPC Server handler 19 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:18,921 [IPC Server handler 19 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,922 [IPC Server handler 19 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:18,922 [IPC Server handler 19 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:18,922 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:18,923 [IPC Server handler 4 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 40501, call Call#245 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:18,924 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:18,925 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testUploadPartOverrideWithRatis(TestOzoneRpcClientAbstract.java:1773)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:18,927 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-90837, with jenkins1000 as owner.
2019-09-19 08:54:19,010 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:19,028 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-90837, creationTime=1568883258929, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:19,031 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-53438, with jenkins1000 as owner.
2019-09-19 08:54:19,103 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-53438, creationTime=1568883259033, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:19,105 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-90837} | ret=SUCCESS |  
2019-09-19 08:54:19,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-53438} | ret=SUCCESS |  
2019-09-19 08:54:19,107 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-0-32849, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:19,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-0-32849, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259108} | ret=SUCCESS |  
2019-09-19 08:54:19,193 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-0-48565, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:19,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:19,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-0-48565, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259194} | ret=SUCCESS |  
2019-09-19 08:54:19,413 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-1-75689, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:19,581 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-1-75689, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259414} | ret=SUCCESS |  
2019-09-19 08:54:19,583 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-1-19433, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:19,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:19,818 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-1-19433, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259583} | ret=SUCCESS |  
2019-09-19 08:54:19,818 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-2-05635, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:19,950 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-2-05635, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259819} | ret=SUCCESS |  
2019-09-19 08:54:19,950 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-2-61840, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:20,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:20,014 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-2-61840, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883259951} | ret=SUCCESS |  
2019-09-19 08:54:20,014 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-3-87953, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:20,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:20,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-3-87953, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883260015} | ret=SUCCESS |  
2019-09-19 08:54:20,708 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-3-75343, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:20,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:21,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:21,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:21,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:22,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:22,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:22,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:22,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-3-75343, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883260709} | ret=SUCCESS |  
2019-09-19 08:54:22,989 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-4-15728, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:23,102 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-4-15728, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883262990} | ret=SUCCESS |  
2019-09-19 08:54:23,103 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-4-96386, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-4-96386, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263104} | ret=SUCCESS |  
2019-09-19 08:54:23,135 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-5-33247, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:23,256 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-5-33247, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263136} | ret=SUCCESS |  
2019-09-19 08:54:23,257 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-5-79439, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,313 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-5-79439, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263258} | ret=SUCCESS |  
2019-09-19 08:54:23,314 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-6-77772, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,360 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-6-77772, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263315} | ret=SUCCESS |  
2019-09-19 08:54:23,360 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-6-61627, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,640 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-6-61627, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263361} | ret=SUCCESS |  
2019-09-19 08:54:23,641 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-7-94604, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:23,795 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-7-94604, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263642} | ret=SUCCESS |  
2019-09-19 08:54:23,796 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-7-25734, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,891 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-7-25734, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263797} | ret=SUCCESS |  
2019-09-19 08:54:23,892 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-8-89953, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:23,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-8-89953, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263893} | ret=SUCCESS |  
2019-09-19 08:54:23,957 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-8-09434, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:24,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:24,086 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-8-09434, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883263958} | ret=SUCCESS |  
2019-09-19 08:54:24,087 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-a-9-21698, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:24,142 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-a-9-21698, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883264089} | ret=SUCCESS |  
2019-09-19 08:54:24,143 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-a-9-94878, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:24,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:24,237 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-a-9-94878, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883264144} | ret=SUCCESS |  
2019-09-19 08:54:24,238 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-0-98693, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:24,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:25,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:25,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:25,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:26,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:26,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:26,386 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-0-98693, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883264239} | ret=SUCCESS |  
2019-09-19 08:54:26,387 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-0-79284, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:26,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:26,809 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-0-79284, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883266388} | ret=SUCCESS |  
2019-09-19 08:54:26,810 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-1-72469, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:26,922 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-1-72469, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883266811} | ret=SUCCESS |  
2019-09-19 08:54:26,923 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-1-49915, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:27,131 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-1-49915, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883266924} | ret=SUCCESS |  
2019-09-19 08:54:27,132 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-2-08161, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,221 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-2-08161, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267133} | ret=SUCCESS |  
2019-09-19 08:54:27,222 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-2-87894, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:27,310 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-2-87894, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267223} | ret=SUCCESS |  
2019-09-19 08:54:27,311 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-3-36236, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,450 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-3-36236, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267312} | ret=SUCCESS |  
2019-09-19 08:54:27,451 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-3-88143, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,529 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-3-88143, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267452} | ret=SUCCESS |  
2019-09-19 08:54:27,530 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-4-95830, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-4-95830, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267531} | ret=SUCCESS |  
2019-09-19 08:54:27,604 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-4-88668, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,655 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-4-88668, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267605} | ret=SUCCESS |  
2019-09-19 08:54:27,656 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-5-34993, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,746 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-5-34993, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267657} | ret=SUCCESS |  
2019-09-19 08:54:27,747 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-5-55921, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:27,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-5-55921, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267748} | ret=SUCCESS |  
2019-09-19 08:54:27,841 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-6-53865, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:27,956 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-6-53865, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267842} | ret=SUCCESS |  
2019-09-19 08:54:27,957 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-6-13914, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:28,068 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-6-13914, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883267958} | ret=SUCCESS |  
2019-09-19 08:54:28,069 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-7-47366, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-7-47366, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268070} | ret=SUCCESS |  
2019-09-19 08:54:28,177 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-7-60884, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:28,255 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-7-60884, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268178} | ret=SUCCESS |  
2019-09-19 08:54:28,256 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-8-24762, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,473 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-8-24762, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268257} | ret=SUCCESS |  
2019-09-19 08:54:28,474 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-8-07191, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,690 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-8-07191, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268475} | ret=SUCCESS |  
2019-09-19 08:54:28,690 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-90837/bucket-b-9-45188, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:28,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:28,877 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-90837, bucket=bucket-b-9-45188, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268691} | ret=SUCCESS |  
2019-09-19 08:54:28,878 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-53438/bucket-b-9-82438, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:29,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:29,042 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-53438, bucket=bucket-b-9-82438, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883268879} | ret=SUCCESS |  
2019-09-19 08:54:29,057 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=bucket-b-9-45188, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,063 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,065 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=bucket-b-9-45188, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,067 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,069 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=bucket-a-9-21698, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,073 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=bucket-b-9-45188, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,074 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-90837, startKey=bucket-b-9-45188, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,077 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-53438, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,079 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-53438, startKey=bucket-a-9-94878, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:29,080 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, with jenkins1000 as owner.
2019-09-19 08:54:29,115 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, creationTime=1568883269081, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:29,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8} | ret=SUCCESS |  
2019-09-19 08:54:29,117 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8/07ea81c2-971d-42f9-b44c-00cf8168ea11, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:29,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, bucket=07ea81c2-971d-42f9-b44c-00cf8168ea11, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883269118} | ret=SUCCESS |  
2019-09-19 08:54:29,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, bucket=07ea81c2-971d-42f9-b44c-00cf8168ea11} | ret=SUCCESS |  
2019-09-19 08:54:29,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:29,356 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, bucket=07ea81c2-971d-42f9-b44c-00cf8168ea11, isVersionEnabled=null, storageType=SSD} | ret=SUCCESS |  
2019-09-19 08:54:29,357 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0dd9463f-c5fb-4f0d-add7-8e658f5ec8a8, bucket=07ea81c2-971d-42f9-b44c-00cf8168ea11} | ret=SUCCESS |  
2019-09-19 08:54:29,358 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a66fcaa8-9da5-4db9-ac03-b69d5e38f942, with jenkins1000 as owner.
2019-09-19 08:54:29,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, creationTime=1568883269359, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:29,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942} | ret=SUCCESS |  
2019-09-19 08:54:29,478 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: a66fcaa8-9da5-4db9-ac03-b69d5e38f942/7536cd52-6159-448e-a832-440d1357f1da, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:29,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:29,858 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883269480} | ret=SUCCESS |  
2019-09-19 08:54:29,859 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da} | ret=SUCCESS |  
2019-09-19 08:54:29,865 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:29,953 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, key=4bca9fd4-3efa-4bfc-8912-809d555a7cb3, dataSize=306, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333973872673
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:29,969 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333973872673 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:29,973 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333973872673 bcsId: 0,size=306]} | ret=SUCCESS |  
2019-09-19 08:54:30,009 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, key=4bca9fd4-3efa-4bfc-8912-809d555a7cb3, dataSize=306, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333973872673
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 306
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:30,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:30,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:30,016 [IPC Server handler 18 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:30,016 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:30,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, key=4bca9fd4-3efa-4bfc-8912-809d555a7cb3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:30,030 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818333973872673 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:30,033 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818333973872673 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:30,035 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:30,036 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, key=4bca9fd4-3efa-4bfc-8912-809d555a7cb3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:30,037 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:30,038 [IPC Server handler 0 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:30,038 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:30,039 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=a66fcaa8-9da5-4db9-ac03-b69d5e38f942, bucket=7536cd52-6159-448e-a832-440d1357f1da, key=4bca9fd4-3efa-4bfc-8912-809d555a7cb3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:30,044 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3d39daac-bc8d-41ef-88f8-01750e1e7308, with jenkins1000 as owner.
2019-09-19 08:54:30,086 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, creationTime=1568883270044, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:30,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308} | ret=SUCCESS |  
2019-09-19 08:54:30,088 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 3d39daac-bc8d-41ef-88f8-01750e1e7308/8a613d8c-58b5-4635-a601-de65922c636f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:30,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:30,238 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883270089} | ret=SUCCESS |  
2019-09-19 08:54:30,239 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f} | ret=SUCCESS |  
2019-09-19 08:54:30,240 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:30,294 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333998448675
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:30,303 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818333998448675 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:30,305 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818333998448675 bcsId: 0,size=2344]} | ret=SUCCESS |  
2019-09-19 08:54:30,606 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=2344, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818333998448675
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2344
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:30,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:30,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:30,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PFb302abc2-5ffa-4f50-8c72-749a75e45bff/KEY2d326e76-a4b7-420e-89d1-715607171c01, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334022631461
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:30,811 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334022631461 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:30,814 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334022631461 bcsId: 0,size=2387]} | ret=SUCCESS |  
2019-09-19 08:54:30,925 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PFb302abc2-5ffa-4f50-8c72-749a75e45bff/KEY2d326e76-a4b7-420e-89d1-715607171c01, dataSize=2387, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334022631461
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2387
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:31,014 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:31,077 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/} | ret=SUCCESS |  
2019-09-19 08:54:31,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:31,334 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/} | ret=SUCCESS |  
2019-09-19 08:54:31,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:32,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:32,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:32,392 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/} | ret=SUCCESS |  
2019-09-19 08:54:32,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:32,881 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:32,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:32,887 [IPC Server handler 17 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-191_320 to index:320
2019-09-19 08:54:32,888 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_191-320
2019-09-19 08:54:32,924 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321
2019-09-19 08:54:32,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334171791399
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:32,946 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334171791399 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:32,950 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334171791399 bcsId: 0,size=2355]} | ret=SUCCESS |  
2019-09-19 08:54:32,985 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=2355, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334171791399
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2355
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:32,987 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/} | ret=SUCCESS |  
2019-09-19 08:54:32,989 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74} | ret=SUCCESS |  
2019-09-19 08:54:33,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,027 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,030 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,044 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334181294121
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,050 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334181294121 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,054 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334181294121 bcsId: 0,size=2408]} | ret=SUCCESS |  
2019-09-19 08:54:33,070 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74, dataSize=2408, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334181294121
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2408
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PFb302abc2-5ffa-4f50-8c72-749a75e45bff/} | ret=SUCCESS |  
2019-09-19 08:54:33,072 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=3d39daac-bc8d-41ef-88f8-01750e1e7308, bucket=8a613d8c-58b5-4635-a601-de65922c636f, key=PF34f5e5a0-71fd-4cbf-a7be-a322a8f5605b/KEYd06e69d6-f508-4b4a-8e7c-f3c4887e6f74} | ret=SUCCESS |  
2019-09-19 08:54:33,074 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48, with jenkins1000 as owner.
2019-09-19 08:54:33,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48, creationTime=1568883273075, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,082 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48} | ret=SUCCESS |  
2019-09-19 08:54:33,082 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48/3ac7bb02-2e0a-4946-bb3f-a03418bf7442, with Versioning true and Storage Type set to SSD and Encryption set to false 
2019-09-19 08:54:33,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48, bucket=3ac7bb02-2e0a-4946-bb3f-a03418bf7442, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=true, storageType=SSD, creationTime=1568883273083} | ret=SUCCESS |  
2019-09-19 08:54:33,096 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48, bucket=3ac7bb02-2e0a-4946-bb3f-a03418bf7442} | ret=SUCCESS |  
2019-09-19 08:54:33,097 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=de3ba17b-10c6-4bb1-b62b-36d9b0fe6b48, bucket=3ac7bb02-2e0a-4946-bb3f-a03418bf7442, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,098 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 58e1cce3-f144-4855-9cce-70d785bac6c8, with jenkins1000 as owner.
2019-09-19 08:54:33,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=58e1cce3-f144-4855-9cce-70d785bac6c8, creationTime=1568883273098, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=58e1cce3-f144-4855-9cce-70d785bac6c8} | ret=SUCCESS |  
2019-09-19 08:54:33,107 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 58e1cce3-f144-4855-9cce-70d785bac6c8/dfce172d-958f-4fed-8390-7d980e12acb7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,120 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=58e1cce3-f144-4855-9cce-70d785bac6c8, bucket=dfce172d-958f-4fed-8390-7d980e12acb7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273108} | ret=SUCCESS |  
2019-09-19 08:54:33,121 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=58e1cce3-f144-4855-9cce-70d785bac6c8, bucket=dfce172d-958f-4fed-8390-7d980e12acb7} | ret=SUCCESS |  
2019-09-19 08:54:33,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=58e1cce3-f144-4855-9cce-70d785bac6c8, bucket=dfce172d-958f-4fed-8390-7d980e12acb7} | ret=SUCCESS |  
2019-09-19 08:54:33,136 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=58e1cce3-f144-4855-9cce-70d785bac6c8, bucket=dfce172d-958f-4fed-8390-7d980e12acb7, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,137 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e7e6ab23-0382-4081-8478-ebbf2a77e5c1, with jenkins1000 as owner.
2019-09-19 08:54:33,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, creationTime=1568883273138, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,176 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,185 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,186 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,200 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,200 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,220 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=e7e6ab23-0382-4081-8478-ebbf2a77e5c1, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:33,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,231 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone1=username, 750d9afc-99dc-4cec-b82c-373875384868=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:33,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone1} | ret=SUCCESS |  
2019-09-19 08:54:33,236 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone1, bucket=750d9afc-99dc-4cec-b82c-373875384868} | ret=SUCCESS |  
2019-09-19 08:54:33,250 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {750d9afc-99dc-4cec-b82c-373875384868=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:33,266 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {6e1f1f2b8cdde9c11717322d7e158a89=username, c54baaf2-ff2f-4a32-8fd5-4eef9a8a53b2=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:33,268 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s36e1f1f2b8cdde9c11717322d7e158a89} | ret=SUCCESS |  
2019-09-19 08:54:33,269 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s36e1f1f2b8cdde9c11717322d7e158a89, bucket=c54baaf2-ff2f-4a32-8fd5-4eef9a8a53b2} | ret=SUCCESS |  
2019-09-19 08:54:33,270 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, with jenkins1000 as owner.
2019-09-19 08:54:33,283 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, creationTime=1568883273271, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,284 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2} | ret=SUCCESS |  
2019-09-19 08:54:33,285 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2/345801f6-c98a-42bf-a041-ff23f8113803, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,297 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273285} | ret=SUCCESS |  
2019-09-19 08:54:33,298 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803} | ret=SUCCESS |  
2019-09-19 08:54:33,311 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, key=a4b89e06-e801-4681-9824-ba4265bc0c05, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, key=a4b89e06-e801-4681-9824-ba4265bc0c05, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, key=a4b89e06-e801-4681-9824-ba4265bc0c05, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334200037420} | ret=SUCCESS |  
2019-09-19 08:54:33,344 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334201020461 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,350 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334201020461 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:33,364 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, key=a4b89e06-e801-4681-9824-ba4265bc0c05, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334201020461
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,386 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2, bucket=345801f6-c98a-42bf-a041-ff23f8113803, key=a4b89e06-e801-4681-9824-ba4265bc0c05, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={3=random}} | ret=FAILURE | MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2bucket: 345801f6-c98a-42bf-a041-ff23f8113803key: a4b89e06-e801-4681-9824-ba4265bc0c05
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:33,388 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: a4b89e06-e801-4681-9824-ba4265bc0c05 in Volume/Bucket 5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2/345801f6-c98a-42bf-a041-ff23f8113803
MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 5e6c0faf-0ab8-4501-b3f3-5cdf3afa24b2bucket: 345801f6-c98a-42bf-a041-ff23f8113803key: a4b89e06-e801-4681-9824-ba4265bc0c05
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:33,389 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4b1f982d-e399-4be4-b052-448a74e47c5b, with jenkins1000 as owner.
2019-09-19 08:54:33,402 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4b1f982d-e399-4be4-b052-448a74e47c5b, creationTime=1568883273390, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,404 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4b1f982d-e399-4be4-b052-448a74e47c5b} | ret=SUCCESS |  
2019-09-19 08:54:33,423 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=SET_QUOTA {volume=4b1f982d-e399-4be4-b052-448a74e47c5b, quota=100000000} | ret=SUCCESS |  
2019-09-19 08:54:33,424 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4b1f982d-e399-4be4-b052-448a74e47c5b} | ret=SUCCESS |  
2019-09-19 08:54:33,425 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 41a60ff9-2c39-4116-9e4f-fcc189107148, with jenkins1000 as owner.
2019-09-19 08:54:33,428 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=41a60ff9-2c39-4116-9e4f-fcc189107148, creationTime=1568883273426, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=41a60ff9-2c39-4116-9e4f-fcc189107148} | ret=SUCCESS |  
2019-09-19 08:54:33,430 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 41a60ff9-2c39-4116-9e4f-fcc189107148/ee07ec1c-4eb9-420a-a989-30e5b1be6e47, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=41a60ff9-2c39-4116-9e4f-fcc189107148, bucket=ee07ec1c-4eb9-420a-a989-30e5b1be6e47, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273430} | ret=SUCCESS |  
2019-09-19 08:54:33,433 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=41a60ff9-2c39-4116-9e4f-fcc189107148, bucket=ee07ec1c-4eb9-420a-a989-30e5b1be6e47} | ret=SUCCESS |  
2019-09-19 08:54:33,436 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=41a60ff9-2c39-4116-9e4f-fcc189107148, bucket=ee07ec1c-4eb9-420a-a989-30e5b1be6e47} | ret=SUCCESS |  
2019-09-19 08:54:33,438 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=41a60ff9-2c39-4116-9e4f-fcc189107148, bucket=ee07ec1c-4eb9-420a-a989-30e5b1be6e47} | ret=FAILURE | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
	at org.apache.hadoop.ozone.om.BucketManagerImpl.getBucketInfo(BucketManagerImpl.java:229)
	at org.apache.hadoop.ozone.om.OzoneManager.getBucketInfo(OzoneManager.java:2147) 
2019-09-19 08:54:33,439 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-75476, with jenkins1000 as owner.
2019-09-19 08:54:33,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-75476, creationTime=1568883273439, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,442 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-22823, with jenkins1000 as owner.
2019-09-19 08:54:33,444 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-22823, creationTime=1568883273442, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:33,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-75476} | ret=SUCCESS |  
2019-09-19 08:54:33,446 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-22823} | ret=SUCCESS |  
2019-09-19 08:54:33,447 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-75476/buc-a-04399, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,450 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-75476, bucket=buc-a-04399, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273447} | ret=SUCCESS |  
2019-09-19 08:54:33,450 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-75476/buc-b-12063, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,469 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-75476, bucket=buc-b-12063, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273451} | ret=SUCCESS |  
2019-09-19 08:54:33,469 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-22823/buc-a-04399, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,494 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-22823, bucket=buc-a-04399, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273470} | ret=SUCCESS |  
2019-09-19 08:54:33,495 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-22823/buc-b-12063, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:33,508 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-22823, bucket=buc-b-12063, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883273496} | ret=SUCCESS |  
2019-09-19 08:54:33,510 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-75476, bucket=buc-a-04399} | ret=SUCCESS |  
2019-09-19 08:54:33,511 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-75476, bucket=buc-b-12063} | ret=SUCCESS |  
2019-09-19 08:54:33,512 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-22823, bucket=buc-a-04399} | ret=SUCCESS |  
2019-09-19 08:54:33,514 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-22823, bucket=buc-b-12063} | ret=SUCCESS |  
2019-09-19 08:54:33,521 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,535 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-0-12888, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334213406766
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,541 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334213406766 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,545 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334213406766 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,560 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-0-12888, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334213406766
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,563 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-0-60782, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334216224816
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,582 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334216224816 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,586 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334216224816 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-0-60782, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334216224816
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,604 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,618 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-0-58042, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334218911794
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,623 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334218911794 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,627 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334218911794 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,644 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-0-58042, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334218911794
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,647 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,661 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-0-70873, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334221664308
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,665 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334221664308 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,670 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334221664308 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,687 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-0-70873, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334221664308
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,692 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,696 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-1-21306, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334224678966
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,700 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334224678966 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,704 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334224678966 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,709 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-1-21306, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334224678966
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,711 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,712 [IPC Server handler 9 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-321_422 to index:422
2019-09-19 08:54:33,713 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_321-422
2019-09-19 08:54:33,742 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423
2019-09-19 08:54:33,744 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-1-42660, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334225924152
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,750 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334225924152 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,753 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334225924152 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:33,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-1-42660, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334225924152
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-1-49906, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334229790778
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,794 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334229790778 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,798 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334229790778 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,815 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-1-49906, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334229790778
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,818 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,827 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-1-15565, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334232936508
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,832 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334232936508 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,835 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334232936508 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-1-15565, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334232936508
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,853 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-2-22991, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334235230270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,871 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334235230270 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,874 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334235230270 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,888 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-2-22991, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334235230270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,890 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-2-43513, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334237655104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,908 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334237655104 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,911 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334237655104 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,916 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-2-43513, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334237655104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,919 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,922 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-2-67351, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334239555650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,926 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334239555650 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,928 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334239555650 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-2-67351, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334239555650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,936 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,939 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-2-58222, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334240604228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,942 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334240604228 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,945 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334240604228 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,949 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-2-58222, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334240604228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,951 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,955 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-3-34074, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334241652806
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,958 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334241652806 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,961 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334241652806 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,964 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-3-34074, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334241652806
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,966 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:33,970 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-3-74675, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334242635848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,973 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334242635848 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:33,979 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334242635848 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:33,983 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-3-74675, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334242635848
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:33,985 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,003 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-3-21558, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334243881034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,008 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334243881034 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,011 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334243881034 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,014 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:34,025 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-3-21558, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334243881034
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,027 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,040 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-3-17468, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334246633548
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,044 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334246633548 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,047 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334246633548 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,062 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-3-17468, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334246633548
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,064 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,077 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-4-62747, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334249058382
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,081 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334249058382 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,084 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334249058382 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,098 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-4-62747, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334249058382
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,100 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,113 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-4-34119, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334251417680
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,117 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334251417680 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,120 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334251417680 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,134 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-4-34119, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334251417680
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,136 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-4-45517, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334253711442
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,153 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334253711442 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,156 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334253711442 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,169 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-4-45517, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334253711442
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,172 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,175 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-4-40854, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334256136276
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,179 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334256136276 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,182 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334256136276 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,187 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-4-40854, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334256136276
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-5-40688, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334257381462
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,198 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334257381462 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,201 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334257381462 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-5-40688, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334257381462
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-5-69009, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334258495576
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,216 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334258495576 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,218 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334258495576 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-5-69009, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334258495576
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:34,229 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-5-88554, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334259609690
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,232 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334259609690 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,237 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334259609690 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,240 [IPC Server handler 11 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-423_492 to index:492
2019-09-19 08:54:34,241 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_423-492
2019-09-19 08:54:34,246 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493
2019-09-19 08:54:34,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-5-88554, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334259609690
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,251 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,279 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-5-25152, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334261313628
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,285 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334261313628 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,289 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334261313628 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-5-25152, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334261313628
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,306 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-6-63110, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334264918110
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,328 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334264918110 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,332 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334264918110 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-6-63110, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334264918110
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,363 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-6-33391, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334267801696
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,371 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334267801696 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,374 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334267801696 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,393 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-6-33391, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334267801696
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,396 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,409 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-6-25290, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334270816354
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,417 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334270816354 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,420 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334270816354 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,436 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-6-25290, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334270816354
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,438 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,448 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-6-00293, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334273568868
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,454 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334273568868 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,458 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334273568868 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,473 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-6-00293, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334273568868
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,489 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-7-04320, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334276059238
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,495 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334276059238 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,499 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334276059238 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,506 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-7-04320, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334276059238
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,509 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,537 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-7-20307, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334278156392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,543 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334278156392 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,546 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334278156392 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,561 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-7-20307, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334278156392
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,563 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-7-69441, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334281760874
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,582 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334281760874 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,585 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334281760874 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,600 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-7-69441, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334281760874
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,616 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-7-65795, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334284316780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,621 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334284316780 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,625 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334284316780 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,639 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-7-65795, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334284316780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,642 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,655 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-8-84174, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334286938222
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,660 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334286938222 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,663 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334286938222 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,677 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-8-84174, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334286938222
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,679 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,692 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-8-56243, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334289363056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,696 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334289363056 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,699 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334289363056 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,704 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-8-56243, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334289363056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,706 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,708 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-8-35047, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334291066994
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,712 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334291066994 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,714 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334291066994 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,718 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-8-35047, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334291066994
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,720 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-8-41374, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334292050036
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,726 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334292050036 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,731 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334292050036 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,735 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-8-41374, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334292050036
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,740 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-9-53162, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334293164150
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,745 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334293164150 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,748 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334293164150 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,752 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-a-9-53162, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334293164150
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,754 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,757 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-9-12809, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334294278264
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,757 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:34,762 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334294278264 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,764 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334294278264 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-a-9-12809, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334294278264
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-9-63738, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334295326842
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,777 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334295326842 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,779 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334295326842 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,783 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-a-9-63738, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334295326842
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,785 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,787 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-9-42314, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334296309884
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,791 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334296309884 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,792 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334296309884 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,820 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-a-9-42314, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334296309884
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,823 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,825 [IPC Server handler 2 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-493_562 to index:562
2019-09-19 08:54:34,825 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_493-562
2019-09-19 08:54:34,847 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563
2019-09-19 08:54:34,849 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-0-94725, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334298800254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,854 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334298800254 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,857 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334298800254 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-0-94725, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334298800254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,874 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,887 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-0-99424, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334302142592
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,892 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334302142592 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,895 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334302142592 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,910 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-0-99424, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334302142592
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,913 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,926 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-0-67099, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334304698498
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,933 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334304698498 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,936 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334304698498 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,950 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-0-67099, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334304698498
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,952 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,966 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-0-61139, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334307254404
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,972 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334307254404 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:34,975 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334307254404 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:34,989 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-0-61139, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334307254404
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:34,992 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:34,996 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-1-79154, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334309875846
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,003 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334309875846 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,006 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334309875846 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-1-79154, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334309875846
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:35,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-1-65805, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334311252104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,022 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334311252104 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,025 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334311252104 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-1-65805, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334311252104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,034 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,038 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-1-51386, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334312628362
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,044 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334312628362 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,048 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334312628362 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,054 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-1-51386, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334312628362
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,057 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,062 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-1-35952, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334314070156
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,068 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334314070156 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,072 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334314070156 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,083 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-1-35952, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334314070156
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,086 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,104 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-2-09598, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334316036238
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,110 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334316036238 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,112 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334316036238 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,127 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-2-09598, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334316036238
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,129 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,142 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-2-94058, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334318854288
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,147 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334318854288 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,149 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334318854288 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,164 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-2-94058, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334318854288
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,166 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,179 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-2-53625, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334321279122
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,185 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334321279122 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,194 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334321279122 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,209 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-2-53625, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334321279122
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,211 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,224 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-2-30098, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334324228244
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:35,231 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334324228244 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,233 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334324228244 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,247 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-2-30098, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334324228244
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,250 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,262 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-3-61775, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334326718614
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,268 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334326718614 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,271 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334326718614 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-3-61775, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334326718614
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,287 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,302 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-3-12294, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334329208984
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,309 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334329208984 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,311 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334329208984 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,316 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-3-12294, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334329208984
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,318 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-3-70902, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334331240602
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,326 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334331240602 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,329 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334331240602 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,333 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-3-70902, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334331240602
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,335 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,365 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-3-19763, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334332354716
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,373 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334332354716 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,376 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334332354716 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-3-19763, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334332354716
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,394 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,408 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-4-52672, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334336221342
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,414 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334336221342 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,417 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334336221342 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-4-52672, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334336221342
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,434 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,447 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-4-96103, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334338842784
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,455 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334338842784 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,458 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334338842784 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,460 [IPC Server handler 16 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-563_632 to index:632
2019-09-19 08:54:35,461 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_563-632
2019-09-19 08:54:35,485 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633
2019-09-19 08:54:35,487 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-4-96103, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334338842784
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,490 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,504 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-4-01033, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334342512802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,510 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334342512802 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,513 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334342512802 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,528 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-4-01033, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334342512802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,531 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,534 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-4-90957, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334345199780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,541 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334345199780 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,544 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334345199780 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,550 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-4-90957, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334345199780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,557 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-5-64865, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334346641574
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,563 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334346641574 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,566 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334346641574 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-5-64865, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334346641574
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,573 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-5-91677, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334347952296
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,583 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334347952296 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,587 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334347952296 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,592 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-5-91677, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334347952296
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,594 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,598 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-5-17011, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334349328554
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,605 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334349328554 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,608 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334349328554 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,613 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-5-17011, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334349328554
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,615 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,619 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-5-99992, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334350704812
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,625 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334350704812 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,629 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334350704812 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,640 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-5-99992, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334350704812
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,642 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,657 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-6-69198, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334352474286
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,662 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334352474286 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,665 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334352474286 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,680 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-6-69198, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334352474286
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,682 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,695 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-6-62983, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334355095728
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,701 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334355095728 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,704 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334355095728 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,718 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-6-62983, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334355095728
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,720 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,733 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-6-60444, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334357586098
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,738 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334357586098 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,741 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334357586098 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-6-60444, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334357586098
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,762 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,762 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:35,775 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-6-14202, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334360338612
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,779 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334360338612 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,782 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334360338612 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-6-14202, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334360338612
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,799 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,813 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-7-43146, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334362763446
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,817 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334362763446 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,820 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334362763446 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,826 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-7-43146, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334362763446
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,828 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,837 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-7-22187, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334364663992
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,841 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334364663992 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,844 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334364663992 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,849 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-7-22187, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334364663992
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,852 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,855 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-7-16611, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334366236858
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,860 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334366236858 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,863 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334366236858 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-7-16611, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334366236858
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,869 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-7-39200, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334367350972
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,877 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334367350972 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,879 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334367350972 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,890 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-7-39200, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334367350972
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,893 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,906 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-8-61825, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334368923838
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,911 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334368923838 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,914 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334368923838 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-8-61825, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334368923838
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,920 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-8-89438, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334370693312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,940 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334370693312 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,943 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334370693312 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-8-89438, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334370693312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,959 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,972 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-8-67771, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334373249218
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,976 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334373249218 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:35,979 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334373249218 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:35,992 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-8-67771, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334373249218
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:35,994 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:35,995 [IPC Server handler 9 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-633_702 to index:702
2019-09-19 08:54:35,996 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_633-702
2019-09-19 08:54:36,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,021 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703
2019-09-19 08:54:36,022 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-8-42726, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334375542980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,030 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334375542980 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,032 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334375542980 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:36,045 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-8-42726, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334375542980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,047 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-9-99481, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334379016390
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,065 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334379016390 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,067 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334379016390 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:36,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-a-04399, key=key-b-9-99481, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334379016390
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-9-21841, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334381310152
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,100 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334381310152 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,102 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334381310152 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:36,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-75476, bucket=buc-b-12063, key=key-b-9-21841, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334381310152
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,123 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-9-85629, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334383800522
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,128 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334383800522 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,131 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334383800522 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:36,144 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-a-04399, key=key-b-9-85629, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334383800522
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,146 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,154 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-9-85244, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334385504460
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,159 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334385504460 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,162 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334385504460 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:36,177 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-22823, bucket=buc-b-12063, key=key-b-9-85244, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334385504460
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,190 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-a-04399, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-a-04399, startKey=key-b-9-99481, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,201 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-b-12063, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-b-12063, startKey=key-b-9-21841, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,209 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-22823, bucket=buc-a-04399, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,214 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-22823, bucket=buc-a-04399, startKey=key-b-9-85629, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,217 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-22823, bucket=buc-b-12063, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-22823, bucket=buc-b-12063, startKey=key-b-9-85244, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-a-04399, startKey=, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-19 08:54:36,225 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-a-04399, startKey=key-a-9-53162, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-19 08:54:36,230 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-a-04399, startKey=, maxKeys=1000, keyPrefix=key-b-} | ret=SUCCESS |  
2019-09-19 08:54:36,233 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-75476, bucket=buc-b-12063, startKey=key-b-9-21841, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:36,234 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555, with jenkins1000 as owner.
2019-09-19 08:54:36,248 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555, creationTime=1568883276235, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:36,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555} | ret=SUCCESS |  
2019-09-19 08:54:36,250 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555/5382a285-ff5a-4708-9c01-84bf70739fea, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:36,259 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555, bucket=5382a285-ff5a-4708-9c01-84bf70739fea, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883276251} | ret=SUCCESS |  
2019-09-19 08:54:36,261 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=d8c3ff9d-f4d0-482e-b2fd-ae8d4e269555, bucket=5382a285-ff5a-4708-9c01-84bf70739fea} | ret=SUCCESS |  
2019-09-19 08:54:36,262 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 677d6c29-8820-4167-a277-07eebea4272a, with jenkins1000 as owner.
2019-09-19 08:54:36,276 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=677d6c29-8820-4167-a277-07eebea4272a, creationTime=1568883276263, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:36,277 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=677d6c29-8820-4167-a277-07eebea4272a} | ret=SUCCESS |  
2019-09-19 08:54:36,278 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 677d6c29-8820-4167-a277-07eebea4272a/86f902b8-2c62-48bb-98f2-9cec5444bd7a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:36,288 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883276279} | ret=SUCCESS |  
2019-09-19 08:54:36,290 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a} | ret=SUCCESS |  
2019-09-19 08:54:36,300 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,313 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,316 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334395662543} | ret=SUCCESS |  
2019-09-19 08:54:36,334 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334396645584 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,337 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334396645584 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:36,350 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334396645584
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,363 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,365 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,367 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334398939345} | ret=SUCCESS |  
2019-09-19 08:54:36,372 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334399856850 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,374 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334399856850 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:36,378 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334399856850
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,404 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(212)) - MultipartUpload: /677d6c29-8820-4167-a277-07eebea4272a/86f902b8-2c62-48bb-98f2-9cec5444bd7a/5087a92b-5bf8-4066-ac62-4fa789efbf17Part number: 1size 4 is less than minimum part size 5242880
2019-09-19 08:54:36,404 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=677d6c29-8820-4167-a277-07eebea4272a, bucket=86f902b8-2c62-48bb-98f2-9cec5444bd7a, key=5087a92b-5bf8-4066-ac62-4fa789efbf17, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=/677d6c29-8820-4167-a277-07eebea4272a/86f902b8-2c62-48bb-98f2-9cec5444bd7a/5087a92b-5bf8-4066-ac62-4fa789efbf17102818334395662543, 2=/677d6c29-8820-4167-a277-07eebea4272a/86f902b8-2c62-48bb-98f2-9cec5444bd7a/5087a92b-5bf8-4066-ac62-4fa789efbf17102818334398939345}} | ret=FAILURE | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 677d6c29-8820-4167-a277-07eebea4272abucket: 86f902b8-2c62-48bb-98f2-9cec5444bd7akey: 5087a92b-5bf8-4066-ac62-4fa789efbf17
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:36,405 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 5087a92b-5bf8-4066-ac62-4fa789efbf17 in Volume/Bucket 677d6c29-8820-4167-a277-07eebea4272a/86f902b8-2c62-48bb-98f2-9cec5444bd7a
ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 677d6c29-8820-4167-a277-07eebea4272abucket: 86f902b8-2c62-48bb-98f2-9cec5444bd7akey: 5087a92b-5bf8-4066-ac62-4fa789efbf17
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:36,406 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5aee68a9-c107-4410-82f5-325ed6082bec, with jenkins1000 as owner.
2019-09-19 08:54:36,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5aee68a9-c107-4410-82f5-325ed6082bec, creationTime=1568883276407, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:36,413 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5aee68a9-c107-4410-82f5-325ed6082bec} | ret=SUCCESS |  
2019-09-19 08:54:36,413 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5aee68a9-c107-4410-82f5-325ed6082bec/4a681fbe-550f-426f-a6d7-98f700d7d794, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:36,421 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883276414} | ret=SUCCESS |  
2019-09-19 08:54:36,422 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794} | ret=SUCCESS |  
2019-09-19 08:54:36,424 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=be8917e4-dd8a-461b-9d0f-f54d450b15d5, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102818334403723475
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 43927
    }
    ports {
      name: "RATIS"
      value: 43014
    }
    ports {
      name: "STANDALONE"
      value: 39573
    }
    networkName: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "52e88d3a-be9a-49a2-b2a4-f7d78e7dc516"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,669 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102818334403723475 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,670 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,684 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102818334403723475 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:36,689 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-A87CB205B2BD->6e2100fe-d804-4987-9ac5-bcccf3c0d596: receive RaftClientReply:client-A87CB205B2BD->6e2100fe-d804-4987-9ac5-bcccf3c0d596@group-F7D78E7DC516, cid=20, SUCCESS, logIndex=1, commits[6e2100fe-d804-4987-9ac5-bcccf3c0d596:c1]
2019-09-19 08:54:36,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:36,806 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102818334403723475 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:36,810 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-A87CB205B2BD->6e2100fe-d804-4987-9ac5-bcccf3c0d596: receive RaftClientReply:client-A87CB205B2BD->6e2100fe-d804-4987-9ac5-bcccf3c0d596@group-F7D78E7DC516, cid=21, SUCCESS, logIndex=3, commits[6e2100fe-d804-4987-9ac5-bcccf3c0d596:c4]
2019-09-19 08:54:36,825 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=be8917e4-dd8a-461b-9d0f-f54d450b15d5, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102818334403723475
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 43927
    }
    ports {
      name: "RATIS"
      value: 43014
    }
    ports {
      name: "STANDALONE"
      value: 39573
    }
    networkName: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "52e88d3a-be9a-49a2-b2a4-f7d78e7dc516"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:36,827 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:36,829 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:36,829 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:36,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=be8917e4-dd8a-461b-9d0f-f54d450b15d5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:36,833 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:36,834 [IPC Server handler 18 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:36,834 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:36,835 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=be8917e4-dd8a-461b-9d0f-f54d450b15d5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:36,844 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 3 locID: 102818334403723475 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:36,850 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 3 locID: 102818334403723475 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:36,852 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:36,853 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=be8917e4-dd8a-461b-9d0f-f54d450b15d5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:36,856 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=3} | ret=SUCCESS |  
2019-09-19 08:54:36,863 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:36,876 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b7b1a407-6cbb-4ed0-ad43-d5afde1e70f3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334432428245
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:37,085 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334432428245 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:37,086 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:37,100 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334432428245 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:37,105 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=22, SUCCESS, logIndex=1, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c1]
2019-09-19 08:54:37,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:37,530 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102818334432428245 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:37,535 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=23, SUCCESS, logIndex=3, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c4]
2019-09-19 08:54:37,551 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b7b1a407-6cbb-4ed0-ad43-d5afde1e70f3, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334432428245
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:37,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,555 [IPC Server handler 4 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:37,556 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:37,557 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b7b1a407-6cbb-4ed0-ad43-d5afde1e70f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,559 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,561 [IPC Server handler 6 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:37,561 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:37,561 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b7b1a407-6cbb-4ed0-ad43-d5afde1e70f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,572 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102818334432428245 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:37,577 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102818334432428245 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:37,579 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,580 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b7b1a407-6cbb-4ed0-ad43-d5afde1e70f3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,580 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-19 08:54:37,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:37,598 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9c29b1d2-3531-4571-991e-e3dd4c86ef8b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334479745239
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:37,606 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334479745239 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:37,621 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334479745239 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:37,622 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102818334479745239 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:37,623 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=24, SUCCESS, logIndex=5, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c7]
2019-09-19 08:54:37,624 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=25, SUCCESS, logIndex=6, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c7]
2019-09-19 08:54:37,639 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9c29b1d2-3531-4571-991e-e3dd4c86ef8b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334479745239
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:37,641 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,642 [IPC Server handler 3 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:37,642 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:37,643 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9c29b1d2-3531-4571-991e-e3dd4c86ef8b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,645 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,647 [IPC Server handler 16 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:37,647 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:37,648 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9c29b1d2-3531-4571-991e-e3dd4c86ef8b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,651 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102818334479745239 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:37,657 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102818334479745239 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:37,659 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:37,660 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9c29b1d2-3531-4571-991e-e3dd4c86ef8b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:37,661 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-19 08:54:37,663 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:37,664 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:37,676 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9cf3ec0-a3a7-4b79-a240-fb8901d7e8ce, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102818334484922585
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "3d4ae66b-cd08-4617-93af-864ee71594b1"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:38,086 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:38,226 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:38,665 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,086 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,227 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,601 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102818334484922585 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:39,601 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,613 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102818334484922585 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:39,618 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-E590FAFB34C7->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-E590FAFB34C7->18897f3d-a606-48ca-8ab1-50a74a285275@group-864EE71594B1, cid=26, SUCCESS, logIndex=1, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c1]
2019-09-19 08:54:39,665 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,723 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 5 locID: 102818334484922585 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:39,727 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-E590FAFB34C7->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-E590FAFB34C7->18897f3d-a606-48ca-8ab1-50a74a285275@group-864EE71594B1, cid=27, SUCCESS, logIndex=3, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c4]
2019-09-19 08:54:39,732 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9cf3ec0-a3a7-4b79-a240-fb8901d7e8ce, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102818334484922585
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "3d4ae66b-cd08-4617-93af-864ee71594b1"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:39,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:39,735 [IPC Server handler 13 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:39,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:39,735 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9cf3ec0-a3a7-4b79-a240-fb8901d7e8ce, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:39,737 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:39,738 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:39,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:39,738 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9cf3ec0-a3a7-4b79-a240-fb8901d7e8ce, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:39,749 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 5 locID: 102818334484922585 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:39,754 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 5 locID: 102818334484922585 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:39,756 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:39,757 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9cf3ec0-a3a7-4b79-a240-fb8901d7e8ce, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:39,758 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=5} | ret=SUCCESS |  
2019-09-19 08:54:39,762 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:39,765 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9a1551c9-1f9d-4e63-84a7-42a553f15d32, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818334622482651
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:39,954 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818334622482651 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:39,955 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:39,967 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818334622482651 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:39,971 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5A3C116E8756->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-5A3C116E8756->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E2EA6504FD1A, cid=28, SUCCESS, logIndex=1, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c2]
2019-09-19 08:54:40,089 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102818334622482651 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:40,092 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5A3C116E8756->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-5A3C116E8756->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E2EA6504FD1A, cid=29, SUCCESS, logIndex=3, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c4]
2019-09-19 08:54:40,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9a1551c9-1f9d-4e63-84a7-42a553f15d32, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818334622482651
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,109 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:40,110 [IPC Server handler 10 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,110 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,111 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9a1551c9-1f9d-4e63-84a7-42a553f15d32, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,113 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:40,114 [IPC Server handler 11 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,115 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,115 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9a1551c9-1f9d-4e63-84a7-42a553f15d32, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,125 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102818334622482651 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:40,130 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102818334622482651 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:40,131 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:40,132 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=9a1551c9-1f9d-4e63-84a7-42a553f15d32, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,132 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-19 08:54:40,134 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:40,148 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9ab6fbc-7c80-4960-a1c6-ec8746f62377, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818334646862045
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1eaec501-0284-41dd-b955-e6cb3d7a5f33"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,430 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818334646862045 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:40,443 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818334646862045 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,449 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E6CB3D7A5F33, cid=30, SUCCESS, logIndex=1, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c1]
2019-09-19 08:54:40,568 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102818334646862045 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:40,572 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E6CB3D7A5F33, cid=31, SUCCESS, logIndex=3, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c4]
2019-09-19 08:54:40,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9ab6fbc-7c80-4960-a1c6-ec8746f62377, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818334646862045
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1eaec501-0284-41dd-b955-e6cb3d7a5f33"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,589 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,591 [IPC Server handler 3 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,591 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,592 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9ab6fbc-7c80-4960-a1c6-ec8746f62377, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,594 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,595 [IPC Server handler 16 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,596 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9ab6fbc-7c80-4960-a1c6-ec8746f62377, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:40,608 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102818334646862045 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:40,623 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102818334646862045 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:40,625 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,626 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=b9ab6fbc-7c80-4960-a1c6-ec8746f62377, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,626 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-19 08:54:40,630 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:40,632 [IPC Server handler 7 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-703_774 to index:774
2019-09-19 08:54:40,632 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_703-774
2019-09-19 08:54:40,658 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775
2019-09-19 08:54:40,660 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=667ae130-35ac-4936-b26b-801a6a0ba070, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818334679367903
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1eaec501-0284-41dd-b955-e6cb3d7a5f33"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,664 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:40,666 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818334679367903 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,679 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818334679367903 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,680 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102818334679367903 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:40,681 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E6CB3D7A5F33, cid=32, SUCCESS, logIndex=5, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c7]
2019-09-19 08:54:40,683 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-667D82F09B50->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-E6CB3D7A5F33, cid=33, SUCCESS, logIndex=6, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c7]
2019-09-19 08:54:40,697 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=667ae130-35ac-4936-b26b-801a6a0ba070, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818334679367903
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "1eaec501-0284-41dd-b955-e6cb3d7a5f33"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,700 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,701 [IPC Server handler 13 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,701 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=667ae130-35ac-4936-b26b-801a6a0ba070, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,704 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,705 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,706 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,706 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=667ae130-35ac-4936-b26b-801a6a0ba070, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,710 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102818334679367903 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:40,713 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102818334679367903 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:40,715 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:40,716 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=667ae130-35ac-4936-b26b-801a6a0ba070, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,716 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-19 08:54:40,718 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:40,732 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=30af76fe-4f4a-4289-8716-d308c5a8e60f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334685135073
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,737 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334685135073 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,750 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818334685135073 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:40,751 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102818334685135073 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:40,752 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=34, SUCCESS, logIndex=8, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c10]
2019-09-19 08:54:40,753 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-FAF70C821928->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-81350EB5AF8A, cid=35, SUCCESS, logIndex=9, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c10]
2019-09-19 08:54:40,766 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=30af76fe-4f4a-4289-8716-d308c5a8e60f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818334685135073
  }
  blockCommitSequenceId: 9
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "f341dfde-b316-4baa-8be5-81350eb5af8a"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:40,768 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:40,769 [IPC Server handler 0 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,770 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=30af76fe-4f4a-4289-8716-d308c5a8e60f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:40,774 [IPC Server handler 15 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:40,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:40,775 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=30af76fe-4f4a-4289-8716-d308c5a8e60f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,778 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102818334685135073 bcsId: 9} | ret=SUCCESS |  
2019-09-19 08:54:40,781 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102818334685135073 bcsId: 9} | ret=SUCCESS |  
2019-09-19 08:54:40,783 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:40,784 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=30af76fe-4f4a-4289-8716-d308c5a8e60f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:40,784 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-19 08:54:40,787 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:40,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=818be4ce-eef2-4637-9d0d-85e790e71a26, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102818334689657059
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "7b0dd393-2f2a-4958-bebe-dffd32b43b1b"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:41,105 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102818334689657059 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,106 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,126 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102818334689657059 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,131 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-349AD685438B->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-349AD685438B->18897f3d-a606-48ca-8ab1-50a74a285275@group-DFFD32B43B1B, cid=36, SUCCESS, logIndex=1, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c1]
2019-09-19 08:54:41,294 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 8 locID: 102818334689657059 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:41,299 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-349AD685438B->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-349AD685438B->18897f3d-a606-48ca-8ab1-50a74a285275@group-DFFD32B43B1B, cid=37, SUCCESS, logIndex=3, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c4]
2019-09-19 08:54:41,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=818be4ce-eef2-4637-9d0d-85e790e71a26, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102818334689657059
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "7b0dd393-2f2a-4958-bebe-dffd32b43b1b"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:41,316 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:41,317 [IPC Server handler 2 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:41,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:41,318 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=818be4ce-eef2-4637-9d0d-85e790e71a26, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,320 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:41,321 [IPC Server handler 5 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:41,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:41,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=818be4ce-eef2-4637-9d0d-85e790e71a26, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,330 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 8 locID: 102818334689657059 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:41,335 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 8 locID: 102818334689657059 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:41,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:41,337 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=818be4ce-eef2-4637-9d0d-85e790e71a26, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=8} | ret=SUCCESS |  
2019-09-19 08:54:41,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:41,352 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=8118be86-a46a-4162-a273-ffa0fd519bb5, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102818334725832933
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5ff289c0-091f-4001-88d9-0ab69db7ea63"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:41,430 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,565 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102818334725832933 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,565 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,577 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102818334725832933 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,583 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-481C9C1D8AEF->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-481C9C1D8AEF->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-0AB69DB7EA63, cid=38, SUCCESS, logIndex=1, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c1]
2019-09-19 08:54:41,664 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,683 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 9 locID: 102818334725832933 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:41,687 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-481C9C1D8AEF->a448d85b-ec9b-4560-ae6c-b2c8a1634a11: receive RaftClientReply:client-481C9C1D8AEF->a448d85b-ec9b-4560-ae6c-b2c8a1634a11@group-0AB69DB7EA63, cid=39, SUCCESS, logIndex=3, commits[a448d85b-ec9b-4560-ae6c-b2c8a1634a11:c4]
2019-09-19 08:54:41,701 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=8118be86-a46a-4162-a273-ffa0fd519bb5, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102818334725832933
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 46319
    }
    ports {
      name: "RATIS"
      value: 45142
    }
    ports {
      name: "STANDALONE"
      value: 43743
    }
    networkName: "a448d85b-ec9b-4560-ae6c-b2c8a1634a11"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5ff289c0-091f-4001-88d9-0ab69db7ea63"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:41,703 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:41,705 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:41,705 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:41,706 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=8118be86-a46a-4162-a273-ffa0fd519bb5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,708 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:41,709 [IPC Server handler 18 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:41,709 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:41,710 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=8118be86-a46a-4162-a273-ffa0fd519bb5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,720 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 9 locID: 102818334725832933 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:41,725 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 9 locID: 102818334725832933 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:41,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:41,727 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=5aee68a9-c107-4410-82f5-325ed6082bec, bucket=4a681fbe-550f-426f-a6d7-98f700d7d794, key=8118be86-a46a-4162-a273-ffa0fd519bb5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:41,728 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=9} | ret=SUCCESS |  
2019-09-19 08:54:41,742 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ee1201ad-16d7-4a1e-888a-9b947a8b8aa3=s3Bucket, ozone100=username} | ret=SUCCESS |  
2019-09-19 08:54:41,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {88f23367-4ec8-4e67-86c1-84d7f5e210d8=s3Bucket, ozone100=username} | ret=SUCCESS |  
2019-09-19 08:54:41,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:41,778 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=ee1201ad-16d7-4a1e-888a-9b947a8b8aa3, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:41,779 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, with jenkins1000 as owner.
2019-09-19 08:54:41,791 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, creationTime=1568883281780, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:41,793 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749} | ret=SUCCESS |  
2019-09-19 08:54:41,793 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b0baf5fc-0ecb-49cf-8b47-6e4aacc42749/fd8954d9-e5a7-44c6-a1aa-96d251376f2c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:41,806 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883281794} | ret=SUCCESS |  
2019-09-19 08:54:41,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c} | ret=SUCCESS |  
2019-09-19 08:54:41,821 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, key=0a433d71-974a-4715-91de-37319fa065be, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,824 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, key=0a433d71-974a-4715-91de-37319fa065be, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,827 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:41,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, key=0a433d71-974a-4715-91de-37319fa065be, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334757486824} | ret=SUCCESS |  
2019-09-19 08:54:41,834 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334757748969 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,838 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334757748969 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:41,843 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, key=0a433d71-974a-4715-91de-37319fa065be, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334757748969
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:41,853 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=b0baf5fc-0ecb-49cf-8b47-6e4aacc42749, bucket=fd8954d9-e5a7-44c6-a1aa-96d251376f2c, key=0a433d71-974a-4715-91de-37319fa065be, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,855 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-19 08:54:41,859 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-19 08:54:41,861 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4bf74191-5006-4ae1-9914-be5a518ae7f2, with jenkins1000 as owner.
2019-09-19 08:54:41,864 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, creationTime=1568883281862, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:41,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2} | ret=SUCCESS |  
2019-09-19 08:54:41,866 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4bf74191-5006-4ae1-9914-be5a518ae7f2/0ea19150-3dc5-4183-b6c8-d1b1670526c3, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:41,884 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883281867} | ret=SUCCESS |  
2019-09-19 08:54:41,886 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3} | ret=SUCCESS |  
2019-09-19 08:54:41,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:41,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:41,930 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334762795243} | ret=SUCCESS |  
2019-09-19 08:54:41,946 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334763778284 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,949 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334763778284 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:41,961 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334763778284 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,964 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334763778284 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:41,973 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334763778284 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,978 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334763778284 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:41,987 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334763778284 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:41,990 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334763778284 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:41,992 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,006 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334762795243} | ret=SUCCESS |  
2019-09-19 08:54:42,018 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334768627949 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,026 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334768627949 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:42,040 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334763778284
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334768627949
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,062 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,075 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334772297966} | ret=SUCCESS |  
2019-09-19 08:54:42,088 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334773215471 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,091 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334773215471 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:42,102 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334773215471 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,105 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334773215471 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:42,106 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,117 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334773215471 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,122 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334773215471 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:42,131 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334773215471 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,135 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334773215471 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:42,138 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,151 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334772297966} | ret=SUCCESS |  
2019-09-19 08:54:42,161 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334778196208 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,164 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334778196208 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:42,181 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334773215471
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334778196208
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,309 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,321 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334788419825} | ret=SUCCESS |  
2019-09-19 08:54:42,333 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334789402866 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,337 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334789402866 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:42,349 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334789402866 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,353 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334789402866 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:42,364 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334789402866 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,367 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334789402866 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:42,377 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334789402866 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,379 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334789402866 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:42,382 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334788419825} | ret=SUCCESS |  
2019-09-19 08:54:42,404 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334794186995 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,407 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334794186995 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:42,420 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334789402866
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334794186995
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,422 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, uploadID=154ae755-a767-4640-ae4b-e932d981b3c1-102818334761746666, partNumberMarker=0, maxParts=2, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c} | ret=SUCCESS |  
2019-09-19 08:54:42,423 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=4bf74191-5006-4ae1-9914-be5a518ae7f2, bucket=0ea19150-3dc5-4183-b6c8-d1b1670526c3, uploadID=154ae755-a767-4640-ae4b-e932d981b3c1-102818334761746666, partNumberMarker=2, maxParts=2, key=47acb7e9-e8c6-44c9-a537-e2161e3a256c} | ret=SUCCESS |  
2019-09-19 08:54:42,424 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-10324, with jenkins1000 as owner.
2019-09-19 08:54:42,437 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-10324, creationTime=1568883282425, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,438 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-10324} | ret=SUCCESS |  
2019-09-19 08:54:42,439 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-10324, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:42,440 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-10324, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:42,441 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cc045a2e-f6c3-4a50-8c44-2ca5914b264e, with jenkins1000 as owner.
2019-09-19 08:54:42,454 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cc045a2e-f6c3-4a50-8c44-2ca5914b264e, creationTime=1568883282442, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,455 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=cc045a2e-f6c3-4a50-8c44-2ca5914b264e} | ret=SUCCESS |  
2019-09-19 08:54:42,455 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: cc045a2e-f6c3-4a50-8c44-2ca5914b264e/4bcc63c6-ef38-4025-9694-7b850e522f15, with Versioning false and Storage Type set to SSD and Encryption set to false 
2019-09-19 08:54:42,468 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=cc045a2e-f6c3-4a50-8c44-2ca5914b264e, bucket=4bcc63c6-ef38-4025-9694-7b850e522f15, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=SSD, creationTime=1568883282456} | ret=SUCCESS |  
2019-09-19 08:54:42,469 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=cc045a2e-f6c3-4a50-8c44-2ca5914b264e, bucket=4bcc63c6-ef38-4025-9694-7b850e522f15} | ret=SUCCESS |  
2019-09-19 08:54:42,469 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d, with jenkins1000 as owner.
2019-09-19 08:54:42,482 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d, creationTime=1568883282470, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,482 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d} | ret=SUCCESS |  
2019-09-19 08:54:42,483 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d/8e659e06-2278-4e0d-bd6b-a1480b1ca2c7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,495 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d, bucket=8e659e06-2278-4e0d-bd6b-a1480b1ca2c7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS], user:test1:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282484} | ret=SUCCESS |  
2019-09-19 08:54:42,509 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d, bucket=8e659e06-2278-4e0d-bd6b-a1480b1ca2c7, key=null} | ret=SUCCESS |  
2019-09-19 08:54:42,510 [IPC Server handler 8 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-775_850 to index:850
2019-09-19 08:54:42,511 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_775-850
2019-09-19 08:54:42,524 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851
2019-09-19 08:54:42,526 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=94a4ae87-658c-414f-8f0b-7ef6ff0f9b6d, bucket=8e659e06-2278-4e0d-bd6b-a1480b1ca2c7, key=null} | ret=SUCCESS |  
2019-09-19 08:54:42,527 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, with jenkins1000 as owner.
2019-09-19 08:54:42,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, creationTime=1568883282528, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,540 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913} | ret=SUCCESS |  
2019-09-19 08:54:42,541 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1e8e058f-f41d-47ef-a9c7-0c72b7e0b913/e6b121ea-0115-4d15-b697-feb771146745, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,553 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282541} | ret=SUCCESS |  
2019-09-19 08:54:42,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745} | ret=SUCCESS |  
2019-09-19 08:54:42,556 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, key=10de71c1-ef22-4ddd-9d72-adef810bb8de, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334805590260
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,573 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334805590260 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,576 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334805590260 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:42,580 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, key=10de71c1-ef22-4ddd-9d72-adef810bb8de, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334805590260
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:42,582 [IPC Server handler 3 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:42,583 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:42,583 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, key=10de71c1-ef22-4ddd-9d72-adef810bb8de, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:42,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, key=10de71c1-ef22-4ddd-9d72-adef810bb8de, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,588 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=1e8e058f-f41d-47ef-a9c7-0c72b7e0b913, bucket=e6b121ea-0115-4d15-b697-feb771146745, key=10de71c1-ef22-4ddd-9d72-adef810bb8de, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-19 08:54:42,591 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b1fcbf42-9537-44c7-b077-f2947738e16c, with jenkins1000 as owner.
2019-09-19 08:54:42,594 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b1fcbf42-9537-44c7-b077-f2947738e16c, creationTime=1568883282592, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,595 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b1fcbf42-9537-44c7-b077-f2947738e16c} | ret=SUCCESS |  
2019-09-19 08:54:42,603 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_VOLUME {volume=b1fcbf42-9537-44c7-b077-f2947738e16c} | ret=SUCCESS |  
2019-09-19 08:54:42,605 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b1fcbf42-9537-44c7-b077-f2947738e16c} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume b1fcbf42-9537-44c7-b077-f2947738e16c is not found
	at org.apache.hadoop.ozone.om.VolumeManagerImpl.getVolumeInfo(VolumeManagerImpl.java:326)
	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1933) 
2019-09-19 08:54:42,606 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 71033d06-4fde-42ab-9787-24425eb2dea5, with jenkins1000 as owner.
2019-09-19 08:54:42,609 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=71033d06-4fde-42ab-9787-24425eb2dea5, creationTime=1568883282607, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,610 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=71033d06-4fde-42ab-9787-24425eb2dea5} | ret=SUCCESS |  
2019-09-19 08:54:42,616 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 8ad0ba4f-350e-4c73-b003-0560a6dba851, with jenkins1000 as owner.
2019-09-19 08:54:42,619 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, creationTime=1568883282617, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851} | ret=SUCCESS |  
2019-09-19 08:54:42,621 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 8ad0ba4f-350e-4c73-b003-0560a6dba851/f3a7206f-9da5-4dab-a64d-9c6b532ee7de, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,623 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282621} | ret=SUCCESS |  
2019-09-19 08:54:42,624 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de} | ret=SUCCESS |  
2019-09-19 08:54:42,627 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:42,630 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de, key=3f681018-e928-4a6e-8482-c60c5c732d10, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818334810243318
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "99f0d179-1c0b-4b8a-81fa-220f5c9ded30"
  }
}
]} | ret=SUCCESS |  
Sep 19, 2019 8:54:42 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=132, target=192.168.157.204:43534} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:175)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:423)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:372)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:285)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:167)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:222)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testGetKeyDetails(TestOzoneRpcClientAbstract.java:999)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

Sep 19, 2019 8:54:42 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=122, target=192.168.157.204:43534} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:175)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:423)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:372)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:285)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:167)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:222)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagDisable(TestOzoneRpcClientAbstract.java:905)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

2019-09-19 08:54:42,647 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818334810243318 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,650 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818334810243318 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:42,653 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-DF8A19BF1231->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-DF8A19BF1231->18897f3d-a606-48ca-8ab1-50a74a285275@group-220F5C9DED30, cid=40, SUCCESS, logIndex=5, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c6]
2019-09-19 08:54:42,665 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,669 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102818334810243318 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:42,671 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-DF8A19BF1231->18897f3d-a606-48ca-8ab1-50a74a285275: receive RaftClientReply:client-DF8A19BF1231->18897f3d-a606-48ca-8ab1-50a74a285275@group-220F5C9DED30, cid=41, SUCCESS, logIndex=7, commits[18897f3d-a606-48ca-8ab1-50a74a285275:c8]
2019-09-19 08:54:42,678 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de, key=3f681018-e928-4a6e-8482-c60c5c732d10, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818334810243318
  }
  blockCommitSequenceId: 7
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "99f0d179-1c0b-4b8a-81fa-220f5c9ded30"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:42,680 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:42,681 [IPC Server handler 13 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:42,681 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:42,682 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de, key=3f681018-e928-4a6e-8482-c60c5c732d10, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:42,693 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:42,694 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:42,694 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:42,695 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=8ad0ba4f-350e-4c73-b003-0560a6dba851, bucket=f3a7206f-9da5-4dab-a64d-9c6b532ee7de, key=3f681018-e928-4a6e-8482-c60c5c732d10, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:42,703 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102818334810243318 bcsId: 7} | ret=SUCCESS |  
2019-09-19 08:54:42,707 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102818334810243318 bcsId: 7} | ret=SUCCESS |  
2019-09-19 08:54:42,709 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "f35e693583b62b56:f35e693583b62b56:0:0"
containerID: 2
datanodeUuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
readChunk {
  blockID {
    containerID: 2
    localID: 102818334810243318
    blockCommitSequenceId: 7
  }
  chunkData {
    chunkName: "102818334810243318_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 18897f3d-a606-48ca-8ab1-50a74a285275
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagEnable(TestOzoneRpcClientAbstract.java:890)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:42,710 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "f35e693583b62b56:f35e693583b62b56:0:0"
containerID: 2
datanodeUuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
readChunk {
  blockID {
    containerID: 2
    localID: 102818334810243318
    blockCommitSequenceId: 7
  }
  chunkData {
    chunkName: "102818334810243318_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: 99f0d179-1c0b-4b8a-81fa-220f5c9ded30, Nodes: 18897f3d-a606-48ca-8ab1-50a74a285275{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-19 08:54:42,711 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 66c85fc6-232f-4645-abb9-699a4573ac08, with jenkins1000 as owner.
2019-09-19 08:54:42,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=66c85fc6-232f-4645-abb9-699a4573ac08, creationTime=1568883282712, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=66c85fc6-232f-4645-abb9-699a4573ac08} | ret=SUCCESS |  
2019-09-19 08:54:42,726 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 66c85fc6-232f-4645-abb9-699a4573ac08/55d873b5-a4f0-4119-990b-3d2dd6ef9093, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,738 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=66c85fc6-232f-4645-abb9-699a4573ac08, bucket=55d873b5-a4f0-4119-990b-3d2dd6ef9093, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282727} | ret=SUCCESS |  
2019-09-19 08:54:42,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=66c85fc6-232f-4645-abb9-699a4573ac08, bucket=55d873b5-a4f0-4119-990b-3d2dd6ef9093} | ret=SUCCESS |  
2019-09-19 08:54:42,752 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=66c85fc6-232f-4645-abb9-699a4573ac08, bucket=55d873b5-a4f0-4119-990b-3d2dd6ef9093, key=4d38e305-5033-40db-bc78-aa688758e5cc, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=66c85fc6-232f-4645-abb9-699a4573ac08, bucket=55d873b5-a4f0-4119-990b-3d2dd6ef9093, key=4d38e305-5033-40db-bc78-aa688758e5cc, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,765 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 982b555c-2e4a-4d18-9a5b-fffb9e5df5c6, with jenkins1000 as owner.
2019-09-19 08:54:42,778 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=982b555c-2e4a-4d18-9a5b-fffb9e5df5c6, creationTime=1568883282766, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=982b555c-2e4a-4d18-9a5b-fffb9e5df5c6} | ret=SUCCESS |  
2019-09-19 08:54:42,780 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 982b555c-2e4a-4d18-9a5b-fffb9e5df5c6/bbb28cb0-e458-4c2f-98d0-3e56cb6b6cd5, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,792 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=982b555c-2e4a-4d18-9a5b-fffb9e5df5c6, bucket=bbb28cb0-e458-4c2f-98d0-3e56cb6b6cd5, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282781} | ret=SUCCESS |  
2019-09-19 08:54:42,794 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=982b555c-2e4a-4d18-9a5b-fffb9e5df5c6, bucket=bbb28cb0-e458-4c2f-98d0-3e56cb6b6cd5} | ret=SUCCESS |  
2019-09-19 08:54:42,795 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6744f03b-4074-4900-af22-5ca62af35700, with jenkins1000 as owner.
2019-09-19 08:54:42,807 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6744f03b-4074-4900-af22-5ca62af35700, creationTime=1568883282796, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6744f03b-4074-4900-af22-5ca62af35700} | ret=SUCCESS |  
2019-09-19 08:54:42,809 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6744f03b-4074-4900-af22-5ca62af35700/451aff84-66d4-46b1-86ce-27213d10eec2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,821 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6744f03b-4074-4900-af22-5ca62af35700, bucket=451aff84-66d4-46b1-86ce-27213d10eec2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282810} | ret=SUCCESS |  
2019-09-19 08:54:42,823 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6744f03b-4074-4900-af22-5ca62af35700, bucket=451aff84-66d4-46b1-86ce-27213d10eec2} | ret=SUCCESS |  
2019-09-19 08:54:42,837 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=6744f03b-4074-4900-af22-5ca62af35700, bucket=451aff84-66d4-46b1-86ce-27213d10eec2, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-19 08:54:42,839 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6744f03b-4074-4900-af22-5ca62af35700, bucket=451aff84-66d4-46b1-86ce-27213d10eec2} | ret=SUCCESS |  
2019-09-19 08:54:42,840 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 4c2fc1b6-8bea-4205-ac4c-bf8102969737, with jenkins1000 as owner.
2019-09-19 08:54:42,843 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=4c2fc1b6-8bea-4205-ac4c-bf8102969737, creationTime=1568883282841, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,844 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=4c2fc1b6-8bea-4205-ac4c-bf8102969737} | ret=SUCCESS |  
2019-09-19 08:54:42,845 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 4c2fc1b6-8bea-4205-ac4c-bf8102969737/889229c7-d882-4df6-9125-d21cf8c60d9e, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=4c2fc1b6-8bea-4205-ac4c-bf8102969737, bucket=889229c7-d882-4df6-9125-d21cf8c60d9e, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282845} | ret=SUCCESS |  
2019-09-19 08:54:42,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=4c2fc1b6-8bea-4205-ac4c-bf8102969737, bucket=889229c7-d882-4df6-9125-d21cf8c60d9e} | ret=SUCCESS |  
2019-09-19 08:54:42,880 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=4c2fc1b6-8bea-4205-ac4c-bf8102969737, bucket=889229c7-d882-4df6-9125-d21cf8c60d9e, key=ab10456b-a135-4c2d-b1c5-36767e72542f, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: 4c2fc1b6-8bea-4205-ac4c-bf8102969737bucket: 889229c7-d882-4df6-9125-d21cf8c60d9ekey: ab10456b-a135-4c2d-b1c5-36767e72542f
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:42,882 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest (S3MultipartUploadAbortRequest.java:validateAndUpdateCache(167)) - Abort Multipart request is failed for KeyName ab10456b-a135-4c2d-b1c5-36767e72542f in VolumeName/Bucket 4c2fc1b6-8bea-4205-ac4c-bf8102969737/889229c7-d882-4df6-9125-d21cf8c60d9e
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: 4c2fc1b6-8bea-4205-ac4c-bf8102969737bucket: 889229c7-d882-4df6-9125-d21cf8c60d9ekey: ab10456b-a135-4c2d-b1c5-36767e72542f
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:42,896 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {377c7822-7706-45e6-81c9-173a47ae1585=s3Bucket, ozone=username} | ret=SUCCESS |  
2019-09-19 08:54:42,898 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone} | ret=SUCCESS |  
2019-09-19 08:54:42,899 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone, bucket=377c7822-7706-45e6-81c9-173a47ae1585} | ret=SUCCESS |  
2019-09-19 08:54:42,901 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3600897d-9077-4533-ae09-59a30a0edac3, with jenkins1000 as owner.
2019-09-19 08:54:42,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3600897d-9077-4533-ae09-59a30a0edac3, creationTime=1568883282902, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:42,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3600897d-9077-4533-ae09-59a30a0edac3} | ret=SUCCESS |  
2019-09-19 08:54:42,917 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 3600897d-9077-4533-ae09-59a30a0edac3/36a12292-57ca-4067-a129-b4bcc05bccff, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:42,937 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=3600897d-9077-4533-ae09-59a30a0edac3, bucket=36a12292-57ca-4067-a129-b4bcc05bccff, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883282918} | ret=SUCCESS |  
2019-09-19 08:54:42,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=3600897d-9077-4533-ae09-59a30a0edac3, bucket=36a12292-57ca-4067-a129-b4bcc05bccff} | ret=SUCCESS |  
2019-09-19 08:54:42,948 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=3600897d-9077-4533-ae09-59a30a0edac3, bucket=36a12292-57ca-4067-a129-b4bcc05bccff, key=a191428b-3128-4455-8ff0-e2281f39d9ae, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,984 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3600897d-9077-4533-ae09-59a30a0edac3, bucket=36a12292-57ca-4067-a129-b4bcc05bccff, key=a191428b-3128-4455-8ff0-e2281f39d9ae, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:42,986 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:42,987 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:42,987 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:42,987 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:42,988 [IPC Server handler 8 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:42,988 [IPC Server handler 8 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:42,988 [IPC Server handler 8 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:42,989 [IPC Server handler 8 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:42,989 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:42,990 [IPC Server handler 8 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 40501, call Call#1020 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:42,993 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:42,995 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:42,995 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:42,995 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:42,996 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:42,996 [IPC Server handler 10 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:42,996 [IPC Server handler 10 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:42,996 [IPC Server handler 10 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:42,997 [IPC Server handler 10 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:42,997 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:42,997 [IPC Server handler 10 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 40501, call Call#1020 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:42,999 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,001 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,001 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,001 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,002 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,002 [IPC Server handler 11 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,002 [IPC Server handler 11 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,002 [IPC Server handler 11 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,003 [IPC Server handler 11 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,003 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,003 [IPC Server handler 19 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 40501, call Call#1020 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,005 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,006 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,007 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,007 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,007 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,007 [IPC Server handler 1 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,008 [IPC Server handler 1 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,008 [IPC Server handler 1 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,008 [IPC Server handler 1 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,008 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,009 [IPC Server handler 16 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 40501, call Call#1020 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,011 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,012 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,013 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,013 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,013 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,013 [IPC Server handler 2 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,014 [IPC Server handler 2 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,014 [IPC Server handler 2 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,014 [IPC Server handler 2 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,015 [IPC Server handler 6 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 40501, call Call#1020 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,017 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,018 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,018 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,019 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,019 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,019 [IPC Server handler 5 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,019 [IPC Server handler 5 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,020 [IPC Server handler 5 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,020 [IPC Server handler 5 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,020 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,021 [IPC Server handler 1 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 40501, call Call#1020 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,022 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,024 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,024 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,024 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,024 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,025 [IPC Server handler 4 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,025 [IPC Server handler 4 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,025 [IPC Server handler 4 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,026 [IPC Server handler 4 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,026 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,026 [IPC Server handler 17 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 40501, call Call#1020 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,028 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,029 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,029 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,030 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,030 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,030 [IPC Server handler 6 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,030 [IPC Server handler 6 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,031 [IPC Server handler 6 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,031 [IPC Server handler 6 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,031 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,032 [IPC Server handler 7 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 40501, call Call#1020 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,033 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,035 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,035 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,035 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,035 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,035 [IPC Server handler 7 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,036 [IPC Server handler 7 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,036 [IPC Server handler 7 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,036 [IPC Server handler 7 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,036 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,037 [IPC Server handler 2 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 40501, call Call#1020 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,038 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,040 [IPC Server handler 3 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,041 [IPC Server handler 3 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,041 [IPC Server handler 3 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,041 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,041 [IPC Server handler 3 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 40501, call Call#1020 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,043 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,044 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,044 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,045 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,045 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,045 [IPC Server handler 16 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,045 [IPC Server handler 16 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,046 [IPC Server handler 16 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,046 [IPC Server handler 16 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,046 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,047 [IPC Server handler 12 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 40501, call Call#1020 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,048 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:43,049 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUploadOverride(TestOzoneRpcClientAbstract.java:1848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:43,052 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 9f4d2ae4-bd05-4986-8ea1-3849f008eacb, with jenkins1000 as owner.
2019-09-19 08:54:43,065 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, creationTime=1568883283053, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb} | ret=SUCCESS |  
2019-09-19 08:54:43,067 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 9f4d2ae4-bd05-4986-8ea1-3849f008eacb/25978d43-dba4-458e-bfca-9a7f62cb328d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,079 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, bucket=25978d43-dba4-458e-bfca-9a7f62cb328d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283067} | ret=SUCCESS |  
2019-09-19 08:54:43,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, bucket=25978d43-dba4-458e-bfca-9a7f62cb328d} | ret=SUCCESS |  
2019-09-19 08:54:43,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, bucket=25978d43-dba4-458e-bfca-9a7f62cb328d, key=26b941da-c3a3-427b-beb8-cd1c61af2dd1, dataSize=4194304, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334840062203
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,100 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334840062203 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,102 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334840062203 bcsId: 0,size=1350]} | ret=SUCCESS |  
2019-09-19 08:54:43,105 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,119 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, bucket=25978d43-dba4-458e-bfca-9a7f62cb328d, key=26b941da-c3a3-427b-beb8-cd1c61af2dd1, dataSize=1350, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334840062203
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1350
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,120 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,121 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=9f4d2ae4-bd05-4986-8ea1-3849f008eacb, bucket=25978d43-dba4-458e-bfca-9a7f62cb328d, key=26b941da-c3a3-427b-beb8-cd1c61af2dd1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,122 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b5fdb2f7-f918-415b-9e24-c79d3447633c, with jenkins1000 as owner.
2019-09-19 08:54:43,135 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b5fdb2f7-f918-415b-9e24-c79d3447633c, creationTime=1568883283123, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,136 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b5fdb2f7-f918-415b-9e24-c79d3447633c} | ret=SUCCESS |  
2019-09-19 08:54:43,136 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b5fdb2f7-f918-415b-9e24-c79d3447633c/0d18db8d-76d8-40ae-a127-634a2b40a5f3, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b5fdb2f7-f918-415b-9e24-c79d3447633c, bucket=0d18db8d-76d8-40ae-a127-634a2b40a5f3, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283137} | ret=SUCCESS |  
2019-09-19 08:54:43,150 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b5fdb2f7-f918-415b-9e24-c79d3447633c, bucket=0d18db8d-76d8-40ae-a127-634a2b40a5f3} | ret=SUCCESS |  
2019-09-19 08:54:43,161 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b5fdb2f7-f918-415b-9e24-c79d3447633c, bucket=0d18db8d-76d8-40ae-a127-634a2b40a5f3, key=bf99809f-2594-4be2-9719-6ea0efadb06c, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,174 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=b5fdb2f7-f918-415b-9e24-c79d3447633c, bucket=0d18db8d-76d8-40ae-a127-634a2b40a5f3, key=bf99809f-2594-4be2-9719-6ea0efadb06c, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=96922e69-3679-4378-90af-ebeddf1bac42}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: b5fdb2f7-f918-415b-9e24-c79d3447633cbucket: 0d18db8d-76d8-40ae-a127-634a2b40a5f3key: bf99809f-2594-4be2-9719-6ea0efadb06c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:43,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: bf99809f-2594-4be2-9719-6ea0efadb06c in Volume/Bucket b5fdb2f7-f918-415b-9e24-c79d3447633c/0d18db8d-76d8-40ae-a127-634a2b40a5f3
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: b5fdb2f7-f918-415b-9e24-c79d3447633cbucket: 0d18db8d-76d8-40ae-a127-634a2b40a5f3key: bf99809f-2594-4be2-9719-6ea0efadb06c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:43,184 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: efc00287-628c-4760-8a84-e50cce568360, with jenkins1000 as owner.
2019-09-19 08:54:43,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=efc00287-628c-4760-8a84-e50cce568360, creationTime=1568883283185, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=efc00287-628c-4760-8a84-e50cce568360} | ret=SUCCESS |  
2019-09-19 08:54:43,195 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: efc00287-628c-4760-8a84-e50cce568360/6e4a47ed-09fe-4638-a18a-7d4c5a855c2d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=efc00287-628c-4760-8a84-e50cce568360, bucket=6e4a47ed-09fe-4638-a18a-7d4c5a855c2d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283196} | ret=SUCCESS |  
2019-09-19 08:54:43,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=efc00287-628c-4760-8a84-e50cce568360, bucket=6e4a47ed-09fe-4638-a18a-7d4c5a855c2d} | ret=SUCCESS |  
2019-09-19 08:54:43,220 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRequest (OMKeyRequest.java:prepareCreateKeyResponse(331)) - ALLOCATE_KEY failed for Key: f48154eb-af16-494a-82c8-1d4121cc4911 in volume/bucket:efc00287-628c-4760-8a84-e50cce568360/6e4a47ed-09fe-4638-a18a-7d4c5a855c2d
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422)
	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:179)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:43,221 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=efc00287-628c-4760-8a84-e50cce568360, bucket=6e4a47ed-09fe-4638-a18a-7d4c5a855c2d, key=f48154eb-af16-494a-82c8-1d4121cc4911, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422) 
2019-09-19 08:54:43,222 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ebf1439a-6b09-4ab3-acfa-c90556da9779, with jenkins1000 as owner.
2019-09-19 08:54:43,234 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ebf1439a-6b09-4ab3-acfa-c90556da9779, creationTime=1568883283222, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ebf1439a-6b09-4ab3-acfa-c90556da9779} | ret=SUCCESS |  
2019-09-19 08:54:43,236 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ebf1439a-6b09-4ab3-acfa-c90556da9779/a3b57f9d-1412-4ed3-89a6-61b5323420e9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,249 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ebf1439a-6b09-4ab3-acfa-c90556da9779, bucket=a3b57f9d-1412-4ed3-89a6-61b5323420e9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283237} | ret=SUCCESS |  
2019-09-19 08:54:43,250 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ebf1439a-6b09-4ab3-acfa-c90556da9779, bucket=a3b57f9d-1412-4ed3-89a6-61b5323420e9} | ret=SUCCESS |  
2019-09-19 08:54:43,252 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,252 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,252 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,253 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,253 [IPC Server handler 13 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,253 [IPC Server handler 13 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,254 [IPC Server handler 13 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,254 [IPC Server handler 13 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,254 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,255 [IPC Server handler 18 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 40501, call Call#1056 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,257 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:43,258 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,259 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,259 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,259 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,259 [IPC Server handler 19 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,259 [IPC Server handler 19 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,260 [IPC Server handler 19 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,260 [IPC Server handler 19 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,260 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,260 [IPC Server handler 11 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 40501, call Call#1056 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,262 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,263 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,264 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,264 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,264 [IPC Server handler 18 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,264 [IPC Server handler 18 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,265 [IPC Server handler 18 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,265 [IPC Server handler 18 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,265 [IPC Server handler 18 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,265 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,266 [IPC Server handler 5 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 40501, call Call#1056 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,267 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,269 [IPC Server handler 0 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,270 [IPC Server handler 0 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,270 [IPC Server handler 0 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,271 [IPC Server handler 13 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 40501, call Call#1056 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,272 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,273 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,274 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,274 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,274 [IPC Server handler 15 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,274 [IPC Server handler 15 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,275 [IPC Server handler 15 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,275 [IPC Server handler 15 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,275 [IPC Server handler 15 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,276 [IPC Server handler 0 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 40501, call Call#1056 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,277 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,278 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,279 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,279 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,279 [IPC Server handler 14 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,279 [IPC Server handler 14 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,279 [IPC Server handler 14 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,280 [IPC Server handler 14 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,280 [IPC Server handler 14 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,280 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,281 [IPC Server handler 4 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 40501, call Call#1056 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,282 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,284 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,284 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,284 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,284 [IPC Server handler 9 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,284 [IPC Server handler 9 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,285 [IPC Server handler 9 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,285 [IPC Server handler 9 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,285 [IPC Server handler 9 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,285 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,286 [IPC Server handler 9 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 40501, call Call#1056 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,287 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,288 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,289 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,289 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,289 [IPC Server handler 17 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,289 [IPC Server handler 17 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,290 [IPC Server handler 17 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,290 [IPC Server handler 17 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,290 [IPC Server handler 17 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,290 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,291 [IPC Server handler 14 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 40501, call Call#1056 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,292 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,294 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,294 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,294 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,294 [IPC Server handler 8 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,295 [IPC Server handler 8 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,295 [IPC Server handler 8 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,300 [IPC Server handler 8 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,300 [IPC Server handler 8 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,300 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,301 [IPC Server handler 8 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 40501, call Call#1056 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,305 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,306 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,307 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,307 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,307 [IPC Server handler 10 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,307 [IPC Server handler 10 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,307 [IPC Server handler 10 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,308 [IPC Server handler 10 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,308 [IPC Server handler 10 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,308 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,309 [IPC Server handler 10 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 40501, call Call#1056 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,310 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,312 [IPC Server handler 11 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,313 [IPC Server handler 11 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,313 [IPC Server handler 11 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,313 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,313 [IPC Server handler 19 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 40501, call Call#1056 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,315 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:43,317 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-24917, with jenkins1000 as owner.
2019-09-19 08:54:43,330 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-24917, creationTime=1568883283318, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-24917} | ret=SUCCESS |  
2019-09-19 08:54:43,332 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-24917/buc-98372, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,344 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-24917, bucket=buc-98372, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283332} | ret=SUCCESS |  
2019-09-19 08:54:43,345 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-24917, bucket=buc-98372} | ret=SUCCESS |  
2019-09-19 08:54:43,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-24917, bucket=buc-98372, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-19 08:54:43,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-24917, bucket=buc-98372, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-19 08:54:43,348 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: abc1a85b-e1c1-4355-8d94-78bbf5549672, with jenkins1000 as owner.
2019-09-19 08:54:43,361 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=abc1a85b-e1c1-4355-8d94-78bbf5549672, creationTime=1568883283349, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,362 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=abc1a85b-e1c1-4355-8d94-78bbf5549672} | ret=SUCCESS |  
2019-09-19 08:54:43,362 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: abc1a85b-e1c1-4355-8d94-78bbf5549672/432c73ea-d644-483b-bc24-b88285258e5c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,375 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=abc1a85b-e1c1-4355-8d94-78bbf5549672, bucket=432c73ea-d644-483b-bc24-b88285258e5c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283363} | ret=SUCCESS |  
2019-09-19 08:54:43,377 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=abc1a85b-e1c1-4355-8d94-78bbf5549672, bucket=432c73ea-d644-483b-bc24-b88285258e5c} | ret=SUCCESS |  
2019-09-19 08:54:43,379 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,379 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,379 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,379 [IPC Server handler 1 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,380 [IPC Server handler 1 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,380 [IPC Server handler 1 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,380 [IPC Server handler 1 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,381 [IPC Server handler 1 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,381 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,381 [IPC Server handler 11 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 40501, call Call#1078 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,383 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501. Trying to failover immediately.
2019-09-19 08:54:43,385 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,385 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,385 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,385 [IPC Server handler 2 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,386 [IPC Server handler 2 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,386 [IPC Server handler 2 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,386 [IPC Server handler 2 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,386 [IPC Server handler 2 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,387 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,387 [IPC Server handler 5 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 40501, call Call#1078 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,389 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,390 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,390 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,391 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,391 [IPC Server handler 5 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,391 [IPC Server handler 5 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,391 [IPC Server handler 5 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,392 [IPC Server handler 5 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,392 [IPC Server handler 5 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,392 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,392 [IPC Server handler 13 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 40501, call Call#1078 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,394 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,396 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,396 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,396 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,396 [IPC Server handler 4 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,396 [IPC Server handler 4 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,397 [IPC Server handler 4 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,397 [IPC Server handler 4 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,397 [IPC Server handler 4 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,397 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,398 [IPC Server handler 0 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 40501, call Call#1078 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,400 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,401 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,401 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,402 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,402 [IPC Server handler 6 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,402 [IPC Server handler 6 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,402 [IPC Server handler 6 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,403 [IPC Server handler 6 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,403 [IPC Server handler 6 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,403 [IPC Server handler 4 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 40501, call Call#1078 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,405 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,406 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,407 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,407 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,407 [IPC Server handler 7 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,407 [IPC Server handler 7 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,408 [IPC Server handler 7 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,408 [IPC Server handler 7 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,408 [IPC Server handler 7 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,409 [IPC Server handler 9 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 40501, call Call#1078 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,411 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,412 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,412 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,412 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,413 [IPC Server handler 3 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,413 [IPC Server handler 3 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,413 [IPC Server handler 3 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,413 [IPC Server handler 3 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,414 [IPC Server handler 3 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,414 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,414 [IPC Server handler 14 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 40501, call Call#1078 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,416 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,417 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,417 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,417 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,418 [IPC Server handler 16 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,418 [IPC Server handler 16 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,418 [IPC Server handler 16 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,419 [IPC Server handler 16 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,419 [IPC Server handler 16 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,419 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,419 [IPC Server handler 8 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 40501, call Call#1078 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,421 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,423 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,423 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,423 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,423 [IPC Server handler 12 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,424 [IPC Server handler 12 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,424 [IPC Server handler 12 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,424 [IPC Server handler 12 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,424 [IPC Server handler 12 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,425 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,425 [IPC Server handler 10 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 40501, call Call#1078 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,427 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,428 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,428 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,429 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,429 [IPC Server handler 13 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,429 [IPC Server handler 13 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,429 [IPC Server handler 13 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,430 [IPC Server handler 13 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,430 [IPC Server handler 13 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,430 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,431 [IPC Server handler 19 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 40501, call Call#1078 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,433 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:40501 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,434 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:43,434 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,434 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,435 [IPC Server handler 19 on 41217] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,435 [IPC Server handler 19 on 41217] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,435 [IPC Server handler 19 on 41217] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,435 [IPC Server handler 19 on 41217] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,436 [IPC Server handler 19 on 41217] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,436 [IPC Server handler 16 on 40501] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 40501, call Call#1078 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:56566
java.lang.NullPointerException
2019-09-19 08:54:43,438 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:43,440 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 929c6d8e-5248-47cf-8412-c2647fb057e7, with jenkins1000 as owner.
2019-09-19 08:54:43,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=929c6d8e-5248-47cf-8412-c2647fb057e7, creationTime=1568883283441, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,454 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=929c6d8e-5248-47cf-8412-c2647fb057e7} | ret=SUCCESS |  
2019-09-19 08:54:43,455 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 929c6d8e-5248-47cf-8412-c2647fb057e7/efb983a1-b7bd-48c5-b83d-d285aea1751c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,486 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283456} | ret=SUCCESS |  
2019-09-19 08:54:43,488 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c} | ret=SUCCESS |  
2019-09-19 08:54:43,489 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=5664cdcf-324b-40f1-86bc-4038849bfb81, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334866735359
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,507 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334866735359 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,510 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334866735359 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,523 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=5664cdcf-324b-40f1-86bc-4038849bfb81, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334866735359
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,525 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,526 [IPC Server handler 0 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,526 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,527 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=5664cdcf-324b-40f1-86bc-4038849bfb81, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,529 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,530 [IPC Server handler 15 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,530 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=5664cdcf-324b-40f1-86bc-4038849bfb81, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,538 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334866735359 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,548 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334866735359 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,549 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,550 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=5664cdcf-324b-40f1-86bc-4038849bfb81, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=befe652e-96b9-43bc-a11b-7193ca74fede, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334870864129
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,565 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,567 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334870864129 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,569 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334870864129 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,582 [Thread-145] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-851_955 to index:955
2019-09-19 08:54:43,583 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_851-955
2019-09-19 08:54:43,583 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=befe652e-96b9-43bc-a11b-7193ca74fede, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334870864129
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,585 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,586 [IPC Server handler 9 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,586 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=befe652e-96b9-43bc-a11b-7193ca74fede, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,588 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,589 [IPC Server handler 17 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,589 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,590 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=befe652e-96b9-43bc-a11b-7193ca74fede, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,592 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334870864129 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,596 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334870864129 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,598 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,598 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=befe652e-96b9-43bc-a11b-7193ca74fede, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,599 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,601 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,607 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956
2019-09-19 08:54:43,608 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=e9c5011d-c1ed-4381-95cf-3d2503a4444a, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334874075395
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,611 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334874075395 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,614 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334874075395 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,627 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=e9c5011d-c1ed-4381-95cf-3d2503a4444a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334874075395
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,629 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,630 [IPC Server handler 10 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,630 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,631 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=e9c5011d-c1ed-4381-95cf-3d2503a4444a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,632 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,633 [IPC Server handler 11 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,634 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,634 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=e9c5011d-c1ed-4381-95cf-3d2503a4444a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,638 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334874075395 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,640 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334874075395 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,644 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,644 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=e9c5011d-c1ed-4381-95cf-3d2503a4444a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,645 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,647 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,659 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=655e2238-763d-49f3-b74e-30d3346264ae, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334877024517
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,662 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334877024517 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,664 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,665 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334877024517 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,668 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=655e2238-763d-49f3-b74e-30d3346264ae, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334877024517
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,670 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,671 [IPC Server handler 2 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,671 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,672 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=655e2238-763d-49f3-b74e-30d3346264ae, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,674 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,675 [IPC Server handler 5 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,675 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,675 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=655e2238-763d-49f3-b74e-30d3346264ae, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,678 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334877024517 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,682 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334877024517 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,685 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,685 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=655e2238-763d-49f3-b74e-30d3346264ae, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,686 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,687 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,690 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=8a5d0718-d9f5-4a80-8dcb-a174b9a91563, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334879711495
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,693 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334879711495 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,696 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334879711495 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,700 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=8a5d0718-d9f5-4a80-8dcb-a174b9a91563, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334879711495
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,702 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,703 [IPC Server handler 6 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,703 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,703 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=8a5d0718-d9f5-4a80-8dcb-a174b9a91563, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,705 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,706 [IPC Server handler 7 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,707 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=8a5d0718-d9f5-4a80-8dcb-a174b9a91563, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,710 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334879711495 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,714 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334879711495 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,717 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,717 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=8a5d0718-d9f5-4a80-8dcb-a174b9a91563, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,718 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,719 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=d36154ff-38f1-4f24-a9c2-e3cbc1f7f9fd, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334881808649
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,726 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334881808649 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,728 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334881808649 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,732 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=d36154ff-38f1-4f24-a9c2-e3cbc1f7f9fd, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334881808649
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,735 [IPC Server handler 16 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,736 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=d36154ff-38f1-4f24-a9c2-e3cbc1f7f9fd, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,739 [IPC Server handler 12 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,739 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,739 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=d36154ff-38f1-4f24-a9c2-e3cbc1f7f9fd, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,742 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334881808649 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,745 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334881808649 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,748 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,748 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=d36154ff-38f1-4f24-a9c2-e3cbc1f7f9fd, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,749 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,750 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=9dd8392f-13f3-4a82-96e0-6723b34dd711, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334883840267
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,771 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334883840267 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,773 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334883840267 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=9dd8392f-13f3-4a82-96e0-6723b34dd711, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334883840267
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,790 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,791 [IPC Server handler 19 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,791 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,791 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=9dd8392f-13f3-4a82-96e0-6723b34dd711, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,793 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,794 [IPC Server handler 18 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,794 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,795 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=9dd8392f-13f3-4a82-96e0-6723b34dd711, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,797 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334883840267 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,801 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334883840267 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,807 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,807 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=9dd8392f-13f3-4a82-96e0-6723b34dd711, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,810 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,823 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=fd31fb39-ab03-49ff-92b7-ba01ef78bdbf, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334887772429
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,827 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334887772429 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,829 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334887772429 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,843 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=fd31fb39-ab03-49ff-92b7-ba01ef78bdbf, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334887772429
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,845 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,846 [IPC Server handler 15 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,846 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=fd31fb39-ab03-49ff-92b7-ba01ef78bdbf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,848 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,849 [IPC Server handler 14 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,850 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,850 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=fd31fb39-ab03-49ff-92b7-ba01ef78bdbf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,853 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334887772429 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,855 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334887772429 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,857 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,857 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=fd31fb39-ab03-49ff-92b7-ba01ef78bdbf, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,858 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,859 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=b9b34a5e-a66f-466f-865a-ed8ca1a89611, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334890983695
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,876 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334890983695 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,878 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334890983695 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,892 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=b9b34a5e-a66f-466f-865a-ed8ca1a89611, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334890983695
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,893 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,894 [IPC Server handler 17 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,894 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,895 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=b9b34a5e-a66f-466f-865a-ed8ca1a89611, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,896 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,897 [IPC Server handler 8 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,898 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,898 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=b9b34a5e-a66f-466f-865a-ed8ca1a89611, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,901 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334890983695 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,903 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334890983695 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,905 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,905 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=b9b34a5e-a66f-466f-865a-ed8ca1a89611, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,906 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,908 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:43,921 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=17d25638-0f8c-4f2a-8e4c-6e4b1ea45771, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334894194961
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,924 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334894194961 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,927 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334894194961 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:43,940 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=17d25638-0f8c-4f2a-8e4c-6e4b1ea45771, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334894194961
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:43,942 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,944 [IPC Server handler 11 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,944 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,945 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=17d25638-0f8c-4f2a-8e4c-6e4b1ea45771, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,947 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,948 [IPC Server handler 1 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:43,948 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:43,948 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=17d25638-0f8c-4f2a-8e4c-6e4b1ea45771, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,951 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818334894194961 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,954 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818334894194961 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:43,956 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:43,957 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=929c6d8e-5248-47cf-8412-c2647fb057e7, bucket=efb983a1-b7bd-48c5-b83d-d285aea1751c, key=17d25638-0f8c-4f2a-8e4c-6e4b1ea45771, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:43,958 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:43,959 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ae078efc-d664-4018-9eeb-bf81aa719a90, with jenkins1000 as owner.
2019-09-19 08:54:43,972 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ae078efc-d664-4018-9eeb-bf81aa719a90, creationTime=1568883283960, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ae078efc-d664-4018-9eeb-bf81aa719a90} | ret=SUCCESS |  
2019-09-19 08:54:43,974 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ae078efc-d664-4018-9eeb-bf81aa719a90/7b2376cc-71df-40d7-9a9b-4ec56157ee52, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,987 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283975} | ret=SUCCESS |  
2019-09-19 08:54:43,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52} | ret=SUCCESS |  
2019-09-19 08:54:43,990 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,003 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52, key=a14f72f0-ddc7-4b6d-a5f3-0e64483f0b71, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102818334899568915
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 43927
    }
    ports {
      name: "RATIS"
      value: 43014
    }
    ports {
      name: "STANDALONE"
      value: 39573
    }
    networkName: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "dc4b7dc7-4444-4ee8-833c-b5e39996abb1"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,105 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,228 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102818334899568915 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,241 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102818334899568915 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,246 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CA2D8494699E->6e2100fe-d804-4987-9ac5-bcccf3c0d596: receive RaftClientReply:client-CA2D8494699E->6e2100fe-d804-4987-9ac5-bcccf3c0d596@group-B5E39996ABB1, cid=42, SUCCESS, logIndex=1, commits[6e2100fe-d804-4987-9ac5-bcccf3c0d596:c1]
2019-09-19 08:54:44,405 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 10 locID: 102818334899568915 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:44,409 [grpc-default-executor-2] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-CA2D8494699E->6e2100fe-d804-4987-9ac5-bcccf3c0d596: receive RaftClientReply:client-CA2D8494699E->6e2100fe-d804-4987-9ac5-bcccf3c0d596@group-B5E39996ABB1, cid=43, SUCCESS, logIndex=3, commits[6e2100fe-d804-4987-9ac5-bcccf3c0d596:c4]
2019-09-19 08:54:44,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52, key=a14f72f0-ddc7-4b6d-a5f3-0e64483f0b71, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102818334899568915
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 43927
    }
    ports {
      name: "RATIS"
      value: 43014
    }
    ports {
      name: "STANDALONE"
      value: 39573
    }
    networkName: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "dc4b7dc7-4444-4ee8-833c-b5e39996abb1"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-19 08:54:44,432 [IPC Server handler 5 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:44,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:44,433 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52, key=a14f72f0-ddc7-4b6d-a5f3-0e64483f0b71, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:44,439 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-19 08:54:44,440 [IPC Server handler 4 on 41217] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:44,440 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:44,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=ae078efc-d664-4018-9eeb-bf81aa719a90, bucket=7b2376cc-71df-40d7-9a9b-4ec56157ee52, key=a14f72f0-ddc7-4b6d-a5f3-0e64483f0b71, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:44,450 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 10 locID: 102818334899568915 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:44,456 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 10 locID: 102818334899568915 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:44,457 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "5920b605c8c62320:5920b605c8c62320:0:0"
containerID: 10
datanodeUuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
readChunk {
  blockID {
    containerID: 10
    localID: 102818334899568915
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102818334899568915_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 6e2100fe-d804-4987-9ac5-bcccf3c0d596
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithCorruptedData(TestOzoneRpcClientAbstract.java:1108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:44,458 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "5920b605c8c62320:5920b605c8c62320:0:0"
containerID: 10
datanodeUuid: "6e2100fe-d804-4987-9ac5-bcccf3c0d596"
readChunk {
  blockID {
    containerID: 10
    localID: 102818334899568915
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102818334899568915_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: dc4b7dc7-4444-4ee8-833c-b5e39996abb1, Nodes: 6e2100fe-d804-4987-9ac5-bcccf3c0d596{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-19 08:54:44,459 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 96e4c495-231e-418a-b904-5818066b4e3b, with jenkins1000 as owner.
2019-09-19 08:54:44,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,787 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=96e4c495-231e-418a-b904-5818066b4e3b, creationTime=1568883284460, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=96e4c495-231e-418a-b904-5818066b4e3b} | ret=SUCCESS |  
2019-09-19 08:54:44,790 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 96e4c495-231e-418a-b904-5818066b4e3b/aba4147d-8aa9-455c-8446-b17fe3e2598e, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=96e4c495-231e-418a-b904-5818066b4e3b, bucket=aba4147d-8aa9-455c-8446-b17fe3e2598e, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284791} | ret=SUCCESS |  
2019-09-19 08:54:44,798 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=96e4c495-231e-418a-b904-5818066b4e3b, bucket=aba4147d-8aa9-455c-8446-b17fe3e2598e} | ret=SUCCESS |  
2019-09-19 08:54:44,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=96e4c495-231e-418a-b904-5818066b4e3b, bucket=aba4147d-8aa9-455c-8446-b17fe3e2598e, key=null} | ret=SUCCESS |  
2019-09-19 08:54:44,800 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e1490a91-386f-4e90-9182-bf5a2faa9fa2, with jenkins1000 as owner.
2019-09-19 08:54:44,805 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, creationTime=1568883284800, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,806 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2} | ret=SUCCESS |  
2019-09-19 08:54:44,807 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e1490a91-386f-4e90-9182-bf5a2faa9fa2/b496b7fd-9bd1-4873-95d1-f696ec1f873f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,815 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284807} | ret=SUCCESS |  
2019-09-19 08:54:44,816 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f} | ret=SUCCESS |  
2019-09-19 08:54:44,839 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, key=021c700f-3f9d-43b0-a0ce-c2ec705096c8, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,846 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, key=021c700f-3f9d-43b0-a0ce-c2ec705096c8, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,848 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,867 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, key=021c700f-3f9d-43b0-a0ce-c2ec705096c8, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334955340054} | ret=SUCCESS |  
2019-09-19 08:54:44,872 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334955798807 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,874 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334955798807 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:44,881 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, key=021c700f-3f9d-43b0-a0ce-c2ec705096c8, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334955798807
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,891 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=e1490a91-386f-4e90-9182-bf5a2faa9fa2, bucket=b496b7fd-9bd1-4873-95d1-f696ec1f873f, key=021c700f-3f9d-43b0-a0ce-c2ec705096c8, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=d3f38bc2-0327-4559-be69-ddb25ff42524}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: e1490a91-386f-4e90-9182-bf5a2faa9fa2bucket: b496b7fd-9bd1-4873-95d1-f696ec1f873fkey: 021c700f-3f9d-43b0-a0ce-c2ec705096c8
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:44,891 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 021c700f-3f9d-43b0-a0ce-c2ec705096c8 in Volume/Bucket e1490a91-386f-4e90-9182-bf5a2faa9fa2/b496b7fd-9bd1-4873-95d1-f696ec1f873f
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: e1490a91-386f-4e90-9182-bf5a2faa9fa2bucket: b496b7fd-9bd1-4873-95d1-f696ec1f873fkey: 021c700f-3f9d-43b0-a0ce-c2ec705096c8
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:202)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:44,892 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a4f41e42-921b-4fb3-85c9-3af01d2b3234, with jenkins1000 as owner.
2019-09-19 08:54:44,900 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a4f41e42-921b-4fb3-85c9-3af01d2b3234, creationTime=1568883284894, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a4f41e42-921b-4fb3-85c9-3af01d2b3234} | ret=SUCCESS |  
2019-09-19 08:54:44,902 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6174eed4-6cfa-422d-be3e-fa55da095712, with jenkins1000 as owner.
2019-09-19 08:54:44,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6174eed4-6cfa-422d-be3e-fa55da095712, creationTime=1568883284902, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6174eed4-6cfa-422d-be3e-fa55da095712} | ret=SUCCESS |  
2019-09-19 08:54:44,910 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6174eed4-6cfa-422d-be3e-fa55da095712/ce07f044-3c45-4061-bf56-c45764bd5b09, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6174eed4-6cfa-422d-be3e-fa55da095712, bucket=ce07f044-3c45-4061-bf56-c45764bd5b09, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284911} | ret=SUCCESS |  
2019-09-19 08:54:44,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6174eed4-6cfa-422d-be3e-fa55da095712, bucket=ce07f044-3c45-4061-bf56-c45764bd5b09} | ret=SUCCESS |  
2019-09-19 08:54:44,920 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 263c7a72-7dc2-4b9f-890b-91089db0301d, with jenkins1000 as owner.
2019-09-19 08:54:44,926 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=263c7a72-7dc2-4b9f-890b-91089db0301d, creationTime=1568883284920, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,927 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=263c7a72-7dc2-4b9f-890b-91089db0301d} | ret=SUCCESS |  
2019-09-19 08:54:44,927 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 263c7a72-7dc2-4b9f-890b-91089db0301d/fe068630-c359-4eb7-9307-f800718367fa, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,940 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284928} | ret=SUCCESS |  
2019-09-19 08:54:44,942 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa} | ret=SUCCESS |  
2019-09-19 08:54:44,952 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,971 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,974 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,985 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334963138841} | ret=SUCCESS |  
2019-09-19 08:54:44,995 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334964056346 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,998 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334964056346 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:45,007 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334964056346 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,010 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334964056346 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:45,018 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334964056346 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,020 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334964056346 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:45,029 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334964056346 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,031 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334964056346 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:45,034 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,042 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334963138841} | ret=SUCCESS |  
2019-09-19 08:54:45,053 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334967922971 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,056 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334967922971 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:45,059 [IPC Server handler 6 on 40501] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-956_1032 to index:1032
2019-09-19 08:54:45,060 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_956 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_956-1032
2019-09-19 08:54:45,106 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,228 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,107 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=a448d85b-ec9b-4560-ae6c-b2c8a1634a11, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,880 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_1033
2019-09-19 08:54:46,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334964056346
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334967922971
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:46,897 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=263c7a72-7dc2-4b9f-890b-91089db0301d, bucket=fe068630-c359-4eb7-9307-f800718367fa, uploadID=804f3248-229a-4918-88a0-e5287c1caf61-102818334962024728, partNumberMarker=100, maxParts=2, key=8a2d5fba-91a9-4535-a1d1-5d121a49cb98} | ret=SUCCESS |  
2019-09-19 08:54:46,898 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 56fd42a6-6f0a-41e8-865a-06238be5e982, with jenkins1000 as owner.
2019-09-19 08:54:46,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=56fd42a6-6f0a-41e8-865a-06238be5e982, creationTime=1568883286899, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:46,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=56fd42a6-6f0a-41e8-865a-06238be5e982} | ret=SUCCESS |  
2019-09-19 08:54:46,909 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 56fd42a6-6f0a-41e8-865a-06238be5e982/03afacca-afc8-4c65-9e1a-d42ffb28f053, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:46,922 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=56fd42a6-6f0a-41e8-865a-06238be5e982, bucket=03afacca-afc8-4c65-9e1a-d42ffb28f053, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883286910} | ret=SUCCESS |  
2019-09-19 08:54:46,923 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=56fd42a6-6f0a-41e8-865a-06238be5e982, bucket=03afacca-afc8-4c65-9e1a-d42ffb28f053} | ret=SUCCESS |  
2019-09-19 08:54:46,924 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 46717b3c-da4e-4f16-822d-43fbafb702aa, with jenkins1000 as owner.
2019-09-19 08:54:46,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=46717b3c-da4e-4f16-822d-43fbafb702aa, creationTime=1568883286925, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:46,937 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=46717b3c-da4e-4f16-822d-43fbafb702aa} | ret=SUCCESS |  
2019-09-19 08:54:46,938 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 46717b3c-da4e-4f16-822d-43fbafb702aa/3a707730-e1ff-47c2-abc6-da36e1162db4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:46,940 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883286938} | ret=SUCCESS |  
2019-09-19 08:54:46,941 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4} | ret=SUCCESS |  
2019-09-19 08:54:46,954 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4, key=c3e68a86-bb3d-4df4-b944-afc0a5e32a96, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,958 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4, key=c3e68a86-bb3d-4df4-b944-afc0a5e32a96, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,961 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=bbe3ba15-15a2-4629-a151-8dd09ebfd45a, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:46,974 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4, key=c3e68a86-bb3d-4df4-b944-afc0a5e32a96, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335093948701} | ret=SUCCESS |  
2019-09-19 08:54:46,984 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335094276382 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:46,989 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335094276382 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:46,995 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=46717b3c-da4e-4f16-822d-43fbafb702aa, bucket=3a707730-e1ff-47c2-abc6-da36e1162db4, key=c3e68a86-bb3d-4df4-b944-afc0a5e32a96, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335094276382
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "18897f3d-a606-48ca-8ab1-50a74a285275"
    ipAddress: "192.168.157.204"
    hostName: "pr-hdds-1569-cpgw4-1311585219"
    ports {
      name: "REST"
      value: 34242
    }
    ports {
      name: "RATIS"
      value: 38850
    }
    ports {
      name: "STANDALONE"
      value: 43534
    }
    networkName: "18897f3d-a606-48ca-8ab1-50a74a285275"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4570369a-28f8-4c21-a1aa-eeb2289e9a9f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:46,997 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b6d31c00-7deb-4982-b073-ba79be65330a, with jenkins1000 as owner.
2019-09-19 08:54:47,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b6d31c00-7deb-4982-b073-ba79be65330a, creationTime=1568883286998, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:47,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b6d31c00-7deb-4982-b073-ba79be65330a} | ret=SUCCESS |  
2019-09-19 08:54:47,013 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b6d31c00-7deb-4982-b073-ba79be65330a/d62b17f7-a605-471e-a944-1c05e14a44b3, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:47,031 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b6d31c00-7deb-4982-b073-ba79be65330a, bucket=d62b17f7-a605-471e-a944-1c05e14a44b3, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883287014} | ret=SUCCESS |  
2019-09-19 08:54:47,037 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b6d31c00-7deb-4982-b073-ba79be65330a, bucket=d62b17f7-a605-471e-a944-1c05e14a44b3} | ret=SUCCESS |  
2019-09-19 08:54:47,050 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b6d31c00-7deb-4982-b073-ba79be65330a, bucket=d62b17f7-a605-471e-a944-1c05e14a44b3, key=07f2a6d6-e04b-4676-a06b-5a99e2004af1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,063 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b6d31c00-7deb-4982-b073-ba79be65330a, bucket=d62b17f7-a605-471e-a944-1c05e14a44b3, key=07f2a6d6-e04b-4676-a06b-5a99e2004af1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,070 [grpc-default-executor-2] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 3-OrderedRequestStreamObserver3: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-09-19 08:54:47,072 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-09-19 08:54:47,073 | INFO  | SCMAudit | user=null | ip=null | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 08:54:47,073 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-09-19 08:54:47,073 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-09-19 08:54:47,073 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40501
2019-09-19 08:54:47,081 [IPC Server listener on 40501] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40501
2019-09-19 08:54:47,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:54:47,090 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: close
2019-09-19 08:54:47,099 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown group-C5BA1605619E
2019-09-19 08:54:47,099 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=bbe3ba15-15a2-4629-a151-8dd09ebfd45a
2019-09-19 08:54:47,099 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown LeaderState
2019-09-19 08:54:47,100 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:47,106 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E: set stopIndex = 1058
2019-09-19 08:54:47,106 [StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(254)) - Saving Ratis snapshot on the OM.
2019-09-19 08:54:47,106 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=18897f3d-a606-48ca-8ab1-50a74a285275, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,111 [StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E] INFO  ratis.OMRatisSnapshotInfo (OMRatisSnapshotInfo.java:saveRatisSnapshotToDisk(107)) - Saved Ratis Snapshot on the OM with snapshotIndex 1057
2019-09-19 08:54:47,111 [StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E: Took a snapshot at index 1057
2019-09-19 08:54:47,113 [StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E: snapshotIndex: updateIncreasingly -1 -> 1057
2019-09-19 08:54:47,117 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a:group-C5BA1605619E closes. The last applied log index is 1058
2019-09-19 08:54:47,118 [bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:47,119 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e close()
2019-09-19 08:54:47,121 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown server with port 9872 now
2019-09-19 08:54:47,123 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - bbe3ba15-15a2-4629-a151-8dd09ebfd45a: shutdown server with port 9872 successfully
2019-09-19 08:54:47,123 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-19 08:54:47,123 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-19 08:54:47,124 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-19 08:54:47,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1debc91c{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-19 08:54:47,133 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:54:47,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-19 08:54:47,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:54:47,137 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-09-19 08:54:47,138 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 08:54:47,138 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 08:54:47,140 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@686cf8ad
2019-09-19 08:54:47,140 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-19 08:54:47,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,565 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 08:54:48,105 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 08:54:48,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:49,229 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,230 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,230 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,142 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 08:54:52,142 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 08:54:52,143 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: close
2019-09-19 08:54:52,144 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 18897f3d-a606-48ca-8ab1-50a74a285275: close
2019-09-19 08:54:52,144 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-E2EA6504FD1A
2019-09-19 08:54:52,144 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-C2A181725365
2019-09-19 08:54:52,144 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E2EA6504FD1A,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,144 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2A181725365,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,145 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,145 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,145 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,146 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,151 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A: set stopIndex = 4
2019-09-19 08:54:52,151 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365: set stopIndex = 0
2019-09-19 08:54:52,151 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-E2EA6504FD1A: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a/sm/snapshot.1_4
2019-09-19 08:54:52,151 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-C2A181725365 closes. The last applied log index is 0
2019-09-19 08:54:52,152 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,154 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/462adf1a-e0ab-434d-8265-c2a181725365 close()
2019-09-19 08:54:52,156 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-39D909CCF0EF
2019-09-19 08:54:52,156 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-39D909CCF0EF,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,156 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,156 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,157 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF: set stopIndex = 0
2019-09-19 08:54:52,157 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-39D909CCF0EF closes. The last applied log index is 0
2019-09-19 08:54:52,157 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,159 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/c18abddb-f074-4bdf-9d26-39d909ccf0ef close()
2019-09-19 08:54:52,161 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-D630FD7012B2
2019-09-19 08:54:52,161 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D630FD7012B2,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,161 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,161 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,162 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2: set stopIndex = 0
2019-09-19 08:54:52,162 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-D630FD7012B2 closes. The last applied log index is 0
2019-09-19 08:54:52,162 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,163 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/0f02329a-09b2-44ad-b105-d630fd7012b2 close()
2019-09-19 08:54:52,165 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-220F5C9DED30
2019-09-19 08:54:52,166 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-220F5C9DED30,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,166 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,166 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,170 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30: set stopIndex = 8
2019-09-19 08:54:52,170 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-220F5C9DED30: Taking a snapshot at:(t:1, i:8) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30/sm/snapshot.1_8
2019-09-19 08:54:52,183 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-E2EA6504FD1A: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a/sm/snapshot.1_4 time:32
2019-09-19 08:54:52,183 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A: Took a snapshot at index 4
2019-09-19 08:54:52,184 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:52,184 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E2EA6504FD1A closes. The last applied log index is 4
2019-09-19 08:54:52,184 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,184 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-220F5C9DED30: Finished taking a snapshot at:(t:1, i:8) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30/sm/snapshot.1_8 time:14
2019-09-19 08:54:52,185 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30: Took a snapshot at index 8
2019-09-19 08:54:52,185 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/766d5ff0-a7c7-40f2-ba79-e2ea6504fd1a close()
2019-09-19 08:54:52,186 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30: snapshotIndex: updateIncreasingly -1 -> 8
2019-09-19 08:54:52,188 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-0254FFF01EE2
2019-09-19 08:54:52,188 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-220F5C9DED30 closes. The last applied log index is 8
2019-09-19 08:54:52,188 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0254FFF01EE2,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,188 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,188 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,190 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/99f0d179-1c0b-4b8a-81fa-220f5c9ded30 close()
2019-09-19 08:54:52,190 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,192 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-DFFD32B43B1B
2019-09-19 08:54:52,192 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2: set stopIndex = 0
2019-09-19 08:54:52,192 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFFD32B43B1B,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,192 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0254FFF01EE2 closes. The last applied log index is 0
2019-09-19 08:54:52,193 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,193 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,193 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,194 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/ee7782eb-17fe-4297-bac6-0254fff01ee2 close()
2019-09-19 08:54:52,199 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B: set stopIndex = 4
2019-09-19 08:54:52,201 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-DFFD32B43B1B: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b/sm/snapshot.1_4
2019-09-19 08:54:52,201 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-0AB69DB7EA63
2019-09-19 08:54:52,202 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0AB69DB7EA63,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,202 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,202 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,209 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63: set stopIndex = 4
2019-09-19 08:54:52,209 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-0AB69DB7EA63: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63/sm/snapshot.1_4
2019-09-19 08:54:52,215 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-DFFD32B43B1B: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b/sm/snapshot.1_4 time:14
2019-09-19 08:54:52,215 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B: Took a snapshot at index 4
2019-09-19 08:54:52,215 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-0AB69DB7EA63: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63/sm/snapshot.1_4 time:7
2019-09-19 08:54:52,215 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:52,215 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63: Took a snapshot at index 4
2019-09-19 08:54:52,215 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:52,216 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-DFFD32B43B1B closes. The last applied log index is 4
2019-09-19 08:54:52,216 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0AB69DB7EA63 closes. The last applied log index is 4
2019-09-19 08:54:52,216 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,216 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,218 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/7b0dd393-2f2a-4958-bebe-dffd32b43b1b close()
2019-09-19 08:54:52,219 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/5ff289c0-091f-4001-88d9-0ab69db7ea63 close()
2019-09-19 08:54:52,221 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown group-864EE71594B1
2019-09-19 08:54:52,223 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-0FC12B4619A5
2019-09-19 08:54:52,223 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-864EE71594B1,id=18897f3d-a606-48ca-8ab1-50a74a285275
2019-09-19 08:54:52,223 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FC12B4619A5,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,223 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown LeaderState
2019-09-19 08:54:52,224 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,224 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 18897f3d-a606-48ca-8ab1-50a74a285275-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,224 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,225 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-864EE71594B1: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1/sm/snapshot.1_4
2019-09-19 08:54:52,224 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1: set stopIndex = 4
2019-09-19 08:54:52,225 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5: set stopIndex = 0
2019-09-19 08:54:52,225 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-0FC12B4619A5 closes. The last applied log index is 0
2019-09-19 08:54:52,226 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,227 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/0a9538d9-48b8-4dd4-b485-0fc12b4619a5 close()
2019-09-19 08:54:52,234 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-E6CB3D7A5F33
2019-09-19 08:54:52,235 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=6e2100fe-d804-4987-9ac5-bcccf3c0d596, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,235 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E6CB3D7A5F33,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,235 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,236 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,236 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33: set stopIndex = 7
2019-09-19 08:54:52,236 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-E6CB3D7A5F33: Taking a snapshot at:(t:1, i:7) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33/sm/snapshot.1_7
2019-09-19 08:54:52,249 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-864EE71594B1: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1/sm/snapshot.1_4 time:25
2019-09-19 08:54:52,249 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1: Took a snapshot at index 4
2019-09-19 08:54:52,249 [StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:52,250 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 18897f3d-a606-48ca-8ab1-50a74a285275:group-864EE71594B1 closes. The last applied log index is 4
2019-09-19 08:54:52,250 [18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,250 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 18897f3d-a606-48ca-8ab1-50a74a285275-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/ratis/3d4ae66b-cd08-4617-93af-864ee71594b1 close()
2019-09-19 08:54:52,252 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown server with port 38850 now
2019-09-19 08:54:52,252 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 18897f3d-a606-48ca-8ab1-50a74a285275: shutdown server with port 38850 successfully
2019-09-19 08:54:52,264 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-E6CB3D7A5F33: Finished taking a snapshot at:(t:1, i:7) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33/sm/snapshot.1_7 time:26
2019-09-19 08:54:52,264 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 08:54:52,265 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33: Took a snapshot at index 7
2019-09-19 08:54:52,266 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33: snapshotIndex: updateIncreasingly -1 -> 7
2019-09-19 08:54:52,266 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-E6CB3D7A5F33 closes. The last applied log index is 7
2019-09-19 08:54:52,267 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,267 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/1eaec501-0284-41dd-b955-e6cb3d7a5f33 close()
2019-09-19 08:54:52,267 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 08:54:52,268 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown group-81350EB5AF8A
2019-09-19 08:54:52,268 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-81350EB5AF8A,id=a448d85b-ec9b-4560-ae6c-b2c8a1634a11
2019-09-19 08:54:52,269 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown LeaderState
2019-09-19 08:54:52,269 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:52,269 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A: set stopIndex = 10
2019-09-19 08:54:52,270 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-81350EB5AF8A: Taking a snapshot at:(t:1, i:10) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a/sm/snapshot.1_10
2019-09-19 08:54:52,288 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 08:54:52,292 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a87026{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 08:54:52,293 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:54:52,295 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 08:54:52,296 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:54:52,298 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 08:54:52,298 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@79add732
2019-09-19 08:54:52,299 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-81350EB5AF8A: Finished taking a snapshot at:(t:1, i:10) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a/sm/snapshot.1_10 time:30
2019-09-19 08:54:52,299 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A: Took a snapshot at index 10
2019-09-19 08:54:52,300 [StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A: snapshotIndex: updateIncreasingly -1 -> 10
2019-09-19 08:54:52,300 [main] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11:group-81350EB5AF8A closes. The last applied log index is 10
2019-09-19 08:54:52,300 [a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:52,301 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/ratis/f341dfde-b316-4baa-8be5-81350eb5af8a close()
2019-09-19 08:54:52,302 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown server with port 45142 now
2019-09-19 08:54:52,302 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - a448d85b-ec9b-4560-ae6c-b2c8a1634a11: shutdown server with port 45142 successfully
2019-09-19 08:54:52,309 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 08:54:52,313 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 08:54:52,326 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 08:54:52,327 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e4d40ea{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 08:54:52,328 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73f6e07{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:54:52,328 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4168f3d9{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 08:54:52,328 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2aa14ae6{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:54:53,235 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 08:54:57,299 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 08:54:57,299 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: close
2019-09-19 08:54:57,299 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-C2EA2C9D0439
2019-09-19 08:54:57,299 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2EA2C9D0439,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439: set stopIndex = 0
2019-09-19 08:54:57,300 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-C2EA2C9D0439 closes. The last applied log index is 0
2019-09-19 08:54:57,301 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,301 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/be3538ca-bfa3-4226-a0a0-c2ea2c9d0439 close()
2019-09-19 08:54:57,303 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-BF6F8028AA44
2019-09-19 08:54:57,303 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF6F8028AA44,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,303 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,304 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,304 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44: set stopIndex = 0
2019-09-19 08:54:57,304 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-BF6F8028AA44 closes. The last applied log index is 0
2019-09-19 08:54:57,305 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,305 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/aec74c59-0e3e-46a1-a804-bf6f8028aa44 close()
2019-09-19 08:54:57,306 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-A8BF8D7B4433
2019-09-19 08:54:57,306 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A8BF8D7B4433,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,306 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,307 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,307 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433: set stopIndex = 0
2019-09-19 08:54:57,307 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-A8BF8D7B4433 closes. The last applied log index is 0
2019-09-19 08:54:57,308 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,308 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/bb7493e2-a290-4d1a-bccb-a8bf8d7b4433 close()
2019-09-19 08:54:57,309 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-2D12FF14B091
2019-09-19 08:54:57,309 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D12FF14B091,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,309 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,310 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,310 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091: set stopIndex = 0
2019-09-19 08:54:57,310 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-2D12FF14B091 closes. The last applied log index is 0
2019-09-19 08:54:57,311 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,311 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/a133b14e-2d0f-46d5-be51-2d12ff14b091 close()
2019-09-19 08:54:57,312 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-F7D78E7DC516
2019-09-19 08:54:57,312 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F7D78E7DC516,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,313 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,313 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,313 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516: set stopIndex = 4
2019-09-19 08:54:57,314 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-F7D78E7DC516: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516/sm/snapshot.1_4
2019-09-19 08:54:57,389 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-F7D78E7DC516: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516/sm/snapshot.1_4 time:76
2019-09-19 08:54:57,390 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516: Took a snapshot at index 4
2019-09-19 08:54:57,390 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:57,390 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-F7D78E7DC516 closes. The last applied log index is 4
2019-09-19 08:54:57,391 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,391 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/52e88d3a-be9a-49a2-b2a4-f7d78e7dc516 close()
2019-09-19 08:54:57,393 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown group-B5E39996ABB1
2019-09-19 08:54:57,393 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5E39996ABB1,id=6e2100fe-d804-4987-9ac5-bcccf3c0d596
2019-09-19 08:54:57,393 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown LeaderState
2019-09-19 08:54:57,394 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-PendingRequests: sendNotLeaderResponses
2019-09-19 08:54:57,394 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1: set stopIndex = 4
2019-09-19 08:54:57,394 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(283)) - group-B5E39996ABB1: Taking a snapshot at:(t:1, i:4) file /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1/sm/snapshot.1_4
2019-09-19 08:54:57,432 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(294)) - group-B5E39996ABB1: Finished taking a snapshot at:(t:1, i:4) file:/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1/sm/snapshot.1_4 time:38
2019-09-19 08:54:57,432 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(242)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1: Took a snapshot at index 4
2019-09-19 08:54:57,432 [StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(80)) - StateMachineUpdater:6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1: snapshotIndex: updateIncreasingly -1 -> 4
2019-09-19 08:54:57,433 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596:group-B5E39996ABB1 closes. The last applied log index is 4
2019-09-19 08:54:57,433 [6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 08:54:57,433 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/ratis/dc4b7dc7-4444-4ee8-833c-b5e39996abb1 close()
2019-09-19 08:54:57,435 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown server with port 43014 now
2019-09-19 08:54:57,435 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 6e2100fe-d804-4987-9ac5-bcccf3c0d596: shutdown server with port 43014 successfully
2019-09-19 08:54:57,442 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 08:54:57,446 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f7a3a46c-5664-4af8-86a5-7e20dc3d0670/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 08:54:57,465 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 08:54:57,468 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c18942{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 08:54:57,469 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@743c3520{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:54:57,470 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71d55b7e{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 08:54:57,471 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52ba685a{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:54:57,472 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-09-19 08:54:57,473 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(797)) - Stopping Replication Manager Service.
2019-09-19 08:54:57,473 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(192)) - Stopping Replication Monitor Thread.
2019-09-19 08:54:57,473 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Lease Manager of the command watchers
2019-09-19 08:54:57,473 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping datanode service RPC server
2019-09-19 08:54:57,473 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-19 08:54:57,473 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35862
2019-09-19 08:54:57,475 [IPC Server listener on 35862] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35862
2019-09-19 08:54:57,476 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:54:57,508 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-19 08:54:57,509 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(819)) - Stopping block service RPC server
2019-09-19 08:54:57,509 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-09-19 08:54:57,509 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41217
2019-09-19 08:54:57,512 [IPC Server listener on 41217] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41217
2019-09-19 08:54:57,512 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-19 08:54:57,513 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-19 08:54:57,513 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:54:57,513 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44546
2019-09-19 08:54:57,515 [IPC Server listener on 44546] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44546
2019-09-19 08:54:57,515 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping Storage Container Manager HTTP server.
2019-09-19 08:54:57,515 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:54:57,516 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43c67247{/,null,UNAVAILABLE}{/scm}
2019-09-19 08:54:57,517 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:54:57,517 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-19 08:54:57,518 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:54:57,519 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Block Manager Service.
2019-09-19 08:54:57,519 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 08:54:57,520 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 08:54:57,520 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(866)) - Stopping SCM Event Queue.
2019-09-19 08:54:57,527 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping XceiverClientMetrics metrics system...
2019-09-19 08:54:57,534 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - XceiverClientMetrics metrics system stopped.

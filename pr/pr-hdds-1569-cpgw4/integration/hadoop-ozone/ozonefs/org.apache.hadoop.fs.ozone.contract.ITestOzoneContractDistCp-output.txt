2019-09-19 10:33:26,063 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:26,161 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:26,164 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:26,187 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @889ms
2019-09-19 10:33:26,304 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-19 10:33:26,305 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-19 10:33:26,305 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-19 10:33:26,305 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-19 10:33:26,306 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-19 10:33:26,306 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-19 10:33:26,318 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 10:33:26,318 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 10:33:26,320 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 10:33:28,176 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6b81ce95
2019-09-19 10:33:28,178 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-19 10:33:28,253 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 10:33:28,255 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 10:33:28,257 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-19 10:33:28,367 [JUnit] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-19 10:33:28,381 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:28,837 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-19 10:33:28,841 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:29,399 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-19 10:33:30,237 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 10:33:30,265 [Socket Reader #1 for port 42600] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42600
2019-09-19 10:33:30,288 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 10:33:30,289 [Socket Reader #1 for port 44264] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 44264
2019-09-19 10:33:30,297 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 10:33:30,297 [Socket Reader #1 for port 36409] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36409
2019-09-19 10:33:30,318 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-19 10:33:30,471 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:30,486 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:30,496 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:30,498 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-19 10:33:30,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:30,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:30,524 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36409
2019-09-19 10:33:30,574 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-19 10:33:30,586 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-19 10:33:30,586 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-19 10:33:30,816 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:36409
2019-09-19 10:33:30,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 10:33:30,816 [IPC Server listener on 36409] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36409: starting
2019-09-19 10:33:30,820 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44264
2019-09-19 10:33:30,821 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:44264
2019-09-19 10:33:30,821 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 10:33:30,821 [IPC Server listener on 44264] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 44264: starting
2019-09-19 10:33:30,824 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:42600
2019-09-19 10:33:30,824 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:42600
2019-09-19 10:33:30,825 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 10:33:30,825 [IPC Server listener on 42600] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42600: starting
2019-09-19 10:33:30,830 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 40717
2019-09-19 10:33:30,832 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:30,868 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65b3a85a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:30,869 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53d1b9b3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:30,936 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@733037{/,file:///tmp/jetty-0.0.0.0-40717-scm-_-any-6764878584322052719.dir/webapp/,AVAILABLE}{/scm}
2019-09-19 10:33:30,941 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50b8ae8d{HTTP/1.1,[http/1.1]}{0.0.0.0:40717}
2019-09-19 10:33:30,942 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5644ms
2019-09-19 10:33:30,943 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:40717
2019-09-19 10:33:30,952 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7577b641] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:30,956 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:31,085 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:31,086 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:31,087 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-19 10:33:31,087 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: 73dc0ff7-2608-4742-8a46-ed5b85eb53f4
2019-09-19 10:33:31,088 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-19 10:33:31,389 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 10:33:31,896 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 10:33:31,906 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-19 10:33:31,907 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-19 10:33:31,907 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-19 10:33:31,907 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-19 10:33:31,907 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-19 10:33:31,908 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-19 10:33:31,908 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-19 10:33:31,908 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-19 10:33:31,908 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-19 10:33:31,909 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-19 10:33:31,909 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-19 10:33:31,909 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-19 10:33:31,909 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-19 10:33:31,910 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-19 10:33:31,910 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-19 10:33:31,910 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-19 10:33:31,910 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-19 10:33:31,911 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-19 10:33:31,911 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-19 10:33:31,911 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-19 10:33:31,911 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-19 10:33:31,912 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-19 10:33:31,912 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 10:33:31,912 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 10:33:31,912 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 10:33:36,111 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 10:33:36,112 [Socket Reader #1 for port 38398] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38398
2019-09-19 10:33:36,144 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:38398
2019-09-19 10:33:36,144 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-19 10:33:36,146 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 10:33:36,146 [IPC Server listener on 38398] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38398: starting
2019-09-19 10:33:36,154 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-19 10:33:36,157 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:36,158 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:36,162 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:36,163 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-19 10:33:36,164 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:36,164 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:36,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36237
2019-09-19 10:33:36,168 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:36,171 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@749ab7b4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:36,172 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bf94401{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:36,232 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54562ea6{/,file:///tmp/jetty-0.0.0.0-36237-ozoneManager-_-any-8767646216001606375.dir/webapp/,AVAILABLE}{/ozoneManager}
2019-09-19 10:33:36,234 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a35993f{HTTP/1.1,[http/1.1]}{0.0.0.0:36237}
2019-09-19 10:33:36,234 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @10936ms
2019-09-19 10:33:36,235 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:36237
2019-09-19 10:33:36,409 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 10:33:36,498 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 10:33:36,532 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 10:33:36,534 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/containers/hdds to VolumeSet
2019-09-19 10:33:36,536 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-19 10:33:36,556 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@1fba386c
2019-09-19 10:33:36,676 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 10:33:36,752 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 10:33:36,757 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 10:33:36,758 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 10:33:36,759 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:36,760 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 10:33:36,761 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 10:33:36,991 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:37,043 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 10:33:37,060 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 10:33:37,063 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:37,064 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:37,067 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:37,068 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 10:33:37,068 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:37,069 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:37,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36690
2019-09-19 10:33:37,070 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:37,075 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb66650{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:37,075 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a869a16{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:37,104 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6d5c2745{/,file:///tmp/jetty-0.0.0.0-36690-hddsDatanode-_-any-1626055687458224648.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 10:33:37,106 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44b29496{HTTP/1.1,[http/1.1]}{0.0.0.0:36690}
2019-09-19 10:33:37,106 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @11808ms
2019-09-19 10:33:37,107 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36690
Sep 19, 2019 10:33:37 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:38,170 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:37671 |  
2019-09-19 10:33:38,172 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@2eda2062
2019-09-19 10:33:38,173 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 10:33:38,176 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 10:33:38,179 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@684fca04] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:38,185 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 10:33:38,185 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/containers/hdds to VolumeSet
2019-09-19 10:33:38,185 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@35e98af
2019-09-19 10:33:38,187 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@35e98af
2019-09-19 10:33:38,207 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 10:33:38,208 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 10:33:38,208 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 10:33:38,208 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 10:33:38,208 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:38,208 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 10:33:38,209 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 10:33:38,209 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:38,210 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 10:33:38,211 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 10:33:38,215 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:38,216 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:38,220 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:38,222 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 10:33:38,222 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:38,222 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:38,224 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33614
2019-09-19 10:33:38,224 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:38,227 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17222c11{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:38,227 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25974207{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:38,270 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34c53688{/,file:///tmp/jetty-0.0.0.0-33614-hddsDatanode-_-any-1111767995859919908.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 10:33:38,271 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ffd4c0d{HTTP/1.1,[http/1.1]}{0.0.0.0:33614}
2019-09-19 10:33:38,271 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @12973ms
2019-09-19 10:33:38,272 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33614
Sep 19, 2019 10:33:38 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:38,315 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/meta/datanode.id
2019-09-19 10:33:38,488 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:42932 |  
2019-09-19 10:33:38,489 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@58b311ba
2019-09-19 10:33:38,489 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 10:33:38,492 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 10:33:38,493 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@33dd0342] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:38,500 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/meta/datanode.id
2019-09-19 10:33:38,505 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 10:33:38,505 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/containers/hdds to VolumeSet
2019-09-19 10:33:38,506 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-19 10:33:38,506 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@20440c6c
2019-09-19 10:33:38,526 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 10:33:38,526 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 10:33:38,526 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 10:33:38,527 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 10:33:38,527 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:38,527 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 10:33:38,527 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 10:33:38,528 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:38,529 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 10:33:38,530 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 10:33:38,534 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:38,534 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:38,538 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:38,539 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 10:33:38,540 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:38,540 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:38,541 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34045
2019-09-19 10:33:38,541 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:38,546 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a0c5be{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:38,547 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14efa279{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:38,590 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24fba488{/,file:///tmp/jetty-0.0.0.0-34045-hddsDatanode-_-any-2108844948321338785.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 10:33:38,590 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73a6cc79{HTTP/1.1,[http/1.1]}{0.0.0.0:34045}
2019-09-19 10:33:38,591 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @13293ms
2019-09-19 10:33:38,592 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34045
Sep 19, 2019 10:33:38 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:38,762 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:44352 |  
2019-09-19 10:33:38,763 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3bbf1c0d
2019-09-19 10:33:38,763 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 10:33:38,766 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f9cbe0f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:38,767 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 10:33:38,769 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/meta/datanode.id
2019-09-19 10:33:38,776 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 10:33:38,776 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/containers/hdds to VolumeSet
2019-09-19 10:33:38,777 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@18ffca6c
2019-09-19 10:33:38,777 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@18ffca6c
2019-09-19 10:33:38,802 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 10:33:38,803 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 10:33:38,803 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 10:33:38,803 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 10:33:38,803 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:38,804 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 10:33:38,804 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 10:33:38,805 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:38,805 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 10:33:38,807 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 10:33:38,808 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:38,809 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:38,811 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:38,812 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 10:33:38,812 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:38,812 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:38,813 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36075
2019-09-19 10:33:38,813 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:38,815 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72a8361b{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:38,816 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c48b543{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:38,844 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f5dfe69{/,file:///tmp/jetty-0.0.0.0-36075-hddsDatanode-_-any-7079678146702878305.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 10:33:38,845 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@571a663c{HTTP/1.1,[http/1.1]}{0.0.0.0:36075}
2019-09-19 10:33:38,846 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @13548ms
2019-09-19 10:33:38,846 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:36075
Sep 19, 2019 10:33:38 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:39,035 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:35053 |  
2019-09-19 10:33:39,035 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@7ac5b4c
2019-09-19 10:33:39,036 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 10:33:39,038 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75efac24] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:39,039 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-cpgw4-1311585219 ip:192.168.157.204
2019-09-19 10:33:39,041 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/meta/datanode.id
2019-09-19 10:33:39,048 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 10:33:39,048 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/containers/hdds to VolumeSet
2019-09-19 10:33:39,048 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-19 10:33:39,049 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7eaa2bc6
2019-09-19 10:33:39,071 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 10:33:39,071 [JUnit] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 10:33:39,072 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 10:33:39,072 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 10:33:39,072 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:39,072 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 10:33:39,073 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 10:33:39,073 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:39,074 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 10:33:39,075 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 10:33:39,078 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 10:33:39,078 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 10:33:39,080 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 10:33:39,081 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 10:33:39,081 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 10:33:39,081 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 10:33:39,082 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35214
2019-09-19 10:33:39,082 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 10:33:39,084 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cf01c2e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-09-19 10:33:39,085 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1eb9bf60{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 10:33:39,113 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68bd8ca7{/,file:///tmp/jetty-0.0.0.0-35214-hddsDatanode-_-any-2848970962021899949.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 10:33:39,114 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6744707b{HTTP/1.1,[http/1.1]}{0.0.0.0:35214}
2019-09-19 10:33:39,115 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @13817ms
2019-09-19 10:33:39,116 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35214
Sep 19, 2019 10:33:39 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:39,377 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:40678 |  
2019-09-19 10:33:39,379 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@6cdbe5ec
2019-09-19 10:33:39,384 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 10:33:39,384 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64e7fc1d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 10:33:39,387 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/meta/datanode.id
2019-09-19 10:33:40,215 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 10:33:40,236 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 10:33:40,238 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 10:33:40,238 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at port 0
2019-09-19 10:33:40,257 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start RPC server
2019-09-19 10:33:40,384 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 10:33:40,404 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: GrpcService started, listening on 0.0.0.0/0.0.0.0:36110
2019-09-19 10:33:40,405 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 is started using port 36110
2019-09-19 10:33:40,408 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 is started using port 41740
2019-09-19 10:33:40,495 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 10:33:40,591 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 10:33:40,594 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 10:33:40,594 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 48adeddc-e5ef-4407-be4a-4b4625283b71 at port 0
2019-09-19 10:33:40,604 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start RPC server
2019-09-19 10:33:40,608 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: GrpcService started, listening on 0.0.0.0/0.0.0.0:37999
2019-09-19 10:33:40,608 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 48adeddc-e5ef-4407-be4a-4b4625283b71 is started using port 37999
2019-09-19 10:33:40,611 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 48adeddc-e5ef-4407-be4a-4b4625283b71 is started using port 45916
2019-09-19 10:33:40,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 10:33:40,812 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 10:33:40,814 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 10:33:40,814 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 76803391-7007-495d-a164-b2d99168fa35 at port 0
2019-09-19 10:33:40,823 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 76803391-7007-495d-a164-b2d99168fa35: start RPC server
2019-09-19 10:33:40,826 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 76803391-7007-495d-a164-b2d99168fa35: GrpcService started, listening on 0.0.0.0/0.0.0.0:40090
2019-09-19 10:33:40,827 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 76803391-7007-495d-a164-b2d99168fa35 is started using port 40090
2019-09-19 10:33:40,830 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 76803391-7007-495d-a164-b2d99168fa35 is started using port 37321
2019-09-19 10:33:41,042 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 10:33:41,057 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 10:33:41,060 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 10:33:41,060 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at port 0
2019-09-19 10:33:41,068 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start RPC server
2019-09-19 10:33:41,072 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: GrpcService started, listening on 0.0.0.0/0.0.0.0:33931
2019-09-19 10:33:41,072 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 is started using port 33931
2019-09-19 10:33:41,075 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 is started using port 34061
2019-09-19 10:33:41,385 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-09-19 10:33:41,388 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 10:33:41,402 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 10:33:41,408 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 10:33:41,408 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 4ddad5db-b8db-4ca3-8007-a88ba910d681 at port 0
2019-09-19 10:33:41,415 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start RPC server
2019-09-19 10:33:41,419 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: GrpcService started, listening on 0.0.0.0/0.0.0.0:37814
2019-09-19 10:33:41,419 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 4ddad5db-b8db-4ca3-8007-a88ba910d681 is started using port 37814
2019-09-19 10:33:41,422 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 4ddad5db-b8db-4ca3-8007-a88ba910d681 is started using port 43634
2019-09-19 10:33:42,236 [IPC Server handler 2 on 42600] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:42,238 [IPC Server handler 2 on 42600] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 10:33:42,246 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-19 10:33:42,246 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-19 10:33:42,246 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-19 10:33:42,254 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 10:33:42,385 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 1 of 5 DN Heartbeats.
2019-09-19 10:33:42,496 [IPC Server handler 1 on 42600] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:42,497 [IPC Server handler 1 on 42600] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 10:33:42,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 10:33:42,770 [IPC Server handler 3 on 42600] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:42,770 [IPC Server handler 3 on 42600] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 10:33:42,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 10:33:43,236 [IPC Server handler 7 on 42600] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:43,237 [IPC Server handler 7 on 42600] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 10:33:43,237 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 10:33:43,387 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-09-19 10:33:43,388 [IPC Server handler 1 on 42600] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:43,388 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-4E97573376BD:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-4E97573376BD:java.util.concurrent.CompletableFuture@ae42daa[Not completed]
2019-09-19 10:33:43,388 [IPC Server handler 1 on 42600] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}
2019-09-19 10:33:43,389 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=REGISTER {datanodeDetails=4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 10:33:43,422 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-4E97573376BD:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:43,424 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:43,425 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:43,426 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:43,427 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:43,428 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:43,437 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:43,437 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:43,445 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd does not exist. Creating ...
2019-09-19 10:33:43,463 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:43,478 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd has been successfully formatted.
2019-09-19 10:33:43,480 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-4E97573376BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:43,481 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:43,483 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:43,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:43,488 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:43,490 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,496 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:43,503 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd
2019-09-19 10:33:43,518 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:43,519 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:43,528 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:43,529 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:43,530 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:43,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:43,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:43,531 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:43,542 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:43,547 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:43,551 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:43,552 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:43,552 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:43,576 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-4E97573376BD
2019-09-19 10:33:43,577 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:43,578 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:43,579 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E97573376BD,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:43,645 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 67b720da-db13-440d-8c9d-4e97573376bd, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:43,668 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-B3336D34D121:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-B3336D34D121:java.util.concurrent.CompletableFuture@5a7a3a7d[Not completed]
2019-09-19 10:33:43,714 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-B3336D34D121:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:43,715 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:43,716 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:43,717 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121 does not exist. Creating ...
2019-09-19 10:33:43,732 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:43,744 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121 has been successfully formatted.
2019-09-19 10:33:43,746 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B3336D34D121: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:43,747 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:43,747 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:43,747 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:43,748 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:43,748 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,748 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:43,748 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:43,750 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:43,751 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:43,751 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:43,751 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:43,751 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:43,752 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:43,752 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:43,752 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:43,752 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:43,752 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-B3336D34D121
2019-09-19 10:33:43,753 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:43,753 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:43,754 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B3336D34D121,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:43,773 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ac3b7e4b-7146-46ff-b997-b3336d34d121, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:43,793 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-97156F10C26D:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-97156F10C26D:java.util.concurrent.CompletableFuture@b7e8756[Not completed]
2019-09-19 10:33:43,805 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-97156F10C26D:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:43,805 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:43,805 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:43,805 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:43,805 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:43,806 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:43,806 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:43,806 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:43,806 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d does not exist. Creating ...
2019-09-19 10:33:43,820 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:43,832 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d has been successfully formatted.
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-97156F10C26D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:43,833 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,834 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:43,835 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:43,836 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:43,836 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:43,836 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:43,836 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:43,837 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-97156F10C26D
2019-09-19 10:33:43,837 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:43,837 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:43,837 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-97156F10C26D,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:43,847 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ec56e9a2-1edb-471f-8a51-97156f10c26d, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:43,869 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-2CB13409A215:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-2CB13409A215:java.util.concurrent.CompletableFuture@443e84b0[Not completed]
2019-09-19 10:33:43,871 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-2CB13409A215:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:43,871 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:43,872 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:43,873 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215 does not exist. Creating ...
2019-09-19 10:33:43,889 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:43,903 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215 has been successfully formatted.
2019-09-19 10:33:43,903 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-2CB13409A215: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:43,903 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:43,904 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:43,904 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:43,904 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:43,904 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,904 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:43,905 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215
2019-09-19 10:33:43,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:43,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:43,905 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:43,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:43,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:43,906 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:43,907 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:43,907 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:43,907 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:43,908 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:43,908 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:43,908 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:43,909 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:43,909 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-2CB13409A215
2019-09-19 10:33:43,909 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:43,909 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:43,910 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2CB13409A215,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:43,921 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a6905970-066c-481c-ba8b-2cb13409a215, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:43,943 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-42EA0EB77676:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-42EA0EB77676:java.util.concurrent.CompletableFuture@5cd215fd[Not completed]
2019-09-19 10:33:43,945 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-42EA0EB77676:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:43,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:43,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:43,945 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:43,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:43,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:43,946 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:43,946 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:43,947 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676 does not exist. Creating ...
2019-09-19 10:33:43,960 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:43,973 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676 has been successfully formatted.
2019-09-19 10:33:43,973 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-42EA0EB77676: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:43,974 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:43,974 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:43,974 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:43,974 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:43,974 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,975 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:43,975 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676
2019-09-19 10:33:43,975 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:43,975 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:43,975 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:43,976 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:43,977 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:43,977 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:43,977 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:43,978 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:43,978 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:43,978 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-42EA0EB77676
2019-09-19 10:33:43,978 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:43,979 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:43,979 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-42EA0EB77676,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:43,992 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7bb7d59d-3a27-4bf5-be00-42ea0eb77676, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,019 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-1F4C174CFF34:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-1F4C174CFF34:java.util.concurrent.CompletableFuture@655b59c3[Not completed]
2019-09-19 10:33:44,021 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-1F4C174CFF34:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,021 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,022 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:44,023 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34 does not exist. Creating ...
2019-09-19 10:33:44,036 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,049 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34 has been successfully formatted.
2019-09-19 10:33:44,049 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1F4C174CFF34: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,050 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,050 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,050 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,050 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,051 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,051 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,051 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34
2019-09-19 10:33:44,051 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,051 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,052 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,052 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,052 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,052 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,052 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,053 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,053 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,053 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,054 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,054 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,054 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,055 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,055 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-1F4C174CFF34
2019-09-19 10:33:44,055 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,055 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:44,056 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F4C174CFF34,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:44,074 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 2027bde4-4e46-469c-bb91-1f4c174cff34, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,089 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-11011EFFFD47:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-11011EFFFD47:java.util.concurrent.CompletableFuture@3d81eb57[Not completed]
2019-09-19 10:33:44,091 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-11011EFFFD47:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,092 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,092 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,092 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,092 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,092 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,093 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,093 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:44,093 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47 does not exist. Creating ...
2019-09-19 10:33:44,107 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,120 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47 has been successfully formatted.
2019-09-19 10:33:44,121 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-11011EFFFD47: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,121 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,121 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,121 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,122 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,123 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,124 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,124 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,124 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,125 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,125 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-11011EFFFD47
2019-09-19 10:33:44,126 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,126 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:44,126 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-11011EFFFD47,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:44,140 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 857293e1-7480-499d-8b22-11011efffd47, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,155 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-8681B13BA8A4:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-8681B13BA8A4:java.util.concurrent.CompletableFuture@556ab770[Not completed]
2019-09-19 10:33:44,157 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-8681B13BA8A4:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,158 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,159 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:44,159 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4 does not exist. Creating ...
2019-09-19 10:33:44,172 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4 has been successfully formatted.
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8681B13BA8A4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,186 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,187 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,188 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,189 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,189 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,191 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,192 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-8681B13BA8A4
2019-09-19 10:33:44,192 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,192 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:44,193 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8681B13BA8A4,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:44,204 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 26ea26f5-8f23-41d0-bb4c-8681b13ba8a4, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:44,218 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-1EC4F5235753:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-1EC4F5235753:java.util.concurrent.CompletableFuture@156a5725[Not completed]
2019-09-19 10:33:44,220 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-1EC4F5235753:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,221 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:44,222 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753 does not exist. Creating ...
2019-09-19 10:33:44,235 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,259 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753 has been successfully formatted.
2019-09-19 10:33:44,260 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1EC4F5235753: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753
2019-09-19 10:33:44,261 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,262 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,263 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,263 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,264 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-1EC4F5235753
2019-09-19 10:33:44,264 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,264 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:44,264 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1EC4F5235753,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:44,272 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 7c8723f9-d98f-4efd-b88e-1ec4f5235753, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,284 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-280957B18BB6:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-280957B18BB6:java.util.concurrent.CompletableFuture@7c67374d[Not completed]
2019-09-19 10:33:44,286 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-280957B18BB6:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,286 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,287 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:44,288 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6 does not exist. Creating ...
2019-09-19 10:33:44,300 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,314 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6 has been successfully formatted.
2019-09-19 10:33:44,314 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-280957B18BB6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,314 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6
2019-09-19 10:33:44,315 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,316 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,317 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,317 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,318 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,318 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-280957B18BB6
2019-09-19 10:33:44,318 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,318 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:44,319 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-280957B18BB6,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:44,328 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d63121e6-be9d-44d2-83fe-280957b18bb6, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,340 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-6B4102A182A8:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-6B4102A182A8:java.util.concurrent.CompletableFuture@2171229[Not completed]
2019-09-19 10:33:44,342 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-6B4102A182A8:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,342 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,342 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,343 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,343 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,343 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,343 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,343 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:44,344 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8 does not exist. Creating ...
2019-09-19 10:33:44,357 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,370 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8 has been successfully formatted.
2019-09-19 10:33:44,370 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6B4102A182A8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,370 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,371 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,372 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,373 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,373 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,373 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,373 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,374 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,374 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,374 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,374 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-6B4102A182A8
2019-09-19 10:33:44,374 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,375 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:44,375 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6B4102A182A8,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:44,384 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 8bebb02d-45eb-49b5-94db-6b4102a182a8, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,387 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
Sep 19, 2019 10:33:44 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 10:33:44,399 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-2D3F23964752:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-2D3F23964752:java.util.concurrent.CompletableFuture@d07f548[Not completed]
2019-09-19 10:33:44,401 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-2D3F23964752:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,401 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,402 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,402 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,403 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:44,403 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752 does not exist. Creating ...
2019-09-19 10:33:44,416 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,438 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752 has been successfully formatted.
2019-09-19 10:33:44,439 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-2D3F23964752: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,439 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,440 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,440 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,440 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,440 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,440 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752
2019-09-19 10:33:44,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,441 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,442 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,443 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,443 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,444 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,444 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-2D3F23964752
2019-09-19 10:33:44,444 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,445 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:44,445 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D3F23964752,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:44,456 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 59fd2853-9936-4a1a-ac3b-2d3f23964752, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,470 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-40385ED061B3:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-40385ED061B3:java.util.concurrent.CompletableFuture@6f56b95b[Not completed]
2019-09-19 10:33:44,472 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-40385ED061B3:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,473 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,473 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,473 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,473 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,473 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,474 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,474 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:44,474 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3 does not exist. Creating ...
2019-09-19 10:33:44,487 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:44,502 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3 has been successfully formatted.
2019-09-19 10:33:44,502 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-40385ED061B3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,502 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,502 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,503 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,503 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,503 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,503 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,503 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3
2019-09-19 10:33:44,504 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,504 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,504 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,504 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,504 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,505 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,505 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,505 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,505 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,505 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,506 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,506 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,506 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,507 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,507 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-40385ED061B3
2019-09-19 10:33:44,507 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,507 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:44,508 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-40385ED061B3,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:44,519 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a7d014eb-7328-449e-8d91-40385ed061b3, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,534 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-BCF135CCD209:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-BCF135CCD209:java.util.concurrent.CompletableFuture@6e976c32[Not completed]
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-BCF135CCD209:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,536 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,537 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:44,537 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209 does not exist. Creating ...
2019-09-19 10:33:44,550 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,563 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209 has been successfully formatted.
2019-09-19 10:33:44,563 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-BCF135CCD209: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,563 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,563 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,563 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,564 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,565 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-BCF135CCD209
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,566 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:44,567 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCF135CCD209,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:44,578 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: f359554c-9351-4dfa-9b8a-bcf135ccd209, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,597 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-A2E0AAC7F29A:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-A2E0AAC7F29A:java.util.concurrent.CompletableFuture@3241c008[Not completed]
2019-09-19 10:33:44,599 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-A2E0AAC7F29A:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,600 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,600 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,600 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,600 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,600 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,601 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,601 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:44,601 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a does not exist. Creating ...
2019-09-19 10:33:44,615 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,628 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a has been successfully formatted.
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A2E0AAC7F29A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,630 [Thread-250] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 10:33:44,630 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a
2019-09-19 10:33:44,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,631 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,632 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,632 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,632 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,633 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,633 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,633 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,633 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-A2E0AAC7F29A
2019-09-19 10:33:44,633 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,634 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:44,634 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2E0AAC7F29A,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:44,640 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fb881b0a-d857-4a59-9b5c-a2e0aac7f29a, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,654 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: addNew group-F7188749185D:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] returns group-F7188749185D:java.util.concurrent.CompletableFuture@15a5d9da[Not completed]
2019-09-19 10:33:44,655 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: new RaftServerImpl for group-F7188749185D:[10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,656 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D ConfigurationManager, init=-1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,656 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis] (custom)
2019-09-19 10:33:44,656 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d does not exist. Creating ...
2019-09-19 10:33:44,669 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,686 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d has been successfully formatted.
2019-09-19 10:33:44,686 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F7188749185D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,686 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,686 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,686 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,687 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,688 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start group-F7188749185D
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,689 [pool-27-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start FollowerState
2019-09-19 10:33:44,690 [pool-27-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F7188749185D,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:33:44,695 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4d213762-0d29-4cf4-aede-f7188749185d, Nodes: 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,698 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,709 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-04F3440F07C7:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-04F3440F07C7:java.util.concurrent.CompletableFuture@5830df71[Not completed]
2019-09-19 10:33:44,710 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-04F3440F07C7:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,711 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:44,712 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7 does not exist. Creating ...
2019-09-19 10:33:44,725 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7 has been successfully formatted.
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-04F3440F07C7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,738 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,739 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,740 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,741 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,741 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,741 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-04F3440F07C7
2019-09-19 10:33:44,741 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,741 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:44,742 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-04F3440F07C7,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:44,750 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e33f7723-37bb-4333-a0f9-04f3440f07c7, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,752 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,763 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-75F2776D5D19:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-75F2776D5D19:java.util.concurrent.CompletableFuture@a3a4635[Not completed]
2019-09-19 10:33:44,765 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-75F2776D5D19:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,765 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,765 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,766 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,766 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,766 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,766 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,766 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:44,767 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19 does not exist. Creating ...
2019-09-19 10:33:44,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:44,780 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,792 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19 has been successfully formatted.
2019-09-19 10:33:44,792 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-75F2776D5D19: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,793 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,793 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,793 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,793 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,793 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,794 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,795 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,795 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,795 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,795 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,795 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,796 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,796 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,796 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,796 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,797 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,797 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-75F2776D5D19
2019-09-19 10:33:44,797 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,797 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:44,798 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-75F2776D5D19,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:44,803 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 86ceac92-22e3-4ced-bfb4-75f2776d5d19, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,805 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,817 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: addNew group-1A940D6A8E41:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] returns group-1A940D6A8E41:java.util.concurrent.CompletableFuture@45c54f9e[Not completed]
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: new RaftServerImpl for group-1A940D6A8E41:[48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,818 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,819 [pool-38-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 ConfigurationManager, init=-1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,819 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis] (custom)
2019-09-19 10:33:44,819 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41 does not exist. Creating ...
2019-09-19 10:33:44,832 [pool-38-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,845 [pool-38-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41 has been successfully formatted.
2019-09-19 10:33:44,845 [pool-38-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1A940D6A8E41: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,845 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,846 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,846 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,846 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,846 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,846 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,847 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,848 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,848 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,848 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,848 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,849 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,849 [pool-38-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,849 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,850 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,850 [pool-38-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,850 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start group-1A940D6A8E41
2019-09-19 10:33:44,850 [pool-38-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,851 [pool-38-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start FollowerState
2019-09-19 10:33:44,851 [pool-38-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1A940D6A8E41,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:33:44,857 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ef1cee78-709c-4334-b3d9-1a940d6a8e41, Nodes: 48adeddc-e5ef-4407-be4a-4b4625283b71{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,859 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,859 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,883 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-35A521A53874:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-35A521A53874:java.util.concurrent.CompletableFuture@7d0aa0f7[Not completed]
2019-09-19 10:33:44,884 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-35A521A53874:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,885 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,886 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:44,886 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874 does not exist. Creating ...
2019-09-19 10:33:44,887 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin55422, owner=user46905, volume=volume16666, creationTime=1568889224882, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:33:44,899 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,915 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874 has been successfully formatted.
2019-09-19 10:33:44,915 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-35A521A53874: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,915 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,916 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,916 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,916 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,917 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,917 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,917 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume16666, bucket=bucket43395, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:33:44,918 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874
2019-09-19 10:33:44,918 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,919 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,919 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,919 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,919 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,919 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,920 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,920 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,920 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,920 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,921 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,921 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,921 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,921 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,922 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-35A521A53874
2019-09-19 10:33:44,922 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,922 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:44,927 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-35A521A53874,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:44,943 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5fb19b71-2cf8-4d1c-889a-35a521a53874, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:44,948 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,949 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:44,959 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-A91B074EF70F:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-A91B074EF70F:java.util.concurrent.CompletableFuture@f17a37d[Not completed]
2019-09-19 10:33:44,962 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-A91B074EF70F:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:44,963 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:44,964 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f does not exist. Creating ...
2019-09-19 10:33:44,977 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:44,990 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f has been successfully formatted.
2019-09-19 10:33:44,990 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A91B074EF70F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,991 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:44,992 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:44,993 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:44,993 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:44,993 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:44,993 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:44,993 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:44,994 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:44,994 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:44,994 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:44,994 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:44,995 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-A91B074EF70F
2019-09-19 10:33:44,995 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:44,995 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:44,995 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A91B074EF70F,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:45,000 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: be9df9b8-4177-45a2-9df2-a91b074ef70f, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,002 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,002 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,014 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-6A7559AA2163:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-6A7559AA2163:java.util.concurrent.CompletableFuture@4888871b[Not completed]
2019-09-19 10:33:45,015 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-6A7559AA2163:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,015 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,016 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:45,017 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163 does not exist. Creating ...
2019-09-19 10:33:45,030 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,043 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163 has been successfully formatted.
2019-09-19 10:33:45,044 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6A7559AA2163: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,044 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,044 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,045 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,045 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,045 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,045 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,046 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163
2019-09-19 10:33:45,046 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,046 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,046 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,046 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,047 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,047 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,047 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,047 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,047 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,048 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,048 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,049 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,049 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,049 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,049 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-6A7559AA2163
2019-09-19 10:33:45,050 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,050 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:45,050 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A7559AA2163,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:45,056 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 362d65dd-d9d6-42c2-8ece-6a7559aa2163, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,058 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,058 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,069 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: addNew group-B5A30BEB4B38:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] returns group-B5A30BEB4B38:java.util.concurrent.CompletableFuture@17504f4c[Not completed]
2019-09-19 10:33:45,070 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: new RaftServerImpl for group-B5A30BEB4B38:[76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,071 [pool-60-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 ConfigurationManager, init=-1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,072 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis] (custom)
2019-09-19 10:33:45,072 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38 does not exist. Creating ...
2019-09-19 10:33:45,085 [pool-60-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,099 [pool-60-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38 has been successfully formatted.
2019-09-19 10:33:45,099 [pool-60-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B5A30BEB4B38: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,099 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,099 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,100 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,100 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,104 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,107 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,108 [pool-60-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,109 [pool-60-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,109 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start group-B5A30BEB4B38
2019-09-19 10:33:45,109 [pool-60-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,110 [pool-60-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start FollowerState
2019-09-19 10:33:45,110 [pool-60-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5A30BEB4B38,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:33:45,116 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 3e0b87ae-871a-421e-a844-b5a30beb4b38, Nodes: 76e76cf4-f2cd-49d2-b0c8-f80a724ad893{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,126 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,126 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,126 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,139 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76803391-7007-495d-a164-b2d99168fa35: addNew group-1CA23982BD24:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] returns group-1CA23982BD24:java.util.concurrent.CompletableFuture@17ba6d75[Not completed]
2019-09-19 10:33:45,143 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76803391-7007-495d-a164-b2d99168fa35: new RaftServerImpl for group-1CA23982BD24:[76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,143 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,143 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,144 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,144 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,144 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,144 [pool-49-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 ConfigurationManager, init=-1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,145 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis] (custom)
2019-09-19 10:33:45,145 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24 does not exist. Creating ...
2019-09-19 10:33:45,159 [pool-49-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,172 [pool-49-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24 has been successfully formatted.
2019-09-19 10:33:45,173 [pool-49-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-1CA23982BD24: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,173 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,173 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,173 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,173 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,174 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,174 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,174 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24
2019-09-19 10:33:45,174 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,174 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,175 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,175 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,175 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,175 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,175 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,176 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,176 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,176 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,179 [pool-49-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,179 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,181 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,181 [pool-49-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,186 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76803391-7007-495d-a164-b2d99168fa35: start group-1CA23982BD24
2019-09-19 10:33:45,190 [pool-49-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:45,190 [pool-49-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start FollowerState
2019-09-19 10:33:45,191 [pool-49-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CA23982BD24,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:33:45,195 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 686bb207-6412-4ae9-882e-1ca23982bd24, Nodes: 76803391-7007-495d-a164-b2d99168fa35{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,197 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,197 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,197 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,197 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,210 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-48C2E2B316E8:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-48C2E2B316E8:java.util.concurrent.CompletableFuture@78fbd1fd[Not completed]
2019-09-19 10:33:45,212 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-48C2E2B316E8:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,213 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,214 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8 does not exist. Creating ...
2019-09-19 10:33:45,226 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,239 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8 has been successfully formatted.
2019-09-19 10:33:45,240 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-48C2E2B316E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,240 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,240 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,241 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,241 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,241 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:45,241 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,241 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,241 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8
2019-09-19 10:33:45,242 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,242 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,242 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,242 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,243 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,243 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,243 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,243 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,243 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,244 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,244 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,244 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,244 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,245 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,245 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-48C2E2B316E8
2019-09-19 10:33:45,245 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,245 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,246 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-48C2E2B316E8,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,249 [Thread-207] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-19 10:33:45,252 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2019-09-19 10:33:45,252 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0c7452fe-eb9f-4031-bc4e-48c2e2b316e8, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,252 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,253 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,253 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,253 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,258 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume16666} | ret=SUCCESS |  
2019-09-19 10:33:45,265 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-73304B49F889:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-73304B49F889:java.util.concurrent.CompletableFuture@406afef5[Not completed]
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-73304B49F889:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,274 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,275 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,275 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume16666, bucket=bucket43395} | ret=SUCCESS |  
2019-09-19 10:33:45,275 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889 does not exist. Creating ...
2019-09-19 10:33:45,288 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,302 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889 has been successfully formatted.
2019-09-19 10:33:45,302 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-73304B49F889: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,302 [Thread-250] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket43395.volume16666 implemented by OzoneFileSystem{URI=o3fs://bucket43395.volume16666, workingDir=o3fs://bucket43395.volume16666/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-09-19 10:33:45,302 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,303 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,304 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,305 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,305 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,305 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,305 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,306 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,306 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,306 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,306 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,307 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-73304B49F889
2019-09-19 10:33:45,307 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,307 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,307 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73304B49F889,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,313 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 55b266b7-71e0-4e4d-bef5-73304b49f889, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,314 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,314 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,314 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,314 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,327 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-B9AE158EE6AB:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-B9AE158EE6AB:java.util.concurrent.CompletableFuture@778721e6[Not completed]
2019-09-19 10:33:45,328 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-B9AE158EE6AB:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,329 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,330 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,330 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab does not exist. Creating ...
2019-09-19 10:33:45,343 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,356 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab has been successfully formatted.
2019-09-19 10:33:45,356 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B9AE158EE6AB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,357 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,357 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,357 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,357 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,357 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,358 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,359 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,359 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,359 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,359 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,359 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,360 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,360 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,360 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,360 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,361 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,361 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,361 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-B9AE158EE6AB
2019-09-19 10:33:45,361 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,361 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,362 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B9AE158EE6AB,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,368 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: fe01ae57-f6e8-42f6-8224-b9ae158ee6ab, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,370 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,370 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,370 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,371 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,388 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-12894775B280:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-12894775B280:java.util.concurrent.CompletableFuture@2afb8503[Not completed]
2019-09-19 10:33:45,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:45,391 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-12894775B280:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,391 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,391 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,391 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,391 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,392 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,392 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,396 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,397 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280 does not exist. Creating ...
2019-09-19 10:33:45,403 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,412 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,412 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,425 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280 has been successfully formatted.
2019-09-19 10:33:45,425 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-12894775B280: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,426 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,426 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,426 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,426 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,426 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,427 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,427 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,427 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280
2019-09-19 10:33:45,427 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,427 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,428 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,428 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,428 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,428 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,428 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,429 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,429 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,429 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,429 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,430 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,432 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-12894775B280
2019-09-19 10:33:45,432 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,433 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,433 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12894775B280,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,439 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 01172124-1782-49a7-a14d-12894775b280, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,440 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,441 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,441 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume16666, bucket=bucket43395, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-19 10:33:45,449 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-B5CE2A18C4F2:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-B5CE2A18C4F2:java.util.concurrent.CompletableFuture@1e224089[Not completed]
2019-09-19 10:33:45,453 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-B5CE2A18C4F2:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,453 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,454 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,454 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,454 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,454 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,454 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,455 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,455 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,457 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2 does not exist. Creating ...
2019-09-19 10:33:45,458 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume16666, bucket=bucket43395, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/} | ret=SUCCESS |  
2019-09-19 10:33:45,461 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:45,467 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:45,470 [Thread-250] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-09-19 10:33:45,470 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,485 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2 has been successfully formatted.
2019-09-19 10:33:45,485 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B5CE2A18C4F2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,485 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,486 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,486 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,486 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,486 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,487 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,487 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2 for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2
2019-09-19 10:33:45,487 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,487 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,488 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,489 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,489 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,490 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,490 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,490 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,491 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-B5CE2A18C4F2
2019-09-19 10:33:45,491 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,491 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,493 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5CE2A18C4F2,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,503 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:45,506 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: dc79d65d-5929-410d-ba27-b5ce2a18c4f2, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,518 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,532 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: addNew group-6AD04E4CEB4F:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] returns group-6AD04E4CEB4F:java.util.concurrent.CompletableFuture@5f099841[Not completed]
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: new RaftServerImpl for group-6AD04E4CEB4F:[4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814] with ContainerStateMachine:uninitialized
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 10:33:45,533 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 10:33:45,534 [pool-71-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F ConfigurationManager, init=-1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null, confs=<EMPTY_MAP>
2019-09-19 10:33:45,534 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis] (custom)
2019-09-19 10:33:45,534 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f does not exist. Creating ...
2019-09-19 10:33:45,547 [pool-71-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f/in_use.lock acquired by nodename 4697@pr-hdds-1569-cpgw4-1311585219
2019-09-19 10:33:45,561 [pool-71-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f has been successfully formatted.
2019-09-19 10:33:45,561 [pool-71-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6AD04E4CEB4F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 10:33:45,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 10:33:45,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 10:33:45,561 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f for RaftStorage:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 10:33:45,562 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 10:33:45,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 10:33:45,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 10:33:45,563 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 10:33:45,564 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 10:33:45,566 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 10:33:45,566 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 10:33:45,566 [pool-71-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f: flushIndex: setUnconditionally 0 -> -1
2019-09-19 10:33:45,566 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 10:33:45,567 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 10:33:45,567 [pool-71-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 10:33:45,567 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start group-6AD04E4CEB4F
2019-09-19 10:33:45,567 [pool-71-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 10:33:45,567 [pool-71-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start FollowerState
2019-09-19 10:33:45,568 [pool-71-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AD04E4CEB4F,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:33:45,580 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e86c1742-a504-4220-9a20-6ad04e4ceb4f, Nodes: 4ddad5db-b8db-4ca3-8007-a88ba910d681{ip: 192.168.157.204, host: pr-hdds-1569-cpgw4-1311585219, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 10:33:45,581 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,582 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,582 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,585 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,585 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,585 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,587 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,588 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,588 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,588 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,588 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,589 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,591 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,591 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,592 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,593 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:45,593 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,593 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:45,666 [Thread-250] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:33:45,704 [Thread-250] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:33:45,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:45,790 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:45,935 [Thread-250] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 10:33:45,935 [Thread-250] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 10:33:45,937 [Thread-250] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-09-19 10:33:45,937 [Thread-250] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-09-19 10:33:45,968 [Thread-250] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:33:45,984 [Thread-250] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:33:45,993 [Thread-250] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:33:46,033 [Thread-250] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 10:33:46,102 [Thread-250] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-19 10:33:46,182 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:46,234 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:46,258 [Thread-250] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local332476091_0001
2019-09-19 10:33:46,259 [Thread-250] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 10:33:46,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:46,427 [Thread-250] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 10:33:46,428 [Thread-250] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local332476091_0001
2019-09-19 10:33:46,429 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local332476091_0001
2019-09-19 10:33:46,436 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 10:33:46,449 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:46,449 [Thread-369] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:46,452 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 10:33:46,497 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:46,534 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 10:33:46,537 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:46,579 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:46,581 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:46,604 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:33:46,609 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:1989+554
2019-09-19 10:33:46,622 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:46,622 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:46,668 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:46,670 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-09-19 10:33:46,678 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:46,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:46,720 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:46,720 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:46,721 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:46,721 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:46,721 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:46,721 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:46,722 [IPC Server handler 3 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:46,723 [IPC Server handler 3 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:33:46,724 [IPC Server handler 3 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:33:46,725 [IPC Server handler 3 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:33:46,725 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:33:46,731 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:33:46,734 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:46,735 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:46,735 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:33:46,769 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:47,181 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:47,232 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:47,387 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:47,431 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local332476091_0001 running in uber mode : false
2019-09-19 10:33:47,433 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 10:33:47,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:47,769 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,182 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,233 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,387 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,730 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD changes to CANDIDATE, lastRpcTime:5152, electionTimeout:5151ms
2019-09-19 10:33:48,730 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:48,730 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:48,733 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:48,751 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:48,754 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:48,755 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:48,755 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5274ms
2019-09-19 10:33:48,765 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:48,765 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:48,769 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:48,769 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:48,773 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:48,774 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:48,775 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:48,775 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:48,777 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 changes to CANDIDATE, lastRpcTime:5023, electionTimeout:5022ms
2019-09-19 10:33:48,779 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:48,779 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:48,779 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:48,788 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:48,788 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:48,788 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:48,789 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:48,789 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:48,789 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:48,789 [IPC Server handler 1 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:48,790 [IPC Server handler 1 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:33:48,791 [IPC Server handler 1 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:33:48,791 [IPC Server handler 1 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:33:48,791 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:33:48,794 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:48,795 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:33:48,798 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:48,799 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:48,804 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:48,804 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:48,804 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:48,804 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5057ms
2019-09-19 10:33:48,805 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:33:48,806 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:48,807 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:48,807 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:48,807 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:48,807 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:48,807 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:48,808 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:48,823 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121: Starting segment from index:0
2019-09-19 10:33:48,823 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd: Starting segment from index:0
2019-09-19 10:33:48,832 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:48,832 [76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:49,004 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd/current/log_inprogress_0
2019-09-19 10:33:49,004 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121/current/log_inprogress_0
2019-09-19 10:33:49,005 [Thread-218] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 changes to CANDIDATE, lastRpcTime:5095, electionTimeout:5095ms
2019-09-19 10:33:49,007 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,007 [Thread-218] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,007 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:49,025 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:49,029 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:49,029 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,029 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5125ms
2019-09-19 10:33:49,031 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,031 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D changes to CANDIDATE, lastRpcTime:5193, electionTimeout:5193ms
2019-09-19 10:33:49,031 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,031 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:49,031 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,031 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,032 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,032 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:49,032 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,032 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,037 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:49,037 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215: Starting segment from index:0
2019-09-19 10:33:49,038 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:49,073 [Thread-221] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 changes to CANDIDATE, lastRpcTime:5093, electionTimeout:5083ms
2019-09-19 10:33:49,073 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:49,073 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:49,073 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:49,073 [Thread-221] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,073 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,074 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5240ms
2019-09-19 10:33:49,074 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:49,076 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,077 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,078 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,081 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,081 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,081 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,081 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:49,082 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d: Starting segment from index:0
2019-09-19 10:33:49,082 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:49,111 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215/current/log_inprogress_0
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5138ms
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,112 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,113 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,113 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,113 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,113 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,113 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:49,114 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676: Starting segment from index:0
2019-09-19 10:33:49,114 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:49,143 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d/current/log_inprogress_0
2019-09-19 10:33:49,152 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676/current/log_inprogress_0
2019-09-19 10:33:49,181 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:49,211 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 changes to CANDIDATE, lastRpcTime:5018, electionTimeout:5018ms
2019-09-19 10:33:49,212 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:49,213 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,213 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:49,230 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:49,232 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:49,232 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,232 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5045ms
2019-09-19 10:33:49,232 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,232 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,233 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,233 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,233 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,233 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,233 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:49,234 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:49,234 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4: Starting segment from index:0
2019-09-19 10:33:49,234 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 changes to CANDIDATE, lastRpcTime:5108, electionTimeout:5108ms
2019-09-19 10:33:49,234 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,234 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,235 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:49,235 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:49,274 [Thread-224] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 changes to CANDIDATE, lastRpcTime:5218, electionTimeout:5183ms
2019-09-19 10:33:49,278 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,278 [Thread-224] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,279 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:49,286 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4/current/log_inprogress_0
2019-09-19 10:33:49,286 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:49,286 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:49,287 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5238ms
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,288 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,289 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34: Starting segment from index:0
2019-09-19 10:33:49,290 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47: Starting segment from index:0
2019-09-19 10:33:49,291 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:49,291 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:49,345 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47/current/log_inprogress_0
2019-09-19 10:33:49,345 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34/current/log_inprogress_0
2019-09-19 10:33:49,387 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:49,400 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 changes to CANDIDATE, lastRpcTime:5136, electionTimeout:5136ms
2019-09-19 10:33:49,403 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:49,403 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,403 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:49,421 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:49,428 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:49,428 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:49,428 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5167ms
2019-09-19 10:33:49,428 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:49,428 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:49,429 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:49,429 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:49,429 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:49,429 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:49,430 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:49,430 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753: Starting segment from index:0
2019-09-19 10:33:49,430 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:49,469 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 changes to CANDIDATE, lastRpcTime:5151, electionTimeout:5120ms
2019-09-19 10:33:49,470 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:49,470 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,470 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:49,479 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 changes to CANDIDATE, lastRpcTime:5104, electionTimeout:5104ms
2019-09-19 10:33:49,479 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:49,479 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,480 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:49,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:49,522 [Thread-245] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 changes to CANDIDATE, lastRpcTime:5014, electionTimeout:5014ms
2019-09-19 10:33:49,522 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,522 [Thread-245] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,522 [Thread-245] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:49,589 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 changes to CANDIDATE, lastRpcTime:5144, electionTimeout:5144ms
2019-09-19 10:33:49,590 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:49,590 [Thread-242] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,590 [Thread-242] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:49,601 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 changes to CANDIDATE, lastRpcTime:5034, electionTimeout:5034ms
2019-09-19 10:33:49,601 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:49,601 [Thread-248] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,601 [Thread-248] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:49,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:49,795 [Thread-252] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A changes to CANDIDATE, lastRpcTime:5161, electionTimeout:5161ms
2019-09-19 10:33:49,795 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:49,796 [Thread-252] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,796 [Thread-252] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:49,849 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 changes to CANDIDATE, lastRpcTime:5051, electionTimeout:5051ms
2019-09-19 10:33:49,849 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:49,849 [Thread-262] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,849 [Thread-262] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:49,871 [Thread-256] INFO  impl.FollowerState (FollowerState.java:run(106)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D changes to CANDIDATE, lastRpcTime:5181, electionTimeout:5181ms
2019-09-19 10:33:49,871 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown FollowerState
2019-09-19 10:33:49,871 [Thread-256] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,871 [Thread-256] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderElection
2019-09-19 10:33:49,896 [Thread-259] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5154ms
2019-09-19 10:33:49,896 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,896 [Thread-259] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,896 [Thread-259] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:49,920 [Thread-265] INFO  impl.FollowerState (FollowerState.java:run(106)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 changes to CANDIDATE, lastRpcTime:5069, electionTimeout:5069ms
2019-09-19 10:33:49,920 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown FollowerState
2019-09-19 10:33:49,920 [Thread-265] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:49,921 [Thread-265] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderElection
2019-09-19 10:33:50,070 [Thread-268] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 changes to CANDIDATE, lastRpcTime:5147, electionTimeout:5147ms
2019-09-19 10:33:50,070 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:50,070 [Thread-268] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,070 [Thread-268] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:50,092 [Thread-274] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 changes to CANDIDATE, lastRpcTime:5042, electionTimeout:5042ms
2019-09-19 10:33:50,093 [Thread-274] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:50,093 [Thread-274] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,093 [Thread-274] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:50,128 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753/current/log_inprogress_0
2019-09-19 10:33:50,130 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:50,130 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:50,130 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,130 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5816ms
2019-09-19 10:33:50,131 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,131 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,131 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:50,131 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,131 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:50,131 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:50,131 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:50,131 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:50,131 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18: begin an election at term 1 for -1: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null
2019-09-19 10:33:50,131 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:50,131 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:50,131 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13: begin an election at term 1 for -1: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null
2019-09-19 10:33:50,131 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:50,131 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:50,133 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:50,133 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:50,133 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:50,133 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:50,133 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,132 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:50,132 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:50,132 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:50,132 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:50,132 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderElection
2019-09-19 10:33:50,132 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,131 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderElection
2019-09-19 10:33:50,135 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,134 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,134 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,134 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,134 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,134 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,136 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5397ms
2019-09-19 10:33:50,134 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5504ms
2019-09-19 10:33:50,133 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,133 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,136 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5697ms
2019-09-19 10:33:50,133 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,136 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5220ms
2019-09-19 10:33:50,133 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:50,137 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,136 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,136 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5572ms
2019-09-19 10:33:50,136 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,136 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,136 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5290ms
2019-09-19 10:33:50,135 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5764ms
2019-09-19 10:33:50,135 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5090ms
2019-09-19 10:33:50,135 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 change Leader from null to 48adeddc-e5ef-4407-be4a-4b4625283b71 at term 1 for becomeLeader, leader elected after 5632ms
2019-09-19 10:33:50,135 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,135 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,138 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,138 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,138 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,138 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,137 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,137 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,137 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,139 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,137 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,137 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,137 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,140 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,140 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,139 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,139 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,139 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,139 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,139 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,139 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,138 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,138 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D change Leader from null to 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64 at term 1 for becomeLeader, leader elected after 5452ms
2019-09-19 10:33:50,138 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:50,142 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,141 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,141 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,141 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,141 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,141 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,141 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,140 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,140 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,140 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,140 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5347ms
2019-09-19 10:33:50,143 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,143 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,143 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,143 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,144 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:50,143 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,144 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a: Starting segment from index:0
2019-09-19 10:33:50,143 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,142 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,142 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,142 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,142 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6: Starting segment from index:0
2019-09-19 10:33:50,142 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,145 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,145 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,145 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:50,145 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,145 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,145 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,144 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,144 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,144 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,186 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:50,144 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,186 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:50,185 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,185 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:50,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:50,185 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,185 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,187 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:50,187 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:50,185 [Thread-271] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F changes to CANDIDATE, lastRpcTime:5189, electionTimeout:5171ms
2019-09-19 10:33:50,187 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8: Starting segment from index:0
2019-09-19 10:33:50,146 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,146 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,187 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:50,146 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,188 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163: Starting segment from index:0
2019-09-19 10:33:50,146 [76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:50,188 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,188 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: start LeaderState
2019-09-19 10:33:50,187 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:50,187 [Thread-271] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:50,187 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41: Starting segment from index:0
2019-09-19 10:33:50,186 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7: Starting segment from index:0
2019-09-19 10:33:50,186 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:50,186 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874: Starting segment from index:0
2019-09-19 10:33:50,229 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:50,186 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,265 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874:LeaderElection20] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:50,186 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752: Starting segment from index:0
2019-09-19 10:33:50,267 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,264 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163/current/log_inprogress_0
2019-09-19 10:33:50,264 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8/current/log_inprogress_0
2019-09-19 10:33:50,264 [Thread-278] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 changes to CANDIDATE, lastRpcTime:5154, electionTimeout:5137ms
2019-09-19 10:33:50,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:50,229 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:50,229 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209: Starting segment from index:0
2019-09-19 10:33:50,228 [Thread-271] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,226 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3: Starting segment from index:0
2019-09-19 10:33:50,226 [76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163:LeaderElection21] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:50,226 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6/current/log_inprogress_0
2019-09-19 10:33:50,327 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752/current/log_inprogress_0
2019-09-19 10:33:50,226 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a/current/log_inprogress_0
2019-09-19 10:33:50,226 [Thread-282] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 changes to CANDIDATE, lastRpcTime:5035, electionTimeout:5029ms
2019-09-19 10:33:50,188 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,327 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown FollowerState
2019-09-19 10:33:50,327 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,327 [48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 set configuration 0: [48adeddc-e5ef-4407-be4a-4b4625283b71:192.168.157.204:37999], old=null at 0
2019-09-19 10:33:50,326 [Thread-289] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 changes to CANDIDATE, lastRpcTime:5019, electionTimeout:5011ms
2019-09-19 10:33:50,300 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:50,300 [Thread-271] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:50,298 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7/current/log_inprogress_0
2019-09-19 10:33:50,298 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41/current/log_inprogress_0
2019-09-19 10:33:50,298 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874/current/log_inprogress_0
2019-09-19 10:33:50,268 [Thread-278] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown FollowerState
2019-09-19 10:33:50,268 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:50,268 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,332 [Thread-278] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,329 [Thread-289] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,334 [Thread-289] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,329 [Thread-285] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 changes to CANDIDATE, lastRpcTime:5083, electionTimeout:5083ms
2019-09-19 10:33:50,328 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: start LeaderState
2019-09-19 10:33:50,327 [Thread-282] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,334 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d: Starting segment from index:0
2019-09-19 10:33:50,334 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,335 [Thread-285] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,334 [Thread-289] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,334 [Thread-278] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderElection
2019-09-19 10:33:50,334 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,335 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D set configuration 0: [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:192.168.157.204:36110], old=null at 0
2019-09-19 10:33:50,335 [Thread-285] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,334 [Thread-282] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderElection
2019-09-19 10:33:50,360 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,360 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:50,360 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209/current/log_inprogress_0
2019-09-19 10:33:50,360 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3/current/log_inprogress_0
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5378ms
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19: Starting segment from index:0
2019-09-19 10:33:50,369 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,370 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,370 [76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:50,370 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,370 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,371 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,371 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,371 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:50,371 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f: Starting segment from index:0
2019-09-19 10:33:50,372 [76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F:LeaderElection22] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:50,400 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d/current/log_inprogress_0
2019-09-19 10:33:50,400 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23: begin an election at term 1 for -1: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null
2019-09-19 10:33:50,400 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,400 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25: begin an election at term 1 for -1: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null
2019-09-19 10:33:50,400 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,400 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderElection
2019-09-19 10:33:50,400 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,400 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderElection
2019-09-19 10:33:50,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:50,401 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,401 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,401 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,401 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 change Leader from null to 76803391-7007-495d-a164-b2d99168fa35 at term 1 for becomeLeader, leader elected after 5228ms
2019-09-19 10:33:50,401 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5098ms
2019-09-19 10:33:50,401 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,437 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19/current/log_inprogress_0
2019-09-19 10:33:50,437 [Thread-293] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB changes to CANDIDATE, lastRpcTime:5076, electionTimeout:5065ms
2019-09-19 10:33:50,437 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,401 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,401 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,438 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,438 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,438 [Thread-293] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,439 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,438 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 change Leader from null to 76e76cf4-f2cd-49d2-b0c8-f80a724ad893 at term 1 for becomeLeader, leader elected after 5338ms
2019-09-19 10:33:50,439 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,439 [Thread-293] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,439 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,439 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5198ms
2019-09-19 10:33:50,440 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,440 [Thread-293] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,439 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,439 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,440 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,440 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,440 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,443 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,443 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,441 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,443 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76803391-7007-495d-a164-b2d99168fa35: start LeaderState
2019-09-19 10:33:50,443 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889: Starting segment from index:0
2019-09-19 10:33:50,443 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,443 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24: Starting segment from index:0
2019-09-19 10:33:50,443 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,444 [76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24:LeaderElection25] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 set configuration 0: [76803391-7007-495d-a164-b2d99168fa35:192.168.157.204:40090], old=null at 0
2019-09-19 10:33:50,444 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889:LeaderElection24] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,481 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,444 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,483 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,481 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f/current/log_inprogress_0
2019-09-19 10:33:50,444 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,483 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,483 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,484 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5127ms
2019-09-19 10:33:50,484 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,484 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,484 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,485 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,485 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,485 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,485 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,485 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: start LeaderState
2019-09-19 10:33:50,485 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,486 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,486 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,486 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38: Starting segment from index:0
2019-09-19 10:33:50,486 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,486 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8: Starting segment from index:0
2019-09-19 10:33:50,487 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,487 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38:LeaderElection23] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 set configuration 0: [76e76cf4-f2cd-49d2-b0c8-f80a724ad893:192.168.157.204:33931], old=null at 0
2019-09-19 10:33:50,487 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab: Starting segment from index:0
2019-09-19 10:33:50,487 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8:LeaderElection26] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,532 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24/current/log_inprogress_0
2019-09-19 10:33:50,532 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889/current/log_inprogress_0
2019-09-19 10:33:50,532 [Thread-299] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5061ms
2019-09-19 10:33:50,533 [Thread-299] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,534 [Thread-299] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,571 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38/current/log_inprogress_0
2019-09-19 10:33:50,572 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:50,571 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8/current/log_inprogress_0
2019-09-19 10:33:50,571 [Thread-304] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 changes to CANDIDATE, lastRpcTime:5080, electionTimeout:5074ms
2019-09-19 10:33:50,572 [Thread-299] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,572 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB:LeaderElection27] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,572 [Thread-304] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,576 [Thread-304] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,576 [Thread-304] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,584 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab/current/log_inprogress_0
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5159ms
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5100ms
2019-09-19 10:33:50,585 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,586 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,587 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,588 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280: Starting segment from index:0
2019-09-19 10:33:50,588 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2: Starting segment from index:0
2019-09-19 10:33:50,588 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280:LeaderElection28] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,588 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2:LeaderElection29] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,638 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2/current/log_inprogress_0
2019-09-19 10:33:50,638 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280/current/log_inprogress_0
2019-09-19 10:33:50,677 [Thread-314] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F changes to CANDIDATE, lastRpcTime:5109, electionTimeout:5109ms
2019-09-19 10:33:50,677 [Thread-314] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown FollowerState
2019-09-19 10:33:50,677 [Thread-314] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 10:33:50,677 [Thread-314] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderElection
2019-09-19 10:33:50,693 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30: begin an election at term 1 for -1: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null
2019-09-19 10:33:50,694 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderElection
2019-09-19 10:33:50,694 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 10:33:50,694 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F change Leader from null to 4ddad5db-b8db-4ca3-8007-a88ba910d681 at term 1 for becomeLeader, leader elected after 5132ms
2019-09-19 10:33:50,694 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 10:33:50,695 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 10:33:50,695 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 10:33:50,695 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 10:33:50,695 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 10:33:50,695 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 10:33:50,696 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: start LeaderState
2019-09-19 10:33:50,696 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f: Starting segment from index:0
2019-09-19 10:33:50,697 [4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F:LeaderElection30] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F set configuration 0: [4ddad5db-b8db-4ca3-8007-a88ba910d681:192.168.157.204:37814], old=null at 0
2019-09-19 10:33:50,742 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f: created new log segment /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f/current/log_inprogress_0
2019-09-19 10:33:50,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:51,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:51,266 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:51,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:51,534 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:51,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:52,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:52,266 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:52,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:52,534 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:52,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:53,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:53,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:53,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:53,535 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:53,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,535 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:54,803 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:54,810 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,810 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,811 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,811 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,811 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,811 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:54,812 [IPC Server handler 18 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:54,812 [IPC Server handler 18 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:33:54,813 [IPC Server handler 18 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:33:54,813 [IPC Server handler 18 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:33:54,813 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:33:54,814 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:33:54,820 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:54,821 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000000_0
2019-09-19 10:33:54,822 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:33:54,823 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:33:54,829 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000001_0
2019-09-19 10:33:54,834 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:54,835 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:54,835 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:33:54,837 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:0+327
2019-09-19 10:33:54,838 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:54,838 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:54,862 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:54,864 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-19 10:33:54,872 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:54,877 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:54,883 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:33:54,894 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000001_0 is done. And is in the process of committing
2019-09-19 10:33:54,895 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:33:54,896 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000001_0 is allowed to commit now
2019-09-19 10:33:54,897 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:33:54,898 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-09-19 10:33:54,899 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000001_0' done.
2019-09-19 10:33:54,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=209046
		FILE: Number of bytes written=823762
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=11
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:33:54,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000001_0
2019-09-19 10:33:54,902 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000002_0
2019-09-19 10:33:54,913 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:54,913 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:54,914 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:33:54,915 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:327+293
2019-09-19 10:33:54,915 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:33:54,916 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:33:54,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:33:54,936 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-19 10:33:54,944 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:54,945 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:33:54,949 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,950 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,950 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,950 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,950 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:54,951 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:54,951 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:54,951 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:33:54,951 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:33:54,952 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:33:54,952 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:33:54,953 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:33:54,957 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:54,958 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:33:54,959 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:33:55,186 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:55,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:55,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:55,484 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:33:55,536 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:55,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,536 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:56,904 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:33:56,910 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:56,910 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:56,911 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:56,911 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:56,911 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:33:56,911 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:56,911 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:33:56,912 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:33:56,912 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:33:56,912 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:33:56,913 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:33:56,914 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:33:56,917 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:33:56,918 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:33:56,918 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:33:57,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:57,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:57,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:57,536 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:57,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:58,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:58,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:58,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:58,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:58,597 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-19 10:33:58,770 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:59,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:59,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:59,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:59,487 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-19 10:33:59,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:33:59,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:00,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:00,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:00,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:00,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:00,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:01,130 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:34:01,135 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,135 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,135 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,136 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,136 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,136 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:01,136 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:01,136 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:01,137 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:01,137 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:01,137 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:01,138 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:01,141 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:01,148 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000002_0
2019-09-19 10:34:01,149 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:01,149 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:01,150 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:01,151 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:01,151 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:01,151 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:01,153 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:2808+293
2019-09-19 10:34:01,153 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:01,153 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:01,172 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:01,173 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-19 10:34:01,180 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:01,183 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:01,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:01,187 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,187 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,187 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,187 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,188 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:01,188 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:01,188 [IPC Server handler 6 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:01,188 [IPC Server handler 6 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:01,188 [IPC Server handler 6 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:01,189 [IPC Server handler 6 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:01,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:01,190 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:01,192 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:01,195 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:01,195 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:01,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:01,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:01,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:01,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:02,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:02,266 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:02,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:02,484 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:02,489 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:02,489 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:02,490 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:02,490 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:02,490 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:02,490 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:02,491 [IPC Server handler 3 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:02,491 [IPC Server handler 3 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:02,492 [IPC Server handler 3 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:02,492 [IPC Server handler 3 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:02,492 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:02,493 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:02,498 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:02,498 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:02,499 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:02,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:02,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:03,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:03,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:03,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:03,538 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:03,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:04,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:04,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:04,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:04,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:04,600 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 > map
2019-09-19 10:34:04,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:05,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:05,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:05,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:05,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:05,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:06,932 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 10:34:07,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:07,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:07,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:07,492 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 25% reduce 0%
2019-09-19 10:34:07,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:07,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:08,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:08,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:08,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:08,464 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:08,468 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,469 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,469 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,469 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,469 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,469 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:08,470 [IPC Server handler 3 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:08,470 [IPC Server handler 3 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:08,470 [IPC Server handler 3 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:08,470 [IPC Server handler 3 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:08,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:08,472 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:08,482 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:08,484 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000003_0
2019-09-19 10:34:08,485 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:08,485 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:08,486 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000004_0
2019-09-19 10:34:08,487 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,488 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,488 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:08,489 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:885+281
2019-09-19 10:34:08,490 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,490 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,513 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:08,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:34:08,525 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:08,528 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:08,529 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:08,529 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000004_0 is done. And is in the process of committing
2019-09-19 10:34:08,530 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:08,530 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000004_0 is allowed to commit now
2019-09-19 10:34:08,532 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:34:08,532 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:34:08,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000004_0' done.
2019-09-19 10:34:08,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=222808
		FILE: Number of bytes written=823786
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=23
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:08,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000004_0
2019-09-19 10:34:08,533 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000005_0
2019-09-19 10:34:08,534 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,534 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:08,536 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:1708+281
2019-09-19 10:34:08,536 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,536 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,538 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:08,558 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:08,559 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:34:08,567 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:08,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:08,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:08,572 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000005_0 is done. And is in the process of committing
2019-09-19 10:34:08,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:08,573 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000005_0 is allowed to commit now
2019-09-19 10:34:08,575 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:34:08,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:34:08,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000005_0' done.
2019-09-19 10:34:08,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=227054
		FILE: Number of bytes written=823794
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=25
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:08,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000005_0
2019-09-19 10:34:08,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:08,577 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,578 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,578 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:08,579 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:1166+277
2019-09-19 10:34:08,580 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:08,580 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:08,599 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:08,600 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-09-19 10:34:08,608 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:08,609 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:08,613 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,613 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,613 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,613 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,614 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:08,614 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:08,614 [IPC Server handler 1 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:08,614 [IPC Server handler 1 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:08,614 [IPC Server handler 1 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:08,615 [IPC Server handler 1 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:08,615 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:08,616 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:08,621 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:08,622 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:08,622 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:08,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:09,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:09,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:09,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:09,493 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:34:09,538 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:09,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:10,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:10,059 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:10,059 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:10,059 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:10,060 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:10,060 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:10,060 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:10,060 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:10,060 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:10,061 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:10,061 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:10,061 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:10,062 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:10,065 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:10,068 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:10,068 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:10,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:10,267 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:10,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:10,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:10,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:11,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:11,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:11,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:11,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:11,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,401 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,771 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:12,933 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 10:34:13,171 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-19 10:34:13,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:13,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:13,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:13,496 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 55% reduce 0%
2019-09-19 10:34:13,538 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:13,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:14,515 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:14,515 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:14,515 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:14,516 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:14,516 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:14,516 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:14,516 [IPC Server handler 1 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:14,517 [IPC Server handler 1 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:14,517 [IPC Server handler 1 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:14,517 [IPC Server handler 1 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:14,518 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:14,519 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:14,522 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:14,533 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local332476091_0001_m_000006_0
2019-09-19 10:34:14,533 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:14,534 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:14,535 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000007_0
2019-09-19 10:34:14,538 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,596 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,596 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,596 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:14,598 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:620+265
2019-09-19 10:34:14,598 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,598 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,621 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-19 10:34:14,630 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,632 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,634 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000007_0 is done. And is in the process of committing
2019-09-19 10:34:14,635 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,635 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000007_0 is allowed to commit now
2019-09-19 10:34:14,637 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:34:14,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-09-19 10:34:14,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000007_0' done.
2019-09-19 10:34:14,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=235034
		FILE: Number of bytes written=823810
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=32
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:14,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000007_0
2019-09-19 10:34:14,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000008_0
2019-09-19 10:34:14,639 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,640 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:14,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:1443+265
2019-09-19 10:34:14,642 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,642 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,661 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,662 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-19 10:34:14,670 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume16666 bucket: bucket43395 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:14,673 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,675 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000008_0 is done. And is in the process of committing
2019-09-19 10:34:14,676 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,676 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000008_0 is allowed to commit now
2019-09-19 10:34:14,678 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:34:14,678 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-09-19 10:34:14,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000008_0' done.
2019-09-19 10:34:14,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=238768
		FILE: Number of bytes written=823818
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=34
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:14,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000008_0
2019-09-19 10:34:14,680 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local332476091_0001_m_000009_0
2019-09-19 10:34:14,680 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,681 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,681 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:14,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/fileList.seq:2543+265
2019-09-19 10:34:14,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:14,683 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:14,701 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-19 10:34:14,709 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,712 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,713 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local332476091_0001_m_000009_0 is done. And is in the process of committing
2019-09-19 10:34:14,714 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:14,714 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local332476091_0001_m_000009_0 is allowed to commit now
2019-09-19 10:34:14,716 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local332476091_0001_m_000009_0' to file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509/_logs
2019-09-19 10:34:14,717 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-09-19 10:34:14,717 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local332476091_0001_m_000009_0' done.
2019-09-19 10:34:14,718 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local332476091_0001_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=242502
		FILE: Number of bytes written=823826
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=36
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=25
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=157
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:14,718 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local332476091_0001_m_000009_0
2019-09-19 10:34:14,718 [Thread-369] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 10:34:14,736 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,743 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,783 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:14,791 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,794 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:14,795 [Thread-369] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001525922719/.staging/_distcp639053509
2019-09-19 10:34:14,797 [Thread-369] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local332476091_0001
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 --> o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket43395.volume16666/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:15,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:15,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:15,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:15,497 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:34:15,498 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local332476091_0001 failed with state FAILED due to: NA
2019-09-19 10:34:15,545 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:15,553 [Thread-250] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=2056374
		FILE: Number of bytes written=7414178
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=239
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=183
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1413
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=18525192192
	File Input Format Counters 
		Bytes Read=28413
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 10:34:15,555 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,557 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,559 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume16666, bucket=bucket43395, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,562 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume16666, bucket=bucket43395, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:15,565 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,567 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,569 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,570 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,572 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,574 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume16666, bucket=bucket43395, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,575 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume16666, bucket=bucket43395, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:15,626 [Thread-485] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 10:34:15,629 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin92842, owner=user92718, volume=volume67452, creationTime=1568889255629, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:34:15,631 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume67452, bucket=bucket50140, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:34:15,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume67452} | ret=SUCCESS |  
2019-09-19 10:34:15,703 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume67452, bucket=bucket50140} | ret=SUCCESS |  
2019-09-19 10:34:15,704 [Thread-485] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket50140.volume67452 implemented by OzoneFileSystem{URI=o3fs://bucket50140.volume67452, workingDir=o3fs://bucket50140.volume67452/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 43 read ops, 0 large read ops, 26 write ops}
2019-09-19 10:34:15,706 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,721 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,724 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume67452, bucket=bucket50140, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:15,726 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,728 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume67452, bucket=bucket50140, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:15,729 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:15,732 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:15,733 [Thread-485] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-09-19 10:34:15,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:15,848 [Thread-485] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:15,873 [Thread-485] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:15,891 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:15,971 [Thread-485] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 10:34:15,972 [Thread-485] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 10:34:15,983 [Thread-485] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:34:15,996 [Thread-485] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:34:15,997 [Thread-485] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:16,010 [Thread-485] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 10:34:16,073 [Thread-485] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-09-19 10:34:16,116 [Thread-485] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local807358366_0002
2019-09-19 10:34:16,116 [Thread-485] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 10:34:16,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:16,227 [Thread-485] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 10:34:16,230 [Thread-548] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 10:34:16,230 [Thread-485] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local807358366_0002
2019-09-19 10:34:16,230 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local807358366_0002
2019-09-19 10:34:16,230 [Thread-548] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:16,231 [Thread-548] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:16,232 [Thread-548] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 10:34:16,264 [Thread-548] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 10:34:16,264 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:16,267 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:16,267 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:16,268 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:16,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:16,271 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:1162+568
2019-09-19 10:34:16,274 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:16,274 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:16,302 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:16,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-19 10:34:16,311 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:16,313 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:16,319 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:16,320 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:16,320 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:16,320 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:16,320 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:16,320 [IPC Server handler 0 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:16,321 [IPC Server handler 0 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:16,321 [IPC Server handler 0 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:16,321 [IPC Server handler 0 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:16,321 [IPC Server handler 0 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:16,321 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:16,322 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:16,326 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:16,327 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:16,329 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:16,402 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:16,545 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:16,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:17,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:17,231 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local807358366_0002 running in uber mode : false
2019-09-19 10:34:17,232 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 10:34:17,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:17,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:17,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:17,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:18,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:18,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:18,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:18,336 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:18,336 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:18,337 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:18,337 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:18,337 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:18,337 [IPC Server handler 3 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:18,337 [IPC Server handler 3 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:18,338 [IPC Server handler 3 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:18,338 [IPC Server handler 3 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:18,339 [IPC Server handler 3 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:18,339 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:18,340 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:18,344 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:18,345 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:18,345 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:18,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:18,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:18,772 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:19,173 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 > map
2019-09-19 10:34:19,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:19,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:19,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:19,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:19,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:20,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:20,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:20,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:20,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:20,586 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 > map
2019-09-19 10:34:20,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:21,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:21,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:21,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:21,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:21,773 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:22,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:22,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:22,384 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:22,389 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,389 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,389 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,390 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,390 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,390 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:22,390 [IPC Server handler 1 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:22,391 [IPC Server handler 1 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:22,391 [IPC Server handler 1 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:22,391 [IPC Server handler 1 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:22,392 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:22,392 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:22,394 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:22,395 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000000_0
2019-09-19 10:34:22,395 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:22,396 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:22,397 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000001_0
2019-09-19 10:34:22,399 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:22,400 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:22,400 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:22,402 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:0+326
2019-09-19 10:34:22,402 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:22,402 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:22,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:22,424 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:22,425 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 10:34:22,432 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:22,435 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:22,436 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:22,437 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000001_0 is done. And is in the process of committing
2019-09-19 10:34:22,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:22,438 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000001_0 is allowed to commit now
2019-09-19 10:34:22,439 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:22,440 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 10:34:22,440 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000001_0' done.
2019-09-19 10:34:22,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=451411
		FILE: Number of bytes written=1647503
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:22,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000001_0
2019-09-19 10:34:22,441 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:22,442 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:22,443 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:22,443 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:22,444 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:326+292
2019-09-19 10:34:22,445 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:22,445 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:22,464 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:22,465 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-19 10:34:22,473 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:22,474 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:22,479 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,479 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,479 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,480 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,480 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:22,480 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:22,480 [IPC Server handler 18 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:22,481 [IPC Server handler 18 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:22,481 [IPC Server handler 18 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:22,481 [IPC Server handler 18 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:22,482 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:22,483 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:22,487 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:22,488 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:22,488 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:22,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:22,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:23,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:23,240 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:34:23,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:23,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:23,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:23,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:24,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:24,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:24,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:24,548 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:24,606 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:24,612 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:24,612 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:24,612 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:24,613 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:24,613 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:24,613 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:24,613 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:24,613 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:24,627 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:24,627 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:24,628 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:24,629 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:24,632 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:24,632 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:24,633 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:24,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:25,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:25,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:25,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:25,548 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:25,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,549 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:26,911 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:26,916 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,916 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,917 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,917 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,917 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,917 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:26,917 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:26,918 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:26,918 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:26,918 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:26,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:26,919 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:26,922 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:26,922 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000002_0
2019-09-19 10:34:26,923 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:26,923 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:26,924 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:26,925 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:26,925 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:26,926 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:26,927 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:1994+292
2019-09-19 10:34:26,928 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:26,928 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:26,951 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:26,957 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-09-19 10:34:26,966 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:26,967 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:26,971 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,971 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,971 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,972 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,972 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:26,972 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:26,972 [IPC Server handler 6 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:26,972 [IPC Server handler 6 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:26,973 [IPC Server handler 6 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:26,973 [IPC Server handler 6 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:26,973 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:26,974 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:26,976 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:26,977 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:26,977 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:27,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:27,268 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:27,404 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:27,549 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:27,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:28,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:28,283 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:28,283 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-19 10:34:28,396 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:28,400 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:28,400 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:28,401 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:28,401 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:28,401 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:28,401 [IPC Server handler 18 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:28,402 [IPC Server handler 18 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:28,402 [IPC Server handler 18 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:28,403 [IPC Server handler 18 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:28,403 [IPC Server handler 18 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:28,403 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:28,404 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:28,405 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:28,406 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:28,408 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:28,408 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:28,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:28,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:29,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:29,244 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 15% reduce 0%
2019-09-19 10:34:29,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:29,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:29,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:29,774 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:30,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:30,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:30,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:30,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:30,775 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:31,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:31,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:31,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:31,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:31,775 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:32,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:32,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:32,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:32,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:32,776 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,593 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:33,599 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,600 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,600 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,600 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,600 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,601 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:33,601 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:33,601 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:33,602 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:33,602 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:33,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:33,603 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:33,606 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,607 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000003_0
2019-09-19 10:34:33,607 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:33,607 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:33,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000004_0
2019-09-19 10:34:33,609 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,610 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,610 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,611 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:618+280
2019-09-19 10:34:33,612 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,612 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,631 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,632 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:34:33,640 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,644 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000004_0 is done. And is in the process of committing
2019-09-19 10:34:33,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000004_0 is allowed to commit now
2019-09-19 10:34:33,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:33,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:34:33,648 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000004_0' done.
2019-09-19 10:34:33,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=465050
		FILE: Number of bytes written=1647527
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=66
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:33,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000004_0
2019-09-19 10:34:33,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000005_0
2019-09-19 10:34:33,650 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,650 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,651 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,652 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:2286+280
2019-09-19 10:34:33,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,653 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,670 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:34:33,679 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,683 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000005_0 is done. And is in the process of committing
2019-09-19 10:34:33,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000005_0 is allowed to commit now
2019-09-19 10:34:33,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:33,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:34:33,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000005_0' done.
2019-09-19 10:34:33,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=469255
		FILE: Number of bytes written=1647535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=68
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:33,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000005_0
2019-09-19 10:34:33,688 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000006_0
2019-09-19 10:34:33,688 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,688 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,689 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,690 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:898+264
2019-09-19 10:34:33,690 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,690 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,708 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,709 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 10:34:33,716 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,719 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,720 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000006_0 is done. And is in the process of committing
2019-09-19 10:34:33,720 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,720 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000006_0 is allowed to commit now
2019-09-19 10:34:33,722 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:33,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 10:34:33,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000006_0' done.
2019-09-19 10:34:33,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=473460
		FILE: Number of bytes written=1647543
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=70
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:33,724 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000006_0
2019-09-19 10:34:33,724 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000007_0
2019-09-19 10:34:33,725 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,725 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,725 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,726 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:1730+264
2019-09-19 10:34:33,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,727 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,744 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,745 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 10:34:33,751 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,753 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,754 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,754 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000007_0 is done. And is in the process of committing
2019-09-19 10:34:33,755 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,755 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000007_0 is allowed to commit now
2019-09-19 10:34:33,756 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:33,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 10:34:33,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000007_0' done.
2019-09-19 10:34:33,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=477153
		FILE: Number of bytes written=1647551
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=72
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:33,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000007_0
2019-09-19 10:34:33,758 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000008_0
2019-09-19 10:34:33,758 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,759 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,759 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,760 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:2826+264
2019-09-19 10:34:33,760 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,761 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,776 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:33,777 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,777 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 10:34:33,783 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,786 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,787 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local807358366_0002_m_000008_0 is done. And is in the process of committing
2019-09-19 10:34:33,787 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:34:33,788 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local807358366_0002_m_000008_0 is allowed to commit now
2019-09-19 10:34:33,789 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local807358366_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/_logs
2019-09-19 10:34:33,789 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 10:34:33,790 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local807358366_0002_m_000008_0' done.
2019-09-19 10:34:33,790 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local807358366_0002_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=480846
		FILE: Number of bytes written=1647559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=74
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=45
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=154
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=3146
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:33,790 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local807358366_0002_m_000008_0
2019-09-19 10:34:33,791 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:33,791 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,791 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,792 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:33,793 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877/fileList.seq:2566+260
2019-09-19 10:34:33,793 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:33,793 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:33,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:33,809 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-19 10:34:33,815 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,815 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:33,819 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,819 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,819 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,819 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,820 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:33,820 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:33,820 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:33,820 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:33,821 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:33,821 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:33,821 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:33,822 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:33,824 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:33,825 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:33,825 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:34,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:34,247 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:34:34,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:34,286 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-19 10:34:34,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:34,462 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-19 10:34:34,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:34,776 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:35,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:35,248 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 75% reduce 0%
2019-09-19 10:34:35,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:35,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:35,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:35,776 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:36,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:36,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:36,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:36,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:36,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:36,712 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:36,712 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:36,712 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:36,713 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:36,713 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:36,713 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:36,713 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:36,714 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:36,714 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:36,714 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:36,715 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:36,716 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:36,719 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:36,720 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:36,720 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:36,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:37,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:37,270 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:37,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:37,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:37,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,201 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:38,943 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 10:34:39,188 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:39,251 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 85% reduce 0%
2019-09-19 10:34:39,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:39,406 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:39,550 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:39,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:40,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:40,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:40,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:40,551 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:40,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:41,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:41,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:41,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:41,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:41,745 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:41,749 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:41,750 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:41,750 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:41,750 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:41,750 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:41,751 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:41,751 [IPC Server handler 6 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:41,751 [IPC Server handler 6 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:41,752 [IPC Server handler 6 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:41,752 [IPC Server handler 6 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:41,752 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:41,753 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:41,755 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume67452 bucket: bucket50140 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:41,756 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local807358366_0002_m_000009_0
2019-09-19 10:34:41,756 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:41,756 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:41,758 [Thread-548] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 10:34:41,766 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:41,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:41,771 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:41,773 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:41,773 [Thread-548] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins1000672137/.staging/_distcp-430585877
2019-09-19 10:34:41,777 [Thread-548] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local807358366_0002
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket50140.volume67452/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:41,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,253 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local807358366_0002 failed with state FAILED due to: NA
2019-09-19 10:34:42,286 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,326 [Thread-485] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=4270792
		FILE: Number of bytes written=14827919
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=636
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=401
	Map-Reduce Framework
		Map input records=9
		Map output records=0
		Input split bytes=1386
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=18525192192
	File Input Format Counters 
		Bytes Read=28314
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 10:34:42,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,330 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume67452, bucket=bucket50140, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,333 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume67452, bucket=bucket50140, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:42,335 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,336 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,337 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,340 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,341 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume67452, bucket=bucket50140, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,343 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume67452, bucket=bucket50140, startKey=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:42,378 [Thread-602] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 10:34:42,381 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin59775, owner=user46749, volume=volume70270, creationTime=1568889282381, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:34:42,383 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume70270, bucket=bucket47323, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:34:42,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,445 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume70270} | ret=SUCCESS |  
2019-09-19 10:34:42,447 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume70270, bucket=bucket47323} | ret=SUCCESS |  
2019-09-19 10:34:42,448 [Thread-602] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket47323.volume70270 implemented by OzoneFileSystem{URI=o3fs://bucket47323.volume70270, workingDir=o3fs://bucket47323.volume70270/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 86 read ops, 0 large read ops, 52 write ops}
2019-09-19 10:34:42,450 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume70270, bucket=bucket47323, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,460 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,462 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,463 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,465 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume70270, bucket=bucket47323, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:42,466 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,467 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume70270, bucket=bucket47323, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:42,469 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:42,471 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:42,472 [Thread-602] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-09-19 10:34:42,479 [Thread-602] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-09-19 10:34:42,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,615 [Thread-602] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:42,632 [Thread-602] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:42,645 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:42,690 [Thread-602] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-09-19 10:34:42,693 [Thread-602] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 10:34:42,703 [Thread-602] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-19 10:34:42,714 [Thread-602] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-09-19 10:34:42,716 [Thread-602] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:42,724 [Thread-602] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 10:34:42,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:42,782 [Thread-602] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-09-19 10:34:42,931 [Thread-602] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local659780934_0003
2019-09-19 10:34:42,931 [Thread-602] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 10:34:43,065 [Thread-602] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 10:34:43,068 [Thread-649] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 10:34:43,068 [Thread-602] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local659780934_0003
2019-09-19 10:34:43,069 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local659780934_0003
2019-09-19 10:34:43,069 [Thread-649] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:43,069 [Thread-649] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:43,069 [Thread-649] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 10:34:43,088 [Thread-649] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 10:34:43,089 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:43,089 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:43,089 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:43,090 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:43,091 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001470899835/.staging/_distcp1031464248/fileList.seq:0+780
2019-09-19 10:34:43,091 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:43,091 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:43,112 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:43,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
2019-09-19 10:34:43,119 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:43,122 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:43,125 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
2019-09-19 10:34:43,134 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:43,135 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:43,139 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:43,140 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:43,140 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:43,140 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:43,140 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:43,141 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:43,141 [IPC Server handler 2 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:43,141 [IPC Server handler 2 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:43,141 [IPC Server handler 2 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:43,141 [IPC Server handler 2 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:43,142 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:43,142 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:43,145 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:43,146 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:43,146 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:43,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:43,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:43,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:43,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:43,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,069 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local659780934_0003 running in uber mode : false
2019-09-19 10:34:44,070 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 10:34:44,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:44,944 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 > map
2019-09-19 10:34:45,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:45,239 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:45,244 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:45,244 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:45,244 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:45,244 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:45,245 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:45,245 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:45,245 [IPC Server handler 8 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:45,245 [IPC Server handler 8 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:45,246 [IPC Server handler 8 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:45,246 [IPC Server handler 8 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:45,246 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:45,247 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:45,249 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:45,250 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:45,250 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:45,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:45,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:45,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:45,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:45,797 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-19 10:34:46,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:46,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:46,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:46,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:46,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:47,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:47,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:47,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:47,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:47,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:48,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:48,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:48,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:48,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:48,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:49,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:49,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:49,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:49,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:49,777 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:50,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:50,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:50,291 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:50,294 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,295 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,295 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,295 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,295 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,296 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:50,296 [IPC Server handler 19 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:50,296 [IPC Server handler 19 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:50,296 [IPC Server handler 19 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:50,296 [IPC Server handler 19 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:50,297 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:50,297 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:50,299 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:50,300 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000000_0
2019-09-19 10:34:50,300 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:50,300 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:50,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:50,313 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:50,313 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:50,313 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:50,314 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001470899835/.staging/_distcp1031464248/fileList.seq:780+238
2019-09-19 10:34:50,315 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:50,315 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:50,344 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:50,345 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
2019-09-19 10:34:50,352 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:50,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:50,356 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,356 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,356 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,357 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,357 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:50,357 [IPC Server handler 1 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:50,357 [IPC Server handler 1 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:50,357 [IPC Server handler 1 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:50,358 [IPC Server handler 1 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:50,358 [IPC Server handler 1 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:50,358 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:50,359 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:50,360 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:50,361 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:50,361 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:50,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:50,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:50,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:51,549 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:51,550 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:51,550 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:51,550 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:51,550 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:51,550 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:51,551 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:51,551 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:51,551 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:51,551 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:51,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:51,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,552 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:51,555 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:51,556 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:51,556 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:51,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:51,798 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-19 10:34:52,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:52,284 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:52,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:52,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:52,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:53,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:53,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:53,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:53,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:53,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:54,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:54,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:54,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:54,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:54,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:55,103 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-19 10:34:55,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:55,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:55,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:55,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:55,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,084 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 33% reduce 0%
2019-09-19 10:34:56,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:56,826 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:56,839 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:56,840 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:56,840 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:56,840 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:56,840 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:56,841 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:56,841 [IPC Server handler 2 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:56,841 [IPC Server handler 2 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:56,842 [IPC Server handler 2 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:56,842 [IPC Server handler 2 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:56,842 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:56,842 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:56,845 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume70270 bucket: bucket47323 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:56,846 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local659780934_0003_m_000001_0
2019-09-19 10:34:56,846 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:56,847 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 --> o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:56,848 [Thread-649] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 10:34:56,853 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:56,855 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:56,858 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:56,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:56,861 [Thread-649] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001470899835/.staging/_distcp1031464248
2019-09-19 10:34:56,862 [Thread-649] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local659780934_0003
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 --> o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket47323.volume70270/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:34:57,085 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local659780934_0003 failed with state FAILED due to: NA
2019-09-19 10:34:57,098 [Thread-602] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=676583
		FILE: Number of bytes written=11973285
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=100
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=63
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=1058
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:34:57,101 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,103 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,104 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume70270, bucket=bucket47323, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume70270, bucket=bucket47323, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:57,109 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume70270, bucket=bucket47323, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,110 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,112 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume70270, bucket=bucket47323, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,113 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume70270, bucket=bucket47323, startKey=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:57,146 [Thread-666] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 10:34:57,149 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin68660, owner=user92517, volume=volume37416, creationTime=1568889297148, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:34:57,153 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume37416, bucket=bucket32380, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:34:57,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:57,221 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume37416} | ret=SUCCESS |  
2019-09-19 10:34:57,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume37416, bucket=bucket32380} | ret=SUCCESS |  
2019-09-19 10:34:57,224 [Thread-666] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket32380.volume37416 implemented by OzoneFileSystem{URI=o3fs://bucket32380.volume37416, workingDir=o3fs://bucket32380.volume37416/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 108 read ops, 0 large read ops, 66 write ops}
2019-09-19 10:34:57,226 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume37416, bucket=bucket32380, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,240 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,243 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,245 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume37416, bucket=bucket32380, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:57,246 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,247 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume37416, bucket=bucket32380, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:57,249 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume37416 bucket: bucket32380 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,252 [Thread-666] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
2019-09-19 10:34:57,254 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,255 [Thread-666] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-09-19 10:34:57,271 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,271 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,271 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,271 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,272 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,272 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:57,272 [IPC Server handler 19 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:57,272 [IPC Server handler 19 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:57,272 [IPC Server handler 19 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:57,273 [IPC Server handler 19 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:57,273 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:57,273 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:57,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:57,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,276 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,278 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume37416, bucket=bucket32380, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,279 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume37416, bucket=bucket32380, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:57,281 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume37416, bucket=bucket32380, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,282 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,284 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume37416, bucket=bucket32380, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume37416, bucket=bucket32380, startKey=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:34:57,312 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin75644, owner=user78093, volume=volume44569, creationTime=1568889297311, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:34:57,313 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume44569, bucket=bucket67824, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:34:57,364 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume44569} | ret=SUCCESS |  
2019-09-19 10:34:57,365 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume44569, bucket=bucket67824} | ret=SUCCESS |  
2019-09-19 10:34:57,366 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket67824.volume44569 implemented by OzoneFileSystem{URI=o3fs://bucket67824.volume44569, workingDir=o3fs://bucket67824.volume44569/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 114 read ops, 0 large read ops, 69 write ops}
2019-09-19 10:34:57,367 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,382 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,384 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,386 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume44569, bucket=bucket67824, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:57,389 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,390 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume44569, bucket=bucket67824, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:34:57,392 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,394 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:34:57,395 [Thread-670] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-09-19 10:34:57,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:57,496 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:57,508 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:57,522 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:57,598 [Thread-670] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-09-19 10:34:57,599 [Thread-670] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-09-19 10:34:57,609 [Thread-670] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:34:57,619 [Thread-670] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-09-19 10:34:57,620 [Thread-670] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-09-19 10:34:57,628 [Thread-670] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-09-19 10:34:57,686 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-09-19 10:34:57,724 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local605569047_0004
2019-09-19 10:34:57,725 [Thread-670] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-09-19 10:34:57,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:57,841 [Thread-670] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-09-19 10:34:57,847 [Thread-732] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-09-19 10:34:57,847 [Thread-670] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local605569047_0004
2019-09-19 10:34:57,848 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local605569047_0004
2019-09-19 10:34:57,848 [Thread-732] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:57,848 [Thread-732] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:57,849 [Thread-732] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-09-19 10:34:57,873 [Thread-732] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-09-19 10:34:57,873 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000000_0
2019-09-19 10:34:57,874 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:57,875 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:57,875 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:34:57,876 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:608+879
2019-09-19 10:34:57,877 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:34:57,877 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:34:57,903 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,904 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-09-19 10:34:57,912 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,913 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:34:57,916 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,916 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,916 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,917 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,917 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:57,917 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:57,917 [IPC Server handler 8 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:57,917 [IPC Server handler 8 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:57,918 [IPC Server handler 8 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:57,918 [IPC Server handler 8 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:57,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:57,919 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:57,920 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:57,920 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:34:57,921 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:58,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:58,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:58,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:58,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:58,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:58,848 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local605569047_0004 running in uber mode : false
2019-09-19 10:34:58,849 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2019-09-19 10:34:59,007 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:34:59,012 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:59,013 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:59,013 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:59,013 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:59,013 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:34:59,013 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:59,014 [IPC Server handler 19 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:34:59,014 [IPC Server handler 19 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:34:59,014 [IPC Server handler 19 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:34:59,014 [IPC Server handler 19 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:34:59,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:34:59,015 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:34:59,017 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:34:59,018 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:34:59,018 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:34:59,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:59,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:59,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:59,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:34:59,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:00,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:00,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:00,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:00,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:00,778 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,105 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 > map
2019-09-19 10:35:01,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,457 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:35:01,463 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,464 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,464 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,464 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,464 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,464 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:01,465 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:01,465 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:01,465 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:01,466 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:01,466 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:01,466 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:01,469 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,469 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000000_0
2019-09-19 10:35:01,470 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:01,470 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:35:01,471 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000001_0
2019-09-19 10:35:01,472 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,472 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,473 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:01,474 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:0+327
2019-09-19 10:35:01,475 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,475 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,494 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,495 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 10:35:01,501 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,504 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,505 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000001_0 is done. And is in the process of committing
2019-09-19 10:35:01,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,506 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000001_0 is allowed to commit now
2019-09-19 10:35:01,508 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:01,508 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-09-19 10:35:01,508 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000001_0' done.
2019-09-19 10:35:01,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=885318
		FILE: Number of bytes written=12796892
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=125
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:01,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000001_0
2019-09-19 10:35:01,509 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000002_0
2019-09-19 10:35:01,510 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,510 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,510 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:01,511 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:327+281
2019-09-19 10:35:01,511 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,511 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,532 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:35:01,539 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,541 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,542 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000002_0 is done. And is in the process of committing
2019-09-19 10:35:01,543 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,544 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000002_0 is allowed to commit now
2019-09-19 10:35:01,545 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:01,545 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-09-19 10:35:01,545 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000002_0' done.
2019-09-19 10:35:01,546 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=889924
		FILE: Number of bytes written=12796900
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=127
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:01,546 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000002_0
2019-09-19 10:35:01,546 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000003_0
2019-09-19 10:35:01,546 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,547 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,547 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:01,548 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:1487+281
2019-09-19 10:35:01,548 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,548 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,566 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,567 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:35:01,575 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,578 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,579 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000003_0 is done. And is in the process of committing
2019-09-19 10:35:01,579 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:01,579 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000003_0 is allowed to commit now
2019-09-19 10:35:01,581 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:01,581 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-09-19 10:35:01,581 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000003_0' done.
2019-09-19 10:35:01,582 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=894530
		FILE: Number of bytes written=12796908
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=76
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:01,582 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000003_0
2019-09-19 10:35:01,582 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:01,583 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,583 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,583 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:01,584 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:1768+277
2019-09-19 10:35:01,585 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:01,585 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:01,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:01,603 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-09-19 10:35:01,611 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,612 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:01,615 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,615 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:01,616 [IPC Server handler 4 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:01,617 [IPC Server handler 4 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:01,617 [IPC Server handler 4 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:01,617 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:01,617 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:01,619 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:01,620 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:01,620 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:01,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:01,854 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-09-19 10:35:02,191 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:02,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:02,337 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
2019-09-19 10:35:02,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:02,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:02,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:03,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:03,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:03,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:03,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:03,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:04,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:04,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:04,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:04,430 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:04,434 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:04,435 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:04,435 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:04,435 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:04,435 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:04,435 [IPC Server handler 10 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:04,436 [IPC Server handler 10 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:04,436 [IPC Server handler 10 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:04,436 [IPC Server handler 10 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:04,436 [IPC Server handler 10 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:04,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:04,437 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:04,439 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:04,440 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:04,440 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:04,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:04,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:05,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:05,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:05,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:05,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:05,779 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:06,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:06,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:06,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:06,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:06,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,781 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:07,867 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:07,870 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:07,871 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:07,871 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:07,871 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:07,871 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:07,872 [IPC Server handler 8 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:07,872 [IPC Server handler 8 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:07,872 [IPC Server handler 8 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:07,873 [IPC Server handler 8 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:07,873 [IPC Server handler 8 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:07,873 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:07,874 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:07,876 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:07,877 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000004_0
2019-09-19 10:35:07,877 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:07,878 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 --> o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:35:07,878 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000005_0
2019-09-19 10:35:07,879 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,879 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,880 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:07,880 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:2045+265
2019-09-19 10:35:07,881 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,881 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,898 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,899 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 10:35:07,905 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:07,907 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,908 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,909 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000005_0 is done. And is in the process of committing
2019-09-19 10:35:07,909 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,909 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000005_0 is allowed to commit now
2019-09-19 10:35:07,911 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000005_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:07,911 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-09-19 10:35:07,911 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000005_0' done.
2019-09-19 10:35:07,912 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=902718
		FILE: Number of bytes written=12796924
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=136
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:07,912 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000005_0
2019-09-19 10:35:07,912 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000006_0
2019-09-19 10:35:07,913 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,913 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,913 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:07,914 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:2310+265
2019-09-19 10:35:07,914 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,914 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,928 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,929 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 10:35:07,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,938 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,939 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000006_0 is done. And is in the process of committing
2019-09-19 10:35:07,939 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,939 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000006_0 is allowed to commit now
2019-09-19 10:35:07,940 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000006_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:07,941 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-09-19 10:35:07,941 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000006_0' done.
2019-09-19 10:35:07,941 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=906812
		FILE: Number of bytes written=12796932
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=138
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:07,941 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000006_0
2019-09-19 10:35:07,942 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000007_0
2019-09-19 10:35:07,942 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,942 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,942 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:07,943 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:2575+265
2019-09-19 10:35:07,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,944 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,959 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 10:35:07,967 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,969 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local605569047_0004_m_000007_0 is done. And is in the process of committing
2019-09-19 10:35:07,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-09-19 10:35:07,971 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local605569047_0004_m_000007_0 is allowed to commit now
2019-09-19 10:35:07,972 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local605569047_0004_m_000007_0' to file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/_logs
2019-09-19 10:35:07,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-09-19 10:35:07,972 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local605569047_0004_m_000007_0' done.
2019-09-19 10:35:07,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local605569047_0004_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=910394
		FILE: Number of bytes written=12796940
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=140
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=82
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=158
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2006974464
	File Input Format Counters 
		Bytes Read=3157
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-09-19 10:35:07,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local605569047_0004_m_000007_0
2019-09-19 10:35:07,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:07,973 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,974 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,974 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-09-19 10:35:07,975 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368/fileList.seq:2840+261
2019-09-19 10:35:07,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-09-19 10:35:07,975 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-09-19 10:35:07,989 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:07,990 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-09-19 10:35:07,996 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:07,997 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:08,000 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:08,000 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:08,000 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:08,000 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:08,001 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:08,001 [IPC Server handler 19 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:08,001 [IPC Server handler 19 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:08,001 [IPC Server handler 19 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:08,001 [IPC Server handler 19 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:08,002 [IPC Server handler 19 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:08,002 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:08,002 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:08,004 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:08,004 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:08,004 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:08,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:08,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:08,338 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 > map
2019-09-19 10:35:08,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:08,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:08,781 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:09,834 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:09,838 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:09,838 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:09,838 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:09,838 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:09,838 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:09,839 [IPC Server handler 2 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:09,839 [IPC Server handler 2 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:09,839 [IPC Server handler 2 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:09,839 [IPC Server handler 2 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:09,839 [IPC Server handler 2 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:09,839 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:09,840 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:09,841 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:09,842 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:09,842 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:09,884 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 > map
2019-09-19 10:35:10,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:10,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:10,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:10,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:10,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:10,859 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 70% reduce 0%
2019-09-19 10:35:11,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:11,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:11,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:11,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:11,781 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:12,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:12,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:12,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:12,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:12,781 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=48adeddc-e5ef-4407-be4a-4b4625283b71, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,603 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-19 10:35:13,625 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:13,629 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:13,629 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:13,630 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:13,630 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:13,630 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:13,630 [IPC Server handler 6 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:13,631 [IPC Server handler 6 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:13,631 [IPC Server handler 6 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:13,631 [IPC Server handler 6 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:13,632 [IPC Server handler 6 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:13,632 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:13,632 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:13,635 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume44569 bucket: bucket67824 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:13,636 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(437)) - delete: Path does not exist: o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local605569047_0004_m_000008_0
2019-09-19 10:35:13,636 [LocalJobRunner Map Task Executor #0] ERROR util.RetriableCommand (RetriableCommand.java:execute(89)) - Failure in Retriable command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 10:35:13,636 [LocalJobRunner Map Task Executor #0] ERROR mapred.CopyMapper (CopyMapper.java:handleFailures(296)) - Failure in copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 --> o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:35:13,638 [Thread-732] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-09-19 10:35:13,644 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,646 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,651 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,651 [Thread-732] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/jenkins10001475740801/.staging/_distcp1828583368
2019-09-19 10:35:13,656 [Thread-732] WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local605569047_0004
java.lang.Exception: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: File copy failed: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 --> o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:259)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:217)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:48)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket67824.volume44569/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
	at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:256)
	... 11 more
Caused by: INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:725)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.createFile(OzoneManagerProtocolClientSideTranslatorPB.java:1474)
	at org.apache.hadoop.ozone.client.rpc.RpcClient.createFile(RpcClient.java:984)
	at org.apache.hadoop.ozone.client.OzoneBucket.createFile(OzoneBucket.java:535)
	at org.apache.hadoop.fs.ozone.BasicOzoneClientAdapterImpl.createFile(BasicOzoneClientAdapterImpl.java:181)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.createOutputStream(BasicOzoneFileSystem.java:249)
	at org.apache.hadoop.fs.ozone.BasicOzoneFileSystem.create(BasicOzoneFileSystem.java:230)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.copyToFile(RetriableFileCopyCommand.java:184)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:123)
	at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
	at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
	... 12 more
2019-09-19 10:35:13,780 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76803391-7007-495d-a164-b2d99168fa35, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:13,861 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 81% reduce 0%
2019-09-19 10:35:13,862 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1660)) - Job job_local605569047_0004 failed with state FAILED due to: NA
2019-09-19 10:35:13,921 [Thread-670] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 22
	File System Counters
		FILE: Number of bytes read=7217648
		FILE: Number of bytes written=102375392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=0
		O3FS: Number of read operations=1083
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=646
	Map-Reduce Framework
		Map input records=8
		Map output records=0
		Input split bytes=1264
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=16055795712
	File Input Format Counters 
		Bytes Read=25256
	File Output Format Counters 
		Bytes Written=64
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=6
2019-09-19 10:35:13,923 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,925 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,927 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume44569, bucket=bucket67824, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume44569, bucket=bucket67824, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:35:13,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume44569, bucket=bucket67824, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:13,939 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume44569, bucket=bucket67824, startKey=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:35:13,965 [Thread-776] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-09-19 10:35:13,971 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=admin52026, owner=user92750, volume=volume63971, creationTime=1568889313970, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 10:35:13,973 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=volume63971, bucket=bucket08642, acls=[], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 10:35:14,027 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=volume63971} | ret=SUCCESS |  
2019-09-19 10:35:14,029 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=volume63971, bucket=bucket08642} | ret=SUCCESS |  
2019-09-19 10:35:14,030 [Thread-776] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket08642.volume63971 implemented by OzoneFileSystem{URI=o3fs://bucket08642.volume63971, workingDir=o3fs://bucket08642.volume63971/user/jenkins1000, userName=jenkins1000, statistics=0 bytes read, 0 bytes written, 152 read ops, 0 large read ops, 89 write ops}
2019-09-19 10:35:14,032 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63971, bucket=bucket08642, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,046 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,047 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,048 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,049 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63971, bucket=bucket08642, startKey=, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:35:14,051 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63971, bucket=bucket08642, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/, maxKeys=1000, keyPrefix=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/} | ret=SUCCESS |  
2019-09-19 10:35:14,053 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | FILE_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume63971 bucket: bucket08642 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1655)
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2868) 
2019-09-19 10:35:14,056 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,056 [Thread-776] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
2019-09-19 10:35:14,058 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_DIRECTORY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,062 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:14,063 [IPC Server handler 9 on 44264] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
2019-09-19 10:35:14,064 [IPC Server handler 9 on 44264] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 5.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 10:35:14,064 [IPC Server handler 9 on 44264] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 10:35:14,064 [IPC Server handler 9 on 44264] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 10:35:14,064 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=ALLOCATE_BLOCK {owner=73dc0ff7-2608-4742-8a46-ed5b85eb53f4, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 10:35:14,065 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_FILE {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/file1, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 10:35:14,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,067 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,069 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume63971, bucket=bucket08642, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,070 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63971, bucket=bucket08642, startKey=, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:35:14,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63971, bucket=bucket08642, key=test/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,073 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,074 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,075 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=volume63971, bucket=bucket08642, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 10:35:14,076 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=volume63971, bucket=bucket08642, startKey=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/, maxKeys=1000, keyPrefix=test/} | ret=SUCCESS |  
2019-09-19 10:35:14,077 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-09-19 10:35:14,078 | INFO  | SCMAudit | user=null | ip=null | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 10:35:14,078 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-09-19 10:35:14,078 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-09-19 10:35:14,078 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38398
2019-09-19 10:35:14,098 [IPC Server listener on 38398] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38398
2019-09-19 10:35:14,106 [JUnit] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-19 10:35:14,108 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 10:35:14,108 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-19 10:35:14,110 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-19 10:35:14,116 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@54562ea6{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-19 10:35:14,123 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a35993f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:14,123 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2bf94401{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.5.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:14,123 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@749ab7b4{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:14,129 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-09-19 10:35:14,129 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 10:35:14,130 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 10:35:14,132 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3bbf1c0d
2019-09-19 10:35:14,132 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@58b311ba
2019-09-19 10:35:14,194 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:14,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:14,411 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:14,555 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 10:35:14,780 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 10:35:15,195 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:15,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:15,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:16,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:16,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:16,412 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:17,197 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:17,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:17,413 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:18,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:18,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:18,414 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=4ddad5db-b8db-4ca3-8007-a88ba910d681, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:19,135 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 10:35:19,135 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 10:35:19,137 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 76803391-7007-495d-a164-b2d99168fa35: close
2019-09-19 10:35:19,137 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: close
2019-09-19 10:35:19,141 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-11011EFFFD47
2019-09-19 10:35:19,141 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-6A7559AA2163
2019-09-19 10:35:19,142 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-11011EFFFD47,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,142 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A7559AA2163,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,142 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,143 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,145 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,145 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,150 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47: set stopIndex = 0
2019-09-19 10:35:19,150 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163: set stopIndex = 0
2019-09-19 10:35:19,153 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-6A7559AA2163 closes. The last applied log index is 0
2019-09-19 10:35:19,152 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-11011EFFFD47 closes. The last applied log index is 0
2019-09-19 10:35:19,156 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,156 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,159 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/857293e1-7480-499d-8b22-11011efffd47 close()
2019-09-19 10:35:19,159 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/362d65dd-d9d6-42c2-8ece-6a7559aa2163 close()
2019-09-19 10:35:19,165 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-2CB13409A215
2019-09-19 10:35:19,165 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-75F2776D5D19
2019-09-19 10:35:19,166 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2CB13409A215,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,166 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-75F2776D5D19,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,166 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,166 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,167 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,167 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,168 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19: set stopIndex = 0
2019-09-19 10:35:19,168 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215: set stopIndex = 0
2019-09-19 10:35:19,168 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-75F2776D5D19 closes. The last applied log index is 0
2019-09-19 10:35:19,168 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-2CB13409A215 closes. The last applied log index is 0
2019-09-19 10:35:19,169 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,169 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,173 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/86ceac92-22e3-4ced-bfb4-75f2776d5d19 close()
2019-09-19 10:35:19,173 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a6905970-066c-481c-ba8b-2cb13409a215 close()
2019-09-19 10:35:19,178 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-B3336D34D121
2019-09-19 10:35:19,182 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-04F3440F07C7
2019-09-19 10:35:19,182 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B3336D34D121,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,183 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,182 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-04F3440F07C7,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,183 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,183 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,184 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121: set stopIndex = 0
2019-09-19 10:35:19,184 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,184 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-B3336D34D121 closes. The last applied log index is 0
2019-09-19 10:35:19,185 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7: set stopIndex = 0
2019-09-19 10:35:19,185 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,185 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-04F3440F07C7 closes. The last applied log index is 0
2019-09-19 10:35:19,187 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/ac3b7e4b-7146-46ff-b997-b3336d34d121 close()
2019-09-19 10:35:19,187 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,190 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-280957B18BB6
2019-09-19 10:35:19,192 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/e33f7723-37bb-4333-a0f9-04f3440f07c7 close()
2019-09-19 10:35:19,192 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-280957B18BB6,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,195 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-40385ED061B3
2019-09-19 10:35:19,196 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:19,196 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,196 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-40385ED061B3,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,197 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,197 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,197 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6: set stopIndex = 0
2019-09-19 10:35:19,197 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,198 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-280957B18BB6 closes. The last applied log index is 0
2019-09-19 10:35:19,198 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3: set stopIndex = 0
2019-09-19 10:35:19,199 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,199 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-40385ED061B3 closes. The last applied log index is 0
2019-09-19 10:35:19,201 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/d63121e6-be9d-44d2-83fe-280957b18bb6 close()
2019-09-19 10:35:19,201 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,204 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-A91B074EF70F
2019-09-19 10:35:19,205 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/a7d014eb-7328-449e-8d91-40385ed061b3 close()
2019-09-19 10:35:19,206 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A91B074EF70F,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,208 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-1A940D6A8E41
2019-09-19 10:35:19,209 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,209 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1A940D6A8E41,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,209 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,209 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,210 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F: set stopIndex = 0
2019-09-19 10:35:19,210 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,210 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-A91B074EF70F closes. The last applied log index is 0
2019-09-19 10:35:19,211 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41: set stopIndex = 0
2019-09-19 10:35:19,211 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1A940D6A8E41 closes. The last applied log index is 0
2019-09-19 10:35:19,211 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,213 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,213 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/be9df9b8-4177-45a2-9df2-a91b074ef70f close()
2019-09-19 10:35:19,215 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/ef1cee78-709c-4334-b3d9-1a940d6a8e41 close()
2019-09-19 10:35:19,218 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown group-1CA23982BD24
2019-09-19 10:35:19,225 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown group-1F4C174CFF34
2019-09-19 10:35:19,225 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CA23982BD24,id=76803391-7007-495d-a164-b2d99168fa35
2019-09-19 10:35:19,225 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F4C174CFF34,id=48adeddc-e5ef-4407-be4a-4b4625283b71
2019-09-19 10:35:19,225 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown LeaderState
2019-09-19 10:35:19,226 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown LeaderState
2019-09-19 10:35:19,226 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76803391-7007-495d-a164-b2d99168fa35-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,226 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:19,227 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24: set stopIndex = 0
2019-09-19 10:35:19,227 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34: set stopIndex = 0
2019-09-19 10:35:19,228 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76803391-7007-495d-a164-b2d99168fa35:group-1CA23982BD24 closes. The last applied log index is 0
2019-09-19 10:35:19,229 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 48adeddc-e5ef-4407-be4a-4b4625283b71:group-1F4C174CFF34 closes. The last applied log index is 0
2019-09-19 10:35:19,229 [76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,229 [48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:19,229 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76803391-7007-495d-a164-b2d99168fa35-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/ratis/686bb207-6412-4ae9-882e-1ca23982bd24 close()
2019-09-19 10:35:19,230 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 48adeddc-e5ef-4407-be4a-4b4625283b71-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/ratis/2027bde4-4e46-469c-bb91-1f4c174cff34 close()
2019-09-19 10:35:19,233 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown server with port 37999 now
2019-09-19 10:35:19,233 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown server with port 40090 now
2019-09-19 10:35:19,237 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 48adeddc-e5ef-4407-be4a-4b4625283b71: shutdown server with port 37999 successfully
2019-09-19 10:35:19,239 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 76803391-7007-495d-a164-b2d99168fa35: shutdown server with port 40090 successfully
2019-09-19 10:35:19,244 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 10:35:19,246 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 10:35:19,253 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 10:35:19,257 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 10:35:19,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:19,282 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 10:35:19,285 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 10:35:19,287 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@24fba488{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 10:35:19,288 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34c53688{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 10:35:19,292 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73a6cc79{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:19,293 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ffd4c0d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:19,294 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14efa279{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:19,296 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25974207{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:19,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a0c5be{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:19,298 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17222c11{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:19,301 [ForkJoinPool.commonPool-worker-1] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 10:35:19,301 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 10:35:19,301 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@6cdbe5ec
2019-09-19 10:35:19,301 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@2eda2062
2019-09-19 10:35:19,412 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 10:35:19,604 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 > map
2019-09-19 10:35:19,980 [communication thread] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copy Failure: file:/workdir/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 > map
2019-09-19 10:35:20,196 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 10:35:20,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:21,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:22,276 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:23,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:24,278 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.157.204 | op=SEND_HEARTBEAT {datanodeUUID=76e76cf4-f2cd-49d2-b0c8-f80a724ad893, command=[]} | ret=SUCCESS |  
2019-09-19 10:35:24,302 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 10:35:24,302 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 10:35:24,303 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: close
2019-09-19 10:35:24,303 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-1EC4F5235753
2019-09-19 10:35:24,303 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: close
2019-09-19 10:35:24,303 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1EC4F5235753,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,304 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-B9AE158EE6AB
2019-09-19 10:35:24,304 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,304 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B9AE158EE6AB,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,305 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,305 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,305 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753: set stopIndex = 0
2019-09-19 10:35:24,306 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,306 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-1EC4F5235753 closes. The last applied log index is 0
2019-09-19 10:35:24,307 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB: set stopIndex = 0
2019-09-19 10:35:24,307 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,307 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B9AE158EE6AB closes. The last applied log index is 0
2019-09-19 10:35:24,308 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/7c8723f9-d98f-4efd-b88e-1ec4f5235753 close()
2019-09-19 10:35:24,308 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,311 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-4E97573376BD
2019-09-19 10:35:24,311 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/fe01ae57-f6e8-42f6-8224-b9ae158ee6ab close()
2019-09-19 10:35:24,311 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4E97573376BD,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,313 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-12894775B280
2019-09-19 10:35:24,313 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,314 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12894775B280,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,314 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,314 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,315 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD: set stopIndex = 0
2019-09-19 10:35:24,315 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,315 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-4E97573376BD closes. The last applied log index is 0
2019-09-19 10:35:24,316 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280: set stopIndex = 0
2019-09-19 10:35:24,316 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,316 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-12894775B280 closes. The last applied log index is 0
2019-09-19 10:35:24,316 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/67b720da-db13-440d-8c9d-4e97573376bd close()
2019-09-19 10:35:24,317 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,318 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-2D3F23964752
2019-09-19 10:35:24,318 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/01172124-1782-49a7-a14d-12894775b280 close()
2019-09-19 10:35:24,318 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D3F23964752,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,320 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-48C2E2B316E8
2019-09-19 10:35:24,320 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,320 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-48C2E2B316E8,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,321 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,321 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,321 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752: set stopIndex = 0
2019-09-19 10:35:24,322 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,322 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-2D3F23964752 closes. The last applied log index is 0
2019-09-19 10:35:24,323 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8: set stopIndex = 0
2019-09-19 10:35:24,323 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,323 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-48C2E2B316E8 closes. The last applied log index is 0
2019-09-19 10:35:24,324 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/59fd2853-9936-4a1a-ac3b-2d3f23964752 close()
2019-09-19 10:35:24,324 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,326 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-F7188749185D
2019-09-19 10:35:24,326 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/0c7452fe-eb9f-4031-bc4e-48c2e2b316e8 close()
2019-09-19 10:35:24,326 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F7188749185D,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,327 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-B5CE2A18C4F2
2019-09-19 10:35:24,327 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,328 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5CE2A18C4F2,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,328 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,329 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,329 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D: set stopIndex = 0
2019-09-19 10:35:24,330 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,330 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-F7188749185D closes. The last applied log index is 0
2019-09-19 10:35:24,330 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2: set stopIndex = 0
2019-09-19 10:35:24,331 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,331 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-B5CE2A18C4F2 closes. The last applied log index is 0
2019-09-19 10:35:24,331 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/4d213762-0d29-4cf4-aede-f7188749185d close()
2019-09-19 10:35:24,332 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,333 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-A2E0AAC7F29A
2019-09-19 10:35:24,333 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/dc79d65d-5929-410d-ba27-b5ce2a18c4f2 close()
2019-09-19 10:35:24,333 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2E0AAC7F29A,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,338 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,338 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-6AD04E4CEB4F
2019-09-19 10:35:24,339 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,339 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AD04E4CEB4F,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,340 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A: set stopIndex = 0
2019-09-19 10:35:24,340 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,340 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-A2E0AAC7F29A closes. The last applied log index is 0
2019-09-19 10:35:24,341 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,341 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,341 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F: set stopIndex = 0
2019-09-19 10:35:24,341 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/fb881b0a-d857-4a59-9b5c-a2e0aac7f29a close()
2019-09-19 10:35:24,342 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-6AD04E4CEB4F closes. The last applied log index is 0
2019-09-19 10:35:24,342 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown group-8681B13BA8A4
2019-09-19 10:35:24,343 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,343 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8681B13BA8A4,id=10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64
2019-09-19 10:35:24,343 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown LeaderState
2019-09-19 10:35:24,343 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/e86c1742-a504-4220-9a20-6ad04e4ceb4f close()
2019-09-19 10:35:24,344 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,344 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown group-73304B49F889
2019-09-19 10:35:24,344 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4: set stopIndex = 0
2019-09-19 10:35:24,345 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-73304B49F889,id=4ddad5db-b8db-4ca3-8007-a88ba910d681
2019-09-19 10:35:24,345 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64:group-8681B13BA8A4 closes. The last applied log index is 0
2019-09-19 10:35:24,345 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown LeaderState
2019-09-19 10:35:24,346 [10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,346 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:24,346 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/ratis/26ea26f5-8f23-41d0-bb4c-8681b13ba8a4 close()
2019-09-19 10:35:24,346 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889: set stopIndex = 0
2019-09-19 10:35:24,347 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown server with port 36110 now
2019-09-19 10:35:24,347 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681:group-73304B49F889 closes. The last applied log index is 0
2019-09-19 10:35:24,350 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 10e7d83c-3430-4d8a-b1b5-9bc7ac6c4a64: shutdown server with port 36110 successfully
2019-09-19 10:35:24,350 [4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:24,351 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/ratis/55b266b7-71e0-4e4d-bef5-73304b49f889 close()
2019-09-19 10:35:24,351 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown server with port 37814 now
2019-09-19 10:35:24,354 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 4ddad5db-b8db-4ca3-8007-a88ba910d681: shutdown server with port 37814 successfully
2019-09-19 10:35:24,355 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 10:35:24,359 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 10:35:24,375 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 10:35:24,379 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 10:35:24,390 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 10:35:24,391 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68bd8ca7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 10:35:24,392 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6744707b{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:24,392 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1eb9bf60{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:24,393 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cf01c2e{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:24,394 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 10:35:24,394 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@7ac5b4c
2019-09-19 10:35:24,401 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 10:35:24,404 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6d5c2745{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 10:35:24,405 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@44b29496{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:24,405 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a869a16{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:24,406 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb66650{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:25,278 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 10:35:29,395 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 10:35:29,396 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: close
2019-09-19 10:35:29,396 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-B5A30BEB4B38
2019-09-19 10:35:29,397 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-97156F10C26D
2019-09-19 10:35:29,397 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B5A30BEB4B38,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,397 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-97156F10C26D,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,397 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,397 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,398 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,398 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,398 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38: set stopIndex = 0
2019-09-19 10:35:29,398 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D: set stopIndex = 0
2019-09-19 10:35:29,398 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-B5A30BEB4B38 closes. The last applied log index is 0
2019-09-19 10:35:29,399 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-97156F10C26D closes. The last applied log index is 0
2019-09-19 10:35:29,399 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,399 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,400 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/ec56e9a2-1edb-471f-8a51-97156f10c26d close()
2019-09-19 10:35:29,400 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/3e0b87ae-871a-421e-a844-b5a30beb4b38 close()
2019-09-19 10:35:29,400 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-35A521A53874
2019-09-19 10:35:29,400 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-BCF135CCD209
2019-09-19 10:35:29,400 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-35A521A53874,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,401 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BCF135CCD209,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,401 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,401 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,401 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,401 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,402 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874: set stopIndex = 0
2019-09-19 10:35:29,402 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209: set stopIndex = 0
2019-09-19 10:35:29,402 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-35A521A53874 closes. The last applied log index is 0
2019-09-19 10:35:29,402 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-BCF135CCD209 closes. The last applied log index is 0
2019-09-19 10:35:29,403 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,403 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,403 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/5fb19b71-2cf8-4d1c-889a-35a521a53874 close()
2019-09-19 10:35:29,403 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/f359554c-9351-4dfa-9b8a-bcf135ccd209 close()
2019-09-19 10:35:29,403 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-6B4102A182A8
2019-09-19 10:35:29,404 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(245)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown group-42EA0EB77676
2019-09-19 10:35:29,404 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6B4102A182A8,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,404 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-42EA0EB77676,id=76e76cf4-f2cd-49d2-b0c8-f80a724ad893
2019-09-19 10:35:29,404 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,404 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown LeaderState
2019-09-19 10:35:29,405 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,405 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(202)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-PendingRequests: sendNotLeaderResponses
2019-09-19 10:35:29,405 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8: set stopIndex = 0
2019-09-19 10:35:29,405 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(115)) - StateMachineUpdater:76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676: set stopIndex = 0
2019-09-19 10:35:29,405 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-6B4102A182A8 closes. The last applied log index is 0
2019-09-19 10:35:29,406 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893:group-42EA0EB77676 closes. The last applied log index is 0
2019-09-19 10:35:29,406 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,406 [76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(313)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676 was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-09-19 10:35:29,406 [JUnit] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/7bb7d59d-3a27-4bf5-be00-42ea0eb77676 close()
2019-09-19 10:35:29,406 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(228)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/ratis/8bebb02d-45eb-49b5-94db-6b4102a182a8 close()
2019-09-19 10:35:29,407 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown server with port 33931 now
2019-09-19 10:35:29,408 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - 76e76cf4-f2cd-49d2-b0c8-f80a724ad893: shutdown server with port 33931 successfully
2019-09-19 10:35:29,414 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 10:35:29,415 [refreshUsed-/workdir/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-597b9b2f-9a24-4cf1-8aa9-0c7c9383bc4a/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 10:35:29,443 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 10:35:29,444 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f5dfe69{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 10:35:29,445 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@571a663c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:29,445 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c48b543{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:29,445 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72a8361b{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:29,446 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-09-19 10:35:29,446 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(797)) - Stopping Replication Manager Service.
2019-09-19 10:35:29,447 [JUnit] INFO  container.ReplicationManager (ReplicationManager.java:stop(192)) - Stopping Replication Monitor Thread.
2019-09-19 10:35:29,447 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Lease Manager of the command watchers
2019-09-19 10:35:29,447 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping datanode service RPC server
2019-09-19 10:35:29,447 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-19 10:35:29,447 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42600
2019-09-19 10:35:29,449 [IPC Server listener on 42600] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42600
2019-09-19 10:35:29,450 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 10:35:29,512 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-19 10:35:29,512 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(819)) - Stopping block service RPC server
2019-09-19 10:35:29,513 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-09-19 10:35:29,513 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 44264
2019-09-19 10:35:29,515 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-19 10:35:29,516 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-19 10:35:29,516 [IPC Server listener on 44264] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 44264
2019-09-19 10:35:29,516 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36409
2019-09-19 10:35:29,516 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 10:35:29,518 [IPC Server listener on 36409] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36409
2019-09-19 10:35:29,518 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping Storage Container Manager HTTP server.
2019-09-19 10:35:29,519 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 10:35:29,520 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@733037{/,null,UNAVAILABLE}{/scm}
2019-09-19 10:35:29,521 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@50b8ae8d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 10:35:29,522 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53d1b9b3{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.5.0-SNAPSHOT/hadoop-hdds-server-scm-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 10:35:29,522 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65b3a85a{/logs,file:///workdir/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-09-19 10:35:29,523 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Block Manager Service.
2019-09-19 10:35:29,524 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 10:35:29,524 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 10:35:29,525 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(866)) - Stopping SCM Event Queue.
2019-09-19 10:35:29,532 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JobTracker metrics system...
2019-09-19 10:35:29,541 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JobTracker metrics system stopped.

2019-09-19 08:54:31,121 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:31,218 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:31,221 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:31,239 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @870ms
2019-09-19 08:54:31,339 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-19 08:54:31,340 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-19 08:54:31,340 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-19 08:54:31,340 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-19 08:54:31,340 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-19 08:54:31,341 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-19 08:54:31,353 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:54:31,354 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:54:31,355 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:54:31,573 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@5ffead27
2019-09-19 08:54:31,575 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-19 08:54:31,658 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 08:54:31,660 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-09-19 08:54:31,664 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-19 08:54:31,749 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-19 08:54:31,765 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:31,826 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-19 08:54:31,828 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:31,930 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-19 08:54:32,622 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:32,650 [Socket Reader #1 for port 34080] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34080
2019-09-19 08:54:32,673 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:32,674 [Socket Reader #1 for port 36462] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36462
2019-09-19 08:54:32,681 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:32,682 [Socket Reader #1 for port 34275] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34275
2019-09-19 08:54:32,703 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-19 08:54:32,848 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:32,856 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:32,864 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:32,866 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-19 08:54:32,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:32,867 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:32,895 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:34275
2019-09-19 08:54:32,987 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-19 08:54:33,001 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-19 08:54:33,001 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-19 08:54:33,265 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:34275
2019-09-19 08:54:33,265 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:33,266 [IPC Server listener on 34275] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34275: starting
2019-09-19 08:54:33,268 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:36462
2019-09-19 08:54:33,269 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:36462
2019-09-19 08:54:33,269 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:33,269 [IPC Server listener on 36462] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36462: starting
2019-09-19 08:54:33,271 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:34080
2019-09-19 08:54:33,271 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:34080
2019-09-19 08:54:33,272 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:33,272 [IPC Server listener on 34080] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34080: starting
2019-09-19 08:54:33,276 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33598
2019-09-19 08:54:33,279 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:33,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33aeca0b{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:33,325 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57ac5227{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:54:33,357 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43c67247{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-19 08:54:33,363 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c1fca1e{HTTP/1.1,[http/1.1]}{0.0.0.0:33598}
2019-09-19 08:54:33,363 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2994ms
2019-09-19 08:54:33,364 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:33598
2019-09-19 08:54:33,370 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24f43aa3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:33,373 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:33,498 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:33,499 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:33,500 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-19 08:54:33,500 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: a0feb9ca-d3c1-42ee-8099-bb90e32f92b7
2019-09-19 08:54:33,501 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-19 08:54:33,782 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 08:54:34,248 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:54:34,257 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-19 08:54:34,257 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-19 08:54:34,257 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-19 08:54:34,257 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-19 08:54:34,258 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-19 08:54:34,258 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-19 08:54:34,258 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-19 08:54:34,258 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-19 08:54:34,259 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-19 08:54:34,259 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-19 08:54:34,259 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-19 08:54:34,259 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-19 08:54:34,259 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-19 08:54:34,260 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-19 08:54:34,260 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-19 08:54:34,260 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-19 08:54:34,260 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-19 08:54:34,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-19 08:54:34,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-19 08:54:34,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-19 08:54:34,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-19 08:54:34,261 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-19 08:54:34,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:54:34,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:54:34,262 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:54:34,725 [KeyDeletingService#0] WARN  utils.BackgroundService (BackgroundService.java:lambda$run$0(135)) - Background task fails to execute, retrying in next interval
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.lambda$run$0(BackgroundService.java:129)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.utils.BackgroundService$PeriodicalTask.run(BackgroundService.java:125)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ozone.om.OzoneManager.isLeader(OzoneManager.java:3406)
	at org.apache.hadoop.ozone.om.KeyDeletingService.shouldRun(KeyDeletingService.java:120)
	at org.apache.hadoop.ozone.om.KeyDeletingService.access$100(KeyDeletingService.java:58)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:149)
	at org.apache.hadoop.ozone.om.KeyDeletingService$KeyDeletingTask.call(KeyDeletingService.java:137)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	... 3 more
2019-09-19 08:54:34,992 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:35,022 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(241)) - Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: localhost:9872
2019-09-19 08:54:35,054 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:35,130 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:35,140 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9872 (custom)
2019-09-19 08:54:35,142 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33554432 (custom)
2019-09-19 08:54:35,143 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:35,144 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:35,145 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:35,311 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis] (custom)
2019-09-19 08:54:35,318 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: addNew group-C5BA1605619E:[a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:localhost:9872] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@5496c165[Not completed]
2019-09-19 08:54:35,320 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1398)) - OzoneManager Ratis server initialized at port 9872
2019-09-19 08:54:35,323 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:35,323 [main] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-09-19 08:54:35,336 [pool-22-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: new RaftServerImpl for group-C5BA1605619E:[a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:localhost:9872] with OzoneManagerStateMachine:uninitialized
2019-09-19 08:54:35,338 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:54:35,339 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-09-19 08:54:35,339 [Socket Reader #1 for port 45830] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 45830
2019-09-19 08:54:35,339 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-09-19 08:54:35,340 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:35,341 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:35,342 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:35,355 [pool-22-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E ConfigurationManager, init=-1: [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:localhost:9872], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:35,356 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis] (custom)
2019-09-19 08:54:35,370 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2019-09-19 08:54:35,380 [main] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45830
2019-09-19 08:54:35,380 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-19 08:54:35,380 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(331)) - Starting OzoneManagerRatisServer a0feb9ca-d3c1-42ee-8099-bb90e32f92b7 at port 9872
2019-09-19 08:54:35,388 [pool-22-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:35,426 [pool-22-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2019-09-19 08:54:35,430 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:35,434 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:35,439 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:35,439 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:35,441 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-19 08:54:35,445 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:35,453 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2019-09-19 08:54:35,467 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2019-09-19 08:54:35,468 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 4096 (default)
2019-09-19 08:54:35,474 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-09-19 08:54:35,474 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:35,475 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2019-09-19 08:54:35,475 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:35,477 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:35,477 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:35,478 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:35,488 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2019-09-19 08:54:35,495 [pool-22-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:35,499 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:35,500 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2019-09-19 08:54:35,501 [pool-22-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:35,522 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: start group-C5BA1605619E
2019-09-19 08:54:35,525 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:35,527 [main] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: start FollowerState
2019-09-19 08:54:35,530 [main] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7
2019-09-19 08:54:35,531 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: start RPC server
2019-09-19 08:54:35,643 [main] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
2019-09-19 08:54:35,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:54:35,661 [IPC Server listener on 45830] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 45830: starting
2019-09-19 08:54:35,668 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-19 08:54:35,670 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:35,671 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:35,673 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:35,674 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-19 08:54:35,675 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:35,675 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:35,677 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42040
2019-09-19 08:54:35,678 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:35,680 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74d3b638{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:35,681 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@126f1ba8{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:54:35,687 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1debc91c{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-19 08:54:35,688 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@687e4c93{HTTP/1.1,[http/1.1]}{0.0.0.0:42040}
2019-09-19 08:54:35,689 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5320ms
2019-09-19 08:54:35,690 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:42040
2019-09-19 08:54:35,828 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:35,913 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-j4bt4-3030777008 ip:192.168.34.5
2019-09-19 08:54:35,943 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:35,945 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/containers/hdds to VolumeSet
2019-09-19 08:54:35,949 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-19 08:54:35,974 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@38b8b6c0
2019-09-19 08:54:36,039 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:36,040 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:36,040 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:36,040 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:36,041 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:36,041 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:36,041 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:36,042 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:36,078 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:36,093 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:36,094 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:36,095 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:36,097 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:36,097 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:36,098 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:36,098 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:36,099 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 33607
2019-09-19 08:54:36,099 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:36,101 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f76c2cc{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:36,101 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d7cac8{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:36,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a87026{/,file:///tmp/jetty-0.0.0.0-33607-hddsDatanode-_-any-3933718655933813896.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:36,134 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ef60710{HTTP/1.1,[http/1.1]}{0.0.0.0:33607}
2019-09-19 08:54:36,136 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5768ms
2019-09-19 08:54:36,137 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:33607
Sep 19, 2019 8:54:36 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:36,529 [Thread-94] INFO  impl.FollowerState (FollowerState.java:run(106)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E changes to CANDIDATE, lastRpcTime:1002, electionTimeout:1001ms
2019-09-19 08:54:36,530 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: shutdown FollowerState
2019-09-19 08:54:36,531 [Thread-94] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:36,533 [Thread-94] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: start LeaderElection
2019-09-19 08:54:36,541 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1: begin an election at term 1 for -1: [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:localhost:9872], old=null
2019-09-19 08:54:36,544 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: shutdown LeaderElection
2019-09-19 08:54:36,545 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:36,545 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E change Leader from null to a0feb9ca-d3c1-42ee-8099-bb90e32f92b7 at term 1 for becomeLeader, leader elected after 1114ms
2019-09-19 08:54:36,553 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:36,553 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:36,557 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:36,560 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:36,561 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:36,562 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:36,575 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7: start LeaderState
2019-09-19 08:54:36,631 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Starting segment from index:0
2019-09-19 08:54:36,656 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:group-C5BA1605619E set configuration 0: [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7:localhost:9872], old=null at 0
2019-09-19 08:54:36,858 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2019-09-19 08:54:37,303 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:39289 |  
2019-09-19 08:54:37,304 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@240f350a
2019-09-19 08:54:37,306 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:37,310 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-j4bt4-3030777008 ip:192.168.34.5
2019-09-19 08:54:37,311 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b8c3d6f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:37,319 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:37,320 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/containers/hdds to VolumeSet
2019-09-19 08:54:37,320 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3e856100
2019-09-19 08:54:37,321 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3e856100
2019-09-19 08:54:37,339 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:37,340 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:37,340 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:37,341 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:37,341 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:37,341 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:37,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:37,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:37,343 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:37,344 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:37,346 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:37,347 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:37,349 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:37,349 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:37,349 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:37,350 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:37,351 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44875
2019-09-19 08:54:37,351 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:37,354 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4168f3d9{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:37,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15e8f9b2{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:37,383 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c9d90fc{/,file:///tmp/jetty-0.0.0.0-44875-hddsDatanode-_-any-1000654804857284908.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:37,384 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1511d157{HTTP/1.1,[http/1.1]}{0.0.0.0:44875}
2019-09-19 08:54:37,385 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7016ms
2019-09-19 08:54:37,386 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:44875
Sep 19, 2019 8:54:37 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:37,422 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/meta/datanode.id
2019-09-19 08:54:37,540 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:46441 |  
2019-09-19 08:54:37,540 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@66e341e9
2019-09-19 08:54:37,541 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:54:37,543 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9e49143] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:37,543 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-j4bt4-3030777008 ip:192.168.34.5
2019-09-19 08:54:37,548 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/meta/datanode.id
2019-09-19 08:54:37,555 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:54:37,555 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/containers/hdds to VolumeSet
2019-09-19 08:54:37,556 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@5939e24
2019-09-19 08:54:37,556 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@5939e24
2019-09-19 08:54:37,582 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:54:37,582 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:54:37,583 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:54:37,583 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:54:37,583 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:37,584 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:54:37,584 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:54:37,585 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:37,586 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:54:37,588 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:54:37,589 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:54:37,590 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:54:37,592 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:54:37,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:54:37,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:54:37,593 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:54:37,594 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 35688
2019-09-19 08:54:37,594 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:54:37,596 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63d677f5{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:54:37,597 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2997ddfc{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:54:37,631 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@743c3520{/,file:///tmp/jetty-0.0.0.0-35688-hddsDatanode-_-any-6473506339850878409.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:54:37,631 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6842c101{HTTP/1.1,[http/1.1]}{0.0.0.0:35688}
2019-09-19 08:54:37,633 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7265ms
2019-09-19 08:54:37,634 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:35688
Sep 19, 2019 8:54:37 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:54:37,777 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:34844 |  
2019-09-19 08:54:37,777 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3be3e76c
2019-09-19 08:54:37,779 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:37,780 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a76d553] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:54:37,783 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/meta/datanode.id
2019-09-19 08:54:38,780 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:39,337 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:39,357 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:39,358 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:39,359 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at port 0
2019-09-19 08:54:39,365 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start RPC server
2019-09-19 08:54:39,368 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: GrpcService started, listening on 0.0.0.0/0.0.0.0:37534
2019-09-19 08:54:39,369 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis c7260c3d-02cd-48af-9cc2-4a77ed8dc512 is started using port 37534
2019-09-19 08:54:39,370 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc c7260c3d-02cd-48af-9cc2-4a77ed8dc512 is started using port 36655
2019-09-19 08:54:39,545 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:39,600 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:39,601 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:39,601 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 4ea6a7aa-b50c-49ea-9342-855376dcfeec at port 0
2019-09-19 08:54:39,608 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start RPC server
2019-09-19 08:54:39,610 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: GrpcService started, listening on 0.0.0.0/0.0.0.0:45332
2019-09-19 08:54:39,610 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 4ea6a7aa-b50c-49ea-9342-855376dcfeec is started using port 45332
2019-09-19 08:54:39,611 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 4ea6a7aa-b50c-49ea-9342-855376dcfeec is started using port 36822
2019-09-19 08:54:39,780 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:39,782 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:54:39,831 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:54:39,832 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:54:39,832 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at port 0
2019-09-19 08:54:39,839 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start RPC server
2019-09-19 08:54:39,842 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: GrpcService started, listening on 0.0.0.0/0.0.0.0:33012
2019-09-19 08:54:39,843 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis 76962bf9-71a4-4e2f-8d90-bb34e6e32caa is started using port 33012
2019-09-19 08:54:39,845 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc 76962bf9-71a4-4e2f-8d90-bb34e6e32caa is started using port 43599
2019-09-19 08:54:40,781 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 3 DN Heartbeats.
2019-09-19 08:54:41,424 [IPC Server handler 2 on 34080] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:41,424 [IPC Server handler 2 on 34080] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:41,428 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-19 08:54:41,428 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-19 08:54:41,428 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-19 08:54:41,433 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=REGISTER {datanodeDetails=c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:41,546 [IPC Server handler 1 on 34080] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:41,546 [IPC Server handler 1 on 34080] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:41,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=REGISTER {datanodeDetails=4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:41,881 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 2 of 3 DN Heartbeats.
2019-09-19 08:54:41,884 [IPC Server handler 3 on 34080] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:41,884 [IPC Server handler 3 on 34080] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:54:41,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=REGISTER {datanodeDetails=76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:54:42,232 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-672B1B33A7F0:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-672B1B33A7F0:java.util.concurrent.CompletableFuture@5dc2cb03[Not completed]
2019-09-19 08:54:42,239 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-672B1B33A7F0:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:42,240 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:42,241 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:42,241 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0 does not exist. Creating ...
2019-09-19 08:54:42,286 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:42,357 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0 has been successfully formatted.
2019-09-19 08:54:42,359 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-672B1B33A7F0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:42,359 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:42,359 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:42,359 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:42,359 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:42,360 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:42,361 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:42,362 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:42,362 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:42,362 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:42,362 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:42,362 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:42,363 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-672B1B33A7F0
2019-09-19 08:54:42,363 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:42,363 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:42,363 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-672B1B33A7F0,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:42,415 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 19e6bd64-1bec-428a-9921-672b1b33a7f0, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:42,431 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-6EBA3A9DAF1E:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-6EBA3A9DAF1E:java.util.concurrent.CompletableFuture@4d71b80d[Not completed]
2019-09-19 08:54:42,462 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-6EBA3A9DAF1E:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:42,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:42,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:42,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:42,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:42,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:42,464 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:42,464 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:42,464 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e does not exist. Creating ...
2019-09-19 08:54:42,525 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:42,595 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e has been successfully formatted.
2019-09-19 08:54:42,596 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-6EBA3A9DAF1E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:42,598 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:42,598 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:42,598 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:42,598 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:42,598 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,599 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:42,599 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e
2019-09-19 08:54:42,599 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:42,599 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:42,599 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:42,600 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:42,601 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:42,601 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:42,601 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:42,601 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:42,601 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:42,602 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-6EBA3A9DAF1E
2019-09-19 08:54:42,602 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:42,602 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:42,602 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6EBA3A9DAF1E,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:42,615 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:42,635 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-F60A55EE331F:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-F60A55EE331F:java.util.concurrent.CompletableFuture@53f69f9e[Not completed]
2019-09-19 08:54:42,642 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-F60A55EE331F:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:42,643 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:42,644 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:42,644 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f does not exist. Creating ...
2019-09-19 08:54:42,662 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:42,723 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f has been successfully formatted.
2019-09-19 08:54:42,724 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F60A55EE331F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:42,724 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:42,724 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:42,724 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:42,725 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:42,725 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,725 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:42,725 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f
2019-09-19 08:54:42,726 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:42,726 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:42,726 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,726 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:42,727 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:42,727 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:42,727 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:42,727 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:42,727 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:42,728 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:42,728 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:42,729 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:42,729 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:42,729 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:42,729 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-F60A55EE331F
2019-09-19 08:54:42,730 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:42,730 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:42,730 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F60A55EE331F,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:42,740 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 158606fd-7dbe-4b80-a7da-f60a55ee331f, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:42,755 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-7D1C3EB29265:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-7D1C3EB29265:java.util.concurrent.CompletableFuture@29e1be40[Not completed]
2019-09-19 08:54:42,757 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-7D1C3EB29265:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:42,757 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:42,757 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:42,757 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:42,758 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:42,758 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:42,758 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:42,758 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:42,758 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265 does not exist. Creating ...
2019-09-19 08:54:42,772 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:42,822 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265 has been successfully formatted.
2019-09-19 08:54:42,822 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7D1C3EB29265: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:42,822 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:42,823 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:42,823 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:42,823 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:42,823 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,823 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:42,824 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:42,825 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:42,825 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:42,825 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:42,825 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:42,825 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:42,826 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:42,826 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:42,826 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:42,827 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:42,827 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-7D1C3EB29265
2019-09-19 08:54:42,827 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:42,827 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:42,828 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7D1C3EB29265,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:42,839 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e94739d0-fa85-449e-bb30-7d1c3eb29265, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:42,856 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-97FF21821600:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-97FF21821600:java.util.concurrent.CompletableFuture@677e7e3a[Not completed]
2019-09-19 08:54:42,858 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-97FF21821600:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:42,858 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:42,858 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:42,858 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:42,858 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:42,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:42,859 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:42,859 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:42,859 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600 does not exist. Creating ...
2019-09-19 08:54:42,882 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 3 of 3 DN Heartbeats.
2019-09-19 08:54:42,912 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:42,991 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600 has been successfully formatted.
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-97FF21821600: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:42,992 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:42,993 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600
2019-09-19 08:54:42,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:42,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:42,993 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:42,994 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:42,995 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:42,995 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:42,995 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:42,996 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:42,996 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:42,996 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-97FF21821600
2019-09-19 08:54:42,996 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:42,996 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:42,997 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-97FF21821600,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:43,009 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 90d9ab51-f902-4cb8-abb5-97ff21821600, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,028 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-3692E24E1389:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-3692E24E1389:java.util.concurrent.CompletableFuture@6f43ec64[Not completed]
2019-09-19 08:54:43,030 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-3692E24E1389:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,030 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,030 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,030 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,030 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,031 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,031 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,031 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:43,031 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389 does not exist. Creating ...
2019-09-19 08:54:43,095 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,152 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389 has been successfully formatted.
2019-09-19 08:54:43,153 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-3692E24E1389: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,153 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,153 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,153 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,154 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,154 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,154 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,154 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389
2019-09-19 08:54:43,154 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,155 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,156 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,156 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,156 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-3692E24E1389
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,157 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:43,158 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3692E24E1389,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:43,169 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5091a49e-97f5-4985-9e4e-3692e24e1389, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,190 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-3C05D29BFF02:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-3C05D29BFF02:java.util.concurrent.CompletableFuture@638dc070[Not completed]
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-3C05D29BFF02:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,193 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,194 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:43,194 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02 does not exist. Creating ...
2019-09-19 08:54:43,200 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,203 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02 has been successfully formatted.
2019-09-19 08:54:43,204 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-3C05D29BFF02: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,204 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,204 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,204 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,204 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,205 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,206 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,207 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,207 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,207 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,207 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,207 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-3C05D29BFF02
2019-09-19 08:54:43,208 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,208 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:43,208 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3C05D29BFF02,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:43,210 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:getStorageContainerLocationClient(241)) - Creating StorageContainerLocationProtocol RPC client with address /0.0.0.0:34275
2019-09-19 08:54:43,219 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 700674b0-0b4e-4b5c-88d2-3c05d29bff02, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,229 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-7070054A7CF5:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-7070054A7CF5:java.util.concurrent.CompletableFuture@7a07ea7f[Not completed]
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-7070054A7CF5:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,231 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:43,232 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5 does not exist. Creating ...
2019-09-19 08:54:43,249 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e45db995-cea0-4c07-b07b-346cea9ebd7e, with jenkins1000 as owner.
2019-09-19 08:54:43,256 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,260 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5 has been successfully formatted.
2019-09-19 08:54:43,260 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-7070054A7CF5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,261 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,262 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,263 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,263 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,263 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,263 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,263 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,264 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-7070054A7CF5
2019-09-19 08:54:43,264 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,264 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:43,264 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7070054A7CF5,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:43,272 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b863e025-ab3f-41f3-8d21-7070054a7cf5, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,282 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-A010169428C6:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-A010169428C6:java.util.concurrent.CompletableFuture@37aa0d93[Not completed]
2019-09-19 08:54:43,284 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-A010169428C6:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,284 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,284 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,285 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,285 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:43,286 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6 does not exist. Creating ...
2019-09-19 08:54:43,300 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,309 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6 has been successfully formatted.
2019-09-19 08:54:43,309 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A010169428C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,310 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,311 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6
2019-09-19 08:54:43,311 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,311 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,311 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,311 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,312 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,312 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,312 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,312 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,312 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,313 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,313 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,314 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,314 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-A010169428C6
2019-09-19 08:54:43,314 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,314 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:43,315 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A010169428C6,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:43,324 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: c90b6d6b-baa6-4cec-830c-a010169428c6, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,328 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,337 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-CC9023C95ECE:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-CC9023C95ECE:java.util.concurrent.CompletableFuture@4062d957[Not completed]
2019-09-19 08:54:43,338 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-CC9023C95ECE:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,339 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:43,340 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece does not exist. Creating ...
2019-09-19 08:54:43,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e45db995-cea0-4c07-b07b-346cea9ebd7e, creationTime=1568883283290, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:43,349 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e45db995-cea0-4c07-b07b-346cea9ebd7e} | ret=SUCCESS |  
2019-09-19 08:54:43,354 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e45db995-cea0-4c07-b07b-346cea9ebd7e/ef2af162-5b99-4486-8a7d-44ecbfb945ec, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:43,399 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e45db995-cea0-4c07-b07b-346cea9ebd7e, bucket=ef2af162-5b99-4486-8a7d-44ecbfb945ec, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883283363} | ret=SUCCESS |  
2019-09-19 08:54:43,402 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e45db995-cea0-4c07-b07b-346cea9ebd7e, bucket=ef2af162-5b99-4486-8a7d-44ecbfb945ec} | ret=SUCCESS |  
2019-09-19 08:54:43,460 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece has been successfully formatted.
2019-09-19 08:54:43,461 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CC9023C95ECE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,461 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,461 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,461 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,462 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,463 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,464 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,464 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,464 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,464 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,465 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,465 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-CC9023C95ECE
2019-09-19 08:54:43,465 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,465 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:43,466 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC9023C95ECE,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:43,474 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 0d97e12d-a55a-4eec-9cec-cc9023c95ece, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,485 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: addNew group-CD5B4E32F6D4:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] returns group-CD5B4E32F6D4:java.util.concurrent.CompletableFuture@5339fe5c[Not completed]
2019-09-19 08:54:43,487 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: new RaftServerImpl for group-CD5B4E32F6D4:[4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,487 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,487 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,488 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,488 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,488 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,488 [pool-43-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 ConfigurationManager, init=-1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,488 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis] (custom)
2019-09-19 08:54:43,489 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4 does not exist. Creating ...
2019-09-19 08:54:43,494 [pool-43-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,497 [pool-43-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4 has been successfully formatted.
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-CD5B4E32F6D4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,498 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,499 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,500 [pool-43-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start group-CD5B4E32F6D4
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,501 [pool-43-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start FollowerState
2019-09-19 08:54:43,502 [pool-43-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD5B4E32F6D4,id=4ea6a7aa-b50c-49ea-9342-855376dcfeec
2019-09-19 08:54:43,507 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4, Nodes: 4ea6a7aa-b50c-49ea-9342-855376dcfeec{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,508 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,517 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-43CE35331E94:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-43CE35331E94:java.util.concurrent.CompletableFuture@1c511473[Not completed]
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-43CE35331E94:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,519 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,520 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:43,520 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94 does not exist. Creating ...
2019-09-19 08:54:43,535 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,548 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,582 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94 has been successfully formatted.
2019-09-19 08:54:43,582 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-43CE35331E94: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,583 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,584 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-43CE35331E94
2019-09-19 08:54:43,585 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,586 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:43,586 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-43CE35331E94,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:43,592 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 5c8a1101-fe27-4643-ba00-43ce35331e94, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,593 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,602 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-3F52C160CC60:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-3F52C160CC60:java.util.concurrent.CompletableFuture@71b17a2d[Not completed]
2019-09-19 08:54:43,604 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-3F52C160CC60:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,604 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,605 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,605 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:43,605 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60 does not exist. Creating ...
2019-09-19 08:54:43,611 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,624 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60 has been successfully formatted.
2019-09-19 08:54:43,625 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-3F52C160CC60: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,625 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,625 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,626 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,627 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,628 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,628 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,628 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,629 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,629 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,629 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-3F52C160CC60
2019-09-19 08:54:43,629 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,629 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:43,630 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3F52C160CC60,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:43,636 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d0f22908-9869-437e-80d7-3f52c160cc60, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,637 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,646 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-ADBECBCDA65E:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-ADBECBCDA65E:java.util.concurrent.CompletableFuture@516cd901[Not completed]
2019-09-19 08:54:43,647 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-ADBECBCDA65E:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,647 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,647 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:43,648 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e does not exist. Creating ...
2019-09-19 08:54:43,662 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e has been successfully formatted.
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-ADBECBCDA65E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,675 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,676 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,677 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-ADBECBCDA65E
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,678 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:43,679 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADBECBCDA65E,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:43,685 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 6f646700-fb5a-4671-89bd-adbecbcda65e, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,686 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,695 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-A708CE867638:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-A708CE867638:java.util.concurrent.CompletableFuture@735eea52[Not completed]
2019-09-19 08:54:43,696 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-A708CE867638:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,696 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,696 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:43,697 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638 does not exist. Creating ...
2019-09-19 08:54:43,702 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638 has been successfully formatted.
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A708CE867638: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,714 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,715 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,716 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,717 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,717 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-A708CE867638
2019-09-19 08:54:43,717 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,717 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:43,717 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A708CE867638,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:43,722 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 254219ee-7bcc-4a2b-bcfe-a708ce867638, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,723 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,732 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-0EC97775B8A7:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-0EC97775B8A7:java.util.concurrent.CompletableFuture@7d86767e[Not completed]
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-0EC97775B8A7:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,734 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,735 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,735 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:43,735 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7 does not exist. Creating ...
2019-09-19 08:54:43,740 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,753 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7 has been successfully formatted.
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0EC97775B8A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,754 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,755 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,756 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,757 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,757 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,757 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,757 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,758 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-0EC97775B8A7
2019-09-19 08:54:43,758 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,758 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:43,758 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0EC97775B8A7,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:43,762 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: ce790b40-6a01-45d6-8953-0ec97775b8a7, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,763 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,772 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: addNew group-A85FBC5108F3:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] returns group-A85FBC5108F3:java.util.concurrent.CompletableFuture@51f4fb2e[Not completed]
2019-09-19 08:54:43,774 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: new RaftServerImpl for group-A85FBC5108F3:[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,774 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,774 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,774 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,774 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,775 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,775 [pool-32-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 ConfigurationManager, init=-1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,775 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis] (custom)
2019-09-19 08:54:43,775 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3 does not exist. Creating ...
2019-09-19 08:54:43,809 [pool-32-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,845 [pool-32-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3 has been successfully formatted.
2019-09-19 08:54:43,846 [pool-32-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A85FBC5108F3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,846 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,846 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,846 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,846 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,847 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,848 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,849 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,849 [pool-32-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,849 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start group-A85FBC5108F3
2019-09-19 08:54:43,849 [pool-32-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,849 [pool-32-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start FollowerState
2019-09-19 08:54:43,850 [pool-32-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A85FBC5108F3,id=c7260c3d-02cd-48af-9cc2-4a77ed8dc512
2019-09-19 08:54:43,854 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: b8450d99-dbd8-48e4-9ae7-a85fbc5108f3, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,855 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,855 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,864 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: addNew group-9CC322F78714:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] returns group-9CC322F78714:java.util.concurrent.CompletableFuture@16738bb9[Not completed]
2019-09-19 08:54:43,867 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: new RaftServerImpl for group-9CC322F78714:[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012] with ContainerStateMachine:uninitialized
2019-09-19 08:54:43,868 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:54:43,868 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:54:43,868 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:54:43,868 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:54:43,868 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:54:43,869 [pool-54-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 ConfigurationManager, init=-1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null, confs=<EMPTY_MAP>
2019-09-19 08:54:43,869 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis] (custom)
2019-09-19 08:54:43,869 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714 does not exist. Creating ...
2019-09-19 08:54:43,881 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:43,882 [pool-54-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714/in_use.lock acquired by nodename 31848@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:54:43,896 [pool-54-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714 has been successfully formatted.
2019-09-19 08:54:43,896 [pool-54-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-9CC322F78714: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:54:43,896 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:54:43,896 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714
2019-09-19 08:54:43,897 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:54:43,898 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:54:43,899 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:54:43,899 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:54:43,899 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:54:43,899 [pool-54-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:54:43,900 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:54:43,900 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:54:43,900 [pool-54-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:54:43,900 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(180)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start group-9CC322F78714
2019-09-19 08:54:43,900 [pool-54-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-09-19 08:54:43,901 [pool-54-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start FollowerState
2019-09-19 08:54:43,901 [pool-54-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9CC322F78714,id=76962bf9-71a4-4e2f-8d90-bb34e6e32caa
2019-09-19 08:54:43,905 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 752aebec-df81-4039-b843-9cc322f78714, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-09-19 08:54:43,910 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,910 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,910 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,911 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,912 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,913 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,914 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,914 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,914 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,914 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,914 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,916 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,916 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,916 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,916 [IPC Server handler 0 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,916 [IPC Server handler 0 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,917 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,917 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,917 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,918 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,918 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 1 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,918 [IPC Server handler 0 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,918 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,918 [IPC Server handler 0 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,918 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,918 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,919 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,919 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,923 [IPC Server handler 13 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 45830, call Call#14 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,928 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:43,932 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,932 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,932 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,933 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,933 [IPC Server handler 2 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,933 [IPC Server handler 2 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,933 [IPC Server handler 2 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,934 [IPC Server handler 2 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,934 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,935 [IPC Server handler 18 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 45830, call Call#14 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,937 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,946 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,946 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,946 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,946 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,947 [IPC Server handler 1 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,947 [IPC Server handler 1 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,947 [IPC Server handler 1 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,947 [IPC Server handler 1 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,947 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,948 [IPC Server handler 17 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 45830, call Call#14 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,951 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,954 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,954 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,954 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,954 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,955 [IPC Server handler 3 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,955 [IPC Server handler 3 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,955 [IPC Server handler 3 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,955 [IPC Server handler 3 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,955 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,956 [IPC Server handler 14 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 45830, call Call#14 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,958 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,961 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,962 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,962 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,962 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,962 [IPC Server handler 7 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,962 [IPC Server handler 7 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,963 [IPC Server handler 7 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,963 [IPC Server handler 7 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,963 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,964 [IPC Server handler 16 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 45830, call Call#14 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,965 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,969 [IPC Server handler 4 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,970 [IPC Server handler 4 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,970 [IPC Server handler 4 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,970 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,970 [IPC Server handler 10 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 45830, call Call#14 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,973 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,977 [IPC Server handler 8 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,978 [IPC Server handler 8 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,978 [IPC Server handler 8 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,978 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,978 [IPC Server handler 11 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 45830, call Call#14 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,980 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,983 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,983 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,983 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,983 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,983 [IPC Server handler 5 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,984 [IPC Server handler 5 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,984 [IPC Server handler 5 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,984 [IPC Server handler 5 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,984 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,985 [IPC Server handler 15 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 45830, call Call#14 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,986 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,989 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,990 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,990 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,990 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,990 [IPC Server handler 10 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,990 [IPC Server handler 10 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,991 [IPC Server handler 10 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,992 [IPC Server handler 10 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,992 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,992 [IPC Server handler 9 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 45830, call Call#14 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,994 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:43,997 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,997 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,997 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:43,997 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,998 [IPC Server handler 6 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:43,998 [IPC Server handler 6 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:43,998 [IPC Server handler 6 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:43,998 [IPC Server handler 6 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:43,999 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:43,999 [IPC Server handler 8 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 45830, call Call#14 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,001 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,004 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,004 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,005 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,005 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,005 [IPC Server handler 9 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,005 [IPC Server handler 9 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,006 [IPC Server handler 9 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,006 [IPC Server handler 9 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,006 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,007 [IPC Server handler 7 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 45830, call Call#14 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,009 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:44,017 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ff0c8cca-cec4-4809-9d20-09ec7e137c82, with jenkins1000 as owner.
2019-09-19 08:54:44,049 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82, creationTime=1568883284019, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82} | ret=SUCCESS |  
2019-09-19 08:54:44,053 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ff0c8cca-cec4-4809-9d20-09ec7e137c82/4d67852b-a4da-4550-85e5-75444ab4bab0, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,070 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82, bucket=4d67852b-a4da-4550-85e5-75444ab4bab0, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284059} | ret=SUCCESS |  
2019-09-19 08:54:44,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82, bucket=4d67852b-a4da-4550-85e5-75444ab4bab0} | ret=SUCCESS |  
2019-09-19 08:54:44,087 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82, bucket=4d67852b-a4da-4550-85e5-75444ab4bab0, key=2e15d262-cde2-4172-a1fa-5f55ed94792e, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,134 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff0c8cca-cec4-4809-9d20-09ec7e137c82, bucket=4d67852b-a4da-4550-85e5-75444ab4bab0, key=2e15d262-cde2-4172-a1fa-5f55ed94792e, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,145 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,145 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,145 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,146 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,146 [IPC Server handler 15 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,146 [IPC Server handler 15 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,146 [IPC Server handler 15 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,146 [IPC Server handler 15 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,147 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,147 [IPC Server handler 0 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 45830, call Call#34 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,148 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:44,150 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,150 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,151 [IPC Server handler 18 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,152 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,152 [IPC Server handler 6 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 45830, call Call#34 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,154 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,156 [IPC Server handler 16 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,157 [IPC Server handler 16 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,157 [IPC Server handler 16 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,157 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,158 [IPC Server handler 19 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 45830, call Call#34 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,160 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,161 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,161 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,161 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,161 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,162 [IPC Server handler 17 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,162 [IPC Server handler 17 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,162 [IPC Server handler 17 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,162 [IPC Server handler 17 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,162 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,163 [IPC Server handler 13 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 45830, call Call#34 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,165 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,167 [IPC Server handler 14 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,168 [IPC Server handler 14 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,168 [IPC Server handler 14 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,168 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,169 [IPC Server handler 18 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 18 on 45830, call Call#34 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,171 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,172 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,173 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,173 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,173 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,173 [IPC Server handler 12 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,173 [IPC Server handler 12 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,174 [IPC Server handler 12 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,174 [IPC Server handler 12 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,174 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,175 [IPC Server handler 17 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 45830, call Call#34 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,177 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,179 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,179 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,179 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,180 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,180 [IPC Server handler 11 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,180 [IPC Server handler 11 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,180 [IPC Server handler 11 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,181 [IPC Server handler 11 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,181 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,181 [IPC Server handler 14 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 45830, call Call#34 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,184 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,186 [IPC Server handler 13 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,187 [IPC Server handler 13 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,187 [IPC Server handler 13 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,187 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,188 [IPC Server handler 16 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 45830, call Call#34 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,192 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,194 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,194 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,195 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,195 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,195 [IPC Server handler 19 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,195 [IPC Server handler 19 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,198 [IPC Server handler 19 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,198 [IPC Server handler 19 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,198 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,199 [IPC Server handler 10 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 45830, call Call#34 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,203 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,205 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,205 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,205 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,205 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,206 [IPC Server handler 0 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,206 [IPC Server handler 0 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,206 [IPC Server handler 0 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,206 [IPC Server handler 0 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,206 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,207 [IPC Server handler 11 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 45830, call Call#34 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,211 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:44,212 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:44,213 [IPC Server handler 2 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:44,214 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:44,214 [IPC Server handler 15 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 45830, call Call#34 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:44,215 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:44,216 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUpload(TestOzoneRpcClientAbstract.java:1833)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:44,219 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: bac93485-c350-46df-914c-33aef9e244e1, with jenkins1000 as owner.
2019-09-19 08:54:44,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=bac93485-c350-46df-914c-33aef9e244e1, creationTime=1568883284221, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=bac93485-c350-46df-914c-33aef9e244e1} | ret=SUCCESS |  
2019-09-19 08:54:44,228 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bac93485-c350-46df-914c-33aef9e244e1/e2397043-bd2f-4d30-8dfe-58bd0295d55a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,235 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bac93485-c350-46df-914c-33aef9e244e1, bucket=e2397043-bd2f-4d30-8dfe-58bd0295d55a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284230} | ret=SUCCESS |  
2019-09-19 08:54:44,236 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=bac93485-c350-46df-914c-33aef9e244e1, bucket=e2397043-bd2f-4d30-8dfe-58bd0295d55a} | ret=SUCCESS |  
2019-09-19 08:54:44,243 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=bac93485-c350-46df-914c-33aef9e244e1, bucket=e2397043-bd2f-4d30-8dfe-58bd0295d55a, key=372bb014-c7e5-4bb2-a26e-703133a17aef, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,246 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=bac93485-c350-46df-914c-33aef9e244e1, bucket=e2397043-bd2f-4d30-8dfe-58bd0295d55a, key=372bb014-c7e5-4bb2-a26e-703133a17aef, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,248 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 31f19937-a0bc-4d06-90e1-45bd99509fb5, with jenkins1000 as owner.
2019-09-19 08:54:44,262 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, creationTime=1568883284249, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,263 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5} | ret=SUCCESS |  
2019-09-19 08:54:44,264 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 31f19937-a0bc-4d06-90e1-45bd99509fb5/18a1b18d-7c50-4764-9ed2-ead4e66d9c14, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,269 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284265} | ret=SUCCESS |  
2019-09-19 08:54:44,271 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14} | ret=SUCCESS |  
2019-09-19 08:54:44,273 [IPC Server handler 1 on 36462] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 4830a652-8502-4c9a-9c1b-599b3764a064, Nodes: c7260c3d-02cd-48af-9cc2-4a77ed8dc512{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN]
2019-09-19 08:54:44,286 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,310 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334918836228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,311 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,345 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2019-09-19 08:54:44,429 [Thread-182] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-19 08:54:44,433 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 3 milliseconds for processing 1 containers.
2019-09-19 08:54:44,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,566 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,579 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334918836228 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,626 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334918836228 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:44,664 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334918836228
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,672 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:44,684 [IPC Server handler 3 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:44,686 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:44,688 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:44,701 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | INVALID_KEY_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Key name is empty
	at org.apache.hadoop.ozone.om.request.key.OMKeyRenameRequest.validateAndUpdateCache(OMKeyRenameRequest.java:117)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:44,703 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRenameRequest (OMKeyRenameRequest.java:validateAndUpdateCache(194)) - Rename key failed for volume:31f19937-a0bc-4d06-90e1-45bd99509fb5 bucket:18a1b18d-7c50-4764-9ed2-ead4e66d9c14 fromKey:c9b65e51-518a-4415-af97-fdc9fefddc92 toKey:. Key: c9b65e51-518a-4415-af97-fdc9fefddc92 not found.
2019-09-19 08:54:44,712 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=RENAME_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,714 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=c9b65e51-518a-4415-af97-fdc9fefddc92, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-19 08:54:44,716 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:44,719 [IPC Server handler 7 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:44,720 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:44,720 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=31f19937-a0bc-4d06-90e1-45bd99509fb5, bucket=18a1b18d-7c50-4764-9ed2-ead4e66d9c14, key=958701c5-500f-40a1-9a81-93ec981dcc9a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:44,722 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f7516d0a-64e3-4d2e-a2dd-350c9433b319, with jenkins1000 as owner.
2019-09-19 08:54:44,728 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f7516d0a-64e3-4d2e-a2dd-350c9433b319, creationTime=1568883284723, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,730 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f7516d0a-64e3-4d2e-a2dd-350c9433b319} | ret=SUCCESS |  
2019-09-19 08:54:44,731 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: f7516d0a-64e3-4d2e-a2dd-350c9433b319/3cda3681-a5cb-4928-97fe-3c6e2919a299, with Versioning true and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,746 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=f7516d0a-64e3-4d2e-a2dd-350c9433b319, bucket=3cda3681-a5cb-4928-97fe-3c6e2919a299, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=true, storageType=DISK, creationTime=1568883284732} | ret=SUCCESS |  
2019-09-19 08:54:44,748 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=f7516d0a-64e3-4d2e-a2dd-350c9433b319, bucket=3cda3681-a5cb-4928-97fe-3c6e2919a299} | ret=SUCCESS |  
2019-09-19 08:54:44,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {jenkins1000=username, 55348870-1046-4738-8574-a529e9a9d78f=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:44,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3jenkins1000} | ret=SUCCESS |  
2019-09-19 08:54:44,768 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3jenkins1000, bucket=55348870-1046-4738-8574-a529e9a9d78f} | ret=SUCCESS |  
2019-09-19 08:54:44,769 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1d66c762-8ff3-41b1-8b54-9b85c2852d7a, with jenkins1000 as owner.
2019-09-19 08:54:44,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, creationTime=1568883284770, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:44,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a} | ret=SUCCESS |  
2019-09-19 08:54:44,800 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1d66c762-8ff3-41b1-8b54-9b85c2852d7a/b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:44,806 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883284801} | ret=SUCCESS |  
2019-09-19 08:54:44,807 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6} | ret=SUCCESS |  
2019-09-19 08:54:44,820 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,838 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,853 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334954029063} | ret=SUCCESS |  
2019-09-19 08:54:44,860 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334955143176 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,866 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334955143176 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:44,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,884 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334955143176
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,906 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=19, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:44,910 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:44,928 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=19, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818334958288905} | ret=SUCCESS |  
2019-09-19 08:54:44,934 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334959796234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:44,938 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334959796234 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:44,963 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=1d66c762-8ff3-41b1-8b54-9b85c2852d7a, bucket=b68ee72b-6b71-4ea2-b4cd-6e8b2ecd19f6, key=b8a0f210-0075-48a4-99ab-ae3fa3c358b9, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334959796234
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:44,964 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 06777153-6e88-438b-8c81-8e91a8e85a69, with jenkins1000 as owner.
2019-09-19 08:54:45,008 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=06777153-6e88-438b-8c81-8e91a8e85a69, creationTime=1568883284966, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:45,010 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=06777153-6e88-438b-8c81-8e91a8e85a69} | ret=SUCCESS |  
2019-09-19 08:54:45,010 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 06777153-6e88-438b-8c81-8e91a8e85a69/84f28810-ac27-4c02-a395-4a1d590f369b, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:45,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883285011} | ret=SUCCESS |  
2019-09-19 08:54:45,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b} | ret=SUCCESS |  
2019-09-19 08:54:45,021 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,028 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334967136267
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,054 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334967136267 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,064 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334967136267 bcsId: 0,size=2394]} | ret=SUCCESS |  
2019-09-19 08:54:45,074 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=2394, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334967136267
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2394
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,077 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2fa5696ef-1ed5-4bf0-8883-24f88bc5b18a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334970740749
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,114 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334970740749 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,118 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334970740749 bcsId: 0,size=2399]} | ret=SUCCESS |  
2019-09-19 08:54:45,134 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2fa5696ef-1ed5-4bf0-8883-24f88bc5b18a, dataSize=2399, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334970740749
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2399
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,178 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,205 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,207 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,209 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,228 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,240 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,256 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,258 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,269 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,320 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,326 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334986731535
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,331 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334986731535 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,334 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334986731535 bcsId: 0,size=2367]} | ret=SUCCESS |  
2019-09-19 08:54:45,348 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=2367, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334986731535
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2367
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,349 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=null} | ret=SUCCESS |  
2019-09-19 08:54:45,351 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,408 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/} | ret=SUCCESS |  
2019-09-19 08:54:45,420 [IPC Server handler 19 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-0_96 to index:96
2019-09-19 08:54:45,422 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_0-96
2019-09-19 08:54:45,432 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97
2019-09-19 08:54:45,474 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,476 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,491 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334996955153
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,497 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818334996955153 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:45,501 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818334996955153 bcsId: 0,size=2392]} | ret=SUCCESS |  
2019-09-19 08:54:45,515 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a, dataSize=2392, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818334996955153
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2392
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,517 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/} | ret=SUCCESS |  
2019-09-19 08:54:45,519 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=06777153-6e88-438b-8c81-8e91a8e85a69, bucket=84f28810-ac27-4c02-a395-4a1d590f369b, key=dir1/dir2c078eea2-b8fb-4244-bba5-605cfed8658a} | ret=SUCCESS |  
2019-09-19 08:54:45,520 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5c44697f-b238-452f-a514-7cee054e74a0, with jenkins1000 as owner.
2019-09-19 08:54:45,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5c44697f-b238-452f-a514-7cee054e74a0, creationTime=1568883285521, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:45,526 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5c44697f-b238-452f-a514-7cee054e74a0} | ret=SUCCESS |  
2019-09-19 08:54:45,527 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5c44697f-b238-452f-a514-7cee054e74a0/76a97e5c-499a-455c-9ba0-07aeba5f44c1, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:45,530 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5c44697f-b238-452f-a514-7cee054e74a0, bucket=76a97e5c-499a-455c-9ba0-07aeba5f44c1, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883285528} | ret=SUCCESS |  
2019-09-19 08:54:45,531 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5c44697f-b238-452f-a514-7cee054e74a0, bucket=76a97e5c-499a-455c-9ba0-07aeba5f44c1} | ret=SUCCESS |  
2019-09-19 08:54:45,544 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5c44697f-b238-452f-a514-7cee054e74a0, bucket=76a97e5c-499a-455c-9ba0-07aeba5f44c1} | ret=SUCCESS |  
2019-09-19 08:54:45,546 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=5c44697f-b238-452f-a514-7cee054e74a0, bucket=76a97e5c-499a-455c-9ba0-07aeba5f44c1, key=null} | ret=SUCCESS |  
2019-09-19 08:54:45,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,547 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 74528d34-5d57-4d80-86db-1365d9f95415, with jenkins1000 as owner.
2019-09-19 08:54:45,552 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:45,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=74528d34-5d57-4d80-86db-1365d9f95415, creationTime=1568883285548, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:45,558 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=74528d34-5d57-4d80-86db-1365d9f95415} | ret=SUCCESS |  
2019-09-19 08:54:45,558 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 74528d34-5d57-4d80-86db-1365d9f95415/cc339fbc-8db8-4e88-8be4-bd4e0a334235, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:45,570 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883285559} | ret=SUCCESS |  
2019-09-19 08:54:45,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235} | ret=SUCCESS |  
2019-09-19 08:54:45,574 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:45,586 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235, key=77a1c68d-e4e6-4c13-8f4c-4bd8091d8c87, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818335003377683
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "700674b0-0b4e-4b5c-88d2-3c05d29bff02"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:45,633 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 4ea6a7aa-b50c-49ea-9342-855376dcfeec is not the leader (null). Request must be sent to leader., logIndex=0, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c-1]
2019-09-19 08:54:45,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:46,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,414 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 changes to CANDIDATE, lastRpcTime:5051, electionTimeout:5051ms
2019-09-19 08:54:47,417 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:47,417 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:47,417 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:47,426 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:47,427 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:47,427 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:47,427 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5068ms
2019-09-19 08:54:47,427 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:47,428 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:47,429 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0: Starting segment from index:0
2019-09-19 08:54:47,429 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-672B1B33A7F0 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:47,465 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/19e6bd64-1bec-428a-9921-672b1b33a7f0/current/log_inprogress_0
2019-09-19 08:54:47,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,655 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=18, FAILED org.apache.ratis.protocol.NotLeaderException: Server 4ea6a7aa-b50c-49ea-9342-855376dcfeec is not the leader (null). Request must be sent to leader., logIndex=0, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c-1]
2019-09-19 08:54:47,664 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E changes to CANDIDATE, lastRpcTime:5062, electionTimeout:5062ms
2019-09-19 08:54:47,665 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:47,665 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:47,665 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:47,673 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:47,673 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5076ms
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:47,674 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:47,675 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:47,675 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e: Starting segment from index:0
2019-09-19 08:54:47,675 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-6EBA3A9DAF1E set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:47,714 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e/current/log_inprogress_0
2019-09-19 08:54:47,753 [Thread-190] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F changes to CANDIDATE, lastRpcTime:5023, electionTimeout:5023ms
2019-09-19 08:54:47,754 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:47,754 [Thread-190] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:47,754 [Thread-190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5060ms
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:47,784 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:47,785 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:47,785 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:47,785 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:47,785 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:47,785 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:47,786 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f: Starting segment from index:0
2019-09-19 08:54:47,786 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-F60A55EE331F set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:47,824 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/158606fd-7dbe-4b80-a7da-f60a55ee331f/current/log_inprogress_0
2019-09-19 08:54:47,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:47,986 [Thread-193] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 changes to CANDIDATE, lastRpcTime:5158, electionTimeout:5158ms
2019-09-19 08:54:47,986 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:47,986 [Thread-193] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:47,986 [Thread-193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:48,014 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:48,014 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:48,014 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,015 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5192ms
2019-09-19 08:54:48,015 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,015 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,015 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,015 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,016 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,016 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,016 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:48,016 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265: Starting segment from index:0
2019-09-19 08:54:48,017 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-7D1C3EB29265 set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:48,050 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/e94739d0-fa85-449e-bb30-7d1c3eb29265/current/log_inprogress_0
2019-09-19 08:54:48,183 [Thread-198] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 changes to CANDIDATE, lastRpcTime:5186, electionTimeout:5186ms
2019-09-19 08:54:48,183 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:48,183 [Thread-198] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,183 [Thread-198] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:48,191 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5200ms
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,192 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,193 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,193 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,193 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,193 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:48,193 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600: Starting segment from index:0
2019-09-19 08:54:48,194 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-97FF21821600 set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:48,230 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/90d9ab51-f902-4cb8-abb5-97ff21821600/current/log_inprogress_0
2019-09-19 08:54:48,270 [Thread-202] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 changes to CANDIDATE, lastRpcTime:5112, electionTimeout:5112ms
2019-09-19 08:54:48,270 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:48,270 [Thread-202] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,270 [Thread-202] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:48,272 [Thread-205] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 changes to CANDIDATE, lastRpcTime:5064, electionTimeout:5064ms
2019-09-19 08:54:48,272 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:48,273 [Thread-205] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,273 [Thread-205] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:48,280 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:48,280 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:48,280 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:48,280 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:48,280 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,280 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,280 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5127ms
2019-09-19 08:54:48,280 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5076ms
2019-09-19 08:54:48,281 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,281 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,281 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,281 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,281 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,281 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,281 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,281 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,282 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,282 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,282 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,282 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,282 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:48,282 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:48,283 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389: Starting segment from index:0
2019-09-19 08:54:48,283 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02: Starting segment from index:0
2019-09-19 08:54:48,283 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3692E24E1389 set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:48,283 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-3C05D29BFF02 set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:48,347 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/5091a49e-97f5-4985-9e4e-3692e24e1389/current/log_inprogress_0
2019-09-19 08:54:48,369 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/700674b0-0b4e-4b5c-88d2-3c05d29bff02/current/log_inprogress_0
2019-09-19 08:54:48,414 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 changes to CANDIDATE, lastRpcTime:5099, electionTimeout:5099ms
2019-09-19 08:54:48,414 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:48,414 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,414 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:48,423 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5114ms
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,424 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,425 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,425 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,425 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,425 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:48,425 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6: Starting segment from index:0
2019-09-19 08:54:48,426 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-A010169428C6 set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:48,450 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 changes to CANDIDATE, lastRpcTime:5186, electionTimeout:5177ms
2019-09-19 08:54:48,450 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:48,451 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,451 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:48,455 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/c90b6d6b-baa6-4cec-830c-a010169428c6/current/log_inprogress_0
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5198ms
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,459 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,460 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,460 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:48,460 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5: Starting segment from index:0
2019-09-19 08:54:48,460 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5:LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-7070054A7CF5 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:48,485 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE changes to CANDIDATE, lastRpcTime:5019, electionTimeout:5009ms
2019-09-19 08:54:48,485 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:48,485 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,486 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:48,508 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b863e025-ab3f-41f3-8d21-7070054a7cf5/current/log_inprogress_0
2019-09-19 08:54:48,508 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:48,508 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:48,508 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5047ms
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,509 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:48,510 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece: Starting segment from index:0
2019-09-19 08:54:48,510 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE:LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CC9023C95ECE set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:48,514 [Thread-218] INFO  impl.FollowerState (FollowerState.java:run(106)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 changes to CANDIDATE, lastRpcTime:5012, electionTimeout:5012ms
2019-09-19 08:54:48,514 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown FollowerState
2019-09-19 08:54:48,514 [Thread-218] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,514 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderElection
2019-09-19 08:54:48,546 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:48,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:48,555 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/0d97e12d-a55a-4eec-9cec-cc9023c95ece/current/log_inprogress_0
2019-09-19 08:54:48,555 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12: begin an election at term 1 for -1: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null
2019-09-19 08:54:48,555 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: shutdown LeaderElection
2019-09-19 08:54:48,555 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 change Leader from null to 4ea6a7aa-b50c-49ea-9342-855376dcfeec at term 1 for becomeLeader, leader elected after 5057ms
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,556 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,557 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec: start LeaderState
2019-09-19 08:54:48,557 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4: Starting segment from index:0
2019-09-19 08:54:48,557 [4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4:LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec:group-CD5B4E32F6D4 set configuration 0: [4ea6a7aa-b50c-49ea-9342-855376dcfeec:192.168.34.5:45332], old=null at 0
2019-09-19 08:54:48,615 [4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 4ea6a7aa-b50c-49ea-9342-855376dcfeec-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-1/data/ratis/135cbedd-bd8f-4624-b3aa-cd5b4e32f6d4/current/log_inprogress_0
2019-09-19 08:54:48,668 [Thread-224] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 changes to CANDIDATE, lastRpcTime:5038, electionTimeout:5038ms
2019-09-19 08:54:48,668 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:48,668 [Thread-224] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,668 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:48,709 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E changes to CANDIDATE, lastRpcTime:5030, electionTimeout:5030ms
2019-09-19 08:54:48,709 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:48,709 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,709 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:48,717 [Thread-221] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 changes to CANDIDATE, lastRpcTime:5131, electionTimeout:5131ms
2019-09-19 08:54:48,717 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:48,717 [Thread-221] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,717 [Thread-221] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:48,759 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 changes to CANDIDATE, lastRpcTime:5041, electionTimeout:5041ms
2019-09-19 08:54:48,759 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:48,759 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,759 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:48,831 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:48,831 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:48,831 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,831 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5206ms
2019-09-19 08:54:48,831 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:48,831 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:48,831 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:48,832 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,832 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:48,832 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,832 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:48,832 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:48,833 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,833 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5118ms
2019-09-19 08:54:48,832 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,833 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,834 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,833 [Thread-233] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 changes to CANDIDATE, lastRpcTime:5075, electionTimeout:5075ms
2019-09-19 08:54:48,833 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5157ms
2019-09-19 08:54:48,833 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,834 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,834 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:48,834 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,834 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,835 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,835 [Thread-233] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,835 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,834 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5251ms
2019-09-19 08:54:48,836 [Thread-233] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:48,836 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,835 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,835 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,841 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:48,836 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,836 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,841 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,841 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60: Starting segment from index:0
2019-09-19 08:54:48,841 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,842 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,841 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,842 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60:LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-3F52C160CC60 set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:48,842 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,878 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:48,842 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,878 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:48,879 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:48,878 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,842 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,879 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5125ms
2019-09-19 08:54:48,879 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,880 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:48,880 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:48,880 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,880 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94: Starting segment from index:0
2019-09-19 08:54:48,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:48,880 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:48,880 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:48,881 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638: Starting segment from index:0
2019-09-19 08:54:48,881 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:48,881 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94:LeaderElection15] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-43CE35331E94 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:48,881 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:48,925 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/d0f22908-9869-437e-80d7-3f52c160cc60/current/log_inprogress_0
2019-09-19 08:54:48,925 [Thread-239] INFO  impl.FollowerState (FollowerState.java:run(106)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 changes to CANDIDATE, lastRpcTime:5024, electionTimeout:5019ms
2019-09-19 08:54:48,882 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638:LeaderElection16] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A708CE867638 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:48,881 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e: Starting segment from index:0
2019-09-19 08:54:48,925 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown FollowerState
2019-09-19 08:54:48,927 [Thread-239] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:48,925 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:48,928 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:48,928 [Thread-239] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderElection
2019-09-19 08:54:48,928 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:48,928 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E:LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-ADBECBCDA65E set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:48,971 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/5c8a1101-fe27-4643-ba00-43ce35331e94/current/log_inprogress_0
2019-09-19 08:54:48,971 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/254219ee-7bcc-4a2b-bcfe-a708ce867638/current/log_inprogress_0
2019-09-19 08:54:48,976 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:48,977 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7: Starting segment from index:0
2019-09-19 08:54:48,978 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7:LeaderElection17] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-0EC97775B8A7 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:49,015 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/6f646700-fb5a-4671-89bd-adbecbcda65e/current/log_inprogress_0
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18: begin an election at term 1 for -1: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: shutdown LeaderElection
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 change Leader from null to 76962bf9-71a4-4e2f-8d90-bb34e6e32caa at term 1 for becomeLeader, leader elected after 5119ms
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:49,016 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa: start LeaderState
2019-09-19 08:54:49,017 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714: Starting segment from index:0
2019-09-19 08:54:49,018 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714:LeaderElection18] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa:group-9CC322F78714 set configuration 0: [76962bf9-71a4-4e2f-8d90-bb34e6e32caa:192.168.34.5:33012], old=null at 0
2019-09-19 08:54:49,044 [Thread-236] INFO  impl.FollowerState (FollowerState.java:run(106)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 changes to CANDIDATE, lastRpcTime:5194, electionTimeout:5193ms
2019-09-19 08:54:49,044 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/ce790b40-6a01-45d6-8953-0ec97775b8a7/current/log_inprogress_0
2019-09-19 08:54:49,044 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown FollowerState
2019-09-19 08:54:49,045 [Thread-236] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-09-19 08:54:49,045 [Thread-236] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderElection
2019-09-19 08:54:49,052 [76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - 76962bf9-71a4-4e2f-8d90-bb34e6e32caa-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-2/data/ratis/752aebec-df81-4039-b843-9cc322f78714/current/log_inprogress_0
2019-09-19 08:54:49,054 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19: begin an election at term 1 for -1: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null
2019-09-19 08:54:49,055 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: shutdown LeaderElection
2019-09-19 08:54:49,055 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(171)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-09-19 08:54:49,055 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 change Leader from null to c7260c3d-02cd-48af-9cc2-4a77ed8dc512 at term 1 for becomeLeader, leader elected after 5208ms
2019-09-19 08:54:49,055 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-09-19 08:54:49,055 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-09-19 08:54:49,056 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.write.element-limit = 4096 (default)
2019-09-19 08:54:49,056 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-09-19 08:54:49,056 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-09-19 08:54:49,056 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.element-limit = 65536 (default)
2019-09-19 08:54:49,056 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512: start LeaderState
2019-09-19 08:54:49,057 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(380)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3: Starting segment from index:0
2019-09-19 08:54:49,057 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3:LeaderElection19] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512:group-A85FBC5108F3 set configuration 0: [c7260c3d-02cd-48af-9cc2-4a77ed8dc512:192.168.34.5:37534], old=null at 0
2019-09-19 08:54:49,101 [c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - c7260c3d-02cd-48af-9cc2-4a77ed8dc512-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/datanode-0/data/ratis/b8450d99-dbd8-48e4-9ae7-a85fbc5108f3/current/log_inprogress_0
2019-09-19 08:54:49,547 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:49,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:49,736 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818335003377683 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:49,737 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:49,780 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818335003377683 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:49,792 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=18, SUCCESS, logIndex=1, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c1]
2019-09-19 08:54:49,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:49,909 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102818335003377683 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:49,915 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-633F509E22C3->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=19, SUCCESS, logIndex=3, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c4]
2019-09-19 08:54:49,935 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235, key=77a1c68d-e4e6-4c13-8f4c-4bd8091d8c87, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818335003377683
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "700674b0-0b4e-4b5c-88d2-3c05d29bff02"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:49,938 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:49,940 [IPC Server handler 9 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:49,940 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:49,941 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235, key=77a1c68d-e4e6-4c13-8f4c-4bd8091d8c87, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:50,011 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:50,012 [IPC Server handler 6 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:50,013 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:50,014 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=74528d34-5d57-4d80-86db-1365d9f95415, bucket=cc339fbc-8db8-4e88-8be4-bd4e0a334235, key=77a1c68d-e4e6-4c13-8f4c-4bd8091d8c87, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:50,062 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102818335003377683 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:50,088 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102818335003377683 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:50,091 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: df93ff2f-639c-46f5-923c-dedadc1bde60, with jenkins1000 as owner.
2019-09-19 08:54:50,106 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=df93ff2f-639c-46f5-923c-dedadc1bde60, creationTime=1568883290093, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:50,108 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=df93ff2f-639c-46f5-923c-dedadc1bde60} | ret=SUCCESS |  
2019-09-19 08:54:50,109 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: df93ff2f-639c-46f5-923c-dedadc1bde60/69340584-b131-4cfc-a812-4cc9b5ce0b15, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:50,125 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883290110} | ret=SUCCESS |  
2019-09-19 08:54:50,127 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15} | ret=SUCCESS |  
2019-09-19 08:54:50,128 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,154 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-19 08:54:50,156 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15} | ret=SUCCESS |  
2019-09-19 08:54:50,158 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=df93ff2f-639c-46f5-923c-dedadc1bde60, bucket=69340584-b131-4cfc-a812-4cc9b5ce0b15, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,159 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: b1a0705a-fab8-4085-81fd-5bffeedf6372, with jenkins1000 as owner.
2019-09-19 08:54:50,182 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, creationTime=1568883290160, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:50,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372} | ret=SUCCESS |  
2019-09-19 08:54:50,185 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: b1a0705a-fab8-4085-81fd-5bffeedf6372/2f304215-7e07-4774-9929-2e569e682e3f, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:50,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883290186} | ret=SUCCESS |  
2019-09-19 08:54:50,193 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f} | ret=SUCCESS |  
2019-09-19 08:54:50,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,248 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,251 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,270 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335308972054} | ret=SUCCESS |  
2019-09-19 08:54:50,314 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335309889559 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,319 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335309889559 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,336 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335309889559 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,340 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335309889559 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:50,362 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335309889559 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,369 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335309889559 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:50,382 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335309889559 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,386 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335309889559 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:50,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,413 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335308972054} | ret=SUCCESS |  
2019-09-19 08:54:50,427 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335318933528 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,432 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335318933528 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,458 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335309889559
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335318933528
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:50,475 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,478 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,493 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335323783193} | ret=SUCCESS |  
2019-09-19 08:54:50,508 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335324766234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,512 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335324766234 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,525 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335324766234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,532 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335324766234 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:50,542 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335324766234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,547 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335324766234 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:50,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,558 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335324766234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,563 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335324766234 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:50,567 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,586 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335323783193} | ret=SUCCESS |  
2019-09-19 08:54:50,599 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335330533403 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,602 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335330533403 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,621 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335324766234
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335330533403
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:50,641 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,644 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,659 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335334596636} | ret=SUCCESS |  
2019-09-19 08:54:50,670 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335335645213 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,675 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335335645213 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,684 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335335645213 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,689 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335335645213 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:50,698 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335335645213 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,705 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335335645213 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:50,715 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335335645213 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,718 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335335645213 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:50,721 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:50,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335334596636} | ret=SUCCESS |  
2019-09-19 08:54:50,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,735 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335340691486 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:50,738 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335340691486 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:50,745 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335335645213
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335340691486
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:50,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=b1a0705a-fab8-4085-81fd-5bffeedf6372, bucket=2f304215-7e07-4774-9929-2e569e682e3f, uploadID=3c355658-f6d0-4159-b483-2a77be5d6c72-102818335306219541, partNumberMarker=0, maxParts=3, key=f82266f8-90f5-4cbc-87f7-05f7c00f15b8} | ret=SUCCESS |  
2019-09-19 08:54:50,761 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 0a32a4d0-fd47-4f1d-9f78-d2047b449062, with jenkins1000 as owner.
2019-09-19 08:54:50,782 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, creationTime=1568883290762, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:50,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062} | ret=SUCCESS |  
2019-09-19 08:54:50,786 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0a32a4d0-fd47-4f1d-9f78-d2047b449062/4596449a-1454-414c-8b34-ffface118e48, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:50,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883290787} | ret=SUCCESS |  
2019-09-19 08:54:50,798 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48} | ret=SUCCESS |  
2019-09-19 08:54:50,827 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,829 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,837 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,838 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,879 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,879 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:50,892 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:50,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:51,231 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48} | ret=SUCCESS |  
2019-09-19 08:54:51,233 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 0a32a4d0-fd47-4f1d-9f78-d2047b449062/4596449a-1454-414c-8b34-ffface118e48, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,251 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:remoteUser:r[ACCESS], group:remoteGroup:r[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291235} | ret=SUCCESS |  
2019-09-19 08:54:51,254 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:51,256 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=0a32a4d0-fd47-4f1d-9f78-d2047b449062, bucket=4596449a-1454-414c-8b34-ffface118e48, key=null} | ret=SUCCESS |  
2019-09-19 08:54:51,270 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {69eb9f82-948a-4a9a-b4c2-c86b94f2018a=s3Bucket} | ret=FAILURE | S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 69eb9f82-948a-4a9a-b4c2-c86b94f2018a not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:51,270 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.S3BucketDeleteRequest (S3BucketDeleteRequest.java:validateAndUpdateCache(175)) - S3Bucket Deletion failed for S3Bucket:69eb9f82-948a-4a9a-b4c2-c86b94f2018a
S3_BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: S3Bucket 69eb9f82-948a-4a9a-b4c2-c86b94f2018a not found
	at org.apache.hadoop.ozone.om.request.s3.bucket.S3BucketDeleteRequest.validateAndUpdateCache(S3BucketDeleteRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:51,274 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a7939bb7-422f-486c-b292-b477f12fd9a0, with jenkins1000 as owner.
2019-09-19 08:54:51,281 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a7939bb7-422f-486c-b292-b477f12fd9a0, creationTime=1568883291276, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:51,283 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a7939bb7-422f-486c-b292-b477f12fd9a0} | ret=SUCCESS |  
2019-09-19 08:54:51,284 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: a7939bb7-422f-486c-b292-b477f12fd9a0/cadfc600-ab58-48e4-812e-c641ebb3ba7c, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,302 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=a7939bb7-422f-486c-b292-b477f12fd9a0, bucket=cadfc600-ab58-48e4-812e-c641ebb3ba7c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291285} | ret=SUCCESS |  
2019-09-19 08:54:51,303 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=a7939bb7-422f-486c-b292-b477f12fd9a0, bucket=cadfc600-ab58-48e4-812e-c641ebb3ba7c} | ret=SUCCESS |  
2019-09-19 08:54:51,305 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=a7939bb7-422f-486c-b292-b477f12fd9a0, bucket=cadfc600-ab58-48e4-812e-c641ebb3ba7c, uploadID=random, partNumberMarker=100, maxParts=2, key=93b6c844-ea93-4d62-9341-ad78f8038ea7} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No Such Multipart upload exists for this key.
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listParts(KeyManagerImpl.java:1294)
	at org.apache.hadoop.ozone.om.OzoneManager.listParts(OzoneManager.java:2846) 
2019-09-19 08:54:51,310 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 190ac720-52bf-4838-af63-7c4d2754fea3, with jenkins1000 as owner.
2019-09-19 08:54:51,312 [IPC Server handler 18 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-97_190 to index:190
2019-09-19 08:54:51,313 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_97 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_97-190
2019-09-19 08:54:51,327 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191
2019-09-19 08:54:51,329 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=190ac720-52bf-4838-af63-7c4d2754fea3, creationTime=1568883291311, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:51,330 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=190ac720-52bf-4838-af63-7c4d2754fea3} | ret=SUCCESS |  
2019-09-19 08:54:51,331 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 190ac720-52bf-4838-af63-7c4d2754fea3/a6d60b44-3c80-4ec2-b167-4194ea496412, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=190ac720-52bf-4838-af63-7c4d2754fea3, bucket=a6d60b44-3c80-4ec2-b167-4194ea496412, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291332} | ret=SUCCESS |  
2019-09-19 08:54:51,347 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=190ac720-52bf-4838-af63-7c4d2754fea3, bucket=a6d60b44-3c80-4ec2-b167-4194ea496412} | ret=SUCCESS |  
2019-09-19 08:54:51,353 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=190ac720-52bf-4838-af63-7c4d2754fea3, bucket=a6d60b44-3c80-4ec2-b167-4194ea496412, key=6eec9df0-b4bd-41be-9805-c97f7fb6a096, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,404 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=190ac720-52bf-4838-af63-7c4d2754fea3, bucket=a6d60b44-3c80-4ec2-b167-4194ea496412, key=6eec9df0-b4bd-41be-9805-c97f7fb6a096, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,408 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,408 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,408 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,409 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,409 [IPC Server handler 4 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,409 [IPC Server handler 4 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,410 [IPC Server handler 4 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,410 [IPC Server handler 4 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,411 [IPC Server handler 15 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 45830, call Call#252 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,414 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:51,416 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,416 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,416 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,417 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,417 [IPC Server handler 8 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,417 [IPC Server handler 8 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,417 [IPC Server handler 8 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,418 [IPC Server handler 8 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,418 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,418 [IPC Server handler 16 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 45830, call Call#252 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,421 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,422 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,423 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,423 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,423 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,423 [IPC Server handler 9 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,424 [IPC Server handler 9 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,424 [IPC Server handler 9 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,424 [IPC Server handler 9 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,425 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,425 [IPC Server handler 10 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 45830, call Call#252 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,427 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,429 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,429 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,429 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,429 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,430 [IPC Server handler 6 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,430 [IPC Server handler 6 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,430 [IPC Server handler 6 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,431 [IPC Server handler 6 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,431 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,431 [IPC Server handler 12 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 45830, call Call#252 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,433 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,435 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,435 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,435 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,436 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,436 [IPC Server handler 10 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,436 [IPC Server handler 10 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,436 [IPC Server handler 10 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,436 [IPC Server handler 10 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,436 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,437 [IPC Server handler 4 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 45830, call Call#252 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,439 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,440 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,441 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,441 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,441 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,441 [IPC Server handler 5 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,441 [IPC Server handler 5 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,442 [IPC Server handler 5 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,442 [IPC Server handler 5 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,442 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,443 [IPC Server handler 5 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 45830, call Call#252 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,444 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,446 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,446 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,446 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,447 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,447 [IPC Server handler 15 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,447 [IPC Server handler 15 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,447 [IPC Server handler 15 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,447 [IPC Server handler 15 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,447 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,448 [IPC Server handler 3 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 45830, call Call#252 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,450 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,451 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,452 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,452 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,452 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,452 [IPC Server handler 18 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,453 [IPC Server handler 18 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,453 [IPC Server handler 18 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,453 [IPC Server handler 18 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,454 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,454 [IPC Server handler 6 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 45830, call Call#252 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,456 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,458 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,458 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,458 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,459 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,459 [IPC Server handler 16 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,459 [IPC Server handler 16 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,459 [IPC Server handler 16 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,460 [IPC Server handler 16 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,460 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,461 [IPC Server handler 0 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 45830, call Call#252 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,462 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,464 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,464 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,464 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,465 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,465 [IPC Server handler 17 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,465 [IPC Server handler 17 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,466 [IPC Server handler 17 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,466 [IPC Server handler 17 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,466 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,466 [IPC Server handler 1 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 45830, call Call#252 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,468 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:51,470 [IPC Server handler 14 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,471 [IPC Server handler 14 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:51,471 [IPC Server handler 14 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:51,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:51,471 [IPC Server handler 2 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 45830, call Call#252 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:51,473 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:51,473 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testUploadPartOverrideWithRatis(TestOzoneRpcClientAbstract.java:1773)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:51,475 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-93126, with jenkins1000 as owner.
2019-09-19 08:54:51,488 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-93126, creationTime=1568883291476, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:51,490 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-45772, with jenkins1000 as owner.
2019-09-19 08:54:51,501 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-45772, creationTime=1568883291490, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:51,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-93126} | ret=SUCCESS |  
2019-09-19 08:54:51,504 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-45772} | ret=SUCCESS |  
2019-09-19 08:54:51,505 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-0-49582, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,521 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-0-49582, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291506} | ret=SUCCESS |  
2019-09-19 08:54:51,522 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-0-87687, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,574 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-0-87687, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291523} | ret=SUCCESS |  
2019-09-19 08:54:51,575 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-1-33979, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,618 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-1-33979, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291576} | ret=SUCCESS |  
2019-09-19 08:54:51,619 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-1-47341, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-1-47341, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291619} | ret=SUCCESS |  
2019-09-19 08:54:51,650 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-2-79400, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,670 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-2-79400, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291651} | ret=SUCCESS |  
2019-09-19 08:54:51,671 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-2-42233, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,693 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-2-42233, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291671} | ret=SUCCESS |  
2019-09-19 08:54:51,694 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-3-11383, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,711 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-3-11383, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291695} | ret=SUCCESS |  
2019-09-19 08:54:51,711 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-3-08358, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,737 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-3-08358, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291712} | ret=SUCCESS |  
2019-09-19 08:54:51,738 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-4-36159, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-4-36159, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291739} | ret=SUCCESS |  
2019-09-19 08:54:51,756 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-4-65522, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-4-65522, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291757} | ret=SUCCESS |  
2019-09-19 08:54:51,790 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-5-94609, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,804 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-5-94609, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291791} | ret=SUCCESS |  
2019-09-19 08:54:51,805 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-5-74018, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,828 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-5-74018, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291806} | ret=SUCCESS |  
2019-09-19 08:54:51,828 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-6-14287, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,840 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-6-14287, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291829} | ret=SUCCESS |  
2019-09-19 08:54:51,841 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-6-06075, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:51,893 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-6-06075, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291842} | ret=SUCCESS |  
2019-09-19 08:54:51,894 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-7-84062, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,915 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-7-84062, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291895} | ret=SUCCESS |  
2019-09-19 08:54:51,916 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-7-07253, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,933 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-7-07253, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291917} | ret=SUCCESS |  
2019-09-19 08:54:51,934 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-8-17382, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-8-17382, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291935} | ret=SUCCESS |  
2019-09-19 08:54:51,946 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-8-95443, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-8-95443, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291947} | ret=SUCCESS |  
2019-09-19 08:54:51,957 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-a-9-93222, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,966 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-a-9-93222, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291959} | ret=SUCCESS |  
2019-09-19 08:54:51,967 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-a-9-78264, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,972 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-a-9-78264, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291968} | ret=SUCCESS |  
2019-09-19 08:54:51,973 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-0-49246, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:51,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-0-49246, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291974} | ret=SUCCESS |  
2019-09-19 08:54:51,989 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-0-43515, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,000 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-0-43515, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883291990} | ret=SUCCESS |  
2019-09-19 08:54:52,001 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-1-65774, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,012 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-1-65774, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292003} | ret=SUCCESS |  
2019-09-19 08:54:52,013 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-1-68685, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,022 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-1-68685, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292014} | ret=SUCCESS |  
2019-09-19 08:54:52,022 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-2-61450, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,033 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-2-61450, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292024} | ret=SUCCESS |  
2019-09-19 08:54:52,034 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-2-48199, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,045 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-2-48199, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292035} | ret=SUCCESS |  
2019-09-19 08:54:52,046 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-3-37689, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,054 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-3-37689, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292046} | ret=SUCCESS |  
2019-09-19 08:54:52,055 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-3-97913, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,061 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-3-97913, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292055} | ret=SUCCESS |  
2019-09-19 08:54:52,061 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-4-85758, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,067 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-4-85758, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292062} | ret=SUCCESS |  
2019-09-19 08:54:52,068 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-4-04614, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,075 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-4-04614, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292069} | ret=SUCCESS |  
2019-09-19 08:54:52,076 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-5-58898, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,082 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-5-58898, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292076} | ret=SUCCESS |  
2019-09-19 08:54:52,083 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-5-66801, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,090 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-5-66801, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292083} | ret=SUCCESS |  
2019-09-19 08:54:52,091 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-6-82449, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,098 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-6-82449, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292092} | ret=SUCCESS |  
2019-09-19 08:54:52,099 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-6-77760, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,107 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-6-77760, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292099} | ret=SUCCESS |  
2019-09-19 08:54:52,108 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-7-38316, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-7-38316, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292109} | ret=SUCCESS |  
2019-09-19 08:54:52,116 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-7-22246, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,124 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-7-22246, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292117} | ret=SUCCESS |  
2019-09-19 08:54:52,125 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-8-91825, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,133 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-8-91825, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292125} | ret=SUCCESS |  
2019-09-19 08:54:52,133 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-8-12530, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,141 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-8-12530, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292134} | ret=SUCCESS |  
2019-09-19 08:54:52,142 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-93126/bucket-b-9-45223, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,153 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-93126, bucket=bucket-b-9-45223, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292143} | ret=SUCCESS |  
2019-09-19 08:54:52,154 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-45772/bucket-b-9-62878, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-45772, bucket=bucket-b-9-62878, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292154} | ret=SUCCESS |  
2019-09-19 08:54:52,169 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,173 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=bucket-b-9-45223, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,190 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,195 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=bucket-b-9-45223, prefix=bucket-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,197 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,198 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=bucket-a-9-93222, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,199 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,201 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=bucket-b-9-45223, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,202 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,203 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-a-93126, startKey=bucket-b-9-45223, prefix=bucket-b-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,204 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-45772, startKey=, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-b-45772, startKey=bucket-a-9-78264, prefix=bucket-a-, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:52,206 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 337892a3-ca0b-4313-a814-00d7ea6c7752, with jenkins1000 as owner.
2019-09-19 08:54:52,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=337892a3-ca0b-4313-a814-00d7ea6c7752, creationTime=1568883292207, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=337892a3-ca0b-4313-a814-00d7ea6c7752} | ret=SUCCESS |  
2019-09-19 08:54:52,224 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 337892a3-ca0b-4313-a814-00d7ea6c7752/54e034e7-5647-4842-9d4e-76ad51e1f824, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,230 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=337892a3-ca0b-4313-a814-00d7ea6c7752, bucket=54e034e7-5647-4842-9d4e-76ad51e1f824, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292224} | ret=SUCCESS |  
2019-09-19 08:54:52,232 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=337892a3-ca0b-4313-a814-00d7ea6c7752, bucket=54e034e7-5647-4842-9d4e-76ad51e1f824} | ret=SUCCESS |  
2019-09-19 08:54:52,241 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=337892a3-ca0b-4313-a814-00d7ea6c7752, bucket=54e034e7-5647-4842-9d4e-76ad51e1f824, isVersionEnabled=null, storageType=SSD} | ret=SUCCESS |  
2019-09-19 08:54:52,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=337892a3-ca0b-4313-a814-00d7ea6c7752, bucket=54e034e7-5647-4842-9d4e-76ad51e1f824} | ret=SUCCESS |  
2019-09-19 08:54:52,242 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: bbcc527e-5971-4e19-83e3-4e298ea8c1f7, with jenkins1000 as owner.
2019-09-19 08:54:52,263 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, creationTime=1568883292243, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,265 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7} | ret=SUCCESS |  
2019-09-19 08:54:52,265 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: bbcc527e-5971-4e19-83e3-4e298ea8c1f7/1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,285 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292266} | ret=SUCCESS |  
2019-09-19 08:54:52,287 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a} | ret=SUCCESS |  
2019-09-19 08:54:52,289 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:52,298 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, key=4ab94561-624b-498d-98d2-75f629f8a915, dataSize=303, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335443451937
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,304 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335443451937 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,308 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335443451937 bcsId: 0,size=303]} | ret=SUCCESS |  
2019-09-19 08:54:52,316 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, key=4ab94561-624b-498d-98d2-75f629f8a915, dataSize=303, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335443451937
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 303
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,318 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:52,319 [IPC Server handler 7 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:52,319 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:52,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, key=4ab94561-624b-498d-98d2-75f629f8a915, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:52,330 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335443451937 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,335 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335443451937 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,336 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:52,337 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, key=4ab94561-624b-498d-98d2-75f629f8a915, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:52,338 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:52,339 [IPC Server handler 4 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:52,340 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:52,341 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=bbcc527e-5971-4e19-83e3-4e298ea8c1f7, bucket=1da09c5a-3cf5-480b-8570-e3e0ebe3a06a, key=4ab94561-624b-498d-98d2-75f629f8a915, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:52,346 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: f7680802-c2d0-4c14-94f1-f3c83b830dba, with jenkins1000 as owner.
2019-09-19 08:54:52,372 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, creationTime=1568883292347, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,373 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba} | ret=SUCCESS |  
2019-09-19 08:54:52,374 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: f7680802-c2d0-4c14-94f1-f3c83b830dba/32b483b8-5de0-4786-aba8-10a054cd08b9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,387 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292375} | ret=SUCCESS |  
2019-09-19 08:54:52,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9} | ret=SUCCESS |  
2019-09-19 08:54:52,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:52,410 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335450071075
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,415 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335450071075 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,418 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335450071075 bcsId: 0,size=2396]} | ret=SUCCESS |  
2019-09-19 08:54:52,465 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=2396, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335450071075
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2396
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,468 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:52,484 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF6bb58af2-4ba2-4acf-bd93-d27174d5019a/KEYc50a541d-8a7f-41db-b77e-88112e4a6a79, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335455182885
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,490 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335455182885 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,493 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335455182885 bcsId: 0,size=2400]} | ret=SUCCESS |  
2019-09-19 08:54:52,538 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF6bb58af2-4ba2-4acf-bd93-d27174d5019a/KEYc50a541d-8a7f-41db-b77e-88112e4a6a79, dataSize=2400, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335455182885
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2400
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,545 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/} | ret=SUCCESS |  
2019-09-19 08:54:52,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/} | ret=SUCCESS |  
2019-09-19 08:54:52,630 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/} | ret=SUCCESS |  
2019-09-19 08:54:52,667 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,670 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:52,671 [IPC Server handler 11 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-191_320 to index:320
2019-09-19 08:54:52,672 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_191 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_191-320
2019-09-19 08:54:52,678 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321
2019-09-19 08:54:52,681 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335468421159
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,688 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335468421159 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,691 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335468421159 bcsId: 0,size=2340]} | ret=SUCCESS |  
2019-09-19 08:54:52,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=2340, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335468421159
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2340
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,703 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/} | ret=SUCCESS |  
2019-09-19 08:54:52,704 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5} | ret=SUCCESS |  
2019-09-19 08:54:52,728 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:52,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,737 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=1024, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335472353321
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,743 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335472353321 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:52,746 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335472353321 bcsId: 0,size=2374]} | ret=SUCCESS |  
2019-09-19 08:54:52,761 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5, dataSize=2374, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335472353321
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 2374
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:52,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=prefix, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF6bb58af2-4ba2-4acf-bd93-d27174d5019a/} | ret=SUCCESS |  
2019-09-19 08:54:52,764 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=key, storageType=ozone, volume=f7680802-c2d0-4c14-94f1-f3c83b830dba, bucket=32b483b8-5de0-4786-aba8-10a054cd08b9, key=PF34602864-9370-42cd-844a-ab4e8ea8b4ba/KEY40d3e398-f203-4b0e-bad5-f732b9d6fce5} | ret=SUCCESS |  
2019-09-19 08:54:52,765 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717, with jenkins1000 as owner.
2019-09-19 08:54:52,778 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717, creationTime=1568883292766, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,779 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717} | ret=SUCCESS |  
2019-09-19 08:54:52,779 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717/7a2af80f-031e-4d0a-b1bc-d234314fad2c, with Versioning true and Storage Type set to SSD and Encryption set to false 
2019-09-19 08:54:52,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717, bucket=7a2af80f-031e-4d0a-b1bc-d234314fad2c, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=true, storageType=SSD, creationTime=1568883292780} | ret=SUCCESS |  
2019-09-19 08:54:52,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717, bucket=7a2af80f-031e-4d0a-b1bc-d234314fad2c} | ret=SUCCESS |  
2019-09-19 08:54:52,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=42b79ff4-8b9f-456c-a2a8-a0e0a1a4b717, bucket=7a2af80f-031e-4d0a-b1bc-d234314fad2c, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,800 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a84504e3-820e-408e-b476-b5eaa5d8c0dd, with jenkins1000 as owner.
2019-09-19 08:54:52,808 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd, creationTime=1568883292801, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,809 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd} | ret=SUCCESS |  
2019-09-19 08:54:52,810 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: a84504e3-820e-408e-b476-b5eaa5d8c0dd/328c7e1e-44e5-4f6a-b781-76243b75d87d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:52,822 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd, bucket=328c7e1e-44e5-4f6a-b781-76243b75d87d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883292810} | ret=SUCCESS |  
2019-09-19 08:54:52,823 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd, bucket=328c7e1e-44e5-4f6a-b781-76243b75d87d} | ret=SUCCESS |  
2019-09-19 08:54:52,837 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd, bucket=328c7e1e-44e5-4f6a-b781-76243b75d87d} | ret=SUCCESS |  
2019-09-19 08:54:52,837 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=a84504e3-820e-408e-b476-b5eaa5d8c0dd, bucket=328c7e1e-44e5-4f6a-b781-76243b75d87d, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,838 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 28155733-80eb-43df-abd6-ccae36e957b4, with jenkins1000 as owner.
2019-09-19 08:54:52,876 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=28155733-80eb-43df-abd6-ccae36e957b4, creationTime=1568883292839, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:52,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:52,920 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,922 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,930 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,932 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,948 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,968 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,981 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,982 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,987 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=volume, storageType=ozone, volume=28155733-80eb-43df-abd6-ccae36e957b4, bucket=null, key=null} | ret=SUCCESS |  
2019-09-19 08:54:52,992 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone1=username, ee90ed87-751e-4b23-92a4-43bcd73760bf=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:52,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone1} | ret=SUCCESS |  
2019-09-19 08:54:52,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone1, bucket=ee90ed87-751e-4b23-92a4-43bcd73760bf} | ret=SUCCESS |  
2019-09-19 08:54:53,000 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_S3_BUCKET {ee90ed87-751e-4b23-92a4-43bcd73760bf=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:53,011 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {6950c4fd-8b60-4be3-b536-dc66757d1fbd=s3Bucket, 6e1f1f2b8cdde9c11717322d7e158a89=username} | ret=SUCCESS |  
2019-09-19 08:54:53,013 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s36e1f1f2b8cdde9c11717322d7e158a89} | ret=SUCCESS |  
2019-09-19 08:54:53,014 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s36e1f1f2b8cdde9c11717322d7e158a89, bucket=6950c4fd-8b60-4be3-b536-dc66757d1fbd} | ret=SUCCESS |  
2019-09-19 08:54:53,015 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 25b9b067-15ec-4899-9815-cb21dd623865, with jenkins1000 as owner.
2019-09-19 08:54:53,038 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=25b9b067-15ec-4899-9815-cb21dd623865, creationTime=1568883293016, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:53,040 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=25b9b067-15ec-4899-9815-cb21dd623865} | ret=SUCCESS |  
2019-09-19 08:54:53,040 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 25b9b067-15ec-4899-9815-cb21dd623865/5977621c-4a58-424c-8063-9d05713a7092, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,057 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293041} | ret=SUCCESS |  
2019-09-19 08:54:53,059 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092} | ret=SUCCESS |  
2019-09-19 08:54:53,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, key=fb4d8a68-918e-45c4-bb59-c8c7b389509c, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:53,091 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, key=fb4d8a68-918e-45c4-bb59-c8c7b389509c, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:53,095 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,109 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, key=fb4d8a68-918e-45c4-bb59-c8c7b389509c, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335495421996} | ret=SUCCESS |  
2019-09-19 08:54:53,115 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335496273965 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,119 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335496273965 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:53,160 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, key=fb4d8a68-918e-45c4-bb59-c8c7b389509c, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335496273965
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,176 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=25b9b067-15ec-4899-9815-cb21dd623865, bucket=5977621c-4a58-424c-8063-9d05713a7092, key=fb4d8a68-918e-45c4-bb59-c8c7b389509c, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={3=random}} | ret=FAILURE | MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 25b9b067-15ec-4899-9815-cb21dd623865bucket: 5977621c-4a58-424c-8063-9d05713a7092key: fb4d8a68-918e-45c4-bb59-c8c7b389509c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:53,176 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: fb4d8a68-918e-45c4-bb59-c8c7b389509c in Volume/Bucket 25b9b067-15ec-4899-9815-cb21dd623865/5977621c-4a58-424c-8063-9d05713a7092
MISSING_UPLOAD_PARTS org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 25b9b067-15ec-4899-9815-cb21dd623865bucket: 5977621c-4a58-424c-8063-9d05713a7092key: fb4d8a68-918e-45c4-bb59-c8c7b389509c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:53,177 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 12d6e345-fc27-4677-b588-d4b7c52a9bb2, with jenkins1000 as owner.
2019-09-19 08:54:53,180 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=12d6e345-fc27-4677-b588-d4b7c52a9bb2, creationTime=1568883293178, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:53,181 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=12d6e345-fc27-4677-b588-d4b7c52a9bb2} | ret=SUCCESS |  
2019-09-19 08:54:53,191 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=SET_QUOTA {volume=12d6e345-fc27-4677-b588-d4b7c52a9bb2, quota=100000000} | ret=SUCCESS |  
2019-09-19 08:54:53,193 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=12d6e345-fc27-4677-b588-d4b7c52a9bb2} | ret=SUCCESS |  
2019-09-19 08:54:53,193 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c0233f33-d41b-441f-a356-590c5dfbe81e, with jenkins1000 as owner.
2019-09-19 08:54:53,223 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c0233f33-d41b-441f-a356-590c5dfbe81e, creationTime=1568883293194, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:53,225 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c0233f33-d41b-441f-a356-590c5dfbe81e} | ret=SUCCESS |  
2019-09-19 08:54:53,226 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c0233f33-d41b-441f-a356-590c5dfbe81e/19a066d4-1301-49ec-8110-fd70401f4202, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,229 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c0233f33-d41b-441f-a356-590c5dfbe81e, bucket=19a066d4-1301-49ec-8110-fd70401f4202, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293227} | ret=SUCCESS |  
2019-09-19 08:54:53,230 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c0233f33-d41b-441f-a356-590c5dfbe81e, bucket=19a066d4-1301-49ec-8110-fd70401f4202} | ret=SUCCESS |  
2019-09-19 08:54:53,241 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_BUCKET {volume=c0233f33-d41b-441f-a356-590c5dfbe81e, bucket=19a066d4-1301-49ec-8110-fd70401f4202} | ret=SUCCESS |  
2019-09-19 08:54:53,244 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c0233f33-d41b-441f-a356-590c5dfbe81e, bucket=19a066d4-1301-49ec-8110-fd70401f4202} | ret=FAILURE | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
	at org.apache.hadoop.ozone.om.BucketManagerImpl.getBucketInfo(BucketManagerImpl.java:229)
	at org.apache.hadoop.ozone.om.OzoneManager.getBucketInfo(OzoneManager.java:2147) 
2019-09-19 08:54:53,247 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-a-06006, with jenkins1000 as owner.
2019-09-19 08:54:53,252 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-a-06006, creationTime=1568883293248, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:53,253 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-b-10893, with jenkins1000 as owner.
2019-09-19 08:54:53,265 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-b-10893, creationTime=1568883293254, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:53,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-a-06006} | ret=SUCCESS |  
2019-09-19 08:54:53,268 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-b-10893} | ret=SUCCESS |  
2019-09-19 08:54:53,268 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-06006/buc-a-47350, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,289 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-06006, bucket=buc-a-47350, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293269} | ret=SUCCESS |  
2019-09-19 08:54:53,290 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-a-06006/buc-b-88544, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,355 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-a-06006, bucket=buc-b-88544, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293292} | ret=SUCCESS |  
2019-09-19 08:54:53,356 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-10893/buc-a-47350, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,385 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-10893, bucket=buc-a-47350, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293357} | ret=SUCCESS |  
2019-09-19 08:54:53,386 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-b-10893/buc-b-88544, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:53,389 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-b-10893, bucket=buc-b-88544, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883293387} | ret=SUCCESS |  
2019-09-19 08:54:53,390 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-06006, bucket=buc-a-47350} | ret=SUCCESS |  
2019-09-19 08:54:53,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-a-06006, bucket=buc-b-88544} | ret=SUCCESS |  
2019-09-19 08:54:53,392 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-10893, bucket=buc-a-47350} | ret=SUCCESS |  
2019-09-19 08:54:53,393 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-b-10893, bucket=buc-b-88544} | ret=SUCCESS |  
2019-09-19 08:54:53,396 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,408 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-0-86874, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335516000302
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,414 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335516000302 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,418 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335516000302 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,422 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-0-86874, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335516000302
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,425 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-0-04909, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335517835312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,435 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335517835312 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,438 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335517835312 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,444 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-0-04909, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335517835312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,445 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,449 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-0-09480, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335519211570
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,454 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335519211570 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,457 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335519211570 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,463 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-0-09480, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335519211570
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,465 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,476 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-0-11703, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335520522292
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,482 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335520522292 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,485 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335520522292 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,501 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-0-11703, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335520522292
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,506 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,517 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-1-28461, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335523209270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,522 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335523209270 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,524 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335523209270 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,537 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-1-28461, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335523209270
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,539 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,540 [IPC Server handler 2 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-321_422 to index:422
2019-09-19 08:54:53,540 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_321 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_321-422
2019-09-19 08:54:53,553 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423
2019-09-19 08:54:53,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:53,555 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-1-73646, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335525371960
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,559 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335525371960 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,563 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335525371960 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,587 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-1-73646, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335525371960
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,590 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,599 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-1-69335, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335528648762
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,603 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335528648762 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,615 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335528648762 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-1-69335, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335528648762
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,635 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,649 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-1-54715, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335531663420
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,652 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335531663420 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,654 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335531663420 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,669 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-1-54715, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335531663420
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,672 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,685 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-2-98328, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335534088254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,690 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335534088254 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,692 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335534088254 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,707 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-2-98328, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335534088254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,710 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-2-71152, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335536578624
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,729 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335536578624 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,732 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335536578624 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,736 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:53,747 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-2-71152, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335536578624
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,750 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,763 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-2-35513, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335539200066
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,771 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335539200066 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,773 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335539200066 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,788 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-2-35513, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335539200066
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,790 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,802 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-2-50565, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335541821508
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,806 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335541821508 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,808 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335541821508 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,819 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-2-50565, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335541821508
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,821 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,830 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-3-52876, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335543853126
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,833 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335543853126 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,835 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335543853126 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,849 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-3-52876, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335543853126
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,852 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,865 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-3-25440, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335545884744
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,869 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335545884744 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,872 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335545884744 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:53,885 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-3-25440, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335545884744
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,891 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-3-52090, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335548440650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,908 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335548440650 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,911 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335548440650 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,916 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-3-52090, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335548440650
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,918 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-3-57175, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335550144588
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,935 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335550144588 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,938 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335550144588 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,952 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-3-57175, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335550144588
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,955 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:53,968 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-4-01712, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335552634958
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,972 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335552634958 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:53,975 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335552634958 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:53,988 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-4-01712, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335552634958
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:53,990 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-4-17187, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335554928720
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,005 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335554928720 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,008 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335554928720 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,020 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-4-17187, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335554928720
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,022 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,043 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-4-74032, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335557025874
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,047 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335557025874 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,049 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335557025874 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,060 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-4-74032, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335557025874
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,061 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,071 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-4-84213, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335559581780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,075 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335559581780 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,077 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335559581780 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,093 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-4-84213, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335559581780
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,096 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,109 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-5-21884, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335561875542
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,115 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335561875542 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,118 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335561875542 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,133 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-5-21884, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335561875542
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,135 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,145 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-5-67284, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335564431448
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,151 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335564431448 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,154 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335564431448 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,169 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-5-67284, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335564431448
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,171 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,181 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-5-00315, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335566790746
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,186 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335566790746 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,188 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335566790746 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,190 [IPC Server handler 5 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-423_492 to index:492
2019-09-19 08:54:54,191 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_423 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_423-492
2019-09-19 08:54:54,204 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493
2019-09-19 08:54:54,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-5-00315, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335566790746
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,220 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-5-24033, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335569215580
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,226 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335569215580 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,229 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335569215580 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,242 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-5-24033, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335569215580
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,245 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,258 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-6-73966, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335571640414
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,262 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335571640414 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,264 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335571640414 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,276 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-6-73966, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335571640414
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,278 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,289 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-6-51821, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335573803104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,293 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335573803104 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,295 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335573803104 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,307 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-6-51821, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335573803104
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,309 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,331 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-6-11524, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335575834722
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,334 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335575834722 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,336 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335575834722 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,350 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-6-11524, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335575834722
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,352 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,364 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-6-02633, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335578652772
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,368 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335578652772 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,370 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335578652772 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,384 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-6-02633, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335578652772
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,386 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,399 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-7-61146, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335580880998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,402 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335580880998 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,404 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335580880998 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,418 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-7-61146, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335580880998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,420 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,433 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-7-28639, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335583109224
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,438 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335583109224 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,441 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335583109224 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,454 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-7-28639, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335583109224
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,457 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,460 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-7-48225, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335585534058
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,464 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335585534058 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,466 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335585534058 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,478 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-7-48225, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335585534058
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,481 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,492 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-7-23503, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335587106924
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,496 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335587106924 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,498 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335587106924 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,512 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-7-23503, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335587106924
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,514 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,548 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-8-61673, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335589269614
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,552 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335589269614 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,555 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335589269614 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,556 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:54,573 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-8-61673, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335589269614
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,576 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,585 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-8-76004, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335593267312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,590 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335593267312 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,592 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335593267312 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,600 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-8-76004, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335593267312
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,615 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-8-62021, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335595036786
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,621 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335595036786 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,623 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335595036786 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,645 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-8-62021, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335595036786
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,649 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,662 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-8-56128, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335598116980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,670 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335598116980 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,674 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335598116980 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,680 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-8-56128, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335598116980
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,683 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,694 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-9-80384, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335600279670
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,701 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335600279670 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,704 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335600279670 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,710 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-a-9-80384, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335600279670
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,712 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,715 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-9-19345, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335602245752
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,721 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335602245752 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,725 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335602245752 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:54,759 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-a-9-19345, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335602245752
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,761 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,772 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-9-36433, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335605457018
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,778 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335605457018 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,782 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335605457018 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,789 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-a-9-36433, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335605457018
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,792 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-9-98331, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335607488636
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,803 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335607488636 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,805 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335607488636 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,817 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-a-9-98331, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335607488636
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,820 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,821 [IPC Server handler 15 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-493_562 to index:562
2019-09-19 08:54:54,822 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_493 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_493-562
2019-09-19 08:54:54,861 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563
2019-09-19 08:54:54,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:54,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-0-35375, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335609323646
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,899 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335609323646 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,902 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335609323646 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,908 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-0-35375, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335609323646
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,910 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,936 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-0-78716, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335615221888
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,940 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335615221888 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,942 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335615221888 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,957 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-0-78716, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335615221888
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,959 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,965 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-0-42150, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335618433154
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,970 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335618433154 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,973 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335618433154 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:54,980 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-0-42150, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335618433154
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,982 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:54,987 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-0-17748, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335619940484
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:54,991 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335619940484 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:54,994 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335619940484 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,001 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-0-17748, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335619940484
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,004 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,015 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-1-29746, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335621382278
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,020 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335621382278 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,022 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335621382278 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,027 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-1-29746, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335621382278
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,029 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,032 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-1-18251, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335623020680
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,036 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335623020680 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,040 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335623020680 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,052 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-1-18251, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335623020680
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,055 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,066 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-1-92531, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335624659082
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,069 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335624659082 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,072 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335624659082 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,084 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-1-92531, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335624659082
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,086 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,099 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-1-48827, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335626756236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,106 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335626756236 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,109 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335626756236 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,125 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-1-48827, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335626756236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,128 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,141 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-2-27178, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335629508750
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,145 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335629508750 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,147 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335629508750 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,162 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-2-27178, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335629508750
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,165 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,178 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-2-89017, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335631868048
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,181 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335631868048 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,184 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335631868048 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,199 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-2-89017, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335631868048
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,202 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,220 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-2-21282, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335634292882
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,224 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335634292882 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,227 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335634292882 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,241 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-2-21282, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335634292882
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,243 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,256 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-2-83886, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335637045396
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,260 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335637045396 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,262 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335637045396 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-2-83886, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335637045396
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,269 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,273 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-3-60063, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335638749334
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,276 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335638749334 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,279 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335638749334 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,282 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-3-60063, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335638749334
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,284 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,295 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-3-96015, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335639732376
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,298 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335639732376 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,300 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335639732376 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-3-96015, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335639732376
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,308 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,318 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-3-84491, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335641239706
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,321 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335641239706 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,323 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335641239706 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,356 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-3-84491, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335641239706
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,358 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,374 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-3-07796, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335644582044
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,378 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335644582044 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,381 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335644582044 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,396 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-3-07796, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335644582044
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,398 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,429 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-4-70293, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335647203486
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,432 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335647203486 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,435 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335647203486 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,449 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-4-70293, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335647203486
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,451 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,463 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-4-98337, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335650611360
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,467 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335650611360 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,469 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335650611360 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,471 [IPC Server handler 14 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-563_632 to index:632
2019-09-19 08:54:55,472 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_563 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_563-632
2019-09-19 08:54:55,486 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633
2019-09-19 08:54:55,488 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-4-98337, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335650611360
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,490 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,503 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-4-88328, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335653232802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,506 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335653232802 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,508 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335653232802 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-4-88328, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335653232802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,524 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,536 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-4-42472, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335655395492
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,540 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335655395492 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,542 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335655395492 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,555 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:55,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-4-42472, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335655395492
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,558 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,571 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-5-72880, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335657689254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,575 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335657689254 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,577 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335657689254 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,589 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-5-72880, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335657689254
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,591 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,602 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-5-89189, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335659786408
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,605 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335659786408 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,607 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335659786408 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,620 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-5-89189, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335659786408
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,621 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,633 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-5-45224, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335661818026
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,635 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335661818026 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,637 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335661818026 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,642 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-5-45224, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335661818026
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,644 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,655 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-5-21173, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335663325356
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,658 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335663325356 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,660 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335663325356 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,671 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-5-21173, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335663325356
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,673 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,684 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-6-03191, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335665225902
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,686 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335665225902 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,689 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335665225902 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,703 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-6-03191, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335665225902
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,705 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,734 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:55,749 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-6-70369, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335667323056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,754 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335667323056 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,756 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335667323056 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-6-70369, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335667323056
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,787 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,807 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-6-37726, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335672697010
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,811 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335672697010 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,814 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335672697010 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,819 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-6-37726, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335672697010
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,821 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,833 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-6-72472, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335674925236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,837 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335674925236 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,839 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335674925236 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,847 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-6-72472, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335674925236
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,849 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,860 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-7-77491, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335676760246
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,864 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335676760246 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,866 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335676760246 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,874 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-7-77491, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335676760246
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,876 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,880 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-7-37728, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335678529720
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,880 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:55,884 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335678529720 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,886 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335678529720 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-7-37728, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335678529720
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,906 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-7-23976, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335680495802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,912 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335680495802 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,914 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335680495802 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,926 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-7-23976, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335680495802
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,928 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,939 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-7-74294, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335681937596
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,942 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335681937596 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,944 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335681937596 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,951 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-7-74294, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335681937596
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,953 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:55,965 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-8-44060, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335683575998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,968 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335683575998 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:55,971 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335683575998 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:55,994 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-8-44060, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335683575998
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:55,996 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,007 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-8-41974, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335686394048
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,011 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335686394048 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,013 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335686394048 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,017 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-8-41974, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335686394048
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,019 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,022 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-8-77802, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335687901378
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,025 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335687901378 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,027 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335687901378 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,039 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-8-77802, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335687901378
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,041 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,042 [IPC Server handler 2 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-633_702 to index:702
2019-09-19 08:54:56,042 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_633 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_633-702
2019-09-19 08:54:56,054 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703
2019-09-19 08:54:56,056 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-8-66307, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335689343172
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,065 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335689343172 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,068 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335689343172 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,080 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-8-66307, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335689343172
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,082 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,085 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-9-49322, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335692030150
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,089 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335692030150 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,091 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335692030150 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-a-47350, key=key-b-9-49322, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335692030150
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,097 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,108 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-9-58260, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335693013192
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,111 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335693013192 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,113 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335693013192 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,137 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-a-06006, bucket=buc-b-88544, key=key-b-9-58260, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335693013192
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,138 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,143 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-9-34879, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335695700170
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,147 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335695700170 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,149 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335695700170 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,154 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-a-47350, key=key-b-9-34879, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335695700170
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,156 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,158 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-9-64974, dataSize=10240, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335696879820
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,161 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335696879820 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,164 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335696879820 bcsId: 0,size=10240]} | ret=SUCCESS |  
2019-09-19 08:54:56,169 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=vol-b-10893, bucket=buc-b-88544, key=key-b-9-64974, dataSize=10240, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335696879820
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 10240
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,177 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-a-47350, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,184 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-a-47350, startKey=key-b-9-49322, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,187 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-b-88544, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,189 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-b-88544, startKey=key-b-9-58260, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,192 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-10893, bucket=buc-a-47350, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,194 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-10893, bucket=buc-a-47350, startKey=key-b-9-34879, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,196 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-10893, bucket=buc-b-88544, startKey=, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,199 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-b-10893, bucket=buc-b-88544, startKey=key-b-9-64974, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,200 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-a-47350, startKey=, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-19 08:54:56,201 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-a-47350, startKey=key-a-9-80384, maxKeys=1000, keyPrefix=key-a-} | ret=SUCCESS |  
2019-09-19 08:54:56,203 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-a-47350, startKey=, maxKeys=1000, keyPrefix=key-b-} | ret=SUCCESS |  
2019-09-19 08:54:56,204 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-a-06006, bucket=buc-b-88544, startKey=key-b-9-58260, maxKeys=1000, keyPrefix=key-} | ret=SUCCESS |  
2019-09-19 08:54:56,205 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5a753510-cca6-4ec0-9b08-2f89c27a24ee, with jenkins1000 as owner.
2019-09-19 08:54:56,209 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5a753510-cca6-4ec0-9b08-2f89c27a24ee, creationTime=1568883296206, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:56,210 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5a753510-cca6-4ec0-9b08-2f89c27a24ee} | ret=SUCCESS |  
2019-09-19 08:54:56,210 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5a753510-cca6-4ec0-9b08-2f89c27a24ee/d8c549b8-6731-461c-a8a0-a84baacd30a1, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:56,233 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5a753510-cca6-4ec0-9b08-2f89c27a24ee, bucket=d8c549b8-6731-461c-a8a0-a84baacd30a1, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883296211} | ret=SUCCESS |  
2019-09-19 08:54:56,234 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5a753510-cca6-4ec0-9b08-2f89c27a24ee, bucket=d8c549b8-6731-461c-a8a0-a84baacd30a1} | ret=SUCCESS |  
2019-09-19 08:54:56,234 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 124dd419-0b29-4031-9bb0-286e20533d2e, with jenkins1000 as owner.
2019-09-19 08:54:56,246 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=124dd419-0b29-4031-9bb0-286e20533d2e, creationTime=1568883296235, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:56,246 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=124dd419-0b29-4031-9bb0-286e20533d2e} | ret=SUCCESS |  
2019-09-19 08:54:56,247 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 124dd419-0b29-4031-9bb0-286e20533d2e/977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:56,267 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883296247} | ret=SUCCESS |  
2019-09-19 08:54:56,268 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2} | ret=SUCCESS |  
2019-09-19 08:54:56,280 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,283 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,284 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,287 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335705071823} | ret=SUCCESS |  
2019-09-19 08:54:56,290 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335705268432 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,292 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335705268432 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:56,303 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335705268432
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,333 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,343 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335706579153} | ret=SUCCESS |  
2019-09-19 08:54:56,346 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335708545234 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,348 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335708545234 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:56,360 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335708545234
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,372 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(212)) - MultipartUpload: /124dd419-0b29-4031-9bb0-286e20533d2e/977f1c66-f4ec-4b6b-97f1-bf6344c55ee2/727b74d7-15f4-47c2-a984-a1d3ef31fadcPart number: 1size 4 is less than minimum part size 5242880
2019-09-19 08:54:56,373 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=124dd419-0b29-4031-9bb0-286e20533d2e, bucket=977f1c66-f4ec-4b6b-97f1-bf6344c55ee2, key=727b74d7-15f4-47c2-a984-a1d3ef31fadc, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=/124dd419-0b29-4031-9bb0-286e20533d2e/977f1c66-f4ec-4b6b-97f1-bf6344c55ee2/727b74d7-15f4-47c2-a984-a1d3ef31fadc102818335705071823, 2=/124dd419-0b29-4031-9bb0-286e20533d2e/977f1c66-f4ec-4b6b-97f1-bf6344c55ee2/727b74d7-15f4-47c2-a984-a1d3ef31fadc102818335706579153}} | ret=FAILURE | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 124dd419-0b29-4031-9bb0-286e20533d2ebucket: 977f1c66-f4ec-4b6b-97f1-bf6344c55ee2key: 727b74d7-15f4-47c2-a984-a1d3ef31fadc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:56,374 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: 727b74d7-15f4-47c2-a984-a1d3ef31fadc in Volume/Bucket 124dd419-0b29-4031-9bb0-286e20533d2e/977f1c66-f4ec-4b6b-97f1-bf6344c55ee2
ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: 124dd419-0b29-4031-9bb0-286e20533d2ebucket: 977f1c66-f4ec-4b6b-97f1-bf6344c55ee2key: 727b74d7-15f4-47c2-a984-a1d3ef31fadc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:216)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:56,375 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6da6d0f8-58cd-4f51-a630-3c12851eed3e, with jenkins1000 as owner.
2019-09-19 08:54:56,387 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, creationTime=1568883296376, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:56,387 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e} | ret=SUCCESS |  
2019-09-19 08:54:56,388 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6da6d0f8-58cd-4f51-a630-3c12851eed3e/5afe8180-6fce-42fb-b99a-798ab32ca198, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:56,390 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883296388} | ret=SUCCESS |  
2019-09-19 08:54:56,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198} | ret=SUCCESS |  
2019-09-19 08:54:56,392 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,395 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=d0beb2c7-2aa3-45fe-9f90-94c7f208d284, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102818335712346323
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b863e025-ab3f-41f3-8d21-7070054a7cf5"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,473 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102818335712346323 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,474 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,492 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 3 locID: 102818335712346323 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,498 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-6D60332FF0BD->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-6D60332FF0BD->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-7070054A7CF5, cid=20, SUCCESS, logIndex=1, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c1]
2019-09-19 08:54:56,541 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 3 locID: 102818335712346323 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:56,549 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-6D60332FF0BD->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-6D60332FF0BD->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-7070054A7CF5, cid=21, SUCCESS, logIndex=3, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c4]
2019-09-19 08:54:56,555 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=d0beb2c7-2aa3-45fe-9f90-94c7f208d284, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 3
    localID: 102818335712346323
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b863e025-ab3f-41f3-8d21-7070054a7cf5"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,558 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:56,560 [IPC Server handler 14 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:56,560 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:56,560 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=d0beb2c7-2aa3-45fe-9f90-94c7f208d284, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,563 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:56,564 [IPC Server handler 12 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:56,564 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:56,564 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=d0beb2c7-2aa3-45fe-9f90-94c7f208d284, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,571 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 3 locID: 102818335712346323 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:56,575 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 3 locID: 102818335712346323 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:56,577 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#3} | ret=SUCCESS |  
2019-09-19 08:54:56,578 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=d0beb2c7-2aa3-45fe-9f90-94c7f208d284, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,580 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=3} | ret=SUCCESS |  
2019-09-19 08:54:56,584 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,596 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=51d75689-9069-4627-973b-f340664eaa3b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818335724929237
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "ce790b40-6a01-45d6-8953-0ec97775b8a7"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,667 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818335724929237 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,668 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,671 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 4 locID: 102818335724929237 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,675 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5B674595DBA9->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-5B674595DBA9->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-0EC97775B8A7, cid=22, SUCCESS, logIndex=1, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c2]
2019-09-19 08:54:56,735 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,775 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 4 locID: 102818335724929237 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:56,779 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-5B674595DBA9->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-5B674595DBA9->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-0EC97775B8A7, cid=23, SUCCESS, logIndex=3, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c4]
2019-09-19 08:54:56,793 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=51d75689-9069-4627-973b-f340664eaa3b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 4
    localID: 102818335724929237
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "ce790b40-6a01-45d6-8953-0ec97775b8a7"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,795 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:56,796 [IPC Server handler 0 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:56,796 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:56,797 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=51d75689-9069-4627-973b-f340664eaa3b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,799 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:56,800 [IPC Server handler 2 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:56,800 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:56,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=51d75689-9069-4627-973b-f340664eaa3b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,808 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 4 locID: 102818335724929237 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:56,812 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 4 locID: 102818335724929237 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:56,814 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#4} | ret=SUCCESS |  
2019-09-19 08:54:56,814 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=51d75689-9069-4627-973b-f340664eaa3b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:56,815 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=4} | ret=SUCCESS |  
2019-09-19 08:54:56,816 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:56,823 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=b0279e16-2f79-45e0-ad18-8c2d49bc277a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102818335740133591
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "6f646700-fb5a-4671-89bd-adbecbcda65e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:56,881 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,911 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102818335740133591 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,911 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:56,918 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 5 locID: 102818335740133591 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:56,922 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-8F97C4D9EA11->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-8F97C4D9EA11->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-ADBECBCDA65E, cid=24, SUCCESS, logIndex=1, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c2]
2019-09-19 08:54:56,987 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 5 locID: 102818335740133591 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:56,991 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-8F97C4D9EA11->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-8F97C4D9EA11->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-ADBECBCDA65E, cid=25, SUCCESS, logIndex=3, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c4]
2019-09-19 08:54:57,014 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=b0279e16-2f79-45e0-ad18-8c2d49bc277a, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 5
    localID: 102818335740133591
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "6f646700-fb5a-4671-89bd-adbecbcda65e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,016 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:57,017 [IPC Server handler 8 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,017 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=b0279e16-2f79-45e0-ad18-8c2d49bc277a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,020 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:57,021 [IPC Server handler 9 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,021 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,021 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=b0279e16-2f79-45e0-ad18-8c2d49bc277a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,029 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 5 locID: 102818335740133591 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,033 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 5 locID: 102818335740133591 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,035 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#5} | ret=SUCCESS |  
2019-09-19 08:54:57,035 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=b0279e16-2f79-45e0-ad18-8c2d49bc277a, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,036 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=5} | ret=SUCCESS |  
2019-09-19 08:54:57,038 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,040 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=6af18483-8bd7-4949-bbf8-7951ac1ddbc6, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818335754682585
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5091a49e-97f5-4985-9e4e-3692e24e1389"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,143 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818335754682585 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,143 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:57,154 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818335754682585 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,159 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-3692E24E1389, cid=26, SUCCESS, logIndex=1, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c2]
2019-09-19 08:54:57,285 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102818335754682585 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,289 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-3692E24E1389, cid=27, SUCCESS, logIndex=3, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c4]
2019-09-19 08:54:57,306 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=6af18483-8bd7-4949-bbf8-7951ac1ddbc6, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818335754682585
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5091a49e-97f5-4985-9e4e-3692e24e1389"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,308 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,309 [IPC Server handler 16 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,310 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,310 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=6af18483-8bd7-4949-bbf8-7951ac1ddbc6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,312 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,313 [IPC Server handler 17 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,314 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=6af18483-8bd7-4949-bbf8-7951ac1ddbc6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,326 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102818335754682585 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,330 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102818335754682585 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,331 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,332 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=6af18483-8bd7-4949-bbf8-7951ac1ddbc6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,332 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-19 08:54:57,334 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,353 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=ec417753-f568-4fdb-b357-cb6629351a7d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818335774081243
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,407 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818335774081243 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:57,418 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818335774081243 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,422 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-6EBA3A9DAF1E, cid=28, SUCCESS, logIndex=1, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c2]
2019-09-19 08:54:57,482 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102818335774081243 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,485 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-6EBA3A9DAF1E, cid=29, SUCCESS, logIndex=3, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c4]
2019-09-19 08:54:57,491 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=ec417753-f568-4fdb-b357-cb6629351a7d, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818335774081243
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,493 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,494 [IPC Server handler 12 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,494 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,494 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=ec417753-f568-4fdb-b357-cb6629351a7d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,497 [IPC Server handler 11 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,498 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,498 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=ec417753-f568-4fdb-b357-cb6629351a7d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,505 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102818335774081243 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,508 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102818335774081243 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,509 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,509 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=ec417753-f568-4fdb-b357-cb6629351a7d, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,510 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-19 08:54:57,512 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,524 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=7208182a-46d9-47d3-aa76-40ff391f5554, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818335785681117
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "700674b0-0b4e-4b5c-88d2-3c05d29bff02"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,533 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818335785681117 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,543 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 2 locID: 102818335785681117 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,545 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D0B1336E7826->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-D0B1336E7826->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=30, SUCCESS, logIndex=5, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c5]
2019-09-19 08:54:57,561 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 2 locID: 102818335785681117 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,564 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D0B1336E7826->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-D0B1336E7826->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-3C05D29BFF02, cid=31, SUCCESS, logIndex=7, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c7]
2019-09-19 08:54:57,577 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=7208182a-46d9-47d3-aa76-40ff391f5554, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 2
    localID: 102818335785681117
  }
  blockCommitSequenceId: 7
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "700674b0-0b4e-4b5c-88d2-3c05d29bff02"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,578 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:57,579 [IPC Server handler 0 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,579 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,580 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=7208182a-46d9-47d3-aa76-40ff391f5554, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,581 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:57,582 [IPC Server handler 2 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,582 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=7208182a-46d9-47d3-aa76-40ff391f5554, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,589 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 2 locID: 102818335785681117 bcsId: 7} | ret=SUCCESS |  
2019-09-19 08:54:57,600 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 2 locID: 102818335785681117 bcsId: 7} | ret=SUCCESS |  
2019-09-19 08:54:57,602 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#2} | ret=SUCCESS |  
2019-09-19 08:54:57,602 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=7208182a-46d9-47d3-aa76-40ff391f5554, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,603 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=2} | ret=SUCCESS |  
2019-09-19 08:54:57,605 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,605 [IPC Server handler 15 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-703_774 to index:774
2019-09-19 08:54:57,606 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_703 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_703-774
2019-09-19 08:54:57,614 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775
2019-09-19 08:54:57,616 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=60c80b21-9810-4064-b7b1-976f98405734, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102818335791775967
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5c8a1101-fe27-4643-ba00-43ce35331e94"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,668 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:57,676 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102818335791775967 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,676 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:57,687 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 8 locID: 102818335791775967 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,690 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-455239C75C58->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-455239C75C58->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-43CE35331E94, cid=32, SUCCESS, logIndex=1, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c2]
2019-09-19 08:54:57,796 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 8 locID: 102818335791775967 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,799 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-455239C75C58->c7260c3d-02cd-48af-9cc2-4a77ed8dc512: receive RaftClientReply:client-455239C75C58->c7260c3d-02cd-48af-9cc2-4a77ed8dc512@group-43CE35331E94, cid=33, SUCCESS, logIndex=3, commits[c7260c3d-02cd-48af-9cc2-4a77ed8dc512:c4]
2019-09-19 08:54:57,805 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=60c80b21-9810-4064-b7b1-976f98405734, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 8
    localID: 102818335791775967
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5c8a1101-fe27-4643-ba00-43ce35331e94"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,807 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:57,808 [IPC Server handler 1 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,809 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=60c80b21-9810-4064-b7b1-976f98405734, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,811 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:57,811 [IPC Server handler 3 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,812 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=60c80b21-9810-4064-b7b1-976f98405734, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,820 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 8 locID: 102818335791775967 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,825 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 8 locID: 102818335791775967 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:57,826 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#8} | ret=SUCCESS |  
2019-09-19 08:54:57,827 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=60c80b21-9810-4064-b7b1-976f98405734, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,827 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=8} | ret=SUCCESS |  
2019-09-19 08:54:57,830 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,843 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=e79d57c2-9201-4125-b294-ef836207ca54, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818335806587105
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,848 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818335806587105 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,856 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 7 locID: 102818335806587105 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,857 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 7 locID: 102818335806587105 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,858 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-6EBA3A9DAF1E, cid=34, SUCCESS, logIndex=5, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c6]
2019-09-19 08:54:57,858 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-9B30AD169178->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-6EBA3A9DAF1E, cid=35, SUCCESS, logIndex=6, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c7]
2019-09-19 08:54:57,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=e79d57c2-9201-4125-b294-ef836207ca54, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 7
    localID: 102818335806587105
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "b028dc11-fa8c-4ebe-b6fd-6eba3a9daf1e"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,873 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,874 [IPC Server handler 4 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,875 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,875 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=e79d57c2-9201-4125-b294-ef836207ca54, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,877 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,877 [IPC Server handler 8 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,878 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,878 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=e79d57c2-9201-4125-b294-ef836207ca54, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,881 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 7 locID: 102818335806587105 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:57,883 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 7 locID: 102818335806587105 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:57,884 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#7} | ret=SUCCESS |  
2019-09-19 08:54:57,885 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=e79d57c2-9201-4125-b294-ef836207ca54, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,885 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=7} | ret=SUCCESS |  
2019-09-19 08:54:57,888 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,901 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=a28380b7-d9c8-4283-999b-68d920f4dc46, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818335810388195
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5091a49e-97f5-4985-9e4e-3692e24e1389"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,905 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818335810388195 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,917 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 6 locID: 102818335810388195 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:57,918 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-3692E24E1389, cid=36, SUCCESS, logIndex=5, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c7]
2019-09-19 08:54:57,928 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 6 locID: 102818335810388195 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:57,929 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-58B23098D342->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-3692E24E1389, cid=37, SUCCESS, logIndex=6, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c7]
2019-09-19 08:54:57,943 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=a28380b7-d9c8-4283-999b-68d920f4dc46, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 6
    localID: 102818335810388195
  }
  blockCommitSequenceId: 6
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "5091a49e-97f5-4985-9e4e-3692e24e1389"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:57,944 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,945 [IPC Server handler 6 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,945 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,946 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=a28380b7-d9c8-4283-999b-68d920f4dc46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,947 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,948 [IPC Server handler 10 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:57,948 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:57,948 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=a28380b7-d9c8-4283-999b-68d920f4dc46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,951 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 6 locID: 102818335810388195 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:57,955 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 6 locID: 102818335810388195 bcsId: 6} | ret=SUCCESS |  
2019-09-19 08:54:57,958 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#6} | ret=SUCCESS |  
2019-09-19 08:54:57,959 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=a28380b7-d9c8-4283-999b-68d920f4dc46, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:57,959 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=6} | ret=SUCCESS |  
2019-09-19 08:54:57,961 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:57,965 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=4fcb2b49-9af3-405e-9fa1-366b20c89b76, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102818335815172325
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "c90b6d6b-baa6-4cec-830c-a010169428c6"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,057 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102818335815172325 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,057 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,067 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 9 locID: 102818335815172325 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,072 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D7E9C14E4121->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-D7E9C14E4121->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-A010169428C6, cid=38, SUCCESS, logIndex=1, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c2]
2019-09-19 08:54:58,122 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 9 locID: 102818335815172325 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:58,125 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-D7E9C14E4121->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-D7E9C14E4121->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-A010169428C6, cid=39, SUCCESS, logIndex=3, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c4]
2019-09-19 08:54:58,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=4fcb2b49-9af3-405e-9fa1-366b20c89b76, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 9
    localID: 102818335815172325
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "c90b6d6b-baa6-4cec-830c-a010169428c6"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,140 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:58,141 [IPC Server handler 15 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:58,141 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:58,142 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=4fcb2b49-9af3-405e-9fa1-366b20c89b76, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:58,143 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:58,144 [IPC Server handler 18 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:58,144 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:58,144 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=4fcb2b49-9af3-405e-9fa1-366b20c89b76, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:58,149 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 9 locID: 102818335815172325 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:58,156 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 9 locID: 102818335815172325 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:58,157 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#9} | ret=SUCCESS |  
2019-09-19 08:54:58,158 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=6da6d0f8-58cd-4f51-a630-3c12851eed3e, bucket=5afe8180-6fce-42fb-b99a-798ab32ca198, key=4fcb2b49-9af3-405e-9fa1-366b20c89b76, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:58,158 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=9} | ret=SUCCESS |  
2019-09-19 08:54:58,171 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone100=username, 5902a5b2-d1c0-4406-8ee6-571d9569c9b7=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:58,183 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {ozone100=username, 70f16fd8-dc4d-4f75-8e4e-0c9e5ce29c89=s3Bucket} | ret=SUCCESS |  
2019-09-19 08:54:58,190 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:58,204 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=ozone100, startKey=70f16fd8-dc4d-4f75-8e4e-0c9e5ce29c89, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:58,205 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: dda86643-997b-420d-b325-29bb33cf06cf, with jenkins1000 as owner.
2019-09-19 08:54:58,222 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=dda86643-997b-420d-b325-29bb33cf06cf, creationTime=1568883298206, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,224 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=dda86643-997b-420d-b325-29bb33cf06cf} | ret=SUCCESS |  
2019-09-19 08:54:58,224 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: dda86643-997b-420d-b325-29bb33cf06cf/662236b4-5d56-4c3f-a78a-c28acfebb2f8, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:58,227 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883298225} | ret=SUCCESS |  
2019-09-19 08:54:58,228 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8} | ret=SUCCESS |  
2019-09-19 08:54:58,232 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, key=cf99b7ec-ba8c-4085-9653-ef94b8642774, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,243 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, key=cf99b7ec-ba8c-4085-9653-ef94b8642774, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,245 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,256 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, key=cf99b7ec-ba8c-4085-9653-ef94b8642774, dataSize=4, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335832998120} | ret=SUCCESS |  
2019-09-19 08:54:58,260 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335833784553 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,262 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335833784553 bcsId: 0,size=4]} | ret=SUCCESS |  
2019-09-19 08:54:58,275 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, key=cf99b7ec-ba8c-4085-9653-ef94b8642774, dataSize=4, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335833784553
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,284 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=dda86643-997b-420d-b325-29bb33cf06cf, bucket=662236b4-5d56-4c3f-a78a-c28acfebb2f8, key=cf99b7ec-ba8c-4085-9653-ef94b8642774, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,285 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-19 08:54:58,288 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_S3BUCKETS {volume=randomUser, startKey=, prefix=, maxNumOfBuckets=1000} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume s3randomUser not found.
	at org.apache.hadoop.ozone.om.OmMetadataManagerImpl.listBuckets(OmMetadataManagerImpl.java:593)
	at org.apache.hadoop.ozone.om.BucketManagerImpl.listBuckets(BucketManagerImpl.java:368) 
2019-09-19 08:54:58,289 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 41a45a72-7246-40dd-8c83-ea1fc22ec8e5, with jenkins1000 as owner.
2019-09-19 08:54:58,292 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, creationTime=1568883298290, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,293 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5} | ret=SUCCESS |  
2019-09-19 08:54:58,293 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 41a45a72-7246-40dd-8c83-ea1fc22ec8e5/60974020-afcb-473c-8ca9-0e9471278007, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:58,303 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883298293} | ret=SUCCESS |  
2019-09-19 08:54:58,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007} | ret=SUCCESS |  
2019-09-19 08:54:58,308 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,316 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335838241003} | ret=SUCCESS |  
2019-09-19 08:54:58,341 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335838503148 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,346 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335838503148 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,355 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335838503148 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,359 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335838503148 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:58,367 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335838503148 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,375 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335838503148 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:58,383 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335838503148 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,387 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335838503148 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:58,389 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,401 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335838241003} | ret=SUCCESS |  
2019-09-19 08:54:58,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,410 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335843221741 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,412 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335843221741 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,426 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335838503148
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335843221741
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,443 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,445 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,457 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335845974254} | ret=SUCCESS |  
2019-09-19 08:54:58,467 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335846891759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,469 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335846891759 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,476 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335846891759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,478 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335846891759 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:58,484 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335846891759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,487 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335846891759 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:58,496 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335846891759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,500 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335846891759 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:58,501 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,513 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335845974254} | ret=SUCCESS |  
2019-09-19 08:54:58,523 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335850561776 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,525 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335850561776 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,539 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335846891759
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335850561776
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,556 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,558 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,578 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335853379825} | ret=SUCCESS |  
2019-09-19 08:54:58,586 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335854297330 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,589 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335854297330 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,596 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335854297330 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,600 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335854297330 bcsId: 0,size=2097152]} | ret=SUCCESS |  
2019-09-19 08:54:58,607 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335854297330 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,609 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335854297330 bcsId: 0,size=3145728]} | ret=SUCCESS |  
2019-09-19 08:54:58,616 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335854297330 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,623 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335854297330 bcsId: 0,size=4194304]} | ret=SUCCESS |  
2019-09-19 08:54:58,624 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,647 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_BLOCK {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[], clientID=102818335853379825} | ret=SUCCESS |  
2019-09-19 08:54:58,655 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335858622707 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,658 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335858622707 bcsId: 0,size=1048576]} | ret=SUCCESS |  
2019-09-19 08:54:58,663 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_MULTIPART_UPLOAD_PARTKEY {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, key=f961916c-0fbf-411c-97da-fb940a46dd17, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335854297330
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
, blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335858622707
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 1048576
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,664 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, uploadID=afdb18fc-fa50-4854-8bb4-b811b926954c-102818335837716714, partNumberMarker=0, maxParts=2, key=f961916c-0fbf-411c-97da-fb940a46dd17} | ret=SUCCESS |  
2019-09-19 08:54:58,665 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_MULTIPART_UPLOAD_PARTS {volume=41a45a72-7246-40dd-8c83-ea1fc22ec8e5, bucket=60974020-afcb-473c-8ca9-0e9471278007, uploadID=afdb18fc-fa50-4854-8bb4-b811b926954c-102818335837716714, partNumberMarker=2, maxParts=2, key=f961916c-0fbf-411c-97da-fb940a46dd17} | ret=SUCCESS |  
2019-09-19 08:54:58,666 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-91376, with jenkins1000 as owner.
2019-09-19 08:54:58,676 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,676 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-91376, creationTime=1568883298666, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,677 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-91376} | ret=SUCCESS |  
2019-09-19 08:54:58,678 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-91376, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:58,679 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_BUCKETS {volume=vol-91376, startKey=, prefix=, maxNumOfBuckets=1000} | ret=SUCCESS |  
2019-09-19 08:54:58,679 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 6b32cc8a-e848-440d-bbc6-5d3cb6e5a064, with jenkins1000 as owner.
2019-09-19 08:54:58,690 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=6b32cc8a-e848-440d-bbc6-5d3cb6e5a064, creationTime=1568883298680, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,691 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=6b32cc8a-e848-440d-bbc6-5d3cb6e5a064} | ret=SUCCESS |  
2019-09-19 08:54:58,691 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 6b32cc8a-e848-440d-bbc6-5d3cb6e5a064/aff0a900-b18e-4f8f-9da9-15027016afc8, with Versioning false and Storage Type set to SSD and Encryption set to false 
2019-09-19 08:54:58,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=6b32cc8a-e848-440d-bbc6-5d3cb6e5a064, bucket=aff0a900-b18e-4f8f-9da9-15027016afc8, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=SSD, creationTime=1568883298691} | ret=SUCCESS |  
2019-09-19 08:54:58,702 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=6b32cc8a-e848-440d-bbc6-5d3cb6e5a064, bucket=aff0a900-b18e-4f8f-9da9-15027016afc8} | ret=SUCCESS |  
2019-09-19 08:54:58,703 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 38c2adae-e9a0-4efc-8bbf-e14fc34450b4, with jenkins1000 as owner.
2019-09-19 08:54:58,713 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=38c2adae-e9a0-4efc-8bbf-e14fc34450b4, creationTime=1568883298703, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,714 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=38c2adae-e9a0-4efc-8bbf-e14fc34450b4} | ret=SUCCESS |  
2019-09-19 08:54:58,714 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 38c2adae-e9a0-4efc-8bbf-e14fc34450b4/54b646ce-4a36-49e3-8c05-a8d1e36c7ec2, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:58,725 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=38c2adae-e9a0-4efc-8bbf-e14fc34450b4, bucket=54b646ce-4a36-49e3-8c05-a8d1e36c7ec2, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS], user:test:a[ACCESS], user:test1:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883298715} | ret=SUCCESS |  
2019-09-19 08:54:58,737 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38c2adae-e9a0-4efc-8bbf-e14fc34450b4, bucket=54b646ce-4a36-49e3-8c05-a8d1e36c7ec2, key=null} | ret=SUCCESS |  
2019-09-19 08:54:58,738 [IPC Server handler 12 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-775_850 to index:850
2019-09-19 08:54:58,738 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_775 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_775-850
2019-09-19 08:54:58,753 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851
2019-09-19 08:54:58,755 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=GET_ACL {resourceType=bucket, storageType=ozone, volume=38c2adae-e9a0-4efc-8bbf-e14fc34450b4, bucket=54b646ce-4a36-49e3-8c05-a8d1e36c7ec2, key=null} | ret=SUCCESS |  
2019-09-19 08:54:58,756 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c5e03a98-5f4e-4366-991e-ca8675591a50, with jenkins1000 as owner.
2019-09-19 08:54:58,767 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c5e03a98-5f4e-4366-991e-ca8675591a50, creationTime=1568883298756, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,828 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c5e03a98-5f4e-4366-991e-ca8675591a50} | ret=SUCCESS |  
2019-09-19 08:54:58,837 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c5e03a98-5f4e-4366-991e-ca8675591a50/484df431-7eec-4275-8002-67cb14323218, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:58,859 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883298841} | ret=SUCCESS |  
2019-09-19 08:54:58,866 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218} | ret=SUCCESS |  
2019-09-19 08:54:58,868 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:58,894 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, key=80043839-f784-4be1-9f16-9311b74cc631, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335874613492
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,898 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335874613492 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:58,900 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335874613492 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:58,909 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, key=80043839-f784-4be1-9f16-9311b74cc631, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335874613492
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:58,911 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:58,912 [IPC Server handler 6 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:58,912 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:58,912 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, key=80043839-f784-4be1-9f16-9311b74cc631, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:58,921 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_KEY {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, key=80043839-f784-4be1-9f16-9311b74cc631, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:58,923 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=c5e03a98-5f4e-4366-991e-ca8675591a50, bucket=484df431-7eec-4275-8002-67cb14323218, key=80043839-f784-4be1-9f16-9311b74cc631, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
	at org.apache.hadoop.ozone.om.KeyManagerImpl.lookupKey(KeyManagerImpl.java:673)
	at org.apache.hadoop.ozone.om.OzoneManager.lookupKey(OzoneManager.java:2320) 
2019-09-19 08:54:58,925 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3976f809-d10d-4b18-9f34-bd274d32d24a, with jenkins1000 as owner.
2019-09-19 08:54:58,937 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3976f809-d10d-4b18-9f34-bd274d32d24a, creationTime=1568883298926, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,938 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3976f809-d10d-4b18-9f34-bd274d32d24a} | ret=SUCCESS |  
2019-09-19 08:54:58,955 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=DELETE_VOLUME {volume=3976f809-d10d-4b18-9f34-bd274d32d24a} | ret=SUCCESS |  
2019-09-19 08:54:58,956 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3976f809-d10d-4b18-9f34-bd274d32d24a} | ret=FAILURE | VOLUME_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Volume 3976f809-d10d-4b18-9f34-bd274d32d24a is not found
	at org.apache.hadoop.ozone.om.VolumeManagerImpl.getVolumeInfo(VolumeManagerImpl.java:326)
	at org.apache.hadoop.ozone.om.OzoneManager.getVolumeInfo(OzoneManager.java:1933) 
2019-09-19 08:54:58,962 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 48fb9f8f-dbe8-4e36-9444-0eaabe9f432a, with jenkins1000 as owner.
2019-09-19 08:54:58,974 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=48fb9f8f-dbe8-4e36-9444-0eaabe9f432a, creationTime=1568883298962, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,975 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=48fb9f8f-dbe8-4e36-9444-0eaabe9f432a} | ret=SUCCESS |  
2019-09-19 08:54:58,978 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 38478fc3-ae4b-4fa4-b317-cd8749d55c8d, with jenkins1000 as owner.
2019-09-19 08:54:58,990 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, creationTime=1568883298979, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:58,991 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d} | ret=SUCCESS |  
2019-09-19 08:54:58,992 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 38478fc3-ae4b-4fa4-b317-cd8749d55c8d/026ca346-38df-4f4e-bb83-10571b4c81c9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,004 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883298992} | ret=SUCCESS |  
2019-09-19 08:54:59,004 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9} | ret=SUCCESS |  
2019-09-19 08:54:59,006 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:59,018 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9, key=078e7afe-21d3-46c0-940a-483c7b714f6f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102818335883657462
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "158606fd-7dbe-4b80-a7da-f60a55ee331f"
  }
}
]} | ret=SUCCESS |  
Sep 19, 2019 8:54:59 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=132, target=192.168.34.5:36822} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:411)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:175)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:423)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:372)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:285)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:167)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:118)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:222)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagDisable(TestOzoneRpcClientAbstract.java:905)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

2019-09-19 08:54:59,057 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,094 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102818335883657462 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,094 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,116 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 10 locID: 102818335883657462 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,119 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-DDF5F6D6EF34->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-DDF5F6D6EF34->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-F60A55EE331F, cid=40, SUCCESS, logIndex=1, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c1]
2019-09-19 08:54:59,234 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 10 locID: 102818335883657462 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:59,236 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-DDF5F6D6EF34->76962bf9-71a4-4e2f-8d90-bb34e6e32caa: receive RaftClientReply:client-DDF5F6D6EF34->76962bf9-71a4-4e2f-8d90-bb34e6e32caa@group-F60A55EE331F, cid=41, SUCCESS, logIndex=3, commits[76962bf9-71a4-4e2f-8d90-bb34e6e32caa:c4]
2019-09-19 08:54:59,257 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9, key=078e7afe-21d3-46c0-940a-483c7b714f6f, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 10
    localID: 102818335883657462
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 34844
    }
    ports {
      name: "RATIS"
      value: 33012
    }
    ports {
      name: "STANDALONE"
      value: 43599
    }
    networkName: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "158606fd-7dbe-4b80-a7da-f60a55ee331f"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,259 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-19 08:54:59,259 [IPC Server handler 17 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:59,260 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:59,260 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9, key=078e7afe-21d3-46c0-940a-483c7b714f6f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,271 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#10} | ret=SUCCESS |  
2019-09-19 08:54:59,272 [IPC Server handler 14 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:59,272 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:59,273 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=38478fc3-ae4b-4fa4-b317-cd8749d55c8d, bucket=026ca346-38df-4f4e-bb83-10571b4c81c9, key=078e7afe-21d3-46c0-940a-483c7b714f6f, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,278 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 10 locID: 102818335883657462 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:59,280 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 10 locID: 102818335883657462 bcsId: 3} | ret=SUCCESS |  
2019-09-19 08:54:59,281 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(293)) - Failed to execute command cmdType: ReadChunk
traceID: "c7774a4b5e33cc10:c7774a4b5e33cc10:0:0"
containerID: 10
datanodeUuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
readChunk {
  blockID {
    containerID: 10
    localID: 102818335883657462
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102818335883657462_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on datanode 76962bf9-71a4-4e2f-8d90-bb34e6e32caa
org.apache.hadoop.ozone.common.OzoneChecksumException: Checksum mismatch at index 0
	at org.apache.hadoop.ozone.common.ChecksumData.verifyChecksumDataMatches(ChecksumData.java:148)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:275)
	at org.apache.hadoop.ozone.common.Checksum.verifyChecksum(Checksum.java:238)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.lambda$new$0(ChunkInputStream.java:375)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:288)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:251)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:234)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.readChunk(ContainerProtocolCalls.java:245)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunk(ChunkInputStream.java:335)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.readChunkFromContainer(ChunkInputStream.java:307)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.prepareRead(ChunkInputStream.java:259)
	at org.apache.hadoop.hdds.scm.storage.ChunkInputStream.read(ChunkInputStream.java:144)
	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:239)
	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:171)
	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:47)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.readCorruptedKey(TestOzoneRpcClientAbstract.java:953)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testReadKeyWithVerifyChecksumFlagEnable(TestOzoneRpcClientAbstract.java:890)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:59,282 [main] ERROR scm.XceiverClientGrpc (XceiverClientGrpc.java:sendCommandWithRetry(314)) - Failed to execute command cmdType: ReadChunk
traceID: "c7774a4b5e33cc10:c7774a4b5e33cc10:0:0"
containerID: 10
datanodeUuid: "76962bf9-71a4-4e2f-8d90-bb34e6e32caa"
readChunk {
  blockID {
    containerID: 10
    localID: 102818335883657462
    blockCommitSequenceId: 3
  }
  chunkData {
    chunkName: "102818335883657462_chunk_1"
    offset: 0
    len: 12
    checksumData {
      type: CRC32
      bytesPerChecksum: 1048576
      checksums: "\000\000\000\000\357\322\354/"
    }
  }
}
 on the pipeline Pipeline[ Id: 158606fd-7dbe-4b80-a7da-f60a55ee331f, Nodes: 76962bf9-71a4-4e2f-8d90-bb34e6e32caa{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN].
2019-09-19 08:54:59,283 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: a3ae13ed-decb-4186-81db-5b56b30392f8, with jenkins1000 as owner.
2019-09-19 08:54:59,294 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=a3ae13ed-decb-4186-81db-5b56b30392f8, creationTime=1568883299284, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,295 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=a3ae13ed-decb-4186-81db-5b56b30392f8} | ret=SUCCESS |  
2019-09-19 08:54:59,296 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: a3ae13ed-decb-4186-81db-5b56b30392f8/0d1ef7cc-7a4c-4ead-87a8-a56bf70538a7, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,299 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=a3ae13ed-decb-4186-81db-5b56b30392f8, bucket=0d1ef7cc-7a4c-4ead-87a8-a56bf70538a7, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299296} | ret=SUCCESS |  
2019-09-19 08:54:59,300 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=a3ae13ed-decb-4186-81db-5b56b30392f8, bucket=0d1ef7cc-7a4c-4ead-87a8-a56bf70538a7} | ret=SUCCESS |  
2019-09-19 08:54:59,302 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=a3ae13ed-decb-4186-81db-5b56b30392f8, bucket=0d1ef7cc-7a4c-4ead-87a8-a56bf70538a7, key=9bfb1035-6de6-499e-a48e-efe8b66ba3f5, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,304 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=a3ae13ed-decb-4186-81db-5b56b30392f8, bucket=0d1ef7cc-7a4c-4ead-87a8-a56bf70538a7, key=9bfb1035-6de6-499e-a48e-efe8b66ba3f5, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,304 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 89a8a2b3-8850-4641-8329-0d37ed4e9fb4, with jenkins1000 as owner.
2019-09-19 08:54:59,308 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=89a8a2b3-8850-4641-8329-0d37ed4e9fb4, creationTime=1568883299305, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,308 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=89a8a2b3-8850-4641-8329-0d37ed4e9fb4} | ret=SUCCESS |  
2019-09-19 08:54:59,309 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 89a8a2b3-8850-4641-8329-0d37ed4e9fb4/6ded061e-976a-4be4-8a5c-d96755fd02a5, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,311 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=89a8a2b3-8850-4641-8329-0d37ed4e9fb4, bucket=6ded061e-976a-4be4-8a5c-d96755fd02a5, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299309} | ret=SUCCESS |  
2019-09-19 08:54:59,312 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=89a8a2b3-8850-4641-8329-0d37ed4e9fb4, bucket=6ded061e-976a-4be4-8a5c-d96755fd02a5} | ret=SUCCESS |  
2019-09-19 08:54:59,312 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: e6e50db3-6ce1-4953-b33c-25021e3b02df, with jenkins1000 as owner.
2019-09-19 08:54:59,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=e6e50db3-6ce1-4953-b33c-25021e3b02df, creationTime=1568883299312, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,314 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=e6e50db3-6ce1-4953-b33c-25021e3b02df} | ret=SUCCESS |  
2019-09-19 08:54:59,315 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: e6e50db3-6ce1-4953-b33c-25021e3b02df/6729ce91-bbd2-40d0-9ed6-97ee58e2d0af, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,316 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=e6e50db3-6ce1-4953-b33c-25021e3b02df, bucket=6729ce91-bbd2-40d0-9ed6-97ee58e2d0af, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299315} | ret=SUCCESS |  
2019-09-19 08:54:59,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e6e50db3-6ce1-4953-b33c-25021e3b02df, bucket=6729ce91-bbd2-40d0-9ed6-97ee58e2d0af} | ret=SUCCESS |  
2019-09-19 08:54:59,327 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=UPDATE_BUCKET {volume=e6e50db3-6ce1-4953-b33c-25021e3b02df, bucket=6729ce91-bbd2-40d0-9ed6-97ee58e2d0af, isVersionEnabled=true} | ret=SUCCESS |  
2019-09-19 08:54:59,328 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=e6e50db3-6ce1-4953-b33c-25021e3b02df, bucket=6729ce91-bbd2-40d0-9ed6-97ee58e2d0af} | ret=SUCCESS |  
2019-09-19 08:54:59,328 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca, with jenkins1000 as owner.
2019-09-19 08:54:59,338 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca, creationTime=1568883299329, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,339 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca} | ret=SUCCESS |  
2019-09-19 08:54:59,339 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca/41bca3c9-7e10-4c28-a6c7-f43e17d4aabf, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,349 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca, bucket=41bca3c9-7e10-4c28-a6c7-f43e17d4aabf, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299340} | ret=SUCCESS |  
2019-09-19 08:54:59,350 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca, bucket=41bca3c9-7e10-4c28-a6c7-f43e17d4aabf} | ret=SUCCESS |  
2019-09-19 08:54:59,375 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ABORT_MULTIPART_UPLOAD {volume=cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca, bucket=41bca3c9-7e10-4c28-a6c7-f43e17d4aabf, key=2535e0a9-1176-4d0f-9d5e-606edbe4111c, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: cc0d16c5-a2a4-4819-8bcb-ea06a458a1cabucket: 41bca3c9-7e10-4c28-a6c7-f43e17d4aabfkey: 2535e0a9-1176-4d0f-9d5e-606edbe4111c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:59,377 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest (S3MultipartUploadAbortRequest.java:validateAndUpdateCache(167)) - Abort Multipart request is failed for KeyName 2535e0a9-1176-4d0f-9d5e-606edbe4111c in VolumeName/Bucket cc0d16c5-a2a4-4819-8bcb-ea06a458a1ca/41bca3c9-7e10-4c28-a6c7-f43e17d4aabf
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: cc0d16c5-a2a4-4819-8bcb-ea06a458a1cabucket: 41bca3c9-7e10-4c28-a6c7-f43e17d4aabfkey: 2535e0a9-1176-4d0f-9d5e-606edbe4111c
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:115)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:59,389 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_S3_BUCKET {a02fff75-1d7c-4d2e-a7cb-5e9744b6f46d=s3Bucket, ozone=username} | ret=SUCCESS |  
2019-09-19 08:54:59,391 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=s3ozone} | ret=SUCCESS |  
2019-09-19 08:54:59,392 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=s3ozone, bucket=a02fff75-1d7c-4d2e-a7cb-5e9744b6f46d} | ret=SUCCESS |  
2019-09-19 08:54:59,394 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5a75035f-b5ea-4728-8a67-c413dc625da6, with jenkins1000 as owner.
2019-09-19 08:54:59,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5a75035f-b5ea-4728-8a67-c413dc625da6, creationTime=1568883299394, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,406 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5a75035f-b5ea-4728-8a67-c413dc625da6} | ret=SUCCESS |  
2019-09-19 08:54:59,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,407 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5a75035f-b5ea-4728-8a67-c413dc625da6/4417ed50-e41c-42b8-abc3-74c04e462e3a, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,419 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5a75035f-b5ea-4728-8a67-c413dc625da6, bucket=4417ed50-e41c-42b8-abc3-74c04e462e3a, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299407} | ret=SUCCESS |  
2019-09-19 08:54:59,420 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5a75035f-b5ea-4728-8a67-c413dc625da6, bucket=4417ed50-e41c-42b8-abc3-74c04e462e3a} | ret=SUCCESS |  
2019-09-19 08:54:59,432 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=5a75035f-b5ea-4728-8a67-c413dc625da6, bucket=4417ed50-e41c-42b8-abc3-74c04e462e3a, key=c603368d-1d4c-4dbf-b3fc-996c727f37e0, dataSize=0, replicationType=RATIS, replicationFactor=THREE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,453 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=5a75035f-b5ea-4728-8a67-c413dc625da6, bucket=4417ed50-e41c-42b8-abc3-74c04e462e3a, key=c603368d-1d4c-4dbf-b3fc-996c727f37e0, dataSize=5242880, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,455 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,455 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,456 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,456 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,456 [IPC Server handler 13 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,456 [IPC Server handler 13 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,457 [IPC Server handler 13 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,457 [IPC Server handler 13 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,457 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,458 [IPC Server handler 12 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 45830, call Call#981 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,460 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:59,461 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,462 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,462 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,462 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,462 [IPC Server handler 0 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,462 [IPC Server handler 0 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,463 [IPC Server handler 0 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,463 [IPC Server handler 0 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,463 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,463 [IPC Server handler 4 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 45830, call Call#981 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,465 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,466 [IPC Server handler 2 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,467 [IPC Server handler 2 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,467 [IPC Server handler 2 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,467 [IPC Server handler 5 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 45830, call Call#981 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,469 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,470 [IPC Server handler 19 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,471 [IPC Server handler 19 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,471 [IPC Server handler 19 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,471 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,471 [IPC Server handler 3 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 45830, call Call#981 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,473 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,474 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,474 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,474 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,475 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,475 [IPC Server handler 1 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,475 [IPC Server handler 1 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,475 [IPC Server handler 1 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,475 [IPC Server handler 1 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,475 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,476 [IPC Server handler 6 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 6 on 45830, call Call#981 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,477 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,478 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,478 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,478 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,478 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,479 [IPC Server handler 3 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,479 [IPC Server handler 3 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,479 [IPC Server handler 3 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,479 [IPC Server handler 3 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,479 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,480 [IPC Server handler 0 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 0 on 45830, call Call#981 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,485 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,486 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,486 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,486 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,486 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,487 [IPC Server handler 7 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,487 [IPC Server handler 7 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,490 [IPC Server handler 7 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,490 [IPC Server handler 7 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,490 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,491 [IPC Server handler 1 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 1 on 45830, call Call#981 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,494 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,495 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,495 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,495 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,496 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,496 [IPC Server handler 4 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,496 [IPC Server handler 4 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,496 [IPC Server handler 4 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,496 [IPC Server handler 4 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,496 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,497 [IPC Server handler 2 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 2 on 45830, call Call#981 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,497 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,498 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,498 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,499 [IPC Server handler 8 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,499 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,500 [IPC Server handler 13 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 13 on 45830, call Call#981 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,500 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,501 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,501 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,501 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,502 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,502 [IPC Server handler 9 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,502 [IPC Server handler 9 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,502 [IPC Server handler 9 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,502 [IPC Server handler 9 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,502 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,502 [IPC Server handler 19 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 19 on 45830, call Call#981 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,503 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,504 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,504 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,504 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,504 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,505 [IPC Server handler 6 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,505 [IPC Server handler 6 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,505 [IPC Server handler 6 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,505 [IPC Server handler 6 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,505 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,505 [IPC Server handler 17 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 17 on 45830, call Call#981 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,506 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:59,506 [main] ERROR io.BlockOutputStreamEntryPool (BlockOutputStreamEntryPool.java:allocateBlockIfNeeded(299)) - Try to allocate more blocks for write failed, already allocated 0 blocks for this write.
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:66)
	at com.sun.proxy.$Proxy48.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:331)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.allocateBlock(OzoneManagerProtocolClientSideTranslatorPB.java:757)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateNewBlock(BlockOutputStreamEntryPool.java:248)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntryPool.allocateBlockIfNeeded(BlockOutputStreamEntryPool.java:296)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleWrite(KeyOutputStream.java:201)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.write(KeyOutputStream.java:193)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.write(OzoneOutputStream.java:49)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.uploadPart(TestOzoneRpcClientAbstract.java:2624)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.doMultipartUpload(TestOzoneRpcClientAbstract.java:2567)
	at org.apache.hadoop.ozone.client.rpc.TestOzoneRpcClientAbstract.testMultipartUploadOverride(TestOzoneRpcClientAbstract.java:1848)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2019-09-19 08:54:59,509 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: c2499f05-7906-45a9-8b90-6ea52719ae29, with jenkins1000 as owner.
2019-09-19 08:54:59,522 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=c2499f05-7906-45a9-8b90-6ea52719ae29, creationTime=1568883299510, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,523 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=c2499f05-7906-45a9-8b90-6ea52719ae29} | ret=SUCCESS |  
2019-09-19 08:54:59,523 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: c2499f05-7906-45a9-8b90-6ea52719ae29/784c5c72-920d-47d6-8945-5b20d9a33204, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,535 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=c2499f05-7906-45a9-8b90-6ea52719ae29, bucket=784c5c72-920d-47d6-8945-5b20d9a33204, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299524} | ret=SUCCESS |  
2019-09-19 08:54:59,536 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=c2499f05-7906-45a9-8b90-6ea52719ae29, bucket=784c5c72-920d-47d6-8945-5b20d9a33204} | ret=SUCCESS |  
2019-09-19 08:54:59,537 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:59,549 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=c2499f05-7906-45a9-8b90-6ea52719ae29, bucket=784c5c72-920d-47d6-8945-5b20d9a33204, key=7b84f057-b6c3-4fde-93ff-a60311a302ce, dataSize=4194304, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335918457083
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,553 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335918457083 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,555 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335918457083 bcsId: 0,size=932]} | ret=SUCCESS |  
2019-09-19 08:54:59,567 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=c2499f05-7906-45a9-8b90-6ea52719ae29, bucket=784c5c72-920d-47d6-8945-5b20d9a33204, key=7b84f057-b6c3-4fde-93ff-a60311a302ce, dataSize=932, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335918457083
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 932
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,568 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:59,569 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=c2499f05-7906-45a9-8b90-6ea52719ae29, bucket=784c5c72-920d-47d6-8945-5b20d9a33204, key=7b84f057-b6c3-4fde-93ff-a60311a302ce, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,569 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 1f3d3541-1b54-4aac-a929-30a5a529f3d4, with jenkins1000 as owner.
2019-09-19 08:54:59,581 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4, creationTime=1568883299570, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,582 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4} | ret=SUCCESS |  
2019-09-19 08:54:59,582 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 1f3d3541-1b54-4aac-a929-30a5a529f3d4/346cc5cb-f049-4079-b109-4dd64a81d0b9, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,594 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4, bucket=346cc5cb-f049-4079-b109-4dd64a81d0b9, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299583} | ret=SUCCESS |  
2019-09-19 08:54:59,595 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4, bucket=346cc5cb-f049-4079-b109-4dd64a81d0b9} | ret=SUCCESS |  
2019-09-19 08:54:59,607 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=INITIATE_MULTIPART_UPLOAD {volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4, bucket=346cc5cb-f049-4079-b109-4dd64a81d0b9, key=c9828754-ab7b-4784-857d-2f91fea58bcc, dataSize=0, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,629 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMPLETE_MULTIPART_UPLOAD {volume=1f3d3541-1b54-4aac-a929-30a5a529f3d4, bucket=346cc5cb-f049-4079-b109-4dd64a81d0b9, key=c9828754-ab7b-4784-857d-2f91fea58bcc, dataSize=0, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[], multipartList={1=6ee709b9-ee20-4cfa-a9ae-637b40698638}} | ret=FAILURE | MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 1f3d3541-1b54-4aac-a929-30a5a529f3d4bucket: 346cc5cb-f049-4079-b109-4dd64a81d0b9key: c9828754-ab7b-4784-857d-2f91fea58bcc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89) 
2019-09-19 08:54:59,631 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest (S3MultipartUploadCompleteRequest.java:validateAndUpdateCache(300)) - MultipartUpload Complete request failed for Key: c9828754-ab7b-4784-857d-2f91fea58bcc in Volume/Bucket 1f3d3541-1b54-4aac-a929-30a5a529f3d4/346cc5cb-f049-4079-b109-4dd64a81d0b9
MISMATCH_MULTIPART_LIST org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: 1f3d3541-1b54-4aac-a929-30a5a529f3d4bucket: 346cc5cb-f049-4079-b109-4dd64a81d0b9key: c9828754-ab7b-4784-857d-2f91fea58bcc
	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:171)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:59,632 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 47e86ae7-66e4-45a8-80cc-2ca2a31dd394, with jenkins1000 as owner.
2019-09-19 08:54:59,666 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=47e86ae7-66e4-45a8-80cc-2ca2a31dd394, creationTime=1568883299633, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,667 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=47e86ae7-66e4-45a8-80cc-2ca2a31dd394} | ret=SUCCESS |  
2019-09-19 08:54:59,668 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 47e86ae7-66e4-45a8-80cc-2ca2a31dd394/758acbfd-6e4e-41c1-8578-8c9aec302396, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,676 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=c7260c3d-02cd-48af-9cc2-4a77ed8dc512, command=[]} | ret=SUCCESS |  
2019-09-19 08:54:59,680 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=47e86ae7-66e4-45a8-80cc-2ca2a31dd394, bucket=758acbfd-6e4e-41c1-8578-8c9aec302396, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299669} | ret=SUCCESS |  
2019-09-19 08:54:59,681 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=47e86ae7-66e4-45a8-80cc-2ca2a31dd394, bucket=758acbfd-6e4e-41c1-8578-8c9aec302396} | ret=SUCCESS |  
2019-09-19 08:54:59,694 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyRequest (OMKeyRequest.java:prepareCreateKeyResponse(331)) - ALLOCATE_KEY failed for Key: be5e03a0-51b4-4cb8-a196-b528d8d71890 in volume/bucket:47e86ae7-66e4-45a8-80cc-2ca2a31dd394/758acbfd-6e4e-41c1-8578-8c9aec302396
NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422)
	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:179)
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerHARequestHandlerImpl.handleApplyTransaction(OzoneManagerHARequestHandlerImpl.java:89)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:327)
	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:202)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-09-19 08:54:59,695 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=47e86ae7-66e4-45a8-80cc-2ca2a31dd394, bucket=758acbfd-6e4e-41c1-8578-8c9aec302396, key=be5e03a0-51b4-4cb8-a196-b528d8d71890, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[]} | ret=FAILURE | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:470)
	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:422) 
2019-09-19 08:54:59,695 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 5db428b9-4035-4394-9783-1a38719602b5, with jenkins1000 as owner.
2019-09-19 08:54:59,708 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=5db428b9-4035-4394-9783-1a38719602b5, creationTime=1568883299696, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,709 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=5db428b9-4035-4394-9783-1a38719602b5} | ret=SUCCESS |  
2019-09-19 08:54:59,709 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 5db428b9-4035-4394-9783-1a38719602b5/bed6e4ee-4d89-43c6-ac66-eba3c7af805d, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,722 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=5db428b9-4035-4394-9783-1a38719602b5, bucket=bed6e4ee-4d89-43c6-ac66-eba3c7af805d, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299710} | ret=SUCCESS |  
2019-09-19 08:54:59,723 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=5db428b9-4035-4394-9783-1a38719602b5, bucket=bed6e4ee-4d89-43c6-ac66-eba3c7af805d} | ret=SUCCESS |  
2019-09-19 08:54:59,724 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,725 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,725 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,725 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,725 [IPC Server handler 5 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,725 [IPC Server handler 5 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,726 [IPC Server handler 5 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,726 [IPC Server handler 5 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,726 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,727 [IPC Server handler 14 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 14 on 45830, call Call#1017 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,727 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,729 [IPC Server handler 15 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,730 [IPC Server handler 15 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,730 [IPC Server handler 15 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,730 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,730 [IPC Server handler 7 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 45830, call Call#1017 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,731 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,732 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,732 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,732 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,732 [IPC Server handler 18 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,732 [IPC Server handler 18 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,733 [IPC Server handler 18 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,733 [IPC Server handler 18 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,733 [IPC Server handler 18 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,733 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,733 [IPC Server handler 8 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 45830, call Call#1017 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,734 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,735 [IPC Server handler 16 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,736 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,736 [IPC Server handler 11 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 45830, call Call#1017 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,736 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,737 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,737 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,737 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,738 [IPC Server handler 17 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,738 [IPC Server handler 17 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,738 [IPC Server handler 17 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,738 [IPC Server handler 17 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,738 [IPC Server handler 17 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,738 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,739 [IPC Server handler 9 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 45830, call Call#1017 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,739 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,740 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,740 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,740 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,740 [IPC Server handler 14 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,741 [IPC Server handler 14 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,741 [IPC Server handler 14 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,741 [IPC Server handler 14 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,741 [IPC Server handler 14 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,741 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,741 [IPC Server handler 15 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 45830, call Call#1017 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,742 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,743 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,743 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,743 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,743 [IPC Server handler 12 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,744 [IPC Server handler 12 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,744 [IPC Server handler 12 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,744 [IPC Server handler 12 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,744 [IPC Server handler 12 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,745 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,745 [IPC Server handler 16 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 45830, call Call#1017 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,745 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,746 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,747 [IPC Server handler 11 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,748 [IPC Server handler 11 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,748 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,748 [IPC Server handler 10 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 45830, call Call#1017 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,748 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,749 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,749 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,749 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,749 [IPC Server handler 13 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,750 [IPC Server handler 13 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,750 [IPC Server handler 13 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,750 [IPC Server handler 13 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,750 [IPC Server handler 13 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,750 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,750 [IPC Server handler 12 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 45830, call Call#1017 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,751 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,752 [IPC Server handler 0 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,753 [IPC Server handler 0 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,753 [IPC Server handler 0 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,753 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,753 [IPC Server handler 4 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 45830, call Call#1017 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,753 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,754 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,754 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,754 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,754 [IPC Server handler 2 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,755 [IPC Server handler 2 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,755 [IPC Server handler 2 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,755 [IPC Server handler 2 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,755 [IPC Server handler 2 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,755 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,755 [IPC Server handler 5 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 45830, call Call#1017 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,756 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:59,757 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: vol-08168, with jenkins1000 as owner.
2019-09-19 08:54:59,769 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=vol-08168, creationTime=1568883299757, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,770 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=vol-08168} | ret=SUCCESS |  
2019-09-19 08:54:59,770 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: vol-08168/buc-72247, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=vol-08168, bucket=buc-72247, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299771} | ret=SUCCESS |  
2019-09-19 08:54:59,784 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=vol-08168, bucket=buc-72247} | ret=SUCCESS |  
2019-09-19 08:54:59,785 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-08168, bucket=buc-72247, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-19 08:54:59,786 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=LIST_KEYS {volume=vol-08168, bucket=buc-72247, startKey=, maxKeys=1000, keyPrefix=} | ret=SUCCESS |  
2019-09-19 08:54:59,786 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: cc468b82-588c-42bd-9050-cab6da22e5c0, with jenkins1000 as owner.
2019-09-19 08:54:59,799 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=cc468b82-588c-42bd-9050-cab6da22e5c0, creationTime=1568883299787, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,800 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=cc468b82-588c-42bd-9050-cab6da22e5c0} | ret=SUCCESS |  
2019-09-19 08:54:59,800 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: cc468b82-588c-42bd-9050-cab6da22e5c0/2ae777cf-1cff-4279-80fb-7254876fa478, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,811 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=cc468b82-588c-42bd-9050-cab6da22e5c0, bucket=2ae777cf-1cff-4279-80fb-7254876fa478, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299800} | ret=SUCCESS |  
2019-09-19 08:54:59,812 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=cc468b82-588c-42bd-9050-cab6da22e5c0, bucket=2ae777cf-1cff-4279-80fb-7254876fa478} | ret=SUCCESS |  
2019-09-19 08:54:59,813 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,813 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,813 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,813 [IPC Server handler 19 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,814 [IPC Server handler 19 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,814 [IPC Server handler 19 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,814 [IPC Server handler 19 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,814 [IPC Server handler 19 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,814 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,814 [IPC Server handler 7 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 7 on 45830, call Call#1039 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,815 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830. Trying to failover immediately.
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,816 [IPC Server handler 1 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,817 [IPC Server handler 1 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,817 [IPC Server handler 1 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,817 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,817 [IPC Server handler 8 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 8 on 45830, call Call#1039 Retry#1 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,818 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 1 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,818 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,819 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,819 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,819 [IPC Server handler 3 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,819 [IPC Server handler 3 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,819 [IPC Server handler 3 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,820 [IPC Server handler 3 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,820 [IPC Server handler 3 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,820 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,820 [IPC Server handler 11 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 11 on 45830, call Call#1039 Retry#2 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,821 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 2 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,822 [IPC Server handler 7 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,823 [IPC Server handler 7 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,823 [IPC Server handler 7 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,823 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,823 [IPC Server handler 9 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 9 on 45830, call Call#1039 Retry#3 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,824 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 3 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,825 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,825 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,825 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,825 [IPC Server handler 4 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,826 [IPC Server handler 4 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,826 [IPC Server handler 4 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,826 [IPC Server handler 4 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,826 [IPC Server handler 4 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,826 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,827 [IPC Server handler 15 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 15 on 45830, call Call#1039 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,827 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 4 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,828 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,828 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,828 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,829 [IPC Server handler 8 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,829 [IPC Server handler 8 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,829 [IPC Server handler 8 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,829 [IPC Server handler 8 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,829 [IPC Server handler 8 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,830 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,830 [IPC Server handler 16 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 16 on 45830, call Call#1039 Retry#5 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,830 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 5 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,831 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,831 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,831 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,831 [IPC Server handler 9 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,832 [IPC Server handler 9 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,832 [IPC Server handler 9 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,832 [IPC Server handler 9 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,832 [IPC Server handler 9 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,832 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,833 [IPC Server handler 10 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 10 on 45830, call Call#1039 Retry#6 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,833 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 6 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,834 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,835 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,835 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,835 [IPC Server handler 6 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,835 [IPC Server handler 6 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,835 [IPC Server handler 6 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,836 [IPC Server handler 6 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,836 [IPC Server handler 6 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,836 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,836 [IPC Server handler 12 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 12 on 45830, call Call#1039 Retry#7 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,837 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 7 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,838 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,838 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,838 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,838 [IPC Server handler 10 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,838 [IPC Server handler 10 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,839 [IPC Server handler 10 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,839 [IPC Server handler 10 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,839 [IPC Server handler 10 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,839 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,839 [IPC Server handler 4 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 4 on 45830, call Call#1039 Retry#8 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,840 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 8 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,840 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,841 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,841 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,841 [IPC Server handler 5 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,841 [IPC Server handler 5 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,841 [IPC Server handler 5 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,842 [IPC Server handler 5 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,842 [IPC Server handler 5 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,842 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,842 [IPC Server handler 5 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 5 on 45830, call Call#1039 Retry#9 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,842 [main] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
, while invoking $Proxy48.submitRequest over nodeId=null,nodeAddress=localhost:45830 after 9 failover attempts. Trying to failover immediately.
2019-09-19 08:54:59,843 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 7
2019-09-19 08:54:59,843 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:meetCriteria(91)) - Pipeline Placement: Doesn't meet the criteria to be viable node. Heaviness: 6
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(146)) - Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:THREE. Retrying get pipelines call once.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Unable to find enough nodes that meet the criteria that cannot engage in more than 5 pipelines. Nodes required: 3 Found: 0, healthy nodes count inNodeManager: 3.
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:147)
	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:170)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:92)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:57)
	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:149)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:190)
	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:175)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:153)
	at org.apache.hadoop.ozone.protocolPB.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:112)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:THREE even after retrying
2019-09-19 08:54:59,844 [IPC Server handler 15 on 36462] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: THREE
2019-09-19 08:54:59,844 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=THREE} | ret=SUCCESS |  
2019-09-19 08:54:59,845 [IPC Server handler 3 on 45830] WARN  ipc.Server (Server.java:logException(2724)) - IPC Server handler 3 on 45830, call Call#1039 Retry#10 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 127.0.0.1:32940
java.lang.NullPointerException
	at org.apache.hadoop.ipc.RpcWritable.wrap(RpcWritable.java:48)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:558)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2019-09-19 08:54:59,845 [main] ERROR ha.OMFailoverProxyProvider (OzoneManagerProtocolClientSideTranslatorPB.java:getRetryAction(261)) - Failed to connect to OM. Attempted 10 retries and 10 failovers
2019-09-19 08:54:59,847 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: 3086674e-8364-4510-ab98-6ec495a1a4e7, with jenkins1000 as owner.
2019-09-19 08:54:59,872 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=3086674e-8364-4510-ab98-6ec495a1a4e7, creationTime=1568883299847, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:54:59,873 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=3086674e-8364-4510-ab98-6ec495a1a4e7} | ret=SUCCESS |  
2019-09-19 08:54:59,874 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: 3086674e-8364-4510-ab98-6ec495a1a4e7/289a3f1b-f725-4e9b-9c3e-d7c00be472d4, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:54:59,904 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883299874} | ret=SUCCESS |  
2019-09-19 08:54:59,905 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4} | ret=SUCCESS |  
2019-09-19 08:54:59,906 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:59,918 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=619d0a7d-51fa-4b17-aaf1-4a7a7c5abf90, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335942639871
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,921 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335942639871 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,923 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335942639871 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:54:59,929 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=619d0a7d-51fa-4b17-aaf1-4a7a7c5abf90, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335942639871
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,930 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:59,931 [IPC Server handler 16 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:59,931 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:59,931 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=619d0a7d-51fa-4b17-aaf1-4a7a7c5abf90, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,933 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:59,933 [IPC Server handler 17 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:54:59,934 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:54:59,934 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=619d0a7d-51fa-4b17-aaf1-4a7a7c5abf90, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,936 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335942639871 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,942 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335942639871 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,943 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:54:59,943 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=619d0a7d-51fa-4b17-aaf1-4a7a7c5abf90, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:54:59,943 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:54:59,945 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:54:59,971 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e6079b3e-bf5f-46c8-ba39-9a6ab83b6db2, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335945195777
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:54:59,974 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335945195777 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:54:59,976 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335945195777 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,010 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e6079b3e-bf5f-46c8-ba39-9a6ab83b6db2, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335945195777
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,012 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,013 [IPC Server handler 12 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,014 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,014 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e6079b3e-bf5f-46c8-ba39-9a6ab83b6db2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,015 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,016 [IPC Server handler 11 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,016 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,016 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e6079b3e-bf5f-46c8-ba39-9a6ab83b6db2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,019 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335945195777 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,021 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335945195777 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,024 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,025 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e6079b3e-bf5f-46c8-ba39-9a6ab83b6db2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,025 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,027 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,027 [IPC Server handler 9 on 45830] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(385)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolling segment log-851_956 to index:956
2019-09-19 08:55:00,028 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(526)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: Rolled log segment from /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_851 to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_851-956
2019-09-19 08:55:00,033 [a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(569)) - a0feb9ca-d3c1-42ee-8099-bb90e32f92b7-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e: created new log segment /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-7f6c5782-dada-483f-8178-17c137c06507/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_957
2019-09-19 08:55:00,035 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e67752e2-5090-4f11-b5cf-62b621f74a85, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335950504195
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,038 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335950504195 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,040 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335950504195 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,045 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e67752e2-5090-4f11-b5cf-62b621f74a85, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335950504195
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,046 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,047 [IPC Server handler 0 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,047 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,047 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e67752e2-5090-4f11-b5cf-62b621f74a85, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,049 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,049 [IPC Server handler 2 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,049 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,050 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e67752e2-5090-4f11-b5cf-62b621f74a85, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,052 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335950504195 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,056 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335950504195 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,058 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,058 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=e67752e2-5090-4f11-b5cf-62b621f74a85, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,059 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,060 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,065 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=88a7de1a-190f-4636-b7e7-fa94aa6cfb52, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335952732421
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,067 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335952732421 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,069 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335952732421 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,093 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=76962bf9-71a4-4e2f-8d90-bb34e6e32caa, command=[]} | ret=SUCCESS |  
2019-09-19 08:55:00,095 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=88a7de1a-190f-4636-b7e7-fa94aa6cfb52, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335952732421
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,097 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,097 [IPC Server handler 1 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,098 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,098 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=88a7de1a-190f-4636-b7e7-fa94aa6cfb52, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,100 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,100 [IPC Server handler 3 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,100 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,101 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=88a7de1a-190f-4636-b7e7-fa94aa6cfb52, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,103 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335952732421 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,107 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335952732421 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,109 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,110 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=88a7de1a-190f-4636-b7e7-fa94aa6cfb52, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,110 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,111 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,116 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=a4d34415-98e0-4365-9658-741b870a3a6b, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335956074759
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,119 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335956074759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,121 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335956074759 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,138 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=a4d34415-98e0-4365-9658-741b870a3a6b, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335956074759
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,140 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,141 [IPC Server handler 4 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,141 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,141 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=a4d34415-98e0-4365-9658-741b870a3a6b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,143 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,144 [IPC Server handler 8 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,144 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,144 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=a4d34415-98e0-4365-9658-741b870a3a6b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,146 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335956074759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,152 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335956074759 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,153 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,154 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=a4d34415-98e0-4365-9658-741b870a3a6b, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,154 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,156 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,168 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=fa868a9d-23b5-4360-b6ef-451565700a21, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335958958345
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,171 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335958958345 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,174 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335958958345 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,188 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=fa868a9d-23b5-4360-b6ef-451565700a21, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335958958345
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,189 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,190 [IPC Server handler 6 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,190 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,191 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=fa868a9d-23b5-4360-b6ef-451565700a21, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,192 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,193 [IPC Server handler 10 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,193 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,193 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=fa868a9d-23b5-4360-b6ef-451565700a21, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,195 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335958958345 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,197 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335958958345 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,198 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,199 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=fa868a9d-23b5-4360-b6ef-451565700a21, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,199 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,200 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,212 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=af456e70-050a-4e12-bde7-bd71cd58b5e6, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335961907467
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,215 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335961907467 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,217 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335961907467 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,231 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=af456e70-050a-4e12-bde7-bd71cd58b5e6, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335961907467
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,232 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,233 [IPC Server handler 15 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,233 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,233 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=af456e70-050a-4e12-bde7-bd71cd58b5e6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,234 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,235 [IPC Server handler 18 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,235 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,236 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=af456e70-050a-4e12-bde7-bd71cd58b5e6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,238 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335961907467 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,240 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335961907467 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,241 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,241 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=af456e70-050a-4e12-bde7-bd71cd58b5e6, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,241 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,242 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,255 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=86cba510-3a35-42e2-8e6c-098e2a03a253, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335964659981
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,258 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335964659981 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,260 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335964659981 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,273 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=86cba510-3a35-42e2-8e6c-098e2a03a253, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335964659981
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,274 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,275 [IPC Server handler 17 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,275 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,276 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=86cba510-3a35-42e2-8e6c-098e2a03a253, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,277 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,278 [IPC Server handler 14 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,278 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,278 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=86cba510-3a35-42e2-8e6c-098e2a03a253, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,281 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335964659981 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,282 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335964659981 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,284 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,284 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=86cba510-3a35-42e2-8e6c-098e2a03a253, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,284 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,286 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,297 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=7dc59ece-ab03-40f0-93b8-ea067a6f894c, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335967478031
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,300 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335967478031 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,302 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335967478031 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,315 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=7dc59ece-ab03-40f0-93b8-ea067a6f894c, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335967478031
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,316 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,317 [IPC Server handler 11 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,317 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,317 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=7dc59ece-ab03-40f0-93b8-ea067a6f894c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,318 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,319 [IPC Server handler 13 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,319 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,320 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=7dc59ece-ab03-40f0-93b8-ea067a6f894c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,321 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335967478031 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,324 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335967478031 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,325 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,325 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=7dc59ece-ab03-40f0-93b8-ea067a6f894c, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,325 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,326 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=STAND_ALONE, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,330 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=8b728bcc-dec9-46a4-b067-614c27f00b17, dataSize=12, replicationType=STAND_ALONE, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335970165009
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,333 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 1 locID: 102818335970165009 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,334 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 1 locID: 102818335970165009 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,346 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=8b728bcc-dec9-46a4-b067-614c27f00b17, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 1
    localID: 102818335970165009
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 39289
    }
    ports {
      name: "RATIS"
      value: 37534
    }
    ports {
      name: "STANDALONE"
      value: 36655
    }
    networkName: "c7260c3d-02cd-48af-9cc2-4a77ed8dc512"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: STAND_ALONE
  factor: ONE
  id {
    id: "4830a652-8502-4c9a-9c1b-599b3764a064"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,347 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,348 [IPC Server handler 2 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,348 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,348 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=8b728bcc-dec9-46a4-b067-614c27f00b17, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,350 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,350 [IPC Server handler 19 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,351 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,351 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=8b728bcc-dec9-46a4-b067-614c27f00b17, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,353 | INFO  | DNAudit | user=null | ip=null | op=GET_BLOCK {blockData=conID: 1 locID: 102818335970165009 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,355 | INFO  | DNAudit | user=null | ip=null | op=READ_CHUNK {blockData=conID: 1 locID: 102818335970165009 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#1} | ret=SUCCESS |  
2019-09-19 08:55:00,356 | INFO  | OMAudit | user=null | ip=null | op=READ_KEY {volume=3086674e-8364-4510-ab98-6ec495a1a4e7, bucket=289a3f1b-f725-4e9b-9c3e-d7c00be472d4, key=8b728bcc-dec9-46a4-b067-614c27f00b17, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
2019-09-19 08:55:00,356 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER {containerID=1} | ret=SUCCESS |  
2019-09-19 08:55:00,357 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, with jenkins1000 as owner.
2019-09-19 08:55:00,368 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, creationTime=1568883300357, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:55:00,369 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf} | ret=SUCCESS |  
2019-09-19 08:55:00,369 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: ff35cff0-d1e3-49a2-a5db-6d0c2b074caf/ce0b7b08-00ba-4359-b477-32440be66a8e, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:55:00,388 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, bucket=ce0b7b08-00ba-4359-b477-32440be66a8e, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=1568883300370} | ret=SUCCESS |  
2019-09-19 08:55:00,389 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, bucket=ce0b7b08-00ba-4359-b477-32440be66a8e} | ret=SUCCESS |  
2019-09-19 08:55:00,390 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=a0feb9ca-d3c1-42ee-8099-bb90e32f92b7, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:55:00,396 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, bucket=ce0b7b08-00ba-4359-b477-32440be66a8e, key=892e3d86-121b-4f6a-a149-a863f9876a99, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 11
    localID: 102818335974359315
  }
  blockCommitSequenceId: 0
}
offset: 0
length: 4194304
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "90d9ab51-f902-4cb8-abb5-97ff21821600"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:55:00,466 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 11 locID: 102818335974359315 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,467 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=4ea6a7aa-b50c-49ea-9342-855376dcfeec, command=[]} | ret=SUCCESS |  
2019-09-19 08:55:00,479 | INFO  | DNAudit | user=null | ip=null | op=WRITE_CHUNK {blockData=conID: 11 locID: 102818335974359315 bcsId: 0} | ret=SUCCESS |  
2019-09-19 08:55:00,481 [grpc-default-executor-1] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-755DCA302F96->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-755DCA302F96->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-97FF21821600, cid=42, SUCCESS, logIndex=1, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c2]
2019-09-19 08:55:00,535 | INFO  | DNAudit | user=null | ip=null | op=PUT_BLOCK {blockData=[blockId=conID: 11 locID: 102818335974359315 bcsId: 0,size=12]} | ret=SUCCESS |  
2019-09-19 08:55:00,538 [grpc-default-executor-0] INFO  client.GrpcClientProtocolClient (GrpcClientProtocolClient.java:onNext(255)) - client-755DCA302F96->4ea6a7aa-b50c-49ea-9342-855376dcfeec: receive RaftClientReply:client-755DCA302F96->4ea6a7aa-b50c-49ea-9342-855376dcfeec@group-97FF21821600, cid=43, SUCCESS, logIndex=3, commits[4ea6a7aa-b50c-49ea-9342-855376dcfeec:c4]
2019-09-19 08:55:00,551 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=COMMIT_KEY {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, bucket=ce0b7b08-00ba-4359-b477-32440be66a8e, key=892e3d86-121b-4f6a-a149-a863f9876a99, dataSize=12, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=[blockID {
  containerBlockID {
    containerID: 11
    localID: 102818335974359315
  }
  blockCommitSequenceId: 3
}
offset: 0
length: 12
createVersion: 0
pipeline {
  leaderID: ""
  members {
    uuid: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    ipAddress: "192.168.34.5"
    hostName: "pr-hdds-1569-j4bt4-3030777008"
    ports {
      name: "REST"
      value: 46441
    }
    ports {
      name: "RATIS"
      value: 45332
    }
    ports {
      name: "STANDALONE"
      value: 36822
    }
    networkName: "4ea6a7aa-b50c-49ea-9342-855376dcfeec"
    networkLocation: "/default-rack"
  }
  state: PIPELINE_OPEN
  type: RATIS
  factor: ONE
  id {
    id: "90d9ab51-f902-4cb8-abb5-97ff21821600"
  }
}
]} | ret=SUCCESS |  
2019-09-19 08:55:00,553 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_CONTAINER_WITH_PIPELINE {containerID=#11} | ret=SUCCESS |  
2019-09-19 08:55:00,554 [IPC Server handler 3 on 36462] WARN  node.SCMNodeManager (SCMNodeManager.java:getNodeByAddress(614)) - Cannot find node for address 127.0.0.1
2019-09-19 08:55:00,554 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SORT_DATANODE null | ret=SUCCESS |  
2019-09-19 08:55:00,554 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_KEY {volume=ff35cff0-d1e3-49a2-a5db-6d0c2b074caf, bucket=ce0b7b08-00ba-4359-b477-32440be66a8e, key=892e3d86-121b-4f6a-a149-a863f9876a99, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=SUCCESS |  
